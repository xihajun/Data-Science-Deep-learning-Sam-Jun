{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function data_genelization in module myfun:\n",
      "\n",
      "data_genelization(sample_size=2, loops=1000, size=26, key=3, x_as_vector=False, y_as_vector=False)\n",
      "    data_genelization(sample_size = 2,loops = 1000, size = 26, key = 3, x_as_vector = False, y_as_vector = False):\n",
      "    return x_train, label with equual size, labels with 1 dimension\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_genelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "x_train, y_train, y_train_small = data_genelization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xihajun/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xihajun/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 0s 229us/step - loss: 0.6740 - acc: 0.6694\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.5854 - acc: 0.8948\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.3808 - acc: 0.9544\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.2030 - acc: 0.9615\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1679 - acc: 0.9615\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1643 - acc: 0.9615\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1624 - acc: 0.9615\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1610 - acc: 0.9615\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1598 - acc: 0.9615\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1586 - acc: 0.9615\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1575 - acc: 0.9615\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.9615\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1536 - acc: 0.9615\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1520 - acc: 0.9615\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1503 - acc: 0.9615\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1483 - acc: 0.9615\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1460 - acc: 0.9615\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1435 - acc: 0.9615\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1407 - acc: 0.9615\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1376 - acc: 0.9615\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1344 - acc: 0.9615\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1308 - acc: 0.9615\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1271 - acc: 0.9615\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1235 - acc: 0.9615\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1197 - acc: 0.9616\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1158 - acc: 0.9617\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1120 - acc: 0.9620\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1080 - acc: 0.9624\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1041 - acc: 0.9629\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1002 - acc: 0.9637\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0964 - acc: 0.9644\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0926 - acc: 0.9653\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0890 - acc: 0.9659\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0853 - acc: 0.9671\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0819 - acc: 0.9679\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0785 - acc: 0.9692\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0752 - acc: 0.9701\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0719 - acc: 0.9712\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0688 - acc: 0.9722\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0656 - acc: 0.9734\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0625 - acc: 0.9750\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0595 - acc: 0.9765\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0565 - acc: 0.9783\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0537 - acc: 0.9796\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0510 - acc: 0.9810\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0484 - acc: 0.9825\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0459 - acc: 0.9837\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0435 - acc: 0.9855\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0412 - acc: 0.9865\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0391 - acc: 0.9878\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0371 - acc: 0.9884\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0352 - acc: 0.9892\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0334 - acc: 0.9899\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0318 - acc: 0.9907\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0301 - acc: 0.9909\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0286 - acc: 0.9916\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0272 - acc: 0.9926\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0258 - acc: 0.9930\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0246 - acc: 0.9935\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0235 - acc: 0.9939\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0223 - acc: 0.9944\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0213 - acc: 0.9946\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0203 - acc: 0.9953\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0194 - acc: 0.9954\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0184 - acc: 0.9960\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0176 - acc: 0.9962\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0168 - acc: 0.9963\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0160 - acc: 0.9964\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0153 - acc: 0.9965\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0146 - acc: 0.9968\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0140 - acc: 0.9970\n",
      "Epoch 73/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0134 - acc: 0.9972\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0128 - acc: 0.9973\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0123 - acc: 0.9974\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0117 - acc: 0.9975\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0112 - acc: 0.9977\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0108 - acc: 0.9977\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0103 - acc: 0.9977\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0095 - acc: 0.9981\n",
      "Epoch 82/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0091 - acc: 0.9982\n",
      "Epoch 83/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0087 - acc: 0.9982\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0084 - acc: 0.9985\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0077 - acc: 0.9987\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0074 - acc: 0.9986\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0071 - acc: 0.9987\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0068 - acc: 0.9988\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0065 - acc: 0.9989\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0063 - acc: 0.9990\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0060 - acc: 0.9992\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0058 - acc: 0.9991\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0056 - acc: 0.9993\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0054 - acc: 0.9993\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0052 - acc: 0.9995\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0049 - acc: 0.9995\n",
      "Epoch 98/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0048 - acc: 0.9994\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0046 - acc: 0.9996\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0038 - acc: 0.9997\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0036 - acc: 0.9997\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0035 - acc: 0.9998\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0034 - acc: 0.9997\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 9.7200e-04 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 9.4170e-04 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 9.1232e-04 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 8.8652e-04 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 8.5919e-04 - acc: 1.0000\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 8.3426e-04 - acc: 1.0000\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 8.1071e-04 - acc: 1.0000\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 7.8487e-04 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 7.6420e-04 - acc: 1.0000\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 7.4157e-04 - acc: 1.0000\n",
      "Epoch 153/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 7.1872e-04 - acc: 1.0000\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 7.0027e-04 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 6.7900e-04 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 6.6164e-04 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 6.4100e-04 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 6.2363e-04 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 6.0661e-04 - acc: 1.0000\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 27us/step - loss: 5.8939e-04 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 5.7181e-04 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 5.5753e-04 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 5.4137e-04 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 5.2831e-04 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 5.1275e-04 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 4.9959e-04 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 4.8655e-04 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 4.7297e-04 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 4.6068e-04 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 4.5044e-04 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 4.3640e-04 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 4.2441e-04 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 4.1423e-04 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 4.0265e-04 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 3.9307e-04 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 3.8327e-04 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 3.7135e-04 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 3.6290e-04 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 3.5303e-04 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 3.4442e-04 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 3.3512e-04 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 3.2651e-04 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 3.1815e-04 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 3.1042e-04 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 3.0245e-04 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.9610e-04 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.8774e-04 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.8054e-04 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.7324e-04 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.6645e-04 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.6009e-04 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.5395e-04 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.4761e-04 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.4167e-04 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3594e-04 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3034e-04 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.2502e-04 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.1972e-04 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.1451e-04 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.0899e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2f87b6a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index1, index2, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return ([I2L[index1], I2L[index2]])\n",
    "\n",
    "\n",
    "def predict_results_only_2(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index1 = np.argmax(predictions[:, 0:26], axis=1)\n",
    "    index2 = np.argmax(predictions[:, 26:52], axis=1)\n",
    "    label1 = np.argmax(y_train[:, 0:26], axis=1)\n",
    "    label2 = np.argmax(y_train[:, 26:52], axis=1)\n",
    "\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index1, index2))\n",
    "    label_list = list(map(num2str, label1, label2))\n",
    "\n",
    "    return (prediction_list, label_list)\n",
    "\n",
    "\n",
    "# 理论上只要把矩阵转成字符就好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(list1, list2):\n",
    "    if \"\".join(list1) != \"\".join(list2):\n",
    "        print(\"\".join(list1), \"\".join(list2))\n",
    "        return(\"\".join(list1), \"\".join(list2))\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 37us/step\n",
      "\n",
      "acc: 99.70%\n",
      "QL QL\n",
      "JO JO\n",
      "GS GS\n",
      "UL UL\n",
      "OE OE\n",
      "YT YT\n",
      "WR WR\n",
      "MJ MJ\n",
      "RW RW\n",
      "FT FT\n",
      "RO RO\n",
      "IR IR\n",
      "LP LP\n",
      "QP QP\n",
      "OB OB\n",
      "JC JC\n",
      "PF PF\n",
      "CZ CZ\n",
      "YN YN\n",
      "II II\n",
      "CR CR\n",
      "JZ JZ\n",
      "TF TF\n",
      "NI NI\n",
      "JA JA\n",
      "OC OC\n",
      "BA BA\n",
      "TH TH\n",
      "MV MV\n",
      "NC NK\n",
      "CA CA\n",
      "LE LE\n",
      "KI KI\n",
      "VI VI\n",
      "VG VG\n",
      "CA CA\n",
      "ZV ZV\n",
      "OW OM\n",
      "TW TW\n",
      "BE BE\n",
      "MM MM\n",
      "IH IH\n",
      "RN RN\n",
      "SD SD\n",
      "NZ NZ\n",
      "MW MW\n",
      "RT RT\n",
      "MW MW\n",
      "DR DR\n",
      "XD XD\n",
      "WG WG\n",
      "PM PM\n",
      "YF YF\n",
      "LO LO\n",
      "KG KG\n",
      "NV NV\n",
      "AX AX\n",
      "NF NF\n",
      "SN SN\n",
      "IH IH\n",
      "YO YO\n",
      "WW WW\n",
      "QT QT\n",
      "SP SP\n",
      "EV EV\n",
      "BV BV\n",
      "TL TL\n",
      "TB ZB\n",
      "EG EG\n",
      "PG PG\n",
      "KX KX\n",
      "ON ON\n",
      "TZ TZ\n",
      "BB BB\n",
      "HR HR\n",
      "KX KX\n",
      "WZ WZ\n",
      "TW TW\n",
      "RU RU\n",
      "ZV ZV\n",
      "OZ OZ\n",
      "RN RN\n",
      "ZW ZW\n",
      "DU DU\n",
      "GA GA\n",
      "XE XE\n",
      "XD XD\n",
      "CJ CJ\n",
      "IY IY\n",
      "FF FF\n",
      "VS VS\n",
      "DX DX\n",
      "AI AI\n",
      "EM EM\n",
      "WB WB\n",
      "IG IG\n",
      "FY FY\n",
      "RO RO\n",
      "UN UN\n",
      "FK FK\n",
      "WQ WQ\n",
      "VK VK\n",
      "GD GD\n",
      "PP PP\n",
      "VT VT\n",
      "PX PX\n",
      "XJ XJ\n",
      "FW FW\n",
      "KV KV\n",
      "UI UI\n",
      "PD PD\n",
      "NB NB\n",
      "SF SF\n",
      "UX UX\n",
      "JE JE\n",
      "XL XL\n",
      "KA KA\n",
      "BH BH\n",
      "HG HG\n",
      "ST ST\n",
      "ZX ZX\n",
      "JK JK\n",
      "GL GL\n",
      "JF JF\n",
      "PI PI\n",
      "QP QP\n",
      "QU QU\n",
      "OD OD\n",
      "VC VC\n",
      "AM AM\n",
      "TU TU\n",
      "RL RL\n",
      "QI QI\n",
      "ML ML\n",
      "ST ST\n",
      "VJ VJ\n",
      "BV BV\n",
      "IO IO\n",
      "DI DI\n",
      "UQ UQ\n",
      "HK HK\n",
      "MD MD\n",
      "MT MT\n",
      "EH EH\n",
      "ZP ZP\n",
      "JV JV\n",
      "WL WL\n",
      "BB BB\n",
      "LZ LZ\n",
      "DA DA\n",
      "HM HM\n",
      "LL LL\n",
      "VN VN\n",
      "FY FY\n",
      "SB SB\n",
      "BF BF\n",
      "XD XD\n",
      "JG JG\n",
      "TP TP\n",
      "MQ MQ\n",
      "CO CO\n",
      "TV TV\n",
      "XL XL\n",
      "OA OA\n",
      "HD HD\n",
      "DV DV\n",
      "UT UT\n",
      "CP CP\n",
      "IK IK\n",
      "MG MG\n",
      "FW FW\n",
      "GU GU\n",
      "KP KP\n",
      "TM TM\n",
      "PM PM\n",
      "ET ET\n",
      "BG UF\n",
      "MF MF\n",
      "XC XC\n",
      "KU KU\n",
      "CZ CZ\n",
      "RC RC\n",
      "IZ IZ\n",
      "JZ JZ\n",
      "XS XS\n",
      "CA CA\n",
      "FL FL\n",
      "FF FF\n",
      "YK YK\n",
      "RL RL\n",
      "BP BP\n",
      "EM EM\n",
      "BW BW\n",
      "KB KB\n",
      "FE FE\n",
      "CT CT\n",
      "EL EL\n",
      "ID ID\n",
      "AQ AQ\n",
      "ZN ZN\n",
      "UD UD\n",
      "HL HL\n",
      "LF LF\n",
      "TD TD\n",
      "UC UC\n",
      "WD WD\n",
      "KH KH\n",
      "DL DL\n",
      "DL DL\n",
      "DB DB\n",
      "CN CN\n",
      "WY WY\n",
      "XH XH\n",
      "OG OG\n",
      "VR VR\n",
      "DP DP\n",
      "CC CC\n",
      "WJ WJ\n",
      "XG XG\n",
      "JK JK\n",
      "VS VS\n",
      "EX EX\n",
      "PE PK\n",
      "KJ KJ\n",
      "UB UB\n",
      "QM QM\n",
      "LA LA\n",
      "WD WD\n",
      "TJ TJ\n",
      "WX WX\n",
      "WA WA\n",
      "XG XG\n",
      "CD CD\n",
      "GV GV\n",
      "PE PE\n",
      "MZ MZ\n",
      "ZV ZV\n",
      "QE QE\n",
      "MQ MQ\n",
      "YI YI\n",
      "RG RG\n",
      "PH PH\n",
      "JC JC\n",
      "YN YN\n",
      "KW KW\n",
      "SA SA\n",
      "SI SI\n",
      "OE OE\n",
      "IH IH\n",
      "ID ID\n",
      "WA WA\n",
      "TA TA\n",
      "PE PE\n",
      "BB BB\n",
      "CU CU\n",
      "PP PP\n",
      "AH AH\n",
      "NC NK\n",
      "JE JE\n",
      "LK LK\n",
      "TP TP\n",
      "IH IH\n",
      "LV LV\n",
      "WR WR\n",
      "VK VK\n",
      "TW TW\n",
      "LG LG\n",
      "BD BD\n",
      "DY DY\n",
      "OR OR\n",
      "AH AH\n",
      "MS MS\n",
      "HE HE\n",
      "CH CH\n",
      "EB EB\n",
      "YI YI\n",
      "KN KN\n",
      "RA RA\n",
      "RJ RJ\n",
      "DZ DZ\n",
      "AL AL\n",
      "YT YT\n",
      "VP VP\n",
      "II II\n",
      "RU RU\n",
      "UA UA\n",
      "UB UB\n",
      "LW LW\n",
      "CV CV\n",
      "VW VW\n",
      "HJ HJ\n",
      "VC VC\n",
      "JB JB\n",
      "OK OK\n",
      "GN GN\n",
      "TB ZB\n",
      "RT RT\n",
      "GB GB\n",
      "CQ CQ\n",
      "DP DP\n",
      "EF EF\n",
      "FY FY\n",
      "AX AX\n",
      "AE AE\n",
      "QR QR\n",
      "BG BG\n",
      "EG EG\n",
      "YW YW\n",
      "ZZ ZZ\n",
      "GH GH\n",
      "LQ LQ\n",
      "DN DN\n",
      "AI AI\n",
      "EV EV\n",
      "AJ AJ\n",
      "XQ XQ\n",
      "RU RU\n",
      "TG TG\n",
      "FM FM\n",
      "AE AE\n",
      "BG BG\n",
      "DE DE\n",
      "RA RA\n",
      "NA NA\n",
      "TA TA\n",
      "AO AO\n",
      "OW OW\n",
      "AZ AZ\n",
      "NG NG\n",
      "OI MN\n",
      "YY YY\n",
      "TI TI\n",
      "OI MN\n",
      "OU OU\n",
      "HS HS\n",
      "NB NB\n",
      "XE XE\n",
      "GW GW\n",
      "QD QD\n",
      "UM UM\n",
      "NO NO\n",
      "GN GN\n",
      "BY BY\n",
      "TG TG\n",
      "JF JF\n",
      "VQ VQ\n",
      "EN EN\n",
      "KY KY\n",
      "RI RI\n",
      "VQ VQ\n",
      "VG VG\n",
      "KH KH\n",
      "NV NV\n",
      "BA BA\n",
      "WT WT\n",
      "FO FO\n",
      "MF MF\n",
      "UC UC\n",
      "HB HB\n",
      "QS QS\n",
      "AE AE\n",
      "VT VT\n",
      "YF YF\n",
      "DV DV\n",
      "IF IF\n",
      "TL TL\n",
      "LZ LZ\n",
      "WD WD\n",
      "PH PH\n",
      "WT WT\n",
      "OB OB\n",
      "KZ KZ\n",
      "NV NV\n",
      "NP NP\n",
      "VH VH\n",
      "IK IK\n",
      "EF EF\n",
      "BP BP\n",
      "FQ FQ\n",
      "FO FO\n",
      "NP NP\n",
      "TE TE\n",
      "VF VF\n",
      "HH HH\n",
      "VF VF\n",
      "VX VX\n",
      "RJ RJ\n",
      "UO UO\n",
      "UE UE\n",
      "NY NY\n",
      "ZK ZK\n",
      "FR FR\n",
      "WL WL\n",
      "XJ XJ\n",
      "ST ST\n",
      "QS QS\n",
      "KH KH\n",
      "OA OA\n",
      "EV EV\n",
      "BF BF\n",
      "LO LO\n",
      "UC UC\n",
      "ES ES\n",
      "BQ BQ\n",
      "IL IL\n",
      "BF BF\n",
      "UJ UJ\n",
      "WH WH\n",
      "XI XI\n",
      "QI QI\n",
      "QW QW\n",
      "YY YY\n",
      "LU LU\n",
      "RU RU\n",
      "BM BM\n",
      "BD BD\n",
      "WO WO\n",
      "XA XA\n",
      "WN WN\n",
      "XS XS\n",
      "DD DD\n",
      "XL XL\n",
      "NA NA\n",
      "IB IB\n",
      "JN JN\n",
      "ZR ZR\n",
      "ZT ZT\n",
      "DK DK\n",
      "SE SE\n",
      "SU SU\n",
      "FB FB\n",
      "FD FD\n",
      "OX OX\n",
      "GP GP\n",
      "CK CK\n",
      "HC HC\n",
      "QN QN\n",
      "OP OP\n",
      "FA FA\n",
      "XL XL\n",
      "XS XS\n",
      "ES ES\n",
      "BP BP\n",
      "QT QT\n",
      "QA QA\n",
      "WL WL\n",
      "EF EF\n",
      "ZI ZI\n",
      "IF IF\n",
      "HC HC\n",
      "WR WR\n",
      "OQ OQ\n",
      "HS HS\n",
      "AI AI\n",
      "XX XX\n",
      "JG JG\n",
      "YQ YQ\n",
      "GU GU\n",
      "SI SI\n",
      "BO BO\n",
      "JH JH\n",
      "RO RO\n",
      "NF NF\n",
      "JJ JJ\n",
      "JH JH\n",
      "AQ AQ\n",
      "QD QD\n",
      "MH MH\n",
      "RK RK\n",
      "WQ WQ\n",
      "OH OH\n",
      "AI AI\n",
      "NN NN\n",
      "NR NR\n",
      "WX WX\n",
      "QX QX\n",
      "NL NL\n",
      "PI PI\n",
      "JR JR\n",
      "WP WP\n",
      "QO QO\n",
      "WH WH\n",
      "DO DO\n",
      "DE DE\n",
      "SP SP\n",
      "GJ GJ\n",
      "FZ FZ\n",
      "QH QH\n",
      "QX QX\n",
      "FB FB\n",
      "AS AS\n",
      "JF JF\n",
      "QP QP\n",
      "JZ JZ\n",
      "TH TH\n",
      "DA DA\n",
      "PC PC\n",
      "EM EM\n",
      "YI YI\n",
      "XG XG\n",
      "GE GE\n",
      "UC UC\n",
      "FW FW\n",
      "TZ TZ\n",
      "BR BR\n",
      "JF JF\n",
      "EW EW\n",
      "PF PF\n",
      "LX LX\n",
      "VB VB\n",
      "DF DF\n",
      "OD OD\n",
      "RW RW\n",
      "TQ TQ\n",
      "LH LH\n",
      "QG QG\n",
      "QL QL\n",
      "LA LA\n",
      "WO WO\n",
      "OS OS\n",
      "UY UY\n",
      "CO CO\n",
      "JX JX\n",
      "EK EK\n",
      "KX KX\n",
      "BS BS\n",
      "FQ FQ\n",
      "HL HL\n",
      "ZY ZY\n",
      "UI UI\n",
      "SF SF\n",
      "TB ZB\n",
      "EG EE\n",
      "MG MG\n",
      "KG KG\n",
      "DL DL\n",
      "TJ TJ\n",
      "CJ CJ\n",
      "RV RV\n",
      "YJ YJ\n",
      "WX WX\n",
      "XY XY\n",
      "TA TA\n",
      "DI DI\n",
      "IV IV\n",
      "XB XB\n",
      "YC YC\n",
      "JJ JJ\n",
      "AO AO\n",
      "ZF ZF\n",
      "SW SW\n",
      "JH JH\n",
      "WX WX\n",
      "ZP ZP\n",
      "QN QN\n",
      "BO BO\n",
      "KJ KJ\n",
      "JQ JQ\n",
      "GC GC\n",
      "EG EE\n",
      "ZZ ZZ\n",
      "UD UD\n",
      "CU CU\n",
      "GR GR\n",
      "DF DF\n",
      "ZY ZY\n",
      "TW TW\n",
      "II II\n",
      "DT DT\n",
      "OK OK\n",
      "DW DW\n",
      "OA OA\n",
      "BS BS\n",
      "GI GI\n",
      "AH AH\n",
      "TL TL\n",
      "BY BY\n",
      "PJ PJ\n",
      "YQ YQ\n",
      "OV OV\n",
      "BZ BZ\n",
      "AL AL\n",
      "KJ KJ\n",
      "GQ GQ\n",
      "IM IM\n",
      "YR YR\n",
      "LQ LQ\n",
      "XB XB\n",
      "GS GS\n",
      "ZQ ZQ\n",
      "UM UM\n",
      "EC EC\n",
      "YH YH\n",
      "VR VR\n",
      "OD OD\n",
      "ZJ ZJ\n",
      "UP UP\n",
      "VT VT\n",
      "QN QN\n",
      "TF TF\n",
      "HM HM\n",
      "IA IA\n",
      "DD DD\n",
      "YA YA\n",
      "CE CE\n",
      "UM UM\n",
      "PJ PJ\n",
      "XD XD\n",
      "CH CH\n",
      "AF AF\n",
      "JT JT\n",
      "WO WO\n",
      "DY DY\n",
      "MF MF\n",
      "KX KX\n",
      "CF CF\n",
      "QR QR\n",
      "JM JM\n",
      "MU MU\n",
      "IC IC\n",
      "XY XY\n",
      "AG AG\n",
      "LO LO\n",
      "GU GU\n",
      "NW NW\n",
      "IP IP\n",
      "WE WE\n",
      "HN HN\n",
      "ZX ZX\n",
      "ZF ZF\n",
      "VV VV\n",
      "LR LR\n",
      "HB HB\n",
      "IY IY\n",
      "ZA ZA\n",
      "VK VK\n",
      "NN NN\n",
      "NT NT\n",
      "UV UV\n",
      "YS YS\n",
      "RX RX\n",
      "WW WW\n",
      "JM JM\n",
      "HQ HQ\n",
      "MX MX\n",
      "KH KH\n",
      "XK XK\n",
      "TX TX\n",
      "AW AW\n",
      "GS GS\n",
      "GO GO\n",
      "ME ME\n",
      "JI JI\n",
      "NX NX\n",
      "YR YR\n",
      "FN FN\n",
      "NE NE\n",
      "VN VN\n",
      "NH NH\n",
      "TC TC\n",
      "YY YY\n",
      "JH JH\n",
      "AJ AJ\n",
      "VW VW\n",
      "KJ KJ\n",
      "AV AV\n",
      "TT TT\n",
      "FD FD\n",
      "RN RN\n",
      "NS NS\n",
      "ZZ ZZ\n",
      "LF LF\n",
      "GF GF\n",
      "MD MD\n",
      "HN HN\n",
      "WZ WZ\n",
      "AO AO\n",
      "EM EM\n",
      "BG BG\n",
      "XG XG\n",
      "SL SL\n",
      "TK TK\n",
      "LR LR\n",
      "HM HM\n",
      "MT MT\n",
      "XO XO\n",
      "QV QV\n",
      "YR YR\n",
      "GN GN\n",
      "YV YV\n",
      "OG OG\n",
      "NC NC\n",
      "XK XK\n",
      "LO LO\n",
      "RG RG\n",
      "WN WN\n",
      "HC HC\n",
      "GY GY\n",
      "AV AV\n",
      "XP XP\n",
      "ST ST\n",
      "WC WC\n",
      "WH WH\n",
      "BV BV\n",
      "WX WX\n",
      "OB OB\n",
      "TH TH\n",
      "XR XR\n",
      "JP JP\n",
      "EF EF\n",
      "RN RN\n",
      "WQ WQ\n",
      "HL HL\n",
      "OW OM\n",
      "PT PT\n",
      "NY NY\n",
      "SI SI\n",
      "DF DF\n",
      "XO XO\n",
      "RS RS\n",
      "BG UF\n",
      "XL XL\n",
      "PH PH\n",
      "YN YN\n",
      "EH EH\n",
      "TI TI\n",
      "CE CE\n",
      "KN KN\n",
      "NX NX\n",
      "OJ OJ\n",
      "CU CU\n",
      "XP XP\n",
      "DV DV\n",
      "ZN ZN\n",
      "KQ KQ\n",
      "RA RA\n",
      "NY NY\n",
      "HD HD\n",
      "VC VC\n",
      "JO JO\n",
      "QB QB\n",
      "JN PN\n",
      "ZG ZG\n",
      "DL DL\n",
      "EY EY\n",
      "RP RP\n",
      "RH RH\n",
      "JP JP\n",
      "ER ER\n",
      "LP LP\n",
      "ZR ZR\n",
      "TP TP\n",
      "VI VI\n",
      "UZ UZ\n",
      "RB RB\n",
      "OJ OJ\n",
      "WN WN\n",
      "JX JX\n",
      "XP XP\n",
      "WV WV\n",
      "ND ND\n",
      "PE PE\n",
      "FZ FZ\n",
      "RC RC\n",
      "UL UL\n",
      "VY VY\n",
      "VS VS\n",
      "KM KM\n",
      "JI JI\n",
      "RL RL\n",
      "WC WC\n",
      "PG PG\n",
      "UR UR\n",
      "JZ JZ\n",
      "LA LA\n",
      "EP EP\n",
      "CR CR\n",
      "EI EI\n",
      "HA HA\n",
      "FB FB\n",
      "FR FR\n",
      "ZO ZO\n",
      "NN NN\n",
      "JG JG\n",
      "WX WX\n",
      "TI TI\n",
      "AP AP\n",
      "YL YL\n",
      "VN VN\n",
      "YC YC\n",
      "TW TW\n",
      "QL QL\n",
      "RI RI\n",
      "YC YC\n",
      "MP MP\n",
      "AM AM\n",
      "JQ JQ\n",
      "QJ QJ\n",
      "IM IM\n",
      "UW LM\n",
      "VR VR\n",
      "KM KM\n",
      "MO MO\n",
      "AN AN\n",
      "AG AG\n",
      "OW OW\n",
      "ES ES\n",
      "HV HV\n",
      "DD DD\n",
      "RA RA\n",
      "QU QU\n",
      "YT YT\n",
      "YH YH\n",
      "CG CG\n",
      "TY TY\n",
      "AN AN\n",
      "XH XH\n",
      "ZN ZN\n",
      "SM SM\n",
      "IG IG\n",
      "MI MI\n",
      "UK UK\n",
      "AD AD\n",
      "OU OU\n",
      "EW EW\n",
      "HG HG\n",
      "SZ SZ\n",
      "KC KC\n",
      "JE JE\n",
      "ZJ ZJ\n",
      "HM HM\n",
      "QR QR\n",
      "DG DG\n",
      "MK MK\n",
      "XM XM\n",
      "VU VU\n",
      "CM CM\n",
      "YB YB\n",
      "HV HV\n",
      "YO YO\n",
      "ZO ZO\n",
      "FZ FZ\n",
      "EU EU\n",
      "UR UR\n",
      "UK UK\n",
      "UB UB\n",
      "SK SK\n",
      "FP FP\n",
      "IF IF\n",
      "PE PK\n",
      "TT TT\n",
      "AZ AZ\n",
      "IS IS\n",
      "EC EC\n",
      "US US\n",
      "RK GK\n",
      "SA SA\n",
      "QO QO\n",
      "ZQ ZQ\n",
      "PP PP\n",
      "PQ PQ\n",
      "HM HM\n",
      "YT YT\n",
      "UP UP\n",
      "RD RD\n",
      "FK FK\n",
      "VE VE\n",
      "YP YP\n",
      "KR KR\n",
      "HG HG\n",
      "KU KU\n",
      "CZ CZ\n",
      "WH WH\n",
      "DM DM\n",
      "DL DL\n",
      "WC WC\n",
      "FN FN\n",
      "TZ TZ\n",
      "SW SW\n",
      "OU OU\n",
      "ZK ZK\n",
      "CG CG\n",
      "KC KC\n",
      "EH EH\n",
      "KR KR\n",
      "MM MM\n",
      "VN VN\n",
      "AB AB\n",
      "DQ DQ\n",
      "LK LK\n",
      "ST ST\n",
      "CR CR\n",
      "KZ KZ\n",
      "QM QM\n",
      "AR AR\n",
      "WE WE\n",
      "NP NP\n",
      "QS QS\n",
      "CT CT\n",
      "IO IO\n",
      "QZ QZ\n",
      "ZV ZV\n",
      "DM DM\n",
      "AO AO\n",
      "DQ DQ\n",
      "OF OF\n",
      "NR NR\n",
      "FP FP\n",
      "TD TD\n",
      "DH DH\n",
      "TO TO\n",
      "JI JI\n",
      "RK GK\n",
      "EV EV\n",
      "RV RV\n",
      "GS GS\n",
      "LW LW\n",
      "MX MX\n",
      "RK GK\n",
      "JS JS\n",
      "WO WO\n",
      "CZ CZ\n",
      "FO FO\n",
      "GW GW\n",
      "SC SC\n",
      "WH WH\n",
      "IG IG\n",
      "HX HX\n",
      "HQ HQ\n",
      "VI VI\n",
      "RI RI\n",
      "WA WA\n",
      "SB SB\n",
      "GR GR\n",
      "VI VI\n",
      "OI OI\n",
      "TK TK\n",
      "ZA ZA\n",
      "RS RS\n",
      "IV IV\n",
      "IO IO\n",
      "DM DM\n",
      "TI TI\n",
      "OI OI\n",
      "QC QC\n",
      "RS RS\n",
      "NV NV\n",
      "HG HG\n",
      "GI GI\n",
      "TQ TQ\n",
      "LL LL\n",
      "VR VR\n",
      "UC UC\n",
      "FV FV\n",
      "PA PA\n",
      "EO EO\n",
      "DE DE\n",
      "ME ME\n",
      "WA WA\n",
      "JQ JQ\n",
      "BS BS\n",
      "CF CF\n",
      "KV KV\n",
      "CU CU\n",
      "HZ HZ\n",
      "FX FX\n",
      "UY UY\n",
      "ED ED\n",
      "YI YI\n",
      "YH YH\n",
      "PD PD\n",
      "IO IO\n",
      "HD HD\n",
      "VS VS\n",
      "GV GV\n",
      "TB ZB\n",
      "KP KP\n",
      "BM BM\n",
      "MT MT\n",
      "QS QS\n",
      "NP NP\n",
      "MF MF\n",
      "PC PC\n",
      "VT VT\n",
      "UM UM\n",
      "EC EC\n",
      "TU TU\n",
      "WT WT\n",
      "DT DT\n",
      "JX JX\n",
      "HE HE\n",
      "HS HS\n",
      "TM TM\n",
      "QM QM\n",
      "UQ UQ\n",
      "SJ SJ\n",
      "FC FC\n",
      "VU VU\n",
      "ZZ ZZ\n",
      "ZJ ZJ\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test, y_test_small = data_genelization()\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "prediction_list, label_list = predict_results_only_2(model, x_test, y_test)\n",
    "\n",
    "for i in range(len(prediction_list)):\n",
    "    print(\"\".join(prediction_list[i]), \"\".join(label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC NK\n",
      "OW OM\n",
      "TB ZB\n",
      "BG UF\n",
      "PE PK\n",
      "NC NK\n",
      "TB ZB\n",
      "OI MN\n",
      "OI MN\n",
      "TB ZB\n",
      "EG EE\n",
      "EG EE\n",
      "OW OM\n",
      "BG UF\n",
      "JN PN\n",
      "UW LM\n",
      "PE PK\n",
      "RK GK\n",
      "RK GK\n",
      "RK GK\n",
      "TB ZB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))\n",
    "diff[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [\"NC\"]\n",
    "for i in range(1000):\n",
    "    temp.append(\"NC\")\n",
    "x_test, y_test, y_test_small = data_test(temp)\n",
    "prediction_list, label_list = predict_results_only_2(model, x_test, y_test)\n",
    "diff = list(map(find_diff, prediction_list, label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy didn't go to 1 but remained at 50% level.(when 26)\n",
    "Try more training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 0s 274us/step - loss: 0.6673 - acc: 0.6910\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.5505 - acc: 0.9302\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.3214 - acc: 0.9615\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1850 - acc: 0.9615\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1678 - acc: 0.9615\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.1648 - acc: 0.9615\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1632 - acc: 0.9615\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1619 - acc: 0.9615\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1608 - acc: 0.9615\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1598 - acc: 0.9615\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1588 - acc: 0.9615\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1576 - acc: 0.9615\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1565 - acc: 0.9615\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1551 - acc: 0.9615\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1537 - acc: 0.9615\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1521 - acc: 0.9615\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1503 - acc: 0.9615\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1484 - acc: 0.9615\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1464 - acc: 0.9615\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1442 - acc: 0.9615\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1419 - acc: 0.9615\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1395 - acc: 0.9615\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1370 - acc: 0.9615\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1343 - acc: 0.9615\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1316 - acc: 0.9615\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1288 - acc: 0.9616\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1260 - acc: 0.9616\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1232 - acc: 0.9617\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1204 - acc: 0.9618\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1177 - acc: 0.9620\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1150 - acc: 0.9622\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1124 - acc: 0.9626\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1099 - acc: 0.9629\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.1073 - acc: 0.9633\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1049 - acc: 0.9637\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1026 - acc: 0.9642\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1003 - acc: 0.9647\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0981 - acc: 0.9651\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0960 - acc: 0.9657\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0939 - acc: 0.9662\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0919 - acc: 0.9667\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0897 - acc: 0.9674\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0879 - acc: 0.9681\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0858 - acc: 0.9687\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0839 - acc: 0.9694\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0820 - acc: 0.9703\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0802 - acc: 0.9712\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0784 - acc: 0.9716\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0766 - acc: 0.9723\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0748 - acc: 0.9729\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0731 - acc: 0.9735\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0714 - acc: 0.9744\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0698 - acc: 0.9752\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0681 - acc: 0.9754\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0665 - acc: 0.9763\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0650 - acc: 0.9767\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0635 - acc: 0.9774\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0620 - acc: 0.9782\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0606 - acc: 0.9785\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0591 - acc: 0.9791\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0578 - acc: 0.9796\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0566 - acc: 0.9804\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0552 - acc: 0.9805\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0539 - acc: 0.9816\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0527 - acc: 0.9815\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0515 - acc: 0.9826\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0503 - acc: 0.9827\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0493 - acc: 0.9835\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0481 - acc: 0.9839\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0470 - acc: 0.9843\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0460 - acc: 0.9847\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0450 - acc: 0.9852\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0440 - acc: 0.9857\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0430 - acc: 0.9861\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0421 - acc: 0.9864\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0412 - acc: 0.9867\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0403 - acc: 0.9870\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0395 - acc: 0.9876\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0385 - acc: 0.9880\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0377 - acc: 0.9884\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0370 - acc: 0.9885\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0362 - acc: 0.9889\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0354 - acc: 0.9890\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0346 - acc: 0.9893\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0338 - acc: 0.9896\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0332 - acc: 0.9899\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0325 - acc: 0.9904\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0318 - acc: 0.9903\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0312 - acc: 0.9908\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0305 - acc: 0.9908\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0300 - acc: 0.9912\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0293 - acc: 0.9914\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0288 - acc: 0.9916\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0281 - acc: 0.9918\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0277 - acc: 0.9919\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0271 - acc: 0.9921\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0266 - acc: 0.9923\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0261 - acc: 0.9926\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0256 - acc: 0.9927\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0251 - acc: 0.9929\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0246 - acc: 0.9930\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0242 - acc: 0.9932\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0238 - acc: 0.9933\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0233 - acc: 0.9934\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0229 - acc: 0.9936\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0225 - acc: 0.9938\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0220 - acc: 0.9940\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0216 - acc: 0.9940\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0213 - acc: 0.9941\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0209 - acc: 0.9942\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0205 - acc: 0.9944\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0202 - acc: 0.9945\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0198 - acc: 0.9948\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0195 - acc: 0.9947\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0191 - acc: 0.9951\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0188 - acc: 0.9950\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0185 - acc: 0.9953\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0182 - acc: 0.9954\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0179 - acc: 0.9954\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0176 - acc: 0.9955\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0173 - acc: 0.9956\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0171 - acc: 0.9957\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0166 - acc: 0.9957\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0164 - acc: 0.9959\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0161 - acc: 0.9959\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0159 - acc: 0.9960\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0155 - acc: 0.9961\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0154 - acc: 0.9961\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0152 - acc: 0.9962\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0149 - acc: 0.9962\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0146 - acc: 0.9964\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0144 - acc: 0.9963\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0141 - acc: 0.9966\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0139 - acc: 0.9965\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0137 - acc: 0.9967\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0135 - acc: 0.9968\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0132 - acc: 0.9967\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0129 - acc: 0.9968\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0128 - acc: 0.9968\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0126 - acc: 0.9969\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0123 - acc: 0.9971\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0121 - acc: 0.9969\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0120 - acc: 0.9973\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0118 - acc: 0.9972\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0116 - acc: 0.9974\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0114 - acc: 0.9973\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0112 - acc: 0.9975\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0110 - acc: 0.9975\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0108 - acc: 0.9976\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0106 - acc: 0.9974\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0104 - acc: 0.9978\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0102 - acc: 0.9977\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0101 - acc: 0.9978\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0099 - acc: 0.9978\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0097 - acc: 0.9979\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0095 - acc: 0.9980\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0094 - acc: 0.9980\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0092 - acc: 0.9980\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0091 - acc: 0.9981\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0089 - acc: 0.9983\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0087 - acc: 0.9982\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0086 - acc: 0.9982\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0085 - acc: 0.9983\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0083 - acc: 0.9984\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0082 - acc: 0.9984\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0079 - acc: 0.9984\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0077 - acc: 0.9986\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0076 - acc: 0.9986\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0075 - acc: 0.9986\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0073 - acc: 0.9987\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0072 - acc: 0.9987\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0071 - acc: 0.9988\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0070 - acc: 0.9988\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0069 - acc: 0.9989\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0068 - acc: 0.9990\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0065 - acc: 0.9990\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0062 - acc: 0.9991\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0061 - acc: 0.9991\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0060 - acc: 0.9992\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0059 - acc: 0.9992\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0058 - acc: 0.9992\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0057 - acc: 0.9992\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0056 - acc: 0.9993\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0055 - acc: 0.9993\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0054 - acc: 0.9993\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0053 - acc: 0.9993\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0052 - acc: 0.9994\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0051 - acc: 0.9994\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0050 - acc: 0.9995\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0049 - acc: 0.9995\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0049 - acc: 0.9996\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0046 - acc: 0.9996\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0046 - acc: 0.9996\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0043 - acc: 0.9996\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0040 - acc: 0.9997\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0038 - acc: 0.9998\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0037 - acc: 0.9998\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0036 - acc: 0.9998\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0036 - acc: 0.9998\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0035 - acc: 0.9998\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0034 - acc: 0.9998\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0034 - acc: 0.9998\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0032 - acc: 0.9999\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0031 - acc: 0.9999\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0030 - acc: 0.9999\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0029 - acc: 0.9999\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0029 - acc: 0.9999\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0028 - acc: 0.9999\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0028 - acc: 0.9999\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0027 - acc: 0.9999\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0027 - acc: 0.9999\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0026 - acc: 0.9999\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0026 - acc: 0.9999\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0025 - acc: 0.9999\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 9.9544e-04 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 9.7988e-04 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 9.6467e-04 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 9.4902e-04 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 9.2953e-04 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 9.1729e-04 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 9.0176e-04 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 8.8797e-04 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 8.7284e-04 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 8.5039e-04 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 8.3824e-04 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 8.2358e-04 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 8.1386e-04 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 7.9105e-04 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 7.8131e-04 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 7.6181e-04 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 7.4799e-04 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 7.3787e-04 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 7.3719e-04 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 7.1321e-04 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 7.0040e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb305bb668>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size = 2,loops = 1000, size = 3, key = 1, x_as_vector = False, y_as_vector = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    " # assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1000/1000 [==============================] - 0s 496us/step - loss: 0.7594 - acc: 0.4820\n",
      "Epoch 2/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.7296 - acc: 0.5332\n",
      "Epoch 3/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.7035 - acc: 0.5535\n",
      "Epoch 4/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6809 - acc: 0.5798\n",
      "Epoch 5/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6600 - acc: 0.6430\n",
      "Epoch 6/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6408 - acc: 0.6497\n",
      "Epoch 7/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.6226 - acc: 0.6707\n",
      "Epoch 8/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6050 - acc: 0.6878\n",
      "Epoch 9/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.5878 - acc: 0.7015\n",
      "Epoch 10/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.5706 - acc: 0.7185\n",
      "Epoch 11/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.5529 - acc: 0.7440\n",
      "Epoch 12/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.5360 - acc: 0.7388\n",
      "Epoch 13/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.5197 - acc: 0.7600\n",
      "Epoch 14/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.5040 - acc: 0.7768\n",
      "Epoch 15/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.4890 - acc: 0.7752\n",
      "Epoch 16/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.4744 - acc: 0.7845\n",
      "Epoch 17/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.4604 - acc: 0.7993\n",
      "Epoch 18/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.4471 - acc: 0.7947\n",
      "Epoch 19/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.4345 - acc: 0.8117\n",
      "Epoch 20/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.4225 - acc: 0.8148\n",
      "Epoch 21/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.4113 - acc: 0.8148\n",
      "Epoch 22/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.4006 - acc: 0.8148\n",
      "Epoch 23/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.3907 - acc: 0.8148\n",
      "Epoch 24/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.3813 - acc: 0.8148\n",
      "Epoch 25/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.3726 - acc: 0.8148\n",
      "Epoch 26/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.3644 - acc: 0.8148\n",
      "Epoch 27/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.3569 - acc: 0.8148\n",
      "Epoch 28/150\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.3499 - acc: 0.8295\n",
      "Epoch 29/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.3431 - acc: 0.8378\n",
      "Epoch 30/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.3369 - acc: 0.8510\n",
      "Epoch 31/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.3310 - acc: 0.8510\n",
      "Epoch 32/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.3254 - acc: 0.8510\n",
      "Epoch 33/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.3201 - acc: 0.8510\n",
      "Epoch 34/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.3150 - acc: 0.8510\n",
      "Epoch 35/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.3094 - acc: 0.8510\n",
      "Epoch 36/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.3021 - acc: 0.8510\n",
      "Epoch 37/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.2954 - acc: 0.8510\n",
      "Epoch 38/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.2889 - acc: 0.8653\n",
      "Epoch 39/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.2827 - acc: 0.8707\n",
      "Epoch 40/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.2765 - acc: 0.8890\n",
      "Epoch 41/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.2700 - acc: 0.8918\n",
      "Epoch 42/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.2634 - acc: 0.9105\n",
      "Epoch 43/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.2567 - acc: 0.9105\n",
      "Epoch 44/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.2501 - acc: 0.9152\n",
      "Epoch 45/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.2433 - acc: 0.9272\n",
      "Epoch 46/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.2366 - acc: 0.9272\n",
      "Epoch 47/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.2299 - acc: 0.9272\n",
      "Epoch 48/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.2234 - acc: 0.9272\n",
      "Epoch 49/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.2169 - acc: 0.9272\n",
      "Epoch 50/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.2106 - acc: 0.9272\n",
      "Epoch 51/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.2044 - acc: 0.9272\n",
      "Epoch 52/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1983 - acc: 0.9272\n",
      "Epoch 53/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1924 - acc: 0.9272\n",
      "Epoch 54/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1867 - acc: 0.9272\n",
      "Epoch 55/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1813 - acc: 0.9272\n",
      "Epoch 56/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1755 - acc: 0.9410\n",
      "Epoch 57/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1695 - acc: 0.9462\n",
      "Epoch 58/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1638 - acc: 0.9610\n",
      "Epoch 59/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1585 - acc: 0.9610\n",
      "Epoch 60/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1533 - acc: 0.9610\n",
      "Epoch 61/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1483 - acc: 0.9610\n",
      "Epoch 62/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1436 - acc: 0.9610\n",
      "Epoch 63/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1391 - acc: 0.9610\n",
      "Epoch 64/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1349 - acc: 0.9610\n",
      "Epoch 65/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1309 - acc: 0.9610\n",
      "Epoch 66/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1271 - acc: 0.9610\n",
      "Epoch 67/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1234 - acc: 0.9610\n",
      "Epoch 68/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1199 - acc: 0.9610\n",
      "Epoch 69/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1165 - acc: 0.9610\n",
      "Epoch 70/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1133 - acc: 0.9610\n",
      "Epoch 71/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.1102 - acc: 0.9722\n",
      "Epoch 72/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1073 - acc: 0.9805\n",
      "Epoch 73/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1045 - acc: 0.9805\n",
      "Epoch 74/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.1018 - acc: 0.9805\n",
      "Epoch 75/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0992 - acc: 0.9805\n",
      "Epoch 76/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0967 - acc: 0.9805\n",
      "Epoch 77/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0943 - acc: 0.9805\n",
      "Epoch 78/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0920 - acc: 0.9805\n",
      "Epoch 79/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0898 - acc: 0.9805\n",
      "Epoch 80/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0877 - acc: 0.9805\n",
      "Epoch 81/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0856 - acc: 0.9805\n",
      "Epoch 82/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0836 - acc: 0.9805\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0817 - acc: 0.9805\n",
      "Epoch 84/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0798 - acc: 0.9805\n",
      "Epoch 85/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0780 - acc: 0.9805\n",
      "Epoch 86/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0763 - acc: 0.9805\n",
      "Epoch 87/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0746 - acc: 0.9972\n",
      "Epoch 88/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0730 - acc: 1.0000\n",
      "Epoch 89/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 90/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0698 - acc: 1.0000\n",
      "Epoch 91/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 92/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0669 - acc: 1.0000\n",
      "Epoch 93/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0654 - acc: 1.0000\n",
      "Epoch 94/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0641 - acc: 1.0000\n",
      "Epoch 95/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0627 - acc: 1.0000\n",
      "Epoch 96/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0614 - acc: 1.0000\n",
      "Epoch 97/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 98/150\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0589 - acc: 1.0000\n",
      "Epoch 99/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0577 - acc: 1.0000\n",
      "Epoch 100/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0565 - acc: 1.0000\n",
      "Epoch 101/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 102/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 103/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0532 - acc: 1.0000\n",
      "Epoch 104/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 105/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 106/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0501 - acc: 1.0000\n",
      "Epoch 107/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 108/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 109/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0472 - acc: 1.0000\n",
      "Epoch 110/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0463 - acc: 1.0000\n",
      "Epoch 111/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 112/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0446 - acc: 1.0000\n",
      "Epoch 113/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0438 - acc: 1.0000\n",
      "Epoch 114/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 115/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 116/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 117/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0406 - acc: 1.0000\n",
      "Epoch 118/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0398 - acc: 1.0000\n",
      "Epoch 119/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 120/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 121/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 122/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 123/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0363 - acc: 1.0000\n",
      "Epoch 124/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 125/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 126/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 127/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 128/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 129/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 130/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0319 - acc: 1.0000\n",
      "Epoch 131/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 132/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 133/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 134/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 135/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 136/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 137/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 138/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 139/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 140/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 141/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 142/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 143/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 144/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 145/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 146/150\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 147/150\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 148/150\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 149/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 150/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0225 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb3659fc88>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.2614266 , -2.1946294 , -1.5446807 ,  1.8021632 ],\n",
       "        [ 2.7304986 , -0.02158582,  2.2005985 , -0.5643796 ],\n",
       "        [-0.7911367 ,  0.73573613, -1.8034464 ,  0.28286067],\n",
       "        [-0.45223793, -1.4599098 ,  0.35353324, -1.505448  ],\n",
       "        [-2.4287415 ,  1.326423  ,  2.4855835 ,  2.368571  ],\n",
       "        [ 3.1350098 ,  3.3867607 ,  0.09662584,  1.5484724 ]],\n",
       "       dtype=float32),\n",
       " array([1.674261 , 1.6234328, 1.4496356, 1.221209 ], dtype=float32),\n",
       " array([[ 0.52297187, -1.7569    ,  0.43578267, -2.4818363 ,  1.0081764 ,\n",
       "          0.9765191 ],\n",
       "        [-0.50075877,  3.203936  , -3.1619108 , -0.61574787,  1.1032968 ,\n",
       "         -1.5845432 ],\n",
       "        [ 2.610292  , -1.8877181 , -1.6999984 ,  1.4167665 , -1.3344872 ,\n",
       "         -0.4839891 ],\n",
       "        [-2.1381495 , -0.88884467,  2.319683  ,  1.6311033 , -0.59197724,\n",
       "         -1.642379  ]], dtype=float32),\n",
       " array([-2.2643292 ,  0.6654069 ,  0.14345963, -1.4512864 , -3.1625571 ,\n",
       "         2.3429961 ], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3233396, 1.1500345, 1.5411345, 1.7671634], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.17041157, -1.3415438 ,  1.0048312 , -2.638664  ,  1.8457879 ,\n",
       "         -0.17494833],\n",
       "        [ 2.8886733 , -0.94209313, -2.50845   ,  1.0273534 , -0.8961908 ,\n",
       "         -0.38473397],\n",
       "        [-1.0961235 ,  0.7975405 , -0.17514314, -0.7438471 , -2.6763222 ,\n",
       "          2.6789653 ],\n",
       "        [-1.288574  ,  2.1119742 , -1.8288964 ,  0.51536745,  0.46846798,\n",
       "         -1.3760177 ]], dtype=float32),\n",
       " array([-2.454229 , -2.5342765,  2.410905 ,  2.4123719, -2.3931627,\n",
       "        -2.2903526], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "biases = model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3632884 , -1.9473228 ,  0.1725147 , -2.4370604 ],\n",
       "       [ 1.7898074 ,  2.9379802 ,  0.23854892, -1.5549669 ],\n",
       "       [ 0.50898445, -0.6219571 ,  1.7738153 ,  2.7723904 ],\n",
       "       [ 1.358545  ,  0.8627558 ,  2.2476776 , -0.2006217 ],\n",
       "       [-2.6864974 ,  0.7966448 , -1.7154862 ,  0.6694634 ],\n",
       "       [ 2.6620388 ,  0.12720749, -2.3726258 ,  2.131371  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3233396, 1.1500345, 1.5411345, 1.7671634], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.52297187, -1.7569    ,  0.43578267, -2.4818363 ,  1.0081764 ,\n",
       "          0.9765191 ],\n",
       "        [-0.50075877,  3.203936  , -3.1619108 , -0.61574787,  1.1032968 ,\n",
       "         -1.5845432 ],\n",
       "        [ 2.610292  , -1.8877181 , -1.6999984 ,  1.4167665 , -1.3344872 ,\n",
       "         -0.4839891 ],\n",
       "        [-2.1381495 , -0.88884467,  2.319683  ,  1.6311033 , -0.59197724,\n",
       "         -1.642379  ]], dtype=float32),\n",
       " array([-2.2643292 ,  0.6654069 ,  0.14345963, -1.4512864 , -3.1625571 ,\n",
       "         2.3429961 ], dtype=float32)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                1060      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 52)                1092      \n",
      "=================================================================\n",
      "Total params: 2,572\n",
      "Trainable params: 2,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "#取某一层的输出为输出新建为model，采用函数模型\n",
    "dense1_layer_model = Model(inputs=model.input,\n",
    "                                     outputs=model.get_layer('dense_1').output)\n",
    "#以这个model的预测值作为输出\n",
    "dense1_output = dense1_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4919815 , 2.8937807 , 1.5359185 , 1.8236827 , 0.        ,\n",
       "       3.5997005 , 0.9909794 , 2.7657804 , 0.24929929, 1.1591802 ,\n",
       "       2.1862164 , 0.6918705 , 0.53684145, 1.0207528 , 0.19604462,\n",
       "       1.7340786 , 0.81079715, 0.87367827, 0.9587232 , 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
