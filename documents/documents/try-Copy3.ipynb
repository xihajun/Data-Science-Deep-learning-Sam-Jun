{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function data_genelization in module myfun:\n",
      "\n",
      "data_genelization(sample_size=2, loops=1000, size=26, key=3, x_as_vector=False, y_as_vector=False)\n",
      "    data_genelization(sample_size = 2,loops = 1000, size = 26, key = 3, x_as_vector = False, y_as_vector = False):\n",
      "    return x_train, label with equual size, labels with 1 dimension\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_genelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "x_train, y_train, y_train_small = data_genelization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 0s 377us/step - loss: 0.6840 - acc: 0.6072\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6277 - acc: 0.8388\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.4774 - acc: 0.9401\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.2658 - acc: 0.9615\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1772 - acc: 0.9615\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1665 - acc: 0.9615\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1635 - acc: 0.9615\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1614 - acc: 0.9615\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1595 - acc: 0.9615\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1576 - acc: 0.9615\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1556 - acc: 0.9615\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1534 - acc: 0.9615\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1510 - acc: 0.9615\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1483 - acc: 0.9615\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1454 - acc: 0.9615\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1423 - acc: 0.9615\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1389 - acc: 0.9615\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1355 - acc: 0.9615\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1318 - acc: 0.9615\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1280 - acc: 0.9616\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1241 - acc: 0.9616\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1201 - acc: 0.9619\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1161 - acc: 0.9622\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1120 - acc: 0.9625\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1078 - acc: 0.9634\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1036 - acc: 0.9639\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0995 - acc: 0.9642\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0954 - acc: 0.9649\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0915 - acc: 0.9659\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0877 - acc: 0.9673\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0839 - acc: 0.9684\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0803 - acc: 0.9698\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0769 - acc: 0.9716\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0735 - acc: 0.9725\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0703 - acc: 0.9736\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0674 - acc: 0.9750\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0644 - acc: 0.9765\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0617 - acc: 0.9773\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0591 - acc: 0.9786\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0566 - acc: 0.9796\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0542 - acc: 0.9809\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0519 - acc: 0.9822\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0497 - acc: 0.9837\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0476 - acc: 0.9844\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0456 - acc: 0.9853\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0437 - acc: 0.9862\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0419 - acc: 0.9868\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0401 - acc: 0.9874\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0384 - acc: 0.9880\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0368 - acc: 0.9888\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0352 - acc: 0.9892\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0338 - acc: 0.9900\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0324 - acc: 0.9903\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0310 - acc: 0.9909\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0298 - acc: 0.9912\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0274 - acc: 0.9921\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0263 - acc: 0.9924\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0253 - acc: 0.9933\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0243 - acc: 0.9935\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0234 - acc: 0.9937\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0224 - acc: 0.9941\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0215 - acc: 0.9943\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0207 - acc: 0.9946\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0200 - acc: 0.9948\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0192 - acc: 0.9950\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0185 - acc: 0.9954\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0178 - acc: 0.9957\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0172 - acc: 0.9957\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0165 - acc: 0.9962\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0159 - acc: 0.9964\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0154 - acc: 0.9964\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0148 - acc: 0.9969\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0143 - acc: 0.9969\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0137 - acc: 0.9972\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0132 - acc: 0.9972\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0128 - acc: 0.9973\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0123 - acc: 0.9973\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0119 - acc: 0.9974\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0115 - acc: 0.9975\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0111 - acc: 0.9976\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0107 - acc: 0.9977\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0104 - acc: 0.9979\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0100 - acc: 0.9979\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0097 - acc: 0.9980\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0093 - acc: 0.9980\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0090 - acc: 0.9980\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0087 - acc: 0.9982\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0084 - acc: 0.9982\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0081 - acc: 0.9983\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0078 - acc: 0.9984\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0076 - acc: 0.9985\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0073 - acc: 0.9986\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0071 - acc: 0.9987\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0068 - acc: 0.9987\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0066 - acc: 0.9987\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0064 - acc: 0.9989\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0062 - acc: 0.9989\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0059 - acc: 0.9989\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0058 - acc: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb26fa9128>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy didn't go to 1 but remained at 50% level.\n",
    "Try more training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(loops=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.1511 - acc: 0.2006\n",
      "Epoch 2/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0864 - acc: 0.4958\n",
      "Epoch 3/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0619 - acc: 0.4914\n",
      "Epoch 4/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0542 - acc: 0.4955\n",
      "Epoch 5/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0509 - acc: 0.5062\n",
      "Epoch 6/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0491 - acc: 0.4926\n",
      "Epoch 7/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0481 - acc: 0.5055\n",
      "Epoch 8/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0474 - acc: 0.5001\n",
      "Epoch 9/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0470 - acc: 0.4999\n",
      "Epoch 10/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0468 - acc: 0.4970\n",
      "Epoch 11/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0466 - acc: 0.5008\n",
      "Epoch 12/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0465 - acc: 0.5061\n",
      "Epoch 13/600\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0464 - acc: 0.4977\n",
      "Epoch 14/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0463 - acc: 0.5002\n",
      "Epoch 15/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0463 - acc: 0.5005\n",
      "Epoch 16/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0462 - acc: 0.4996\n",
      "Epoch 17/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0462 - acc: 0.5077\n",
      "Epoch 18/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0462 - acc: 0.5040\n",
      "Epoch 19/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0462 - acc: 0.4988\n",
      "Epoch 20/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4988\n",
      "Epoch 21/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0462 - acc: 0.4960\n",
      "Epoch 22/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5029\n",
      "Epoch 23/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0462 - acc: 0.4951\n",
      "Epoch 24/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5008\n",
      "Epoch 25/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5003\n",
      "Epoch 26/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4957\n",
      "Epoch 27/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4984\n",
      "Epoch 28/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5001\n",
      "Epoch 29/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4984\n",
      "Epoch 30/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0461 - acc: 0.5024\n",
      "Epoch 31/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0462 - acc: 0.4977\n",
      "Epoch 32/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5014\n",
      "Epoch 33/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4994\n",
      "Epoch 34/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4994\n",
      "Epoch 35/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4950\n",
      "Epoch 36/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5011\n",
      "Epoch 37/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5017\n",
      "Epoch 38/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4982\n",
      "Epoch 39/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4993\n",
      "Epoch 40/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5018\n",
      "Epoch 41/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4973\n",
      "Epoch 42/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5011\n",
      "Epoch 43/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4940\n",
      "Epoch 44/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4976\n",
      "Epoch 45/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4987\n",
      "Epoch 46/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5040\n",
      "Epoch 47/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4981\n",
      "Epoch 48/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5003\n",
      "Epoch 49/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5037\n",
      "Epoch 50/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4989\n",
      "Epoch 51/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5008\n",
      "Epoch 52/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4952\n",
      "Epoch 53/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4967\n",
      "Epoch 54/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4986\n",
      "Epoch 55/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4951\n",
      "Epoch 56/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5022\n",
      "Epoch 57/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5016\n",
      "Epoch 58/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4984\n",
      "Epoch 59/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4955\n",
      "Epoch 60/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4973\n",
      "Epoch 61/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4997\n",
      "Epoch 62/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0461 - acc: 0.5035\n",
      "Epoch 63/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4984\n",
      "Epoch 64/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5012\n",
      "Epoch 65/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5002\n",
      "Epoch 66/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5005\n",
      "Epoch 67/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4981\n",
      "Epoch 68/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5037\n",
      "Epoch 69/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5019\n",
      "Epoch 70/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5024\n",
      "Epoch 71/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4988\n",
      "Epoch 72/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5012\n",
      "Epoch 73/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5019\n",
      "Epoch 74/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4956\n",
      "Epoch 75/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4988\n",
      "Epoch 76/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4976\n",
      "Epoch 77/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5020\n",
      "Epoch 78/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5052\n",
      "Epoch 79/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5028\n",
      "Epoch 80/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5020\n",
      "Epoch 81/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4999\n",
      "Epoch 82/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4992\n",
      "Epoch 83/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4988\n",
      "Epoch 84/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4978\n",
      "Epoch 85/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4978\n",
      "Epoch 86/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5007\n",
      "Epoch 87/600\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0460 - acc: 0.5015\n",
      "Epoch 88/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5026\n",
      "Epoch 89/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4962\n",
      "Epoch 90/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4976\n",
      "Epoch 91/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4978\n",
      "Epoch 92/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4981\n",
      "Epoch 93/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4977\n",
      "Epoch 94/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0462 - acc: 0.4990\n",
      "Epoch 95/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4996\n",
      "Epoch 96/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4983\n",
      "Epoch 97/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0461 - acc: 0.5014\n",
      "Epoch 98/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4975\n",
      "Epoch 99/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5014\n",
      "Epoch 100/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5100\n",
      "Epoch 101/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4957\n",
      "Epoch 102/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4965\n",
      "Epoch 103/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0460 - acc: 0.5009\n",
      "Epoch 104/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4961\n",
      "Epoch 105/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5029\n",
      "Epoch 106/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5003\n",
      "Epoch 107/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5039\n",
      "Epoch 108/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5017\n",
      "Epoch 109/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5008\n",
      "Epoch 110/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4994\n",
      "Epoch 111/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4960\n",
      "Epoch 112/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4978\n",
      "Epoch 113/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5004\n",
      "Epoch 114/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4993\n",
      "Epoch 115/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4966\n",
      "Epoch 116/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4971\n",
      "Epoch 117/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4991\n",
      "Epoch 118/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4984\n",
      "Epoch 119/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5016\n",
      "Epoch 120/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5005\n",
      "Epoch 121/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4935\n",
      "Epoch 122/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5007\n",
      "Epoch 123/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4976\n",
      "Epoch 124/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4983\n",
      "Epoch 125/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5013\n",
      "Epoch 126/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4986\n",
      "Epoch 127/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5026\n",
      "Epoch 128/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5006\n",
      "Epoch 129/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5000\n",
      "Epoch 130/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5029\n",
      "Epoch 131/600\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0460 - acc: 0.5041\n",
      "Epoch 132/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5062\n",
      "Epoch 133/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0461 - acc: 0.4966\n",
      "Epoch 134/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5007\n",
      "Epoch 135/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5018\n",
      "Epoch 136/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5039\n",
      "Epoch 137/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4972\n",
      "Epoch 138/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4965\n",
      "Epoch 139/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4941\n",
      "Epoch 140/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4948\n",
      "Epoch 141/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0461 - acc: 0.5006\n",
      "Epoch 142/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5016\n",
      "Epoch 143/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5004\n",
      "Epoch 144/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4988\n",
      "Epoch 145/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0460 - acc: 0.5015\n",
      "Epoch 146/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4955\n",
      "Epoch 147/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5033\n",
      "Epoch 148/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0461 - acc: 0.4992\n",
      "Epoch 149/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5010\n",
      "Epoch 150/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5021\n",
      "Epoch 151/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5002\n",
      "Epoch 152/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4934\n",
      "Epoch 153/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5040\n",
      "Epoch 154/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5018\n",
      "Epoch 155/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4985\n",
      "Epoch 156/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5031\n",
      "Epoch 157/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5029\n",
      "Epoch 158/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4992\n",
      "Epoch 159/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5023\n",
      "Epoch 160/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4982\n",
      "Epoch 161/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4941\n",
      "Epoch 162/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4949\n",
      "Epoch 163/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4959\n",
      "Epoch 164/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5004\n",
      "Epoch 165/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4924\n",
      "Epoch 166/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5005\n",
      "Epoch 167/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5014\n",
      "Epoch 168/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4964\n",
      "Epoch 169/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4990\n",
      "Epoch 170/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4947\n",
      "Epoch 171/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5037\n",
      "Epoch 172/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5030\n",
      "Epoch 173/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5057\n",
      "Epoch 174/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5021\n",
      "Epoch 175/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5039\n",
      "Epoch 176/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0459 - acc: 0.4945\n",
      "Epoch 177/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0459 - acc: 0.5019\n",
      "Epoch 178/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5043\n",
      "Epoch 179/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5024\n",
      "Epoch 180/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0459 - acc: 0.5032\n",
      "Epoch 181/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4952\n",
      "Epoch 182/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4973\n",
      "Epoch 183/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5023\n",
      "Epoch 184/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5054\n",
      "Epoch 185/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4984\n",
      "Epoch 186/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5032\n",
      "Epoch 187/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4997\n",
      "Epoch 188/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4980\n",
      "Epoch 189/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4951\n",
      "Epoch 190/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4967\n",
      "Epoch 191/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5009\n",
      "Epoch 192/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4973\n",
      "Epoch 193/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5003\n",
      "Epoch 194/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5023\n",
      "Epoch 195/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4985\n",
      "Epoch 196/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4989\n",
      "Epoch 197/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5005\n",
      "Epoch 198/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4968\n",
      "Epoch 199/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0459 - acc: 0.5045\n",
      "Epoch 200/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5010\n",
      "Epoch 201/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5008\n",
      "Epoch 202/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4969\n",
      "Epoch 203/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5033\n",
      "Epoch 204/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4997\n",
      "Epoch 205/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5003\n",
      "Epoch 206/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4955\n",
      "Epoch 207/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5018\n",
      "Epoch 208/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4965\n",
      "Epoch 209/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5008\n",
      "Epoch 210/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5039\n",
      "Epoch 211/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4964\n",
      "Epoch 212/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5009\n",
      "Epoch 213/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.4975\n",
      "Epoch 214/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5000\n",
      "Epoch 215/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5004\n",
      "Epoch 216/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4948\n",
      "Epoch 217/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4989\n",
      "Epoch 218/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4998\n",
      "Epoch 219/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4965\n",
      "Epoch 220/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5040\n",
      "Epoch 221/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4965\n",
      "Epoch 222/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4948\n",
      "Epoch 223/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4961\n",
      "Epoch 224/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4975\n",
      "Epoch 225/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4978\n",
      "Epoch 226/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5025\n",
      "Epoch 227/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5017\n",
      "Epoch 228/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5022\n",
      "Epoch 229/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5000\n",
      "Epoch 230/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0459 - acc: 0.5023\n",
      "Epoch 231/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4969\n",
      "Epoch 232/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4944\n",
      "Epoch 233/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4990\n",
      "Epoch 234/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5014\n",
      "Epoch 235/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4942\n",
      "Epoch 236/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0460 - acc: 0.5034\n",
      "Epoch 237/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5033\n",
      "Epoch 238/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4977\n",
      "Epoch 239/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4992\n",
      "Epoch 240/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4975\n",
      "Epoch 241/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4981\n",
      "Epoch 242/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5007\n",
      "Epoch 243/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5015\n",
      "Epoch 244/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0459 - acc: 0.4967\n",
      "Epoch 245/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5034\n",
      "Epoch 246/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4959\n",
      "Epoch 247/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5007\n",
      "Epoch 248/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5046\n",
      "Epoch 249/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4958\n",
      "Epoch 250/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4998\n",
      "Epoch 251/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5016\n",
      "Epoch 252/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4917\n",
      "Epoch 253/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5037\n",
      "Epoch 254/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5000\n",
      "Epoch 255/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4989\n",
      "Epoch 256/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4998\n",
      "Epoch 257/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4973\n",
      "Epoch 258/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4996\n",
      "Epoch 259/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4984\n",
      "Epoch 260/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4992\n",
      "Epoch 261/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5004\n",
      "Epoch 262/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5018\n",
      "Epoch 263/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4982\n",
      "Epoch 264/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4977\n",
      "Epoch 265/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4995\n",
      "Epoch 266/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4963\n",
      "Epoch 267/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0459 - acc: 0.4981\n",
      "Epoch 268/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4930\n",
      "Epoch 269/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.5007\n",
      "Epoch 270/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5028\n",
      "Epoch 271/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4990\n",
      "Epoch 272/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.4940\n",
      "Epoch 273/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5032\n",
      "Epoch 274/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5017\n",
      "Epoch 275/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5035\n",
      "Epoch 276/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0461 - acc: 0.4984\n",
      "Epoch 277/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4964\n",
      "Epoch 278/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0459 - acc: 0.5022\n",
      "Epoch 279/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0461 - acc: 0.4989\n",
      "Epoch 280/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5012\n",
      "Epoch 281/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.4973\n",
      "Epoch 282/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5038\n",
      "Epoch 283/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.4991\n",
      "Epoch 284/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4994\n",
      "Epoch 285/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4984\n",
      "Epoch 286/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5016\n",
      "Epoch 287/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5009\n",
      "Epoch 288/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5014\n",
      "Epoch 289/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4999\n",
      "Epoch 290/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5010\n",
      "Epoch 291/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4982\n",
      "Epoch 292/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4969\n",
      "Epoch 293/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4978\n",
      "Epoch 294/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.4982\n",
      "Epoch 295/600\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0460 - acc: 0.4999\n",
      "Epoch 296/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0459 - acc: 0.4977\n",
      "Epoch 297/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0460 - acc: 0.5063\n",
      "Epoch 298/600\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0461 - acc: 0.4968\n",
      "Epoch 299/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0459 - acc: 0.4899\n",
      "Epoch 300/600\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0460 - acc: 0.4985\n",
      "Epoch 301/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5004\n",
      "Epoch 302/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5023\n",
      "Epoch 303/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5006\n",
      "Epoch 304/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5013\n",
      "Epoch 305/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5001\n",
      "Epoch 306/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4989\n",
      "Epoch 307/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4994\n",
      "Epoch 308/600\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0461 - acc: 0.4959\n",
      "Epoch 309/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0459 - acc: 0.4990\n",
      "Epoch 310/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.4986\n",
      "Epoch 311/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.4960\n",
      "Epoch 312/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.4980\n",
      "Epoch 313/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0460 - acc: 0.4986\n",
      "Epoch 314/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0461 - acc: 0.4988\n",
      "Epoch 315/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0459 - acc: 0.5000\n",
      "Epoch 316/600\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0460 - acc: 0.4994\n",
      "Epoch 317/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0460 - acc: 0.4964\n",
      "Epoch 318/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4999\n",
      "Epoch 319/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.4973\n",
      "Epoch 320/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0460 - acc: 0.4992\n",
      "Epoch 321/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5040\n",
      "Epoch 322/600\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0460 - acc: 0.5006\n",
      "Epoch 323/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5010\n",
      "Epoch 324/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5024\n",
      "Epoch 325/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5003\n",
      "Epoch 326/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5038\n",
      "Epoch 327/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5026\n",
      "Epoch 328/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5062\n",
      "Epoch 329/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5006\n",
      "Epoch 330/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4906\n",
      "Epoch 331/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.5025\n",
      "Epoch 332/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5040\n",
      "Epoch 333/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4967\n",
      "Epoch 334/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5022\n",
      "Epoch 335/600\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0460 - acc: 0.4956\n",
      "Epoch 336/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0461 - acc: 0.5021\n",
      "Epoch 337/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5016\n",
      "Epoch 338/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5019\n",
      "Epoch 339/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5036\n",
      "Epoch 340/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5065\n",
      "Epoch 341/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5030\n",
      "Epoch 342/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0459 - acc: 0.4997\n",
      "Epoch 343/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.4997\n",
      "Epoch 344/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5063\n",
      "Epoch 345/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5016\n",
      "Epoch 346/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5018\n",
      "Epoch 347/600\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0460 - acc: 0.5017\n",
      "Epoch 348/600\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0460 - acc: 0.5055\n",
      "Epoch 349/600\n",
      " 6272/10000 [=================>............] - ETA: 0s - loss: 0.0460 - acc: 0.5021"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f42356a79962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size = 2,loops = 1000, size = 3, key = 1, x_as_vector = False, y_as_vector = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "i=26\n",
    "string.ascii_uppercase[0:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
