{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprocess(datalist):\n",
    "    for i in datalist:\n",
    "        temp = []\n",
    "        for j in range(26):\n",
    "            if i!=j:\n",
    "                temp.append(0)\n",
    "            else:\n",
    "                temp.append(1)\n",
    "        try:\n",
    "            transfered_data = np.vstack([transfered_data, temp])\n",
    "        except:\n",
    "            transfered_data = temp\n",
    "    return(transfered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caeserde_1(plaintext, key=3):\n",
    "    L2I = dict(zip(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", range(26)))\n",
    "    I2L = dict(zip(range(26), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    ciphertext = \"\"\n",
    "    ciphernum = []\n",
    "    plainnum = []\n",
    "\n",
    "    for c in plaintext.upper():\n",
    "        if c.isalpha():\n",
    "            # L2I[c]+key represents the order eg A=1 B=2\n",
    "            ciphertext += I2L[(L2I[c] + key) % 26]\n",
    "            ciphernum.append((L2I[c] + key) % 26)\n",
    "            plainnum.append((L2I[c]) % 26)\n",
    "        else:\n",
    "            ciphertext += c\n",
    "            ciphernum.append('-1')\n",
    "    return (ciphertext, ciphernum, plainnum)\n",
    "# random data\n",
    "text, train, label = caeserde_1(\n",
    "    'WERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKLJHGFDCVBNMHGFDSRTRYUHIJKOIUYTREWQAZXCVBNMFGHIJKLMNOPQRSTUVWXYZ'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def caeserde_26(plaintext, key=3):\n",
    "    L2I = dict(zip(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", range(26)))\n",
    "    I2L = dict(zip(range(26), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    ciphertext = \"\"\n",
    "    ciphernum = []\n",
    "    plainnum = []\n",
    "\n",
    "    for c in plaintext.upper():\n",
    "        if c.isalpha():\n",
    "            # L2I[c]+key represents the order eg A=1 B=2\n",
    "            ciphertext += I2L[(L2I[c] + key) % 26]\n",
    "            ciphernum.append((L2I[c] + key) % 26)\n",
    "            plainnum.append((L2I[c]) % 26)\n",
    "        else:\n",
    "            ciphertext += c\n",
    "            ciphernum.append('-1')\n",
    "    ciphernum = dataprocess(ciphernum)\n",
    "    plainnum = dataprocess(plainnum)\n",
    "    return (ciphertext, ciphernum, plainnum)\n",
    "# random data\n",
    "text, train, label = caeserde_26(\n",
    "    'WERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKLJHGFDCVBNMHGFDSRTRYUHIJKOIUYTREWQAZXCVBNMFGHIJKLMNOPQRSTUVWXYZ'\n",
    ")\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO list\n",
    "## Caeser ciper and impliment deep learning model**<br>\n",
    "    Caeser encryption function prediction\n",
    "## **Try to play around with caeser ciper and deep learning input and output**<br>\n",
    "### input 3(d) -- output a(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with 1 input and 26 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = None\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(10, input_dim=1, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "model1.compile(loss='poisson', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_4_input to have shape (1,) but got array with shape (130,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dfbd6f45d493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_4_input to have shape (1,) but got array with shape (130,)"
     ]
    }
   ],
   "source": [
    "model1.fit(train, label, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                546       \n",
      "=================================================================\n",
      "Total params: 1,426\n",
      "Trainable params: 1,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[]),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(26, activation=tf.nn.softmax),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    #loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "model.summary() #20*20+20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_input to have 1 dimensions, but got array with shape (2, 130)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-67dd0cef7c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    351\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected flatten_input to have 1 dimensions, but got array with shape (2, 130)"
     ]
    }
   ],
   "source": [
    "model.fit(train, label, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with 26 input and 26 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=26, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random data\n",
    "text, train, label = caeserde_26(\n",
    "    'WERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKLJHGFDCVBNMHGFDSRTRYUHIJKOIUYTREWQAZXCVBNMFGHIJKLMNOPQRSTUVWXYZ'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 12)                324       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                260       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 26)                546       \n",
      "=================================================================\n",
      "Total params: 1,130\n",
      "Trainable params: 1,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xihajun/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - acc: 0.9615\n",
      "Epoch 2/300\n",
      "185/185 [==============================] - 0s 32us/step - loss: 0.1631 - acc: 0.9615\n",
      "Epoch 3/300\n",
      "185/185 [==============================] - 0s 32us/step - loss: 0.1624 - acc: 0.9615\n",
      "Epoch 4/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.1618 - acc: 0.9615\n",
      "Epoch 5/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 0.1612 - acc: 0.9615\n",
      "Epoch 6/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1605 - acc: 0.9615\n",
      "Epoch 7/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1598 - acc: 0.9615\n",
      "Epoch 8/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1591 - acc: 0.9615\n",
      "Epoch 9/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1584 - acc: 0.9615\n",
      "Epoch 10/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1576 - acc: 0.9615\n",
      "Epoch 11/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.1568 - acc: 0.9615\n",
      "Epoch 12/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1559 - acc: 0.9615\n",
      "Epoch 13/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 14/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.1539 - acc: 0.9615\n",
      "Epoch 15/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1528 - acc: 0.9615\n",
      "Epoch 16/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1516 - acc: 0.9615\n",
      "Epoch 17/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1503 - acc: 0.9615\n",
      "Epoch 18/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1489 - acc: 0.9615\n",
      "Epoch 19/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.1474 - acc: 0.9615\n",
      "Epoch 20/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1458 - acc: 0.9615\n",
      "Epoch 21/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1442 - acc: 0.9615\n",
      "Epoch 22/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1423 - acc: 0.9615\n",
      "Epoch 23/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1405 - acc: 0.9615\n",
      "Epoch 24/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1384 - acc: 0.9615\n",
      "Epoch 25/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1362 - acc: 0.9615\n",
      "Epoch 26/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1339 - acc: 0.9615\n",
      "Epoch 27/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1315 - acc: 0.9615\n",
      "Epoch 28/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1290 - acc: 0.9615\n",
      "Epoch 29/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1263 - acc: 0.9615\n",
      "Epoch 30/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1235 - acc: 0.9615\n",
      "Epoch 31/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1206 - acc: 0.9615\n",
      "Epoch 32/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1176 - acc: 0.9615\n",
      "Epoch 33/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1144 - acc: 0.9615\n",
      "Epoch 34/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1113 - acc: 0.9615\n",
      "Epoch 35/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.1080 - acc: 0.9615\n",
      "Epoch 36/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.1048 - acc: 0.9615\n",
      "Epoch 37/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1016 - acc: 0.9640\n",
      "Epoch 38/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0983 - acc: 0.9644\n",
      "Epoch 39/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0951 - acc: 0.9672\n",
      "Epoch 40/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0918 - acc: 0.9672\n",
      "Epoch 41/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0886 - acc: 0.9672\n",
      "Epoch 42/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0854 - acc: 0.9686\n",
      "Epoch 43/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0823 - acc: 0.9732\n",
      "Epoch 44/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0792 - acc: 0.9748\n",
      "Epoch 45/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0762 - acc: 0.9765\n",
      "Epoch 46/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0732 - acc: 0.9796\n",
      "Epoch 47/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0703 - acc: 0.9813\n",
      "Epoch 48/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0675 - acc: 0.9813\n",
      "Epoch 49/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0647 - acc: 0.9813\n",
      "Epoch 50/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0621 - acc: 0.9813\n",
      "Epoch 51/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0594 - acc: 0.9813\n",
      "Epoch 52/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0569 - acc: 0.9827\n",
      "Epoch 53/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0544 - acc: 0.9832\n",
      "Epoch 54/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0520 - acc: 0.9832\n",
      "Epoch 55/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0497 - acc: 0.9840\n",
      "Epoch 56/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0474 - acc: 0.9844\n",
      "Epoch 57/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0451 - acc: 0.9852\n",
      "Epoch 58/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0430 - acc: 0.9865\n",
      "Epoch 59/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0409 - acc: 0.9865\n",
      "Epoch 60/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0389 - acc: 0.9879\n",
      "Epoch 61/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0369 - acc: 0.9886\n",
      "Epoch 62/300\n",
      "185/185 [==============================] - 0s 43us/step - loss: 0.0350 - acc: 0.9886\n",
      "Epoch 63/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0332 - acc: 0.9896\n",
      "Epoch 64/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 65/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 66/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 67/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0267 - acc: 0.9931\n",
      "Epoch 68/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0252 - acc: 0.9950\n",
      "Epoch 69/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0238 - acc: 0.9950\n",
      "Epoch 70/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0226 - acc: 0.9950\n",
      "Epoch 71/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0214 - acc: 0.9950\n",
      "Epoch 72/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0202 - acc: 0.9950\n",
      "Epoch 73/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0191 - acc: 0.9950\n",
      "Epoch 74/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0181 - acc: 0.9950\n",
      "Epoch 75/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0170 - acc: 0.9954\n",
      "Epoch 76/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0162 - acc: 0.9973\n",
      "Epoch 77/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0153 - acc: 0.9983\n",
      "Epoch 78/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0145 - acc: 0.9983\n",
      "Epoch 79/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0137 - acc: 0.9990\n",
      "Epoch 80/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0130 - acc: 0.9992\n",
      "Epoch 81/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0124 - acc: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0117 - acc: 0.9992\n",
      "Epoch 83/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0111 - acc: 0.9992\n",
      "Epoch 84/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0106 - acc: 0.9992\n",
      "Epoch 85/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0101 - acc: 0.9992\n",
      "Epoch 86/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0096 - acc: 0.9992\n",
      "Epoch 87/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0092 - acc: 0.9992\n",
      "Epoch 88/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0088 - acc: 0.9992\n",
      "Epoch 89/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0084 - acc: 0.9992\n",
      "Epoch 90/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0080 - acc: 0.9996\n",
      "Epoch 91/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0077 - acc: 0.9996\n",
      "Epoch 92/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0074 - acc: 0.9996\n",
      "Epoch 93/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0070 - acc: 0.9996\n",
      "Epoch 94/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0068 - acc: 0.9996\n",
      "Epoch 95/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0065 - acc: 0.9996\n",
      "Epoch 96/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0062 - acc: 0.9996\n",
      "Epoch 97/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0060 - acc: 0.9996\n",
      "Epoch 98/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0058 - acc: 0.9996\n",
      "Epoch 99/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0056 - acc: 0.9996\n",
      "Epoch 100/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0054 - acc: 0.9996\n",
      "Epoch 101/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0052 - acc: 0.9996\n",
      "Epoch 102/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0050 - acc: 0.9996\n",
      "Epoch 103/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0048 - acc: 0.9996\n",
      "Epoch 104/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0046 - acc: 0.9996\n",
      "Epoch 105/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 106/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 107/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 108/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0040 - acc: 0.9996\n",
      "Epoch 109/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0039 - acc: 0.9996\n",
      "Epoch 110/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0038 - acc: 0.9996\n",
      "Epoch 111/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0037 - acc: 0.9996\n",
      "Epoch 112/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 113/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 114/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 115/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 116/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 117/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 118/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 119/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0028 - acc: 0.9996\n",
      "Epoch 120/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 121/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 122/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 123/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0025 - acc: 0.9996\n",
      "Epoch 124/300\n",
      "185/185 [==============================] - 0s 32us/step - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 125/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 126/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 127/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 128/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 129/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 130/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 131/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 132/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 133/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 134/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 135/300\n",
      "185/185 [==============================] - 0s 43us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 136/300\n",
      "185/185 [==============================] - 0s 45us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 137/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 138/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 139/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 140/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 141/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 142/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 143/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 144/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 145/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 146/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 147/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 148/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 149/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 150/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 151/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 152/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 153/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 154/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 155/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 156/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 157/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 158/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 159/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 9.8270e-04 - acc: 1.0000\n",
      "Epoch 160/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 9.6092e-04 - acc: 1.0000\n",
      "Epoch 161/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 9.4414e-04 - acc: 1.0000\n",
      "Epoch 162/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 9.2293e-04 - acc: 1.0000\n",
      "Epoch 163/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 9.0456e-04 - acc: 1.0000\n",
      "Epoch 164/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 8.8638e-04 - acc: 1.0000\n",
      "Epoch 165/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 8.6894e-04 - acc: 1.0000\n",
      "Epoch 166/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 8.5245e-04 - acc: 1.0000\n",
      "Epoch 167/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 8.3615e-04 - acc: 1.0000\n",
      "Epoch 168/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 8.1964e-04 - acc: 1.0000\n",
      "Epoch 169/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 8.0432e-04 - acc: 1.0000\n",
      "Epoch 170/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 7.9000e-04 - acc: 1.0000\n",
      "Epoch 171/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 7.7496e-04 - acc: 1.0000\n",
      "Epoch 172/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 7.6136e-04 - acc: 1.0000\n",
      "Epoch 173/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 7.4712e-04 - acc: 1.0000\n",
      "Epoch 174/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 7.3309e-04 - acc: 1.0000\n",
      "Epoch 175/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 7.2148e-04 - acc: 1.0000\n",
      "Epoch 176/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 7.0779e-04 - acc: 1.0000\n",
      "Epoch 177/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.9529e-04 - acc: 1.0000\n",
      "Epoch 178/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 6.8335e-04 - acc: 1.0000\n",
      "Epoch 179/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 6.7187e-04 - acc: 1.0000\n",
      "Epoch 180/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.6062e-04 - acc: 1.0000\n",
      "Epoch 181/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 6.4919e-04 - acc: 1.0000\n",
      "Epoch 182/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.3853e-04 - acc: 1.0000\n",
      "Epoch 183/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 6.2781e-04 - acc: 1.0000\n",
      "Epoch 184/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.1771e-04 - acc: 1.0000\n",
      "Epoch 185/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.0780e-04 - acc: 1.0000\n",
      "Epoch 186/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 5.9779e-04 - acc: 1.0000\n",
      "Epoch 187/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 5.8899e-04 - acc: 1.0000\n",
      "Epoch 188/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 5.7901e-04 - acc: 1.0000\n",
      "Epoch 189/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 5.7109e-04 - acc: 1.0000\n",
      "Epoch 190/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 5.6124e-04 - acc: 1.0000\n",
      "Epoch 191/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 5.5237e-04 - acc: 1.0000\n",
      "Epoch 192/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 5.4390e-04 - acc: 1.0000\n",
      "Epoch 193/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 5.3628e-04 - acc: 1.0000\n",
      "Epoch 194/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 5.2823e-04 - acc: 1.0000\n",
      "Epoch 195/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 5.1975e-04 - acc: 1.0000\n",
      "Epoch 196/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 5.1202e-04 - acc: 1.0000\n",
      "Epoch 197/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 5.0484e-04 - acc: 1.0000\n",
      "Epoch 198/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 4.9730e-04 - acc: 1.0000\n",
      "Epoch 199/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 4.9023e-04 - acc: 1.0000\n",
      "Epoch 200/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 4.8332e-04 - acc: 1.0000\n",
      "Epoch 201/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 4.7641e-04 - acc: 1.0000\n",
      "Epoch 202/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 4.6968e-04 - acc: 1.0000\n",
      "Epoch 203/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 4.6302e-04 - acc: 1.0000\n",
      "Epoch 204/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 4.5675e-04 - acc: 1.0000\n",
      "Epoch 205/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 4.5046e-04 - acc: 1.0000\n",
      "Epoch 206/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 4.4432e-04 - acc: 1.0000\n",
      "Epoch 207/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 4.3818e-04 - acc: 1.0000\n",
      "Epoch 208/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 4.3222e-04 - acc: 1.0000\n",
      "Epoch 209/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 4.2623e-04 - acc: 1.0000\n",
      "Epoch 210/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 4.2088e-04 - acc: 1.0000\n",
      "Epoch 211/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 4.1523e-04 - acc: 1.0000\n",
      "Epoch 212/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 4.0985e-04 - acc: 1.0000\n",
      "Epoch 213/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 4.0457e-04 - acc: 1.0000\n",
      "Epoch 214/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.9927e-04 - acc: 1.0000\n",
      "Epoch 215/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 3.9394e-04 - acc: 1.0000\n",
      "Epoch 216/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.8883e-04 - acc: 1.0000\n",
      "Epoch 217/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.8411e-04 - acc: 1.0000\n",
      "Epoch 218/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.7919e-04 - acc: 1.0000\n",
      "Epoch 219/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 3.7446e-04 - acc: 1.0000\n",
      "Epoch 220/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.7009e-04 - acc: 1.0000\n",
      "Epoch 221/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 3.6505e-04 - acc: 1.0000\n",
      "Epoch 222/300\n",
      "185/185 [==============================] - 0s 43us/step - loss: 3.6047e-04 - acc: 1.0000\n",
      "Epoch 223/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 3.5619e-04 - acc: 1.0000\n",
      "Epoch 224/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 3.5173e-04 - acc: 1.0000\n",
      "Epoch 225/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 3.4759e-04 - acc: 1.0000\n",
      "Epoch 226/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.4345e-04 - acc: 1.0000\n",
      "Epoch 227/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.3920e-04 - acc: 1.0000\n",
      "Epoch 228/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.3512e-04 - acc: 1.0000\n",
      "Epoch 229/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.3114e-04 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.2751e-04 - acc: 1.0000\n",
      "Epoch 231/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 3.2346e-04 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 3.1972e-04 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.1604e-04 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 3.1238e-04 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 3.0883e-04 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 3.0535e-04 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 3.0192e-04 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 2.9856e-04 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.9517e-04 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.9208e-04 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 2.8856e-04 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.8536e-04 - acc: 1.0000\n",
      "Epoch 243/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 37us/step - loss: 2.8221e-04 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.7930e-04 - acc: 1.0000\n",
      "Epoch 245/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 2.7623e-04 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.7323e-04 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.7030e-04 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 2.6736e-04 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.6463e-04 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 2.6186e-04 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 2.5910e-04 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 2.5653e-04 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "185/185 [==============================] - 0s 32us/step - loss: 2.5387e-04 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 2.5113e-04 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.4862e-04 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 2.4611e-04 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.4370e-04 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.4116e-04 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 2.3870e-04 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.3639e-04 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 2.3396e-04 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.3164e-04 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 2.2938e-04 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.2725e-04 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.2496e-04 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 2.2269e-04 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.2063e-04 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 2.1852e-04 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 2.1646e-04 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 2.1428e-04 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "185/185 [==============================] - 0s 48us/step - loss: 2.1223e-04 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 2.1036e-04 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 2.0823e-04 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 2.0629e-04 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 2.0437e-04 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 2.0244e-04 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 2.0056e-04 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.9869e-04 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.9691e-04 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.9512e-04 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "185/185 [==============================] - 0s 43us/step - loss: 1.9330e-04 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 1.9153e-04 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 1.8975e-04 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 1.8809e-04 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.8636e-04 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.8472e-04 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.8305e-04 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 1.8144e-04 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.7987e-04 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.7823e-04 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 1.7670e-04 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "185/185 [==============================] - 0s 45us/step - loss: 1.7510e-04 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.7364e-04 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 1.7206e-04 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "185/185 [==============================] - 0s 45us/step - loss: 1.7058e-04 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 1.6923e-04 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.6769e-04 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.6629e-04 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.6487e-04 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 1.6346e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb30209908>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, label, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train)\n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir = \"./graphs/{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 582us/step\n",
      "\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(train, label)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with 1 input and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fcd5e3a64f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model1 = None\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(26, input_dim=1, activation='relu'))\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "\n",
    "model1.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, train, label = caeserde_26(\n",
    "    'IAMSAMILIKEDST'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how can we chose the loss function: https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='poisson', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 2/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 3/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 4/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 5/500\n",
      "308/308 [==============================] - 0s 66us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 6/500\n",
      "308/308 [==============================] - 0s 59us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 7/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 8/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 9/500\n",
      "308/308 [==============================] - 0s 55us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 10/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 11/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 12/500\n",
      "308/308 [==============================] - 0s 53us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 13/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 14/500\n",
      "308/308 [==============================] - 0s 53us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 15/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 16/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 17/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 18/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 19/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 20/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 21/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 22/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 23/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 24/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 25/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 26/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 27/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 28/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 29/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 30/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 31/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 32/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 33/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 34/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 35/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 36/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 37/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 38/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 39/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 40/500\n",
      "308/308 [==============================] - 0s 56us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 41/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 42/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 43/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 44/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 45/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 46/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 47/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 48/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 49/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 50/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 51/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 52/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 53/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 54/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 55/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 56/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 57/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 58/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 59/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 60/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 61/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 62/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 63/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 64/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 65/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 66/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 67/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 68/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 69/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 70/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 71/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 72/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 73/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 74/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 75/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 76/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 77/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 78/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 79/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 80/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 81/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 82/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 84/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 85/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 86/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 87/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 88/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 89/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 90/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 91/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 92/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 93/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 94/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 95/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 96/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 97/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 98/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 99/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 100/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 101/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 102/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 103/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 104/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 105/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 106/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 107/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 108/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 109/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 110/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 111/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 112/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 113/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 114/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 115/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 116/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 117/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 118/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 119/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 120/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 121/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 122/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 123/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 124/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 125/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 126/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 127/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 128/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 129/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 130/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 131/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 132/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 133/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 134/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 135/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 136/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 137/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 138/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 139/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 140/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 141/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 142/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 143/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 144/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 145/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 146/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 147/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 148/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 149/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 150/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 151/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 152/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 153/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 154/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 155/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 156/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 157/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 158/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 159/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 160/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 161/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 162/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 163/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 164/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 165/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 166/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 167/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 168/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 169/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 170/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 171/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 172/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 173/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 174/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 175/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 176/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 177/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 178/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 179/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 180/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 181/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 182/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 183/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 184/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 185/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 186/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 187/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 188/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 189/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 190/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 191/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 192/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 193/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 194/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 195/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 196/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 197/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 198/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 199/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 200/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 201/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 202/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 203/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 204/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 205/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 206/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 207/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 208/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 209/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 210/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 211/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 212/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 213/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 214/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 215/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 216/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 217/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 218/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 219/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 220/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 221/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 222/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 223/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 224/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 225/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 226/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 227/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 228/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 229/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 230/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 231/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 232/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 233/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 234/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 235/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 236/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 237/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 238/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 239/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 240/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 241/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 242/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 243/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 244/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 246/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 247/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 248/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 249/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 250/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 251/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 252/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 253/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 254/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 255/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 256/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 257/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 258/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 259/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 260/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 261/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 262/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 263/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 264/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 265/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 266/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 267/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 268/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 269/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 270/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 271/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 272/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 273/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 274/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 275/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 276/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 277/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 278/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 279/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 280/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 281/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 282/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 283/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 284/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 285/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 286/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 287/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 288/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 289/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 290/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 291/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 292/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 293/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 294/500\n",
      "308/308 [==============================] - 0s 56us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 295/500\n",
      "308/308 [==============================] - 0s 53us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 296/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 297/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 298/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 299/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 300/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 301/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 302/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 303/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 304/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 305/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 306/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 307/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 308/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 309/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 310/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 311/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 312/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 313/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 314/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 315/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 316/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 317/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 318/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 319/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 320/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 321/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 322/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 323/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 324/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 325/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 326/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 327/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 328/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 329/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 330/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 331/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 332/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 333/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 334/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 335/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 336/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 337/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 338/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 339/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 340/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 341/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 342/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 343/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 344/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 345/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 346/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 347/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 348/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 349/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 350/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 351/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 352/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 353/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 354/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 355/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 356/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 357/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 358/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 359/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 360/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 361/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 362/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 363/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 364/500\n",
      "308/308 [==============================] - 0s 55us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 365/500\n",
      "308/308 [==============================] - 0s 53us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 366/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 367/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 368/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 369/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 370/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 371/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 372/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 373/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 374/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 375/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 376/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 377/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 378/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 379/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 380/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 381/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 382/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 383/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 384/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 385/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 386/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 387/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 388/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 389/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 390/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 391/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 392/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 393/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 394/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 395/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 396/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 397/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 398/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 399/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 400/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 401/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 402/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 403/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 404/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 405/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 406/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 408/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 409/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 410/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 411/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 412/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 413/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 414/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 415/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 416/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 417/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 418/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 419/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 420/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 421/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 422/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 423/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 424/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 425/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 426/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 427/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 428/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 429/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 430/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 431/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 432/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 433/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 434/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 435/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 436/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 437/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 438/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 439/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 440/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 441/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 442/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 443/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 444/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 445/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 446/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 447/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 448/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 449/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 450/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 451/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 452/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 453/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 454/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 455/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 456/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 457/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 458/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 459/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 460/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 461/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 462/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 463/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 464/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 465/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 466/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 467/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 468/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 469/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 470/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 471/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 472/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 473/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 474/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 475/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 476/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 477/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 478/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 479/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 480/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 481/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 482/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 483/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 484/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 485/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 486/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 487/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 488/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 489/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 490/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 491/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 492/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 493/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 494/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 495/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 496/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 497/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 498/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 499/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 500/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb350af128>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random data\n",
    "text, train, label = caeserde_1(\n",
    "    'WERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKLJHGFDCVBNMHGFDSRTRYUHIJKOIUYTREWQAZXCVBNMFGHIJKLMNOPQRSTUVWXYZWERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKL'\n",
    ")\n",
    "model1.fit(train, label, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 26)                52        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 20)                540       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,873\n",
      "Trainable params: 1,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 3(d) -- output (1,0,0,...,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input (0,0,0,1,0,...,0) -- output a(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input (0,0,0,1,0,...,0) -- output (1,0,0,...,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input (0,0,0,1,0,...,0) -- output (1,0,0,...,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analyse this results**<br>\n",
    "\n",
    "   For example, which model minimises the number of echos \n",
    "   Which model cannot reach the 100% accuracy? Why?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using unseen data 26-100**<br>\n",
    "\n",
    "    The model has seen 0-26)<br>\n",
    "    Try to find the weight in this model<br>\n",
    "    Try to visualize it by using tensorboard<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Try to add more training data, see if things change**<br>\n",
    "    If it is better, try to explain why<br>\n",
    "    If it is not, maybe 23 is enough?<br>\n",
    "* My prior: Maybe more data can make the training procedure faster? I don't know given the same input how doesthe neural network learn? Stop updating or **keep updating**?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Try to hide some data**\n",
    "* For human, it is reasonable if we hide z, we are able to judge the one we cannot see (high probability)\n",
    "* I tried it makes no sense so far. 98%?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new data to make the neural network learn the shift, but how to learn the piecewise function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Try to given pairs of data, and change the structure of neural output and input**\n",
    "* How many we combination we have? **676** (no order). More deeperly, combining with more words (we know the number of combination is too large, we just want to test, if neural network could learn something unseen?\n",
    "* Need a smart way to do this (consider to restruct the input and output as well as the order)<br>\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>Example 1 </th><th>Example 2</th></tr>\n",
    "<tr><td>\n",
    "\n",
    "Set|Input| Output|Seen\n",
    "---|---|---|---|\n",
    "Training| AB | DE |Yes\n",
    "Training| CD | FG |Yes\n",
    "Testing | BC | EF |No\n",
    "\n",
    "</td><td>\n",
    "\n",
    "\n",
    "Set|Input| Output|Seen\n",
    "---|---|---|---|\n",
    "Training| AB | DE |Yes\n",
    "Testing | BA | ED |No\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "* Idea: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Watching videos and papers for logic programming**\n",
    "\n",
    "    To figure out logic programming in deep learning\n",
    "    Video<br>\n",
    "    [Deep learning course: Introduction to Deep Learning](https://www.youtube.com/watch?v=JN6H4rQvwgY)<br>\n",
    "    [Richard Evans: Inductive logic programming and deep learning I](https://www.youtube.com/watch?v=yD02DlZnHJw)<br>\n",
    "    [Learning Explanatory Rules from Noisy Data - Richard Evans, DeepMind](https://www.youtube.com/watch?v=_wuFBF_Cgm0&t=24s)<br>\n",
    "    Paper<br>\n",
    "    [LOGIC MINING USING NEURAL NETWORKS](https://arxiv.org/pdf/0804.4071.pdf)<br>\n",
    "    [First-order Logic Learning in Artificial Neural Networks](https://core.ac.uk/download/pdf/17294404.pdf)<br>\n",
    "    Python logic programming<br>\n",
    "    [PYKE](http://pyke.sourceforge.net/index.html)\n",
    "\n",
    "- [ ] **Try to use ILD to guide our neural system**\n",
    "    How? Set rules, recurrent?\n",
    "\n",
    "- [ ] **Try to find new encryption function to learn more complex stuff**\n",
    "    key=[1,2,3,4]? \n",
    "    Consider the input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## letters position matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caeserde_1(plaintext, key=3):\n",
    "    L2I = dict(zip(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", range(26)))\n",
    "    I2L = dict(zip(range(26), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    ciphertext = \"\"\n",
    "    ciphernum = []\n",
    "    plainnum = []\n",
    "\n",
    "    for c in plaintext.upper():\n",
    "        if c.isalpha():\n",
    "            # L2I[c]+key represents the order eg A=1 B=2\n",
    "            ciphertext += I2L[(L2I[c] + key) % 26]\n",
    "            ciphernum.append((L2I[c] + key) % 26)\n",
    "            plainnum.append((L2I[c]) % 26)\n",
    "        else:\n",
    "            ciphertext += c\n",
    "            ciphernum.append('-1')\n",
    "    return (ciphertext, ciphernum, plainnum)\n",
    "def letter_position_matrix(text,key=3):\n",
    "    length = len(text)\n",
    "    matrix = [[0 for y in range(26)] for x in range(length)]\n",
    "    for idx, val in enumerate(text):\n",
    "        matrix[idx][val] = 1\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciphertext, ciphernum, plainnum = caeserde_1(\"Hello\")\n",
    "\n",
    "\n",
    "a = letter_position_matrix(plainnum)\n",
    "b = letter_position_matrix(ciphernum)\n",
    "\n",
    "label_smaller = np.array(plainnum)\n",
    "# flatten label and training set\n",
    "label_equalsize = a.flatten()\n",
    "train = b.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_genelization(k=2,loops = 1000):\n",
    "    temp = ''.join(random.choices(string.ascii_uppercase, k=2))\n",
    "    ciphertext, ciphernum, plainnum = caeserde_1(temp)\n",
    "\n",
    "    a = letter_position_matrix(plainnum)\n",
    "    b = letter_position_matrix(ciphernum)\n",
    "\n",
    "    label_smaller = np.array(plainnum)\n",
    "    # flatten label and training set\n",
    "    label_equalsize = a.flatten()\n",
    "    train = b.flatten()\n",
    "    for i in range(loops):\n",
    "        temp = ''.join(random.choices(string.ascii_uppercase, k=2))\n",
    "        ciphertext, ciphernum, plainnum = caeserde_1(temp)\n",
    "        a = letter_position_matrix(plainnum)\n",
    "        b = letter_position_matrix(ciphernum)\n",
    "        label_smaller = np.vstack([label_smaller,np.array(plainnum)])\n",
    "        # flatten label and training set\n",
    "        label_equalsize = np.vstack([label_equalsize,a.flatten()])\n",
    "        train = np.vstack([train,b.flatten()])\n",
    "    return(train,label_equalsize,label_smaller)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,label_equalsize,label_smaller = data_genelization(loops=10000)\n",
    "# loops = 5000 accuracy will stay in 98% maybe they not see all the data set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=52, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "\n",
    "model.add(Dense(52, activation='sigmoid'))#01 so sigmoid is better?>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#logcosh reduce the accuracy 52-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0074 - acc: 0.9988\n",
      "Epoch 2/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9988\n",
      "Epoch 3/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9988\n",
      "Epoch 4/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9988\n",
      "Epoch 5/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9988\n",
      "Epoch 6/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9988\n",
      "Epoch 7/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9988\n",
      "Epoch 8/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9989\n",
      "Epoch 9/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9989\n",
      "Epoch 10/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9990\n",
      "Epoch 11/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9989\n",
      "Epoch 12/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9990\n",
      "Epoch 13/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9990\n",
      "Epoch 14/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9991\n",
      "Epoch 15/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 16/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 17/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 18/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 19/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 20/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9990\n",
      "Epoch 21/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9990\n",
      "Epoch 22/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 23/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 24/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9991\n",
      "Epoch 25/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9991\n",
      "Epoch 26/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9991\n",
      "Epoch 27/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9992\n",
      "Epoch 28/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9992\n",
      "Epoch 29/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9992\n",
      "Epoch 30/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9992\n",
      "Epoch 31/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9992\n",
      "Epoch 32/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9991\n",
      "Epoch 33/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9992\n",
      "Epoch 34/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9992\n",
      "Epoch 35/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9992\n",
      "Epoch 36/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9992\n",
      "Epoch 37/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9992\n",
      "Epoch 38/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9992\n",
      "Epoch 39/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0059 - acc: 0.9993\n",
      "Epoch 40/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9993\n",
      "Epoch 41/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9994\n",
      "Epoch 42/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9994\n",
      "Epoch 43/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9994\n",
      "Epoch 44/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9994\n",
      "Epoch 45/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9994\n",
      "Epoch 46/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0057 - acc: 0.9994\n",
      "Epoch 47/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0057 - acc: 0.9993\n",
      "Epoch 48/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0057 - acc: 0.9993\n",
      "Epoch 49/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0057 - acc: 0.9994\n",
      "Epoch 50/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0057 - acc: 0.9994\n",
      "Epoch 51/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0057 - acc: 0.9994\n",
      "Epoch 52/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0056 - acc: 0.9994\n",
      "Epoch 53/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0056 - acc: 0.9993\n",
      "Epoch 54/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0055 - acc: 0.9993\n",
      "Epoch 55/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0055 - acc: 0.9993\n",
      "Epoch 56/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0055 - acc: 0.9993\n",
      "Epoch 57/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0054 - acc: 0.9994\n",
      "Epoch 58/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0054 - acc: 0.9995\n",
      "Epoch 59/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0054 - acc: 0.9995\n",
      "Epoch 60/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0054 - acc: 0.9994\n",
      "Epoch 61/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9993\n",
      "Epoch 62/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9993\n",
      "Epoch 63/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9994\n",
      "Epoch 64/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0052 - acc: 0.9995\n",
      "Epoch 65/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0052 - acc: 0.9995\n",
      "Epoch 66/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0052 - acc: 0.9995\n",
      "Epoch 67/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0052 - acc: 0.9995\n",
      "Epoch 68/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0051 - acc: 0.9995\n",
      "Epoch 69/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0051 - acc: 0.9995\n",
      "Epoch 70/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0051 - acc: 0.9996\n",
      "Epoch 71/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.9995\n",
      "Epoch 72/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.9996\n",
      "Epoch 73/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.9995\n",
      "Epoch 74/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.9996\n",
      "Epoch 75/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0051 - acc: 0.9996\n",
      "Epoch 76/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0053 - acc: 0.9995\n",
      "Epoch 77/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0052 - acc: 0.9995\n",
      "Epoch 78/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0051 - acc: 0.9996\n",
      "Epoch 79/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.9996\n",
      "Epoch 80/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0049 - acc: 0.9996\n",
      "Epoch 81/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0049 - acc: 0.9996\n",
      "Epoch 82/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 83/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 84/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0048 - acc: 0.9996\n",
      "Epoch 85/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0047 - acc: 0.9996\n",
      "Epoch 86/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0047 - acc: 0.9996\n",
      "Epoch 87/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0047 - acc: 0.9996\n",
      "Epoch 88/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0046 - acc: 0.9996\n",
      "Epoch 89/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0046 - acc: 0.9996\n",
      "Epoch 90/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0046 - acc: 0.9996\n",
      "Epoch 91/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 92/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 93/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 94/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 95/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 96/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 97/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 98/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 99/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 100/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 101/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.9996\n",
      "Epoch 102/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.9996\n",
      "Epoch 103/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.9997\n",
      "Epoch 104/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.9997\n",
      "Epoch 105/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0042 - acc: 0.9997\n",
      "Epoch 106/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0042 - acc: 0.9997\n",
      "Epoch 107/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 108/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 109/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 110/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 111/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 112/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 0.9997\n",
      "Epoch 113/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 0.9996\n",
      "Epoch 114/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 0.9997\n",
      "Epoch 115/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 0.9997\n",
      "Epoch 116/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 0.9997\n",
      "Epoch 117/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 0.9997\n",
      "Epoch 118/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 119/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 120/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 121/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 122/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0038 - acc: 0.9997\n",
      "Epoch 123/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0038 - acc: 0.9997\n",
      "Epoch 124/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0038 - acc: 0.9997\n",
      "Epoch 125/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0038 - acc: 0.9997\n",
      "Epoch 126/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0038 - acc: 0.9998\n",
      "Epoch 127/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 0.9998\n",
      "Epoch 128/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0040 - acc: 0.9998\n",
      "Epoch 129/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0039 - acc: 0.9998\n",
      "Epoch 130/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0038 - acc: 0.9998\n",
      "Epoch 131/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0037 - acc: 0.9997\n",
      "Epoch 132/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0037 - acc: 0.9997\n",
      "Epoch 133/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0036 - acc: 0.9998\n",
      "Epoch 134/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0036 - acc: 0.9998\n",
      "Epoch 135/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0036 - acc: 0.9998\n",
      "Epoch 136/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0036 - acc: 0.9998\n",
      "Epoch 137/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0035 - acc: 0.9998\n",
      "Epoch 138/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0035 - acc: 0.9998\n",
      "Epoch 139/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0035 - acc: 0.9998\n",
      "Epoch 140/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0034 - acc: 0.9998\n",
      "Epoch 141/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0034 - acc: 0.9998\n",
      "Epoch 142/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0034 - acc: 0.9998\n",
      "Epoch 143/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0034 - acc: 0.9998\n",
      "Epoch 144/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0034 - acc: 0.9998\n",
      "Epoch 145/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 146/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 147/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 148/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 149/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 150/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 151/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 152/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 153/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 154/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 155/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 156/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 157/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 158/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 159/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 161/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 162/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 163/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 164/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 165/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 166/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 167/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 168/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 169/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 170/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 171/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 172/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 173/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 174/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 175/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 176/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 177/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 178/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 179/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 180/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 181/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 182/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 183/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 184/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 185/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 186/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 187/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 188/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 189/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 190/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 191/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 192/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 193/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 194/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 195/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 196/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 197/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 198/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 199/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 200/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 201/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 202/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 203/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 204/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 205/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 206/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 207/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 208/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 209/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 210/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 211/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 212/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 213/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 214/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 215/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 216/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 217/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 218/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 219/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 220/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 221/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 222/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 223/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 224/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 225/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 226/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 227/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 228/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 229/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 230/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 231/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 232/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 233/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 234/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 235/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 236/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 237/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 238/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 239/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 240/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 241/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 242/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 243/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 244/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 245/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 246/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 247/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 248/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 249/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 250/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 251/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 252/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 253/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 254/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 255/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 256/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 257/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 258/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 259/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 260/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 261/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 262/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 263/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 264/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 265/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 266/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 267/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 268/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 269/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 270/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 271/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 272/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 273/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 274/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 275/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 276/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 277/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 278/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 279/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 280/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 281/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 282/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 283/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 284/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 285/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 286/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 287/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 288/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 289/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 290/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 291/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 292/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 293/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 294/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 295/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 296/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 297/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 298/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 299/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 300/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 301/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 302/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 303/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 304/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 305/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 306/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 307/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 308/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 309/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0011 - acc: 0.9999\n",
      "Epoch 310/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 311/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 312/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 313/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 314/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 315/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 316/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 317/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 318/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 5us/step - loss: 9.9712e-04 - acc: 1.0000\n",
      "Epoch 319/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.8912e-04 - acc: 1.0000\n",
      "Epoch 320/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.8341e-04 - acc: 1.0000\n",
      "Epoch 321/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.8813e-04 - acc: 1.0000\n",
      "Epoch 322/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.9452e-04 - acc: 1.0000\n",
      "Epoch 323/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.7393e-04 - acc: 1.0000\n",
      "Epoch 324/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.5875e-04 - acc: 1.0000\n",
      "Epoch 325/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.5340e-04 - acc: 1.0000\n",
      "Epoch 326/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.4969e-04 - acc: 1.0000\n",
      "Epoch 327/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.4067e-04 - acc: 1.0000\n",
      "Epoch 328/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.2933e-04 - acc: 1.0000\n",
      "Epoch 329/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 9.1974e-04 - acc: 1.0000\n",
      "Epoch 330/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.1205e-04 - acc: 1.0000\n",
      "Epoch 331/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.0459e-04 - acc: 1.0000\n",
      "Epoch 332/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.9810e-04 - acc: 1.0000\n",
      "Epoch 333/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.9214e-04 - acc: 1.0000\n",
      "Epoch 334/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.8776e-04 - acc: 1.0000\n",
      "Epoch 335/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.8041e-04 - acc: 1.0000\n",
      "Epoch 336/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.7258e-04 - acc: 1.0000\n",
      "Epoch 337/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.6508e-04 - acc: 1.0000\n",
      "Epoch 338/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.5761e-04 - acc: 1.0000\n",
      "Epoch 339/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.5003e-04 - acc: 1.0000\n",
      "Epoch 340/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.5012e-04 - acc: 1.0000\n",
      "Epoch 341/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.5366e-04 - acc: 1.0000\n",
      "Epoch 342/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.4399e-04 - acc: 1.0000\n",
      "Epoch 343/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.3245e-04 - acc: 1.0000\n",
      "Epoch 344/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.2255e-04 - acc: 1.0000\n",
      "Epoch 345/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.2399e-04 - acc: 1.0000\n",
      "Epoch 346/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.4587e-04 - acc: 1.0000\n",
      "Epoch 347/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.6135e-04 - acc: 1.0000\n",
      "Epoch 348/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.3489e-04 - acc: 1.0000\n",
      "Epoch 349/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.1002e-04 - acc: 1.0000\n",
      "Epoch 350/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 7.9639e-04 - acc: 1.0000\n",
      "Epoch 351/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.8406e-04 - acc: 1.0000\n",
      "Epoch 352/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.7555e-04 - acc: 1.0000\n",
      "Epoch 353/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.6828e-04 - acc: 1.0000\n",
      "Epoch 354/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.6168e-04 - acc: 1.0000\n",
      "Epoch 355/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.5417e-04 - acc: 1.0000\n",
      "Epoch 356/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.4703e-04 - acc: 1.0000\n",
      "Epoch 357/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.4062e-04 - acc: 1.0000\n",
      "Epoch 358/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.3448e-04 - acc: 1.0000\n",
      "Epoch 359/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.2883e-04 - acc: 1.0000\n",
      "Epoch 360/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.2438e-04 - acc: 1.0000\n",
      "Epoch 361/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.2256e-04 - acc: 1.0000\n",
      "Epoch 362/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.1791e-04 - acc: 1.0000\n",
      "Epoch 363/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.1087e-04 - acc: 1.0000\n",
      "Epoch 364/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.0413e-04 - acc: 1.0000\n",
      "Epoch 365/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.9958e-04 - acc: 1.0000\n",
      "Epoch 366/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.9680e-04 - acc: 1.0000\n",
      "Epoch 367/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 6.9067e-04 - acc: 1.0000\n",
      "Epoch 368/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.8828e-04 - acc: 1.0000\n",
      "Epoch 369/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.8853e-04 - acc: 1.0000\n",
      "Epoch 370/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.8318e-04 - acc: 1.0000\n",
      "Epoch 371/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.7636e-04 - acc: 1.0000\n",
      "Epoch 372/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.6688e-04 - acc: 1.0000\n",
      "Epoch 373/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.5814e-04 - acc: 1.0000\n",
      "Epoch 374/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.5332e-04 - acc: 1.0000\n",
      "Epoch 375/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.4988e-04 - acc: 1.0000\n",
      "Epoch 376/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.4397e-04 - acc: 1.0000\n",
      "Epoch 377/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.3825e-04 - acc: 1.0000\n",
      "Epoch 378/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 6.3289e-04 - acc: 1.0000\n",
      "Epoch 379/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.2842e-04 - acc: 1.0000\n",
      "Epoch 380/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.2476e-04 - acc: 1.0000\n",
      "Epoch 381/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.2002e-04 - acc: 1.0000\n",
      "Epoch 382/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.1515e-04 - acc: 1.0000\n",
      "Epoch 383/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.0968e-04 - acc: 1.0000\n",
      "Epoch 384/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.0454e-04 - acc: 1.0000\n",
      "Epoch 385/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.9912e-04 - acc: 1.0000\n",
      "Epoch 386/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.9541e-04 - acc: 1.0000\n",
      "Epoch 387/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.9174e-04 - acc: 1.0000\n",
      "Epoch 388/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.8640e-04 - acc: 1.0000\n",
      "Epoch 389/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.8098e-04 - acc: 1.0000\n",
      "Epoch 390/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 5.7612e-04 - acc: 1.0000\n",
      "Epoch 391/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.7555e-04 - acc: 1.0000\n",
      "Epoch 392/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 5.8649e-04 - acc: 1.0000\n",
      "Epoch 393/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.8997e-04 - acc: 1.0000\n",
      "Epoch 394/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.7500e-04 - acc: 1.0000\n",
      "Epoch 395/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.6202e-04 - acc: 1.0000\n",
      "Epoch 396/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.5395e-04 - acc: 1.0000\n",
      "Epoch 397/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.4757e-04 - acc: 1.0000\n",
      "Epoch 398/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.4299e-04 - acc: 1.0000\n",
      "Epoch 399/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.4123e-04 - acc: 1.0000\n",
      "Epoch 400/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.4028e-04 - acc: 1.0000\n",
      "Epoch 401/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.3638e-04 - acc: 1.0000\n",
      "Epoch 402/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.3184e-04 - acc: 1.0000\n",
      "Epoch 403/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.3034e-04 - acc: 1.0000\n",
      "Epoch 404/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.2549e-04 - acc: 1.0000\n",
      "Epoch 405/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.1984e-04 - acc: 1.0000\n",
      "Epoch 406/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.1333e-04 - acc: 1.0000\n",
      "Epoch 407/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.0769e-04 - acc: 1.0000\n",
      "Epoch 408/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.0297e-04 - acc: 1.0000\n",
      "Epoch 409/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.9870e-04 - acc: 1.0000\n",
      "Epoch 410/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.9474e-04 - acc: 1.0000\n",
      "Epoch 411/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.9205e-04 - acc: 1.0000\n",
      "Epoch 412/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.9081e-04 - acc: 1.0000\n",
      "Epoch 413/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 4.8792e-04 - acc: 1.0000\n",
      "Epoch 414/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.8320e-04 - acc: 1.0000\n",
      "Epoch 415/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.7854e-04 - acc: 1.0000\n",
      "Epoch 416/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 4.7624e-04 - acc: 1.0000\n",
      "Epoch 417/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.7853e-04 - acc: 1.0000\n",
      "Epoch 418/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.8148e-04 - acc: 1.0000\n",
      "Epoch 419/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.7424e-04 - acc: 1.0000\n",
      "Epoch 420/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.6610e-04 - acc: 1.0000\n",
      "Epoch 421/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.5961e-04 - acc: 1.0000\n",
      "Epoch 422/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.5847e-04 - acc: 1.0000\n",
      "Epoch 423/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.6164e-04 - acc: 1.0000\n",
      "Epoch 424/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.5554e-04 - acc: 1.0000\n",
      "Epoch 425/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.4826e-04 - acc: 1.0000\n",
      "Epoch 426/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.4255e-04 - acc: 1.0000\n",
      "Epoch 427/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.3767e-04 - acc: 1.0000\n",
      "Epoch 428/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.3357e-04 - acc: 1.0000\n",
      "Epoch 429/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.3031e-04 - acc: 1.0000\n",
      "Epoch 430/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.2893e-04 - acc: 1.0000\n",
      "Epoch 431/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.2782e-04 - acc: 1.0000\n",
      "Epoch 432/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.2315e-04 - acc: 1.0000\n",
      "Epoch 433/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 4.1845e-04 - acc: 1.0000\n",
      "Epoch 434/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.2000e-04 - acc: 1.0000\n",
      "Epoch 435/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.2599e-04 - acc: 1.0000\n",
      "Epoch 436/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.1872e-04 - acc: 1.0000\n",
      "Epoch 437/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.1104e-04 - acc: 1.0000\n",
      "Epoch 438/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.0769e-04 - acc: 1.0000\n",
      "Epoch 439/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.0343e-04 - acc: 1.0000\n",
      "Epoch 440/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.9752e-04 - acc: 1.0000\n",
      "Epoch 441/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.9311e-04 - acc: 1.0000\n",
      "Epoch 442/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.8995e-04 - acc: 1.0000\n",
      "Epoch 443/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.8654e-04 - acc: 1.0000\n",
      "Epoch 444/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.8302e-04 - acc: 1.0000\n",
      "Epoch 445/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7996e-04 - acc: 1.0000\n",
      "Epoch 446/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7726e-04 - acc: 1.0000\n",
      "Epoch 447/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7500e-04 - acc: 1.0000\n",
      "Epoch 448/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7203e-04 - acc: 1.0000\n",
      "Epoch 449/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.6894e-04 - acc: 1.0000\n",
      "Epoch 450/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.6609e-04 - acc: 1.0000\n",
      "Epoch 451/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 3.6324e-04 - acc: 1.0000\n",
      "Epoch 452/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 3.6072e-04 - acc: 1.0000\n",
      "Epoch 453/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 3.5827e-04 - acc: 1.0000\n",
      "Epoch 454/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5567e-04 - acc: 1.0000\n",
      "Epoch 455/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5327e-04 - acc: 1.0000\n",
      "Epoch 456/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5110e-04 - acc: 1.0000\n",
      "Epoch 457/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4833e-04 - acc: 1.0000\n",
      "Epoch 458/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4543e-04 - acc: 1.0000\n",
      "Epoch 459/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4265e-04 - acc: 1.0000\n",
      "Epoch 460/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4043e-04 - acc: 1.0000\n",
      "Epoch 461/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3862e-04 - acc: 1.0000\n",
      "Epoch 462/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3594e-04 - acc: 1.0000\n",
      "Epoch 463/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3387e-04 - acc: 1.0000\n",
      "Epoch 464/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4046e-04 - acc: 1.0000\n",
      "Epoch 465/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4761e-04 - acc: 1.0000\n",
      "Epoch 466/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3952e-04 - acc: 1.0000\n",
      "Epoch 467/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3126e-04 - acc: 1.0000\n",
      "Epoch 468/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.2529e-04 - acc: 1.0000\n",
      "Epoch 469/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.2121e-04 - acc: 1.0000\n",
      "Epoch 470/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1753e-04 - acc: 1.0000\n",
      "Epoch 471/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1422e-04 - acc: 1.0000\n",
      "Epoch 472/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1210e-04 - acc: 1.0000\n",
      "Epoch 473/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1065e-04 - acc: 1.0000\n",
      "Epoch 474/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0789e-04 - acc: 1.0000\n",
      "Epoch 475/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0622e-04 - acc: 1.0000\n",
      "Epoch 476/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0470e-04 - acc: 1.0000\n",
      "Epoch 477/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0247e-04 - acc: 1.0000\n",
      "Epoch 478/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0307e-04 - acc: 1.0000\n",
      "Epoch 479/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0030e-04 - acc: 1.0000\n",
      "Epoch 480/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9790e-04 - acc: 1.0000\n",
      "Epoch 481/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0249e-04 - acc: 1.0000\n",
      "Epoch 482/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0947e-04 - acc: 1.0000\n",
      "Epoch 483/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0178e-04 - acc: 1.0000\n",
      "Epoch 484/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9708e-04 - acc: 1.0000\n",
      "Epoch 485/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9014e-04 - acc: 1.0000\n",
      "Epoch 486/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.8455e-04 - acc: 1.0000\n",
      "Epoch 487/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.7960e-04 - acc: 1.0000\n",
      "Epoch 488/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.7615e-04 - acc: 1.0000\n",
      "Epoch 489/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.7368e-04 - acc: 1.0000\n",
      "Epoch 490/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.7160e-04 - acc: 1.0000\n",
      "Epoch 491/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6899e-04 - acc: 1.0000\n",
      "Epoch 492/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6719e-04 - acc: 1.0000\n",
      "Epoch 493/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6618e-04 - acc: 1.0000\n",
      "Epoch 494/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6599e-04 - acc: 1.0000\n",
      "Epoch 495/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6450e-04 - acc: 1.0000\n",
      "Epoch 496/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.7431e-04 - acc: 1.0000\n",
      "Epoch 497/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9613e-04 - acc: 1.0000\n",
      "Epoch 498/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.8946e-04 - acc: 1.0000\n",
      "Epoch 499/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.7127e-04 - acc: 1.0000\n",
      "Epoch 500/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5966e-04 - acc: 1.0000\n",
      "Epoch 501/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5338e-04 - acc: 1.0000\n",
      "Epoch 502/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5138e-04 - acc: 1.0000\n",
      "Epoch 503/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5182e-04 - acc: 1.0000\n",
      "Epoch 504/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4804e-04 - acc: 1.0000\n",
      "Epoch 505/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4416e-04 - acc: 1.0000\n",
      "Epoch 506/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4196e-04 - acc: 1.0000\n",
      "Epoch 507/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4093e-04 - acc: 1.0000\n",
      "Epoch 508/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3871e-04 - acc: 1.0000\n",
      "Epoch 509/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3601e-04 - acc: 1.0000\n",
      "Epoch 510/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3529e-04 - acc: 1.0000\n",
      "Epoch 511/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3619e-04 - acc: 1.0000\n",
      "Epoch 512/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3275e-04 - acc: 1.0000\n",
      "Epoch 513/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2982e-04 - acc: 1.0000\n",
      "Epoch 514/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2735e-04 - acc: 1.0000\n",
      "Epoch 515/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2517e-04 - acc: 1.0000\n",
      "Epoch 516/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2325e-04 - acc: 1.0000\n",
      "Epoch 517/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2159e-04 - acc: 1.0000\n",
      "Epoch 518/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1988e-04 - acc: 1.0000\n",
      "Epoch 519/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1807e-04 - acc: 1.0000\n",
      "Epoch 520/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1642e-04 - acc: 1.0000\n",
      "Epoch 521/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1484e-04 - acc: 1.0000\n",
      "Epoch 522/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1325e-04 - acc: 1.0000\n",
      "Epoch 523/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1172e-04 - acc: 1.0000\n",
      "Epoch 524/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1024e-04 - acc: 1.0000\n",
      "Epoch 525/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0885e-04 - acc: 1.0000\n",
      "Epoch 526/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0750e-04 - acc: 1.0000\n",
      "Epoch 527/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0738e-04 - acc: 1.0000\n",
      "Epoch 528/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0968e-04 - acc: 1.0000\n",
      "Epoch 529/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0880e-04 - acc: 1.0000\n",
      "Epoch 530/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0820e-04 - acc: 1.0000\n",
      "Epoch 531/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1160e-04 - acc: 1.0000\n",
      "Epoch 532/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0814e-04 - acc: 1.0000\n",
      "Epoch 533/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0461e-04 - acc: 1.0000\n",
      "Epoch 534/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9978e-04 - acc: 1.0000\n",
      "Epoch 535/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9677e-04 - acc: 1.0000\n",
      "Epoch 536/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9512e-04 - acc: 1.0000\n",
      "Epoch 537/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9278e-04 - acc: 1.0000\n",
      "Epoch 538/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9068e-04 - acc: 1.0000\n",
      "Epoch 539/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8885e-04 - acc: 1.0000\n",
      "Epoch 540/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8779e-04 - acc: 1.0000\n",
      "Epoch 541/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8714e-04 - acc: 1.0000\n",
      "Epoch 542/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8655e-04 - acc: 1.0000\n",
      "Epoch 543/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8631e-04 - acc: 1.0000\n",
      "Epoch 544/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8458e-04 - acc: 1.0000\n",
      "Epoch 545/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8267e-04 - acc: 1.0000\n",
      "Epoch 546/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8150e-04 - acc: 1.0000\n",
      "Epoch 547/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8171e-04 - acc: 1.0000\n",
      "Epoch 548/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8520e-04 - acc: 1.0000\n",
      "Epoch 549/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8729e-04 - acc: 1.0000\n",
      "Epoch 550/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8469e-04 - acc: 1.0000\n",
      "Epoch 551/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7995e-04 - acc: 1.0000\n",
      "Epoch 552/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7540e-04 - acc: 1.0000\n",
      "Epoch 553/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 1.7176e-04 - acc: 1.0000\n",
      "Epoch 554/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6931e-04 - acc: 1.0000\n",
      "Epoch 555/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6784e-04 - acc: 1.0000\n",
      "Epoch 556/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6653e-04 - acc: 1.0000\n",
      "Epoch 557/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6584e-04 - acc: 1.0000\n",
      "Epoch 558/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6607e-04 - acc: 1.0000\n",
      "Epoch 559/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6948e-04 - acc: 1.0000\n",
      "Epoch 560/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7522e-04 - acc: 1.0000\n",
      "Epoch 561/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6917e-04 - acc: 1.0000\n",
      "Epoch 562/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6336e-04 - acc: 1.0000\n",
      "Epoch 563/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6036e-04 - acc: 1.0000\n",
      "Epoch 564/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5822e-04 - acc: 1.0000\n",
      "Epoch 565/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5655e-04 - acc: 1.0000\n",
      "Epoch 566/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5480e-04 - acc: 1.0000\n",
      "Epoch 567/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5334e-04 - acc: 1.0000\n",
      "Epoch 568/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5207e-04 - acc: 1.0000\n",
      "Epoch 569/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5084e-04 - acc: 1.0000\n",
      "Epoch 570/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4978e-04 - acc: 1.0000\n",
      "Epoch 571/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4965e-04 - acc: 1.0000\n",
      "Epoch 572/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4940e-04 - acc: 1.0000\n",
      "Epoch 573/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4743e-04 - acc: 1.0000\n",
      "Epoch 574/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4717e-04 - acc: 1.0000\n",
      "Epoch 575/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4858e-04 - acc: 1.0000\n",
      "Epoch 576/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4698e-04 - acc: 1.0000\n",
      "Epoch 577/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4465e-04 - acc: 1.0000\n",
      "Epoch 578/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4262e-04 - acc: 1.0000\n",
      "Epoch 579/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4104e-04 - acc: 1.0000\n",
      "Epoch 580/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3996e-04 - acc: 1.0000\n",
      "Epoch 581/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3888e-04 - acc: 1.0000\n",
      "Epoch 582/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3776e-04 - acc: 1.0000\n",
      "Epoch 583/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3653e-04 - acc: 1.0000\n",
      "Epoch 584/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3543e-04 - acc: 1.0000\n",
      "Epoch 585/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3476e-04 - acc: 1.0000\n",
      "Epoch 586/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3466e-04 - acc: 1.0000\n",
      "Epoch 587/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3357e-04 - acc: 1.0000\n",
      "Epoch 588/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3222e-04 - acc: 1.0000\n",
      "Epoch 589/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3114e-04 - acc: 1.0000\n",
      "Epoch 590/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3012e-04 - acc: 1.0000\n",
      "Epoch 591/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3631e-04 - acc: 1.0000\n",
      "Epoch 592/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4879e-04 - acc: 1.0000\n",
      "Epoch 593/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3448e-04 - acc: 1.0000\n",
      "Epoch 594/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2944e-04 - acc: 1.0000\n",
      "Epoch 595/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2732e-04 - acc: 1.0000\n",
      "Epoch 596/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2568e-04 - acc: 1.0000\n",
      "Epoch 597/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2460e-04 - acc: 1.0000\n",
      "Epoch 598/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2350e-04 - acc: 1.0000\n",
      "Epoch 599/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2244e-04 - acc: 1.0000\n",
      "Epoch 600/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2154e-04 - acc: 1.0000\n",
      "Epoch 601/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2075e-04 - acc: 1.0000\n",
      "Epoch 602/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2081e-04 - acc: 1.0000\n",
      "Epoch 603/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2118e-04 - acc: 1.0000\n",
      "Epoch 604/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2010e-04 - acc: 1.0000\n",
      "Epoch 605/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1839e-04 - acc: 1.0000\n",
      "Epoch 606/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1696e-04 - acc: 1.0000\n",
      "Epoch 607/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1573e-04 - acc: 1.0000\n",
      "Epoch 608/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1460e-04 - acc: 1.0000\n",
      "Epoch 609/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1363e-04 - acc: 1.0000\n",
      "Epoch 610/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1269e-04 - acc: 1.0000\n",
      "Epoch 611/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1185e-04 - acc: 1.0000\n",
      "Epoch 612/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1121e-04 - acc: 1.0000\n",
      "Epoch 613/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1044e-04 - acc: 1.0000\n",
      "Epoch 614/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0969e-04 - acc: 1.0000\n",
      "Epoch 615/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0902e-04 - acc: 1.0000\n",
      "Epoch 616/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0831e-04 - acc: 1.0000\n",
      "Epoch 617/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0755e-04 - acc: 1.0000\n",
      "Epoch 618/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0670e-04 - acc: 1.0000\n",
      "Epoch 619/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0763e-04 - acc: 1.0000\n",
      "Epoch 620/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1050e-04 - acc: 1.0000\n",
      "Epoch 621/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0884e-04 - acc: 1.0000\n",
      "Epoch 622/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0692e-04 - acc: 1.0000\n",
      "Epoch 623/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0516e-04 - acc: 1.0000\n",
      "Epoch 624/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0369e-04 - acc: 1.0000\n",
      "Epoch 625/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0267e-04 - acc: 1.0000\n",
      "Epoch 626/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0154e-04 - acc: 1.0000\n",
      "Epoch 627/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0051e-04 - acc: 1.0000\n",
      "Epoch 628/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.9836e-05 - acc: 1.0000\n",
      "Epoch 629/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.9526e-05 - acc: 1.0000\n",
      "Epoch 630/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.9704e-05 - acc: 1.0000\n",
      "Epoch 631/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0261e-04 - acc: 1.0000\n",
      "Epoch 632/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0199e-04 - acc: 1.0000\n",
      "Epoch 633/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.9198e-05 - acc: 1.0000\n",
      "Epoch 634/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.7483e-05 - acc: 1.0000\n",
      "Epoch 635/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.6352e-05 - acc: 1.0000\n",
      "Epoch 636/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.4893e-05 - acc: 1.0000\n",
      "Epoch 637/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.3753e-05 - acc: 1.0000\n",
      "Epoch 638/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.3873e-05 - acc: 1.0000\n",
      "Epoch 639/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.4918e-05 - acc: 1.0000\n",
      "Epoch 640/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.3391e-05 - acc: 1.0000\n",
      "Epoch 641/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.1583e-05 - acc: 1.0000\n",
      "Epoch 642/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.0304e-05 - acc: 1.0000\n",
      "Epoch 643/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.9374e-05 - acc: 1.0000\n",
      "Epoch 644/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.8604e-05 - acc: 1.0000\n",
      "Epoch 645/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.7946e-05 - acc: 1.0000\n",
      "Epoch 646/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.7584e-05 - acc: 1.0000\n",
      "Epoch 647/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.7516e-05 - acc: 1.0000\n",
      "Epoch 648/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.6790e-05 - acc: 1.0000\n",
      "Epoch 649/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.6007e-05 - acc: 1.0000\n",
      "Epoch 650/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.6035e-05 - acc: 1.0000\n",
      "Epoch 651/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.8800e-05 - acc: 1.0000\n",
      "Epoch 652/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.0677e-05 - acc: 1.0000\n",
      "Epoch 653/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.7296e-05 - acc: 1.0000\n",
      "Epoch 654/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.4737e-05 - acc: 1.0000\n",
      "Epoch 655/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.3789e-05 - acc: 1.0000\n",
      "Epoch 656/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.3079e-05 - acc: 1.0000\n",
      "Epoch 657/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.2972e-05 - acc: 1.0000\n",
      "Epoch 658/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.2542e-05 - acc: 1.0000\n",
      "Epoch 659/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.1296e-05 - acc: 1.0000\n",
      "Epoch 660/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.0062e-05 - acc: 1.0000\n",
      "Epoch 661/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.9586e-05 - acc: 1.0000\n",
      "Epoch 662/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.9706e-05 - acc: 1.0000\n",
      "Epoch 663/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.8912e-05 - acc: 1.0000\n",
      "Epoch 664/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.7779e-05 - acc: 1.0000\n",
      "Epoch 665/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.6841e-05 - acc: 1.0000\n",
      "Epoch 666/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.6095e-05 - acc: 1.0000\n",
      "Epoch 667/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.5490e-05 - acc: 1.0000\n",
      "Epoch 668/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.4962e-05 - acc: 1.0000\n",
      "Epoch 669/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.4496e-05 - acc: 1.0000\n",
      "Epoch 670/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.3965e-05 - acc: 1.0000\n",
      "Epoch 671/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.4204e-05 - acc: 1.0000\n",
      "Epoch 672/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.5012e-05 - acc: 1.0000\n",
      "Epoch 673/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 7.4166e-05 - acc: 1.0000\n",
      "Epoch 674/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.3161e-05 - acc: 1.0000\n",
      "Epoch 675/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.2088e-05 - acc: 1.0000\n",
      "Epoch 676/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.1256e-05 - acc: 1.0000\n",
      "Epoch 677/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.0602e-05 - acc: 1.0000\n",
      "Epoch 678/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.0078e-05 - acc: 1.0000\n",
      "Epoch 679/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.9562e-05 - acc: 1.0000\n",
      "Epoch 680/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.9079e-05 - acc: 1.0000\n",
      "Epoch 681/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.0283e-05 - acc: 1.0000\n",
      "Epoch 682/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.2549e-05 - acc: 1.0000\n",
      "Epoch 683/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 7.1124e-05 - acc: 1.0000\n",
      "Epoch 684/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.9314e-05 - acc: 1.0000\n",
      "Epoch 685/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.8396e-05 - acc: 1.0000\n",
      "Epoch 686/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.7432e-05 - acc: 1.0000\n",
      "Epoch 687/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 6.7542e-05 - acc: 1.0000\n",
      "Epoch 688/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.8583e-05 - acc: 1.0000\n",
      "Epoch 689/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.7126e-05 - acc: 1.0000\n",
      "Epoch 690/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.5510e-05 - acc: 1.0000\n",
      "Epoch 691/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.4501e-05 - acc: 1.0000\n",
      "Epoch 692/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.3823e-05 - acc: 1.0000\n",
      "Epoch 693/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.3280e-05 - acc: 1.0000\n",
      "Epoch 694/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.2759e-05 - acc: 1.0000\n",
      "Epoch 695/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.2302e-05 - acc: 1.0000\n",
      "Epoch 696/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.1941e-05 - acc: 1.0000\n",
      "Epoch 697/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.1548e-05 - acc: 1.0000\n",
      "Epoch 698/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.1118e-05 - acc: 1.0000\n",
      "Epoch 699/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.0705e-05 - acc: 1.0000\n",
      "Epoch 700/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 6.0304e-05 - acc: 1.0000\n",
      "Epoch 701/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.9958e-05 - acc: 1.0000\n",
      "Epoch 702/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.9589e-05 - acc: 1.0000\n",
      "Epoch 703/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.9316e-05 - acc: 1.0000\n",
      "Epoch 704/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.8915e-05 - acc: 1.0000\n",
      "Epoch 705/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.8483e-05 - acc: 1.0000\n",
      "Epoch 706/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.8078e-05 - acc: 1.0000\n",
      "Epoch 707/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.7894e-05 - acc: 1.0000\n",
      "Epoch 708/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.7871e-05 - acc: 1.0000\n",
      "Epoch 709/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.7351e-05 - acc: 1.0000\n",
      "Epoch 710/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.6948e-05 - acc: 1.0000\n",
      "Epoch 711/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.6620e-05 - acc: 1.0000\n",
      "Epoch 712/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.6153e-05 - acc: 1.0000\n",
      "Epoch 713/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.5606e-05 - acc: 1.0000\n",
      "Epoch 714/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.5092e-05 - acc: 1.0000\n",
      "Epoch 715/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.6492e-05 - acc: 1.0000\n",
      "Epoch 716/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.9566e-05 - acc: 1.0000\n",
      "Epoch 717/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.7454e-05 - acc: 1.0000\n",
      "Epoch 718/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.5231e-05 - acc: 1.0000\n",
      "Epoch 719/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.3881e-05 - acc: 1.0000\n",
      "Epoch 720/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.3056e-05 - acc: 1.0000\n",
      "Epoch 721/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.2375e-05 - acc: 1.0000\n",
      "Epoch 722/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.1862e-05 - acc: 1.0000\n",
      "Epoch 723/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.1501e-05 - acc: 1.0000\n",
      "Epoch 724/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.1246e-05 - acc: 1.0000\n",
      "Epoch 725/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.1092e-05 - acc: 1.0000\n",
      "Epoch 726/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.1096e-05 - acc: 1.0000\n",
      "Epoch 727/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.0647e-05 - acc: 1.0000\n",
      "Epoch 728/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.0277e-05 - acc: 1.0000\n",
      "Epoch 729/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.0427e-05 - acc: 1.0000\n",
      "Epoch 730/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 5.0500e-05 - acc: 1.0000\n",
      "Epoch 731/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.9712e-05 - acc: 1.0000\n",
      "Epoch 732/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.9071e-05 - acc: 1.0000\n",
      "Epoch 733/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.8622e-05 - acc: 1.0000\n",
      "Epoch 734/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.8112e-05 - acc: 1.0000\n",
      "Epoch 735/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.7647e-05 - acc: 1.0000\n",
      "Epoch 736/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.7245e-05 - acc: 1.0000\n",
      "Epoch 737/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.7004e-05 - acc: 1.0000\n",
      "Epoch 738/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.7000e-05 - acc: 1.0000\n",
      "Epoch 739/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.6982e-05 - acc: 1.0000\n",
      "Epoch 740/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.6475e-05 - acc: 1.0000\n",
      "Epoch 741/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.5932e-05 - acc: 1.0000\n",
      "Epoch 742/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.5516e-05 - acc: 1.0000\n",
      "Epoch 743/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.5124e-05 - acc: 1.0000\n",
      "Epoch 744/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.4743e-05 - acc: 1.0000\n",
      "Epoch 745/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.4400e-05 - acc: 1.0000\n",
      "Epoch 746/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.4130e-05 - acc: 1.0000\n",
      "Epoch 747/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.3857e-05 - acc: 1.0000\n",
      "Epoch 748/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.3538e-05 - acc: 1.0000\n",
      "Epoch 749/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.3415e-05 - acc: 1.0000\n",
      "Epoch 750/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.3535e-05 - acc: 1.0000\n",
      "Epoch 751/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.3207e-05 - acc: 1.0000\n",
      "Epoch 752/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.2715e-05 - acc: 1.0000\n",
      "Epoch 753/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.2283e-05 - acc: 1.0000\n",
      "Epoch 754/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.1943e-05 - acc: 1.0000\n",
      "Epoch 755/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.1650e-05 - acc: 1.0000\n",
      "Epoch 756/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.1375e-05 - acc: 1.0000\n",
      "Epoch 757/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.1137e-05 - acc: 1.0000\n",
      "Epoch 758/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.1024e-05 - acc: 1.0000\n",
      "Epoch 759/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.0983e-05 - acc: 1.0000\n",
      "Epoch 760/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.0625e-05 - acc: 1.0000\n",
      "Epoch 761/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 4.0187e-05 - acc: 1.0000\n",
      "Epoch 762/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.9796e-05 - acc: 1.0000\n",
      "Epoch 763/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.9461e-05 - acc: 1.0000\n",
      "Epoch 764/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.9157e-05 - acc: 1.0000\n",
      "Epoch 765/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.8972e-05 - acc: 1.0000\n",
      "Epoch 766/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.8952e-05 - acc: 1.0000\n",
      "Epoch 767/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.8681e-05 - acc: 1.0000\n",
      "Epoch 768/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.8369e-05 - acc: 1.0000\n",
      "Epoch 769/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.8032e-05 - acc: 1.0000\n",
      "Epoch 770/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7723e-05 - acc: 1.0000\n",
      "Epoch 771/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7439e-05 - acc: 1.0000\n",
      "Epoch 772/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7381e-05 - acc: 1.0000\n",
      "Epoch 773/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7598e-05 - acc: 1.0000\n",
      "Epoch 774/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.7436e-05 - acc: 1.0000\n",
      "Epoch 775/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.6973e-05 - acc: 1.0000\n",
      "Epoch 776/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.6503e-05 - acc: 1.0000\n",
      "Epoch 777/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.6127e-05 - acc: 1.0000\n",
      "Epoch 778/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5804e-05 - acc: 1.0000\n",
      "Epoch 779/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5560e-05 - acc: 1.0000\n",
      "Epoch 780/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5342e-05 - acc: 1.0000\n",
      "Epoch 781/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5084e-05 - acc: 1.0000\n",
      "Epoch 782/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4961e-05 - acc: 1.0000\n",
      "Epoch 783/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5006e-05 - acc: 1.0000\n",
      "Epoch 784/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4724e-05 - acc: 1.0000\n",
      "Epoch 785/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4343e-05 - acc: 1.0000\n",
      "Epoch 786/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.4027e-05 - acc: 1.0000\n",
      "Epoch 787/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3788e-05 - acc: 1.0000\n",
      "Epoch 788/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3563e-05 - acc: 1.0000\n",
      "Epoch 789/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3335e-05 - acc: 1.0000\n",
      "Epoch 790/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.3152e-05 - acc: 1.0000\n",
      "Epoch 791/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.2909e-05 - acc: 1.0000\n",
      "Epoch 792/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.2682e-05 - acc: 1.0000\n",
      "Epoch 793/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 3.2447e-05 - acc: 1.0000\n",
      "Epoch 794/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.2231e-05 - acc: 1.0000\n",
      "Epoch 795/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.2022e-05 - acc: 1.0000\n",
      "Epoch 796/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1818e-05 - acc: 1.0000\n",
      "Epoch 797/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1675e-05 - acc: 1.0000\n",
      "Epoch 798/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1525e-05 - acc: 1.0000\n",
      "Epoch 799/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1310e-05 - acc: 1.0000\n",
      "Epoch 800/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1207e-05 - acc: 1.0000\n",
      "Epoch 801/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1373e-05 - acc: 1.0000\n",
      "Epoch 802/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1347e-05 - acc: 1.0000\n",
      "Epoch 803/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1009e-05 - acc: 1.0000\n",
      "Epoch 804/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0533e-05 - acc: 1.0000\n",
      "Epoch 805/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.0170e-05 - acc: 1.0000\n",
      "Epoch 806/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9921e-05 - acc: 1.0000\n",
      "Epoch 807/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9786e-05 - acc: 1.0000\n",
      "Epoch 808/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9648e-05 - acc: 1.0000\n",
      "Epoch 809/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9353e-05 - acc: 1.0000\n",
      "Epoch 810/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9070e-05 - acc: 1.0000\n",
      "Epoch 811/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.8822e-05 - acc: 1.0000\n",
      "Epoch 812/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.8608e-05 - acc: 1.0000\n",
      "Epoch 813/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.8399e-05 - acc: 1.0000\n",
      "Epoch 814/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.8190e-05 - acc: 1.0000\n",
      "Epoch 815/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1093e-05 - acc: 1.0000\n",
      "Epoch 816/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.5823e-05 - acc: 1.0000\n",
      "Epoch 817/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 3.1691e-05 - acc: 1.0000\n",
      "Epoch 818/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.9332e-05 - acc: 1.0000\n",
      "Epoch 819/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.8317e-05 - acc: 1.0000\n",
      "Epoch 820/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.7748e-05 - acc: 1.0000\n",
      "Epoch 821/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.7253e-05 - acc: 1.0000\n",
      "Epoch 822/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6872e-05 - acc: 1.0000\n",
      "Epoch 823/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6577e-05 - acc: 1.0000\n",
      "Epoch 824/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6358e-05 - acc: 1.0000\n",
      "Epoch 825/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.6141e-05 - acc: 1.0000\n",
      "Epoch 826/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5959e-05 - acc: 1.0000\n",
      "Epoch 827/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5828e-05 - acc: 1.0000\n",
      "Epoch 828/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5680e-05 - acc: 1.0000\n",
      "Epoch 829/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5470e-05 - acc: 1.0000\n",
      "Epoch 830/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5289e-05 - acc: 1.0000\n",
      "Epoch 831/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5205e-05 - acc: 1.0000\n",
      "Epoch 832/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.5038e-05 - acc: 1.0000\n",
      "Epoch 833/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4821e-05 - acc: 1.0000\n",
      "Epoch 834/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4600e-05 - acc: 1.0000\n",
      "Epoch 835/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4418e-05 - acc: 1.0000\n",
      "Epoch 836/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4319e-05 - acc: 1.0000\n",
      "Epoch 837/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4302e-05 - acc: 1.0000\n",
      "Epoch 838/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.4123e-05 - acc: 1.0000\n",
      "Epoch 839/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3971e-05 - acc: 1.0000\n",
      "Epoch 840/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3891e-05 - acc: 1.0000\n",
      "Epoch 841/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3682e-05 - acc: 1.0000\n",
      "Epoch 842/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3436e-05 - acc: 1.0000\n",
      "Epoch 843/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3240e-05 - acc: 1.0000\n",
      "Epoch 844/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3125e-05 - acc: 1.0000\n",
      "Epoch 845/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.3002e-05 - acc: 1.0000\n",
      "Epoch 846/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2798e-05 - acc: 1.0000\n",
      "Epoch 847/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2588e-05 - acc: 1.0000\n",
      "Epoch 848/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2409e-05 - acc: 1.0000\n",
      "Epoch 849/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2340e-05 - acc: 1.0000\n",
      "Epoch 850/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2314e-05 - acc: 1.0000\n",
      "Epoch 851/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.2149e-05 - acc: 1.0000\n",
      "Epoch 852/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1951e-05 - acc: 1.0000\n",
      "Epoch 853/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1760e-05 - acc: 1.0000\n",
      "Epoch 854/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1587e-05 - acc: 1.0000\n",
      "Epoch 855/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1439e-05 - acc: 1.0000\n",
      "Epoch 856/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1316e-05 - acc: 1.0000\n",
      "Epoch 857/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1321e-05 - acc: 1.0000\n",
      "Epoch 858/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1495e-05 - acc: 1.0000\n",
      "Epoch 859/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1437e-05 - acc: 1.0000\n",
      "Epoch 860/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1366e-05 - acc: 1.0000\n",
      "Epoch 861/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.1099e-05 - acc: 1.0000\n",
      "Epoch 862/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0812e-05 - acc: 1.0000\n",
      "Epoch 863/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0578e-05 - acc: 1.0000\n",
      "Epoch 864/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0342e-05 - acc: 1.0000\n",
      "Epoch 865/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0143e-05 - acc: 1.0000\n",
      "Epoch 866/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9976e-05 - acc: 1.0000\n",
      "Epoch 867/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9909e-05 - acc: 1.0000\n",
      "Epoch 868/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9928e-05 - acc: 1.0000\n",
      "Epoch 869/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0199e-05 - acc: 1.0000\n",
      "Epoch 870/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 2.0926e-05 - acc: 1.0000\n",
      "Epoch 871/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9992e-05 - acc: 1.0000\n",
      "Epoch 872/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9671e-05 - acc: 1.0000\n",
      "Epoch 873/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9438e-05 - acc: 1.0000\n",
      "Epoch 874/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.9159e-05 - acc: 1.0000\n",
      "Epoch 875/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8927e-05 - acc: 1.0000\n",
      "Epoch 876/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8750e-05 - acc: 1.0000\n",
      "Epoch 877/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8624e-05 - acc: 1.0000\n",
      "Epoch 878/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8477e-05 - acc: 1.0000\n",
      "Epoch 879/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8388e-05 - acc: 1.0000\n",
      "Epoch 880/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8384e-05 - acc: 1.0000\n",
      "Epoch 881/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8280e-05 - acc: 1.0000\n",
      "Epoch 882/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.8150e-05 - acc: 1.0000\n",
      "Epoch 883/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7947e-05 - acc: 1.0000\n",
      "Epoch 884/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7763e-05 - acc: 1.0000\n",
      "Epoch 885/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7618e-05 - acc: 1.0000\n",
      "Epoch 886/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7487e-05 - acc: 1.0000\n",
      "Epoch 887/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7398e-05 - acc: 1.0000\n",
      "Epoch 888/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7318e-05 - acc: 1.0000\n",
      "Epoch 889/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7224e-05 - acc: 1.0000\n",
      "Epoch 890/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.7138e-05 - acc: 1.0000\n",
      "Epoch 891/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6997e-05 - acc: 1.0000\n",
      "Epoch 892/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6859e-05 - acc: 1.0000\n",
      "Epoch 893/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 1.6728e-05 - acc: 1.0000\n",
      "Epoch 894/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6702e-05 - acc: 1.0000\n",
      "Epoch 895/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6736e-05 - acc: 1.0000\n",
      "Epoch 896/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6594e-05 - acc: 1.0000\n",
      "Epoch 897/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6432e-05 - acc: 1.0000\n",
      "Epoch 898/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6266e-05 - acc: 1.0000\n",
      "Epoch 899/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6158e-05 - acc: 1.0000\n",
      "Epoch 900/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6117e-05 - acc: 1.0000\n",
      "Epoch 901/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6039e-05 - acc: 1.0000\n",
      "Epoch 902/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5942e-05 - acc: 1.0000\n",
      "Epoch 903/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6092e-05 - acc: 1.0000\n",
      "Epoch 904/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6467e-05 - acc: 1.0000\n",
      "Epoch 905/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.6231e-05 - acc: 1.0000\n",
      "Epoch 906/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5964e-05 - acc: 1.0000\n",
      "Epoch 907/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5788e-05 - acc: 1.0000\n",
      "Epoch 908/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5531e-05 - acc: 1.0000\n",
      "Epoch 909/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5534e-05 - acc: 1.0000\n",
      "Epoch 910/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5892e-05 - acc: 1.0000\n",
      "Epoch 911/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5639e-05 - acc: 1.0000\n",
      "Epoch 912/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.5269e-05 - acc: 1.0000\n",
      "Epoch 913/1000\n",
      "10001/10001 [==============================] - 0s 5us/step - loss: 1.4950e-05 - acc: 1.0000\n",
      "Epoch 914/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4712e-05 - acc: 1.0000\n",
      "Epoch 915/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4551e-05 - acc: 1.0000\n",
      "Epoch 916/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4402e-05 - acc: 1.0000\n",
      "Epoch 917/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4339e-05 - acc: 1.0000\n",
      "Epoch 918/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4359e-05 - acc: 1.0000\n",
      "Epoch 919/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4301e-05 - acc: 1.0000\n",
      "Epoch 920/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4469e-05 - acc: 1.0000\n",
      "Epoch 921/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4701e-05 - acc: 1.0000\n",
      "Epoch 922/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.4340e-05 - acc: 1.0000\n",
      "Epoch 923/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3984e-05 - acc: 1.0000\n",
      "Epoch 924/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3732e-05 - acc: 1.0000\n",
      "Epoch 925/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3560e-05 - acc: 1.0000\n",
      "Epoch 926/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3425e-05 - acc: 1.0000\n",
      "Epoch 927/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3318e-05 - acc: 1.0000\n",
      "Epoch 928/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3245e-05 - acc: 1.0000\n",
      "Epoch 929/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3167e-05 - acc: 1.0000\n",
      "Epoch 930/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.3076e-05 - acc: 1.0000\n",
      "Epoch 931/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2980e-05 - acc: 1.0000\n",
      "Epoch 932/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2903e-05 - acc: 1.0000\n",
      "Epoch 933/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2936e-05 - acc: 1.0000\n",
      "Epoch 934/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2977e-05 - acc: 1.0000\n",
      "Epoch 935/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2837e-05 - acc: 1.0000\n",
      "Epoch 936/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2722e-05 - acc: 1.0000\n",
      "Epoch 937/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2660e-05 - acc: 1.0000\n",
      "Epoch 938/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2539e-05 - acc: 1.0000\n",
      "Epoch 939/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2411e-05 - acc: 1.0000\n",
      "Epoch 940/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2296e-05 - acc: 1.0000\n",
      "Epoch 941/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2206e-05 - acc: 1.0000\n",
      "Epoch 942/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2144e-05 - acc: 1.0000\n",
      "Epoch 943/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.2062e-05 - acc: 1.0000\n",
      "Epoch 944/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1973e-05 - acc: 1.0000\n",
      "Epoch 945/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1886e-05 - acc: 1.0000\n",
      "Epoch 946/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1804e-05 - acc: 1.0000\n",
      "Epoch 947/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1728e-05 - acc: 1.0000\n",
      "Epoch 948/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1646e-05 - acc: 1.0000\n",
      "Epoch 949/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1564e-05 - acc: 1.0000\n",
      "Epoch 950/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1482e-05 - acc: 1.0000\n",
      "Epoch 951/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1430e-05 - acc: 1.0000\n",
      "Epoch 952/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1391e-05 - acc: 1.0000\n",
      "Epoch 953/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1318e-05 - acc: 1.0000\n",
      "Epoch 954/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1230e-05 - acc: 1.0000\n",
      "Epoch 955/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1160e-05 - acc: 1.0000\n",
      "Epoch 956/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.1075e-05 - acc: 1.0000\n",
      "Epoch 957/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0998e-05 - acc: 1.0000\n",
      "Epoch 958/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0922e-05 - acc: 1.0000\n",
      "Epoch 959/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0848e-05 - acc: 1.0000\n",
      "Epoch 960/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0780e-05 - acc: 1.0000\n",
      "Epoch 961/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0714e-05 - acc: 1.0000\n",
      "Epoch 962/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0652e-05 - acc: 1.0000\n",
      "Epoch 963/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0600e-05 - acc: 1.0000\n",
      "Epoch 964/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0533e-05 - acc: 1.0000\n",
      "Epoch 965/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0469e-05 - acc: 1.0000\n",
      "Epoch 966/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0410e-05 - acc: 1.0000\n",
      "Epoch 967/1000\n",
      "10001/10001 [==============================] - 0s 8us/step - loss: 1.0347e-05 - acc: 1.0000\n",
      "Epoch 968/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0301e-05 - acc: 1.0000\n",
      "Epoch 969/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0238e-05 - acc: 1.0000\n",
      "Epoch 970/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0200e-05 - acc: 1.0000\n",
      "Epoch 971/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0147e-05 - acc: 1.0000\n",
      "Epoch 972/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0077e-05 - acc: 1.0000\n",
      "Epoch 973/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0140e-05 - acc: 1.0000\n",
      "Epoch 974/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0189e-05 - acc: 1.0000\n",
      "Epoch 975/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 1.0028e-05 - acc: 1.0000\n",
      "Epoch 976/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.8678e-06 - acc: 1.0000\n",
      "Epoch 977/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.7587e-06 - acc: 1.0000\n",
      "Epoch 978/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.6826e-06 - acc: 1.0000\n",
      "Epoch 979/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.6057e-06 - acc: 1.0000\n",
      "Epoch 980/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.5686e-06 - acc: 1.0000\n",
      "Epoch 981/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.5602e-06 - acc: 1.0000\n",
      "Epoch 982/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.4908e-06 - acc: 1.0000\n",
      "Epoch 983/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.4783e-06 - acc: 1.0000\n",
      "Epoch 984/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.4814e-06 - acc: 1.0000\n",
      "Epoch 985/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.3720e-06 - acc: 1.0000\n",
      "Epoch 986/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.2490e-06 - acc: 1.0000\n",
      "Epoch 987/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.1497e-06 - acc: 1.0000\n",
      "Epoch 988/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.0695e-06 - acc: 1.0000\n",
      "Epoch 989/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 9.0486e-06 - acc: 1.0000\n",
      "Epoch 990/1000\n",
      "10001/10001 [==============================] - 0s 6us/step - loss: 9.0618e-06 - acc: 1.0000\n",
      "Epoch 991/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.9984e-06 - acc: 1.0000\n",
      "Epoch 992/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.9195e-06 - acc: 1.0000\n",
      "Epoch 993/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.8750e-06 - acc: 1.0000\n",
      "Epoch 994/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.7863e-06 - acc: 1.0000\n",
      "Epoch 995/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.7055e-06 - acc: 1.0000\n",
      "Epoch 996/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.6503e-06 - acc: 1.0000\n",
      "Epoch 997/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.5966e-06 - acc: 1.0000\n",
      "Epoch 998/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.5310e-06 - acc: 1.0000\n",
      "Epoch 999/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.4808e-06 - acc: 1.0000\n",
      "Epoch 1000/1000\n",
      "10001/10001 [==============================] - 0s 4us/step - loss: 8.4266e-06 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb396a6ba8>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, label_equalsize, epochs=1000, batch_size= 1000)\n",
    "#repeat a lot of time to get 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciphertext, ciphernum, plainnum = caeserde_1(\"He\")\n",
    "\n",
    "a = letter_position_matrix(plainnum)\n",
    "b = letter_position_matrix(ciphernum)\n",
    "\n",
    "label_smaller1 = np.array(plainnum)\n",
    "# flatten label and training set\n",
    "label_equalsize1 = a.flatten()\n",
    "train1 = b.flatten()\n",
    "train1 = np.vstack([train1,b.flatten()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1[0].reshape(2,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6822090e-07, 0.0000000e+00, 0.0000000e+00, 1.1026859e-06,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.5765429e-05, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        3.1888485e-06, 1.4901161e-07, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 9.0897083e-06, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.9999219e-01,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [2.9802322e-07, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0430813e-06, 0.0000000e+00, 4.7683716e-07, 9.9999994e-01,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.4901161e-07, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 5.9604645e-08, 0.0000000e+00, 0.0000000e+00,\n",
       "        2.9802322e-08, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train)[0].reshape(2,26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2/2 [==============================] - 0s 207ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(train1, np.vstack([label_equalsize1,b.flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 96.15%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_equalsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_equalsize.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  5],\n",
       "       [24,  9],\n",
       "       [15,  8],\n",
       "       ...,\n",
       "       [23, 15],\n",
       "       [17, 13],\n",
       "       [ 0,  7]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xihajun/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/xihajun/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  import sys\n",
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, activation=\"relu\", return_sequences=True, input_shape=(None, 26))`\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <tensorflow.python.keras.optimizers.Adam object at 0xb2d2b2978>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1d7996b87ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         raise ValueError('Could not interpret optimizer identifier: ' +\n\u001b[0;32m--> 801\u001b[0;31m                          str(identifier))\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizers.Adam object at 0xb2d2b2978>"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM#, CuDNNLSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# IF you are running with a GPU, try out the CuDNNLSTM layer type instead (don't pass an activation, tanh is required)\n",
    "model.add(LSTM(128, input_dim=26, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "784px",
    "left": "29px",
    "top": "170px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
