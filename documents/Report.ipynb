{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprocess(datalist):\n",
    "    for i in datalist:\n",
    "        temp = []\n",
    "        for j in range(26):\n",
    "            if i!=j:\n",
    "                temp.append(0)\n",
    "            else:\n",
    "                temp.append(1)\n",
    "        try:\n",
    "            transfered_data = np.vstack([transfered_data, temp])\n",
    "        except:\n",
    "            transfered_data = temp\n",
    "    return(transfered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caeserde_1(plaintext, key=3):\n",
    "    L2I = dict(zip(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", range(26)))\n",
    "    I2L = dict(zip(range(26), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    ciphertext = \"\"\n",
    "    ciphernum = []\n",
    "    plainnum = []\n",
    "\n",
    "    for c in plaintext.upper():\n",
    "        if c.isalpha():\n",
    "            # L2I[c]+key represents the order eg A=1 B=2\n",
    "            ciphertext += I2L[(L2I[c] + key) % 26]\n",
    "            ciphernum.append((L2I[c] + key) % 26)\n",
    "            plainnum.append((L2I[c]) % 26)\n",
    "        else:\n",
    "            ciphertext += c\n",
    "            ciphernum.append('-1')\n",
    "    return (ciphertext, ciphernum, plainnum)\n",
    "# random data\n",
    "text, train, label = caeserde_1(\n",
    "    'WERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKLJHGFDCVBNMHGFDSRTRYUHIJKOIUYTREWQAZXCVBNMFGHIJKLMNOPQRSTUVWXYZ'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caeserde_26(plaintext, key=3):\n",
    "    L2I = dict(zip(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", range(26)))\n",
    "    I2L = dict(zip(range(26), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    ciphertext = \"\"\n",
    "    ciphernum = []\n",
    "    plainnum = []\n",
    "\n",
    "    for c in plaintext.upper():\n",
    "        if c.isalpha():\n",
    "            # L2I[c]+key represents the order eg A=1 B=2\n",
    "            ciphertext += I2L[(L2I[c] + key) % 26]\n",
    "            ciphernum.append((L2I[c] + key) % 26)\n",
    "            plainnum.append((L2I[c]) % 26)\n",
    "        else:\n",
    "            ciphertext += c\n",
    "            ciphernum.append('-1')\n",
    "    ciphernum = dataprocess(ciphernum)\n",
    "    plainnum = dataprocess(plainnum)\n",
    "    return (ciphertext, ciphernum, plainnum)\n",
    "# random data\n",
    "text, train, label = caeserde_26(\n",
    "    'WERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKLJHGFDCVBNMHGFDSRTRYUHIJKOIUYTREWQAZXCVBNMFGHIJKLMNOPQRSTUVWXYZ'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO list\n",
    "## Caeser ciper and impliment deep learning model**<br>\n",
    "    Caeser encryption function prediction\n",
    "## **Try to play around with caeser ciper and deep learning input and output**<br>\n",
    "### input 3(d) -- output a(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with 1 input and 26 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = None\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(10, input_dim=1, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "model1.compile(loss='poisson', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_4_input to have shape (1,) but got array with shape (130,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dfbd6f45d493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_4_input to have shape (1,) but got array with shape (130,)"
     ]
    }
   ],
   "source": [
    "model1.fit(train, label, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                546       \n",
      "=================================================================\n",
      "Total params: 1,426\n",
      "Trainable params: 1,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[]),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(26, activation=tf.nn.softmax),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    #loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "model.summary() #20*20+20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_input to have 1 dimensions, but got array with shape (2, 130)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-67dd0cef7c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    351\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected flatten_input to have 1 dimensions, but got array with shape (2, 130)"
     ]
    }
   ],
   "source": [
    "model.fit(train, label, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with 26 input and 26 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=26, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random data\n",
    "text, train, label = caeserde_26(\n",
    "    'WERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKLJHGFDCVBNMHGFDSRTRYUHIJKOIUYTREWQAZXCVBNMFGHIJKLMNOPQRSTUVWXYZ'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 12)                324       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                260       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 26)                546       \n",
      "=================================================================\n",
      "Total params: 1,130\n",
      "Trainable params: 1,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xihajun/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - acc: 0.9615\n",
      "Epoch 2/300\n",
      "185/185 [==============================] - 0s 32us/step - loss: 0.1631 - acc: 0.9615\n",
      "Epoch 3/300\n",
      "185/185 [==============================] - 0s 32us/step - loss: 0.1624 - acc: 0.9615\n",
      "Epoch 4/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.1618 - acc: 0.9615\n",
      "Epoch 5/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 0.1612 - acc: 0.9615\n",
      "Epoch 6/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1605 - acc: 0.9615\n",
      "Epoch 7/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1598 - acc: 0.9615\n",
      "Epoch 8/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1591 - acc: 0.9615\n",
      "Epoch 9/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1584 - acc: 0.9615\n",
      "Epoch 10/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1576 - acc: 0.9615\n",
      "Epoch 11/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.1568 - acc: 0.9615\n",
      "Epoch 12/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1559 - acc: 0.9615\n",
      "Epoch 13/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 14/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.1539 - acc: 0.9615\n",
      "Epoch 15/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1528 - acc: 0.9615\n",
      "Epoch 16/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1516 - acc: 0.9615\n",
      "Epoch 17/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1503 - acc: 0.9615\n",
      "Epoch 18/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1489 - acc: 0.9615\n",
      "Epoch 19/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.1474 - acc: 0.9615\n",
      "Epoch 20/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1458 - acc: 0.9615\n",
      "Epoch 21/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1442 - acc: 0.9615\n",
      "Epoch 22/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1423 - acc: 0.9615\n",
      "Epoch 23/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1405 - acc: 0.9615\n",
      "Epoch 24/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1384 - acc: 0.9615\n",
      "Epoch 25/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1362 - acc: 0.9615\n",
      "Epoch 26/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1339 - acc: 0.9615\n",
      "Epoch 27/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1315 - acc: 0.9615\n",
      "Epoch 28/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1290 - acc: 0.9615\n",
      "Epoch 29/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.1263 - acc: 0.9615\n",
      "Epoch 30/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1235 - acc: 0.9615\n",
      "Epoch 31/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1206 - acc: 0.9615\n",
      "Epoch 32/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.1176 - acc: 0.9615\n",
      "Epoch 33/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1144 - acc: 0.9615\n",
      "Epoch 34/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.1113 - acc: 0.9615\n",
      "Epoch 35/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.1080 - acc: 0.9615\n",
      "Epoch 36/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.1048 - acc: 0.9615\n",
      "Epoch 37/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.1016 - acc: 0.9640\n",
      "Epoch 38/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0983 - acc: 0.9644\n",
      "Epoch 39/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0951 - acc: 0.9672\n",
      "Epoch 40/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0918 - acc: 0.9672\n",
      "Epoch 41/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0886 - acc: 0.9672\n",
      "Epoch 42/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0854 - acc: 0.9686\n",
      "Epoch 43/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0823 - acc: 0.9732\n",
      "Epoch 44/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0792 - acc: 0.9748\n",
      "Epoch 45/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0762 - acc: 0.9765\n",
      "Epoch 46/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0732 - acc: 0.9796\n",
      "Epoch 47/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0703 - acc: 0.9813\n",
      "Epoch 48/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0675 - acc: 0.9813\n",
      "Epoch 49/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0647 - acc: 0.9813\n",
      "Epoch 50/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0621 - acc: 0.9813\n",
      "Epoch 51/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0594 - acc: 0.9813\n",
      "Epoch 52/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0569 - acc: 0.9827\n",
      "Epoch 53/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0544 - acc: 0.9832\n",
      "Epoch 54/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0520 - acc: 0.9832\n",
      "Epoch 55/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0497 - acc: 0.9840\n",
      "Epoch 56/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0474 - acc: 0.9844\n",
      "Epoch 57/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0451 - acc: 0.9852\n",
      "Epoch 58/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0430 - acc: 0.9865\n",
      "Epoch 59/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0409 - acc: 0.9865\n",
      "Epoch 60/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0389 - acc: 0.9879\n",
      "Epoch 61/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0369 - acc: 0.9886\n",
      "Epoch 62/300\n",
      "185/185 [==============================] - 0s 43us/step - loss: 0.0350 - acc: 0.9886\n",
      "Epoch 63/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0332 - acc: 0.9896\n",
      "Epoch 64/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0315 - acc: 0.9917\n",
      "Epoch 65/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0298 - acc: 0.9917\n",
      "Epoch 66/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 67/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0267 - acc: 0.9931\n",
      "Epoch 68/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0252 - acc: 0.9950\n",
      "Epoch 69/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0238 - acc: 0.9950\n",
      "Epoch 70/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0226 - acc: 0.9950\n",
      "Epoch 71/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0214 - acc: 0.9950\n",
      "Epoch 72/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0202 - acc: 0.9950\n",
      "Epoch 73/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0191 - acc: 0.9950\n",
      "Epoch 74/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0181 - acc: 0.9950\n",
      "Epoch 75/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0170 - acc: 0.9954\n",
      "Epoch 76/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0162 - acc: 0.9973\n",
      "Epoch 77/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0153 - acc: 0.9983\n",
      "Epoch 78/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0145 - acc: 0.9983\n",
      "Epoch 79/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0137 - acc: 0.9990\n",
      "Epoch 80/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0130 - acc: 0.9992\n",
      "Epoch 81/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0124 - acc: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0117 - acc: 0.9992\n",
      "Epoch 83/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0111 - acc: 0.9992\n",
      "Epoch 84/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0106 - acc: 0.9992\n",
      "Epoch 85/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0101 - acc: 0.9992\n",
      "Epoch 86/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0096 - acc: 0.9992\n",
      "Epoch 87/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0092 - acc: 0.9992\n",
      "Epoch 88/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0088 - acc: 0.9992\n",
      "Epoch 89/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0084 - acc: 0.9992\n",
      "Epoch 90/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0080 - acc: 0.9996\n",
      "Epoch 91/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0077 - acc: 0.9996\n",
      "Epoch 92/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0074 - acc: 0.9996\n",
      "Epoch 93/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0070 - acc: 0.9996\n",
      "Epoch 94/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0068 - acc: 0.9996\n",
      "Epoch 95/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0065 - acc: 0.9996\n",
      "Epoch 96/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0062 - acc: 0.9996\n",
      "Epoch 97/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0060 - acc: 0.9996\n",
      "Epoch 98/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0058 - acc: 0.9996\n",
      "Epoch 99/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0056 - acc: 0.9996\n",
      "Epoch 100/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0054 - acc: 0.9996\n",
      "Epoch 101/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0052 - acc: 0.9996\n",
      "Epoch 102/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0050 - acc: 0.9996\n",
      "Epoch 103/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0048 - acc: 0.9996\n",
      "Epoch 104/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0046 - acc: 0.9996\n",
      "Epoch 105/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 106/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 107/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 108/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0040 - acc: 0.9996\n",
      "Epoch 109/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0039 - acc: 0.9996\n",
      "Epoch 110/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0038 - acc: 0.9996\n",
      "Epoch 111/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0037 - acc: 0.9996\n",
      "Epoch 112/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 113/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 114/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 115/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 116/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 117/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 118/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 119/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0028 - acc: 0.9996\n",
      "Epoch 120/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 121/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 122/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 123/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0025 - acc: 0.9996\n",
      "Epoch 124/300\n",
      "185/185 [==============================] - 0s 32us/step - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 125/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 126/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 127/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 128/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 129/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 130/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 131/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 132/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 133/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 134/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 135/300\n",
      "185/185 [==============================] - 0s 43us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 136/300\n",
      "185/185 [==============================] - 0s 45us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 137/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 138/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 139/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 140/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 141/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 142/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 143/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 144/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 145/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 146/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 147/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 148/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 149/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 150/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 151/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 152/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 153/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 154/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 155/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 156/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 157/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 158/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 159/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 9.8270e-04 - acc: 1.0000\n",
      "Epoch 160/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 9.6092e-04 - acc: 1.0000\n",
      "Epoch 161/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 9.4414e-04 - acc: 1.0000\n",
      "Epoch 162/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 9.2293e-04 - acc: 1.0000\n",
      "Epoch 163/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 9.0456e-04 - acc: 1.0000\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 39us/step - loss: 8.8638e-04 - acc: 1.0000\n",
      "Epoch 165/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 8.6894e-04 - acc: 1.0000\n",
      "Epoch 166/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 8.5245e-04 - acc: 1.0000\n",
      "Epoch 167/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 8.3615e-04 - acc: 1.0000\n",
      "Epoch 168/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 8.1964e-04 - acc: 1.0000\n",
      "Epoch 169/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 8.0432e-04 - acc: 1.0000\n",
      "Epoch 170/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 7.9000e-04 - acc: 1.0000\n",
      "Epoch 171/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 7.7496e-04 - acc: 1.0000\n",
      "Epoch 172/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 7.6136e-04 - acc: 1.0000\n",
      "Epoch 173/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 7.4712e-04 - acc: 1.0000\n",
      "Epoch 174/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 7.3309e-04 - acc: 1.0000\n",
      "Epoch 175/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 7.2148e-04 - acc: 1.0000\n",
      "Epoch 176/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 7.0779e-04 - acc: 1.0000\n",
      "Epoch 177/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.9529e-04 - acc: 1.0000\n",
      "Epoch 178/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 6.8335e-04 - acc: 1.0000\n",
      "Epoch 179/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 6.7187e-04 - acc: 1.0000\n",
      "Epoch 180/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.6062e-04 - acc: 1.0000\n",
      "Epoch 181/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 6.4919e-04 - acc: 1.0000\n",
      "Epoch 182/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.3853e-04 - acc: 1.0000\n",
      "Epoch 183/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 6.2781e-04 - acc: 1.0000\n",
      "Epoch 184/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.1771e-04 - acc: 1.0000\n",
      "Epoch 185/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 6.0780e-04 - acc: 1.0000\n",
      "Epoch 186/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 5.9779e-04 - acc: 1.0000\n",
      "Epoch 187/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 5.8899e-04 - acc: 1.0000\n",
      "Epoch 188/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 5.7901e-04 - acc: 1.0000\n",
      "Epoch 189/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 5.7109e-04 - acc: 1.0000\n",
      "Epoch 190/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 5.6124e-04 - acc: 1.0000\n",
      "Epoch 191/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 5.5237e-04 - acc: 1.0000\n",
      "Epoch 192/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 5.4390e-04 - acc: 1.0000\n",
      "Epoch 193/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 5.3628e-04 - acc: 1.0000\n",
      "Epoch 194/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 5.2823e-04 - acc: 1.0000\n",
      "Epoch 195/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 5.1975e-04 - acc: 1.0000\n",
      "Epoch 196/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 5.1202e-04 - acc: 1.0000\n",
      "Epoch 197/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 5.0484e-04 - acc: 1.0000\n",
      "Epoch 198/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 4.9730e-04 - acc: 1.0000\n",
      "Epoch 199/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 4.9023e-04 - acc: 1.0000\n",
      "Epoch 200/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 4.8332e-04 - acc: 1.0000\n",
      "Epoch 201/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 4.7641e-04 - acc: 1.0000\n",
      "Epoch 202/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 4.6968e-04 - acc: 1.0000\n",
      "Epoch 203/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 4.6302e-04 - acc: 1.0000\n",
      "Epoch 204/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 4.5675e-04 - acc: 1.0000\n",
      "Epoch 205/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 4.5046e-04 - acc: 1.0000\n",
      "Epoch 206/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 4.4432e-04 - acc: 1.0000\n",
      "Epoch 207/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 4.3818e-04 - acc: 1.0000\n",
      "Epoch 208/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 4.3222e-04 - acc: 1.0000\n",
      "Epoch 209/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 4.2623e-04 - acc: 1.0000\n",
      "Epoch 210/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 4.2088e-04 - acc: 1.0000\n",
      "Epoch 211/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 4.1523e-04 - acc: 1.0000\n",
      "Epoch 212/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 4.0985e-04 - acc: 1.0000\n",
      "Epoch 213/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 4.0457e-04 - acc: 1.0000\n",
      "Epoch 214/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.9927e-04 - acc: 1.0000\n",
      "Epoch 215/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 3.9394e-04 - acc: 1.0000\n",
      "Epoch 216/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.8883e-04 - acc: 1.0000\n",
      "Epoch 217/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.8411e-04 - acc: 1.0000\n",
      "Epoch 218/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.7919e-04 - acc: 1.0000\n",
      "Epoch 219/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 3.7446e-04 - acc: 1.0000\n",
      "Epoch 220/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.7009e-04 - acc: 1.0000\n",
      "Epoch 221/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 3.6505e-04 - acc: 1.0000\n",
      "Epoch 222/300\n",
      "185/185 [==============================] - 0s 43us/step - loss: 3.6047e-04 - acc: 1.0000\n",
      "Epoch 223/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 3.5619e-04 - acc: 1.0000\n",
      "Epoch 224/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 3.5173e-04 - acc: 1.0000\n",
      "Epoch 225/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 3.4759e-04 - acc: 1.0000\n",
      "Epoch 226/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.4345e-04 - acc: 1.0000\n",
      "Epoch 227/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.3920e-04 - acc: 1.0000\n",
      "Epoch 228/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 3.3512e-04 - acc: 1.0000\n",
      "Epoch 229/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.3114e-04 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.2751e-04 - acc: 1.0000\n",
      "Epoch 231/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 3.2346e-04 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 3.1972e-04 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 3.1604e-04 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 3.1238e-04 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 3.0883e-04 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 3.0535e-04 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 3.0192e-04 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 2.9856e-04 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.9517e-04 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.9208e-04 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 2.8856e-04 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.8536e-04 - acc: 1.0000\n",
      "Epoch 243/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 37us/step - loss: 2.8221e-04 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.7930e-04 - acc: 1.0000\n",
      "Epoch 245/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 2.7623e-04 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.7323e-04 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.7030e-04 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 2.6736e-04 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.6463e-04 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 2.6186e-04 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "185/185 [==============================] - 0s 33us/step - loss: 2.5910e-04 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "185/185 [==============================] - 0s 36us/step - loss: 2.5653e-04 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "185/185 [==============================] - 0s 32us/step - loss: 2.5387e-04 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 2.5113e-04 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.4862e-04 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "185/185 [==============================] - 0s 35us/step - loss: 2.4611e-04 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.4370e-04 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.4116e-04 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 2.3870e-04 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.3639e-04 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "185/185 [==============================] - 0s 38us/step - loss: 2.3396e-04 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.3164e-04 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 2.2938e-04 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "185/185 [==============================] - 0s 34us/step - loss: 2.2725e-04 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.2496e-04 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 2.2269e-04 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 2.2063e-04 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 2.1852e-04 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 2.1646e-04 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 2.1428e-04 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "185/185 [==============================] - 0s 48us/step - loss: 2.1223e-04 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 2.1036e-04 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 2.0823e-04 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 2.0629e-04 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 2.0437e-04 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 2.0244e-04 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 2.0056e-04 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.9869e-04 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.9691e-04 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.9512e-04 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "185/185 [==============================] - 0s 43us/step - loss: 1.9330e-04 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 1.9153e-04 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "185/185 [==============================] - 0s 44us/step - loss: 1.8975e-04 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 1.8809e-04 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.8636e-04 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.8472e-04 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.8305e-04 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 1.8144e-04 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.7987e-04 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.7823e-04 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 1.7670e-04 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "185/185 [==============================] - 0s 45us/step - loss: 1.7510e-04 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.7364e-04 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "185/185 [==============================] - 0s 39us/step - loss: 1.7206e-04 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "185/185 [==============================] - 0s 45us/step - loss: 1.7058e-04 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "185/185 [==============================] - 0s 42us/step - loss: 1.6923e-04 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.6769e-04 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "185/185 [==============================] - 0s 40us/step - loss: 1.6629e-04 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "185/185 [==============================] - 0s 41us/step - loss: 1.6487e-04 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "185/185 [==============================] - 0s 37us/step - loss: 1.6346e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb30209908>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, label, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train)\n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir = \"./graphs/{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 582us/step\n",
      "\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(train, label)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with 1 input and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fcd5e3a64f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model1 = None\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(26, input_dim=1, activation='relu'))\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "\n",
    "model1.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, train, label = caeserde_26(\n",
    "    'IAMSAMILIKEDST'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how can we chose the loss function: https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='poisson', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 2/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 3/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 4/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 5/500\n",
      "308/308 [==============================] - 0s 66us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 6/500\n",
      "308/308 [==============================] - 0s 59us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 7/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 8/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 9/500\n",
      "308/308 [==============================] - 0s 55us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 10/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 11/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 12/500\n",
      "308/308 [==============================] - 0s 53us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 13/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 14/500\n",
      "308/308 [==============================] - 0s 53us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 15/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 16/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 17/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 18/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 19/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 20/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 21/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 22/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 23/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 24/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 25/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 26/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 27/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 28/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 29/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 30/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 31/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 32/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 33/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 34/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 35/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 36/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 37/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 38/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 39/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 40/500\n",
      "308/308 [==============================] - 0s 56us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 41/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 42/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 43/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 44/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 45/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 46/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 47/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 48/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 49/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 50/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 51/500\n",
      "308/308 [==============================] - 0s 54us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 52/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 53/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 54/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 55/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 56/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 57/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 58/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 59/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 60/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 61/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 62/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 63/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 64/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 65/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 66/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 67/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 68/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 69/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 70/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 71/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 72/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 73/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 74/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 75/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 76/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 77/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 78/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 79/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 80/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 81/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 82/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 84/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 85/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 86/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 87/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 88/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 89/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 90/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 91/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 92/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 93/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 94/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 95/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 96/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 97/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 98/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 99/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 100/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 101/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 102/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 103/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 104/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 105/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 106/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 107/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 108/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 109/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 110/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 111/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 112/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 113/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 114/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 115/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 116/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 117/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 118/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 119/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 120/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 121/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 122/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 123/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 124/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 125/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 126/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 127/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 128/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 129/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 130/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 131/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 132/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 133/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 134/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 135/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 136/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 137/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 138/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 139/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 140/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 141/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 142/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 143/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 144/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 145/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 146/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 147/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 148/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 149/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 150/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 151/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 152/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 153/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 154/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 155/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 156/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 157/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 158/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 159/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 160/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 161/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 162/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 163/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 164/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 165/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 166/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 167/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 168/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 169/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 170/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 171/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 172/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 173/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 174/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 175/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 176/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 177/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 178/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 179/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 180/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 181/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 182/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 183/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 184/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 185/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 186/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 187/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 188/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 189/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 190/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 191/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 192/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 193/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 194/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 195/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 196/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 197/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 198/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 199/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 200/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 201/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 202/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 203/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 204/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 205/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 206/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 207/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 208/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 209/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 210/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 211/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 212/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 213/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 214/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 215/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 216/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 217/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 218/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 219/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 220/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 221/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 222/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 223/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 224/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 225/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 226/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 227/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 228/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 229/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 230/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 231/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 232/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 233/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 234/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 235/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 236/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 237/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 238/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 239/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 240/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 241/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 242/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 243/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 244/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 246/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 247/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 248/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 249/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 250/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 251/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 252/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 253/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 254/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 255/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 256/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 257/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 258/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 259/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 260/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 261/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 262/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 263/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 264/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 265/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 266/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 267/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 268/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 269/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 270/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 271/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 272/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 273/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 274/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 275/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 276/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 277/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 278/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 279/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 280/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 281/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 282/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 283/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 284/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 285/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 286/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 287/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 288/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 289/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 290/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 291/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 292/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 293/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 294/500\n",
      "308/308 [==============================] - 0s 56us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 295/500\n",
      "308/308 [==============================] - 0s 53us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 296/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 297/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 298/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 299/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 300/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 301/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 302/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 303/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 304/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 305/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 306/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 307/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 308/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 309/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 310/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 311/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 312/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 313/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 314/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 315/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 316/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 317/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 318/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 319/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 320/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 321/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 322/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 323/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 324/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 325/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 326/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 327/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 328/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 329/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 330/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 331/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 332/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 333/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 334/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 335/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 336/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 337/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 338/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 339/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 340/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 341/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 342/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 343/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 344/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 345/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 346/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 347/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 348/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 349/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 350/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 351/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 352/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 353/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 354/500\n",
      "308/308 [==============================] - 0s 39us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 355/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 356/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 357/500\n",
      "308/308 [==============================] - 0s 40us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 358/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 359/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 360/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 361/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 362/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 363/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 364/500\n",
      "308/308 [==============================] - 0s 55us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 365/500\n",
      "308/308 [==============================] - 0s 53us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 366/500\n",
      "308/308 [==============================] - 0s 51us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 367/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 368/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 369/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 370/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 371/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 372/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 373/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 374/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 375/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 376/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 377/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 378/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 379/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 380/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 381/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 382/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 383/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 384/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 385/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 386/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 387/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 388/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 389/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 390/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 391/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 392/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 393/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 394/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 395/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 396/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 397/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 398/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 399/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 400/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 401/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 402/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 403/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 404/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 405/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 406/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 408/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 409/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 410/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 411/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 412/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 413/500\n",
      "308/308 [==============================] - 0s 42us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 414/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 415/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 416/500\n",
      "308/308 [==============================] - 0s 41us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 417/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 418/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 419/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 420/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 421/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 422/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 423/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 424/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 425/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 426/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 427/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 428/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 429/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 430/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 431/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 432/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 433/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 434/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 435/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 436/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 437/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 438/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 439/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 440/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 441/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 442/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 443/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 444/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 445/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 446/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 447/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 448/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 449/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 450/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 451/500\n",
      "308/308 [==============================] - 0s 52us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 452/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 453/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 454/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 455/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 456/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 457/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 458/500\n",
      "308/308 [==============================] - 0s 50us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 459/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 460/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 461/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 462/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 463/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 464/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 465/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 466/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 467/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 468/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 469/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 470/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 471/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 472/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 473/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 474/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 475/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 476/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 477/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 478/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 479/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 480/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 481/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 482/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 483/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 484/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 485/500\n",
      "308/308 [==============================] - 0s 43us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 486/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 487/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 488/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 489/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 490/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 491/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 492/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 493/500\n",
      "308/308 [==============================] - 0s 49us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 494/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 495/500\n",
      "308/308 [==============================] - 0s 47us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 496/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 497/500\n",
      "308/308 [==============================] - 0s 48us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 498/500\n",
      "308/308 [==============================] - 0s 46us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 499/500\n",
      "308/308 [==============================] - 0s 45us/step - loss: 184.6778 - acc: 0.0227\n",
      "Epoch 500/500\n",
      "308/308 [==============================] - 0s 44us/step - loss: 184.6778 - acc: 0.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb350af128>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random data\n",
    "text, train, label = caeserde_1(\n",
    "    'WERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKLJHGFDCVBNMHGFDSRTRYUHIJKOIUYTREWQAZXCVBNMFGHIJKLMNOPQRSTUVWXYZWERTYUIOPOIUGFDSASXCVBNMKJHGFREWQASXCVBNMJKUJYTFRDCVBNMKLOIUYTFCVBABCDEFTYGUHIJGFTGHJKLGYFHJRTFYGUHIJOKIHUGYFTGHJKLJHJGFJKL'\n",
    ")\n",
    "model1.fit(train, label, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 26)                52        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 20)                540       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,873\n",
      "Trainable params: 1,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 3(d) -- output (1,0,0,...,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input (0,0,0,1,0,...,0) -- output a(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input (0,0,0,1,0,...,0) -- output (1,0,0,...,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input (0,0,0,1,0,...,0) -- output (1,0,0,...,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analyse this results**<br>\n",
    "\n",
    "   For example, which model minimises the number of echos \n",
    "   Which model cannot reach the 100% accuracy? Why?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using unseen data 26-100**<br>\n",
    "\n",
    "    The model has seen 0-26)<br>\n",
    "    Try to find the weight in this model<br>\n",
    "    Try to visualize it by using tensorboard<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Try to add more training data, see if things change**<br>\n",
    "    If it is better, try to explain why<br>\n",
    "    If it is not, maybe 23 is enough?<br>\n",
    "* My prior: Maybe more data can make the training procedure faster? I don't know given the same input how doesthe neural network learn? Stop updating or **keep updating**?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Try to hide some data**\n",
    "* For human, it is reasonable if we hide z, we are able to judge the one we cannot see (high probability)\n",
    "* I tried it makes no sense so far. 98%?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new data to make the neural network learn the shift, but how to learn the piecewise function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Try to given pairs of data, and change the structure of neural output and input**\n",
    "* How many we combination we have? **676** (no order). More deeperly, combining with more words (we know the number of combination is too large, we just want to test, if neural network could learn something unseen?\n",
    "* Need a smart way to do this (consider to restruct the input and output as well as the order)<br>\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>Example 1 </th><th>Example 2</th></tr>\n",
    "<tr><td>\n",
    "\n",
    "Set|Input| Output|Seen\n",
    "---|---|---|---|\n",
    "Training| AB | DE |Yes\n",
    "Training| CD | FG |Yes\n",
    "Testing | BC | EF |No\n",
    "\n",
    "</td><td>\n",
    "\n",
    "\n",
    "Set|Input| Output|Seen\n",
    "---|---|---|---|\n",
    "Training| AB | DE |Yes\n",
    "Testing | BA | ED |No\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "* Idea: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Watching videos and papers for logic programming**\n",
    "\n",
    "    To figure out logic programming in deep learning\n",
    "    Video<br>\n",
    "    [Deep learning course: Introduction to Deep Learning](https://www.youtube.com/watch?v=JN6H4rQvwgY)<br>\n",
    "    [Richard Evans: Inductive logic programming and deep learning I](https://www.youtube.com/watch?v=yD02DlZnHJw)<br>\n",
    "    [Learning Explanatory Rules from Noisy Data - Richard Evans, DeepMind](https://www.youtube.com/watch?v=_wuFBF_Cgm0&t=24s)<br>\n",
    "    Paper<br>\n",
    "    [LOGIC MINING USING NEURAL NETWORKS](https://arxiv.org/pdf/0804.4071.pdf)<br>\n",
    "    [First-order Logic Learning in Artificial Neural Networks](https://core.ac.uk/download/pdf/17294404.pdf)<br>\n",
    "    Python logic programming<br>\n",
    "    [PYKE](http://pyke.sourceforge.net/index.html)\n",
    "\n",
    "- [ ] **Try to use ILD to guide our neural system**\n",
    "    How? Set rules, recurrent?\n",
    "\n",
    "- [ ] **Try to find new encryption function to learn more complex stuff**\n",
    "    key=[1,2,3,4]? \n",
    "    Consider the input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## letters position matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caeserde_1(plaintext, key=3):\n",
    "    L2I = dict(zip(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", range(26)))\n",
    "    I2L = dict(zip(range(26), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    ciphertext = \"\"\n",
    "    ciphernum = []\n",
    "    plainnum = []\n",
    "\n",
    "    for c in plaintext.upper():\n",
    "        if c.isalpha():\n",
    "            # L2I[c]+key represents the order eg A=1 B=2\n",
    "            ciphertext += I2L[(L2I[c] + key) % 26]\n",
    "            ciphernum.append((L2I[c] + key) % 26)\n",
    "            plainnum.append((L2I[c]) % 26)\n",
    "        else:\n",
    "            ciphertext += c\n",
    "            ciphernum.append('-1')\n",
    "    return (ciphertext, ciphernum, plainnum)\n",
    "def letter_position_matrix(text,key=3):\n",
    "    length = len(text)\n",
    "    matrix = [[0 for y in range(26)] for x in range(length)]\n",
    "    for idx, val in enumerate(text):\n",
    "        matrix[idx][val] = 1\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciphertext, ciphernum, plainnum = caeserde_1(\"Hello\")\n",
    "\n",
    "\n",
    "a = letter_position_matrix(plainnum)\n",
    "b = letter_position_matrix(ciphernum)\n",
    "\n",
    "label_smaller = np.array(plainnum)\n",
    "# flatten label and training set\n",
    "label_equalsize = a.flatten()\n",
    "train = b.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=130, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(130, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='poisson', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.1593 - acc: 0.1252\n",
      "Epoch 2/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.1394 - acc: 0.1406\n",
      "Epoch 3/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1350 - acc: 0.1524\n",
      "Epoch 4/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1323 - acc: 0.1612\n",
      "Epoch 5/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1303 - acc: 0.1642\n",
      "Epoch 6/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1288 - acc: 0.1691\n",
      "Epoch 7/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1275 - acc: 0.1713\n",
      "Epoch 8/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1263 - acc: 0.1739\n",
      "Epoch 9/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1254 - acc: 0.1740\n",
      "Epoch 10/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1247 - acc: 0.1762\n",
      "Epoch 11/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1239 - acc: 0.1774\n",
      "Epoch 12/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1232 - acc: 0.1769\n",
      "Epoch 13/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1224 - acc: 0.1728\n",
      "Epoch 14/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1217 - acc: 0.1812\n",
      "Epoch 15/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1211 - acc: 0.1816\n",
      "Epoch 16/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1205 - acc: 0.1793\n",
      "Epoch 17/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1200 - acc: 0.1785\n",
      "Epoch 18/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1196 - acc: 0.1789\n",
      "Epoch 19/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1192 - acc: 0.1834\n",
      "Epoch 20/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.1188 - acc: 0.1784\n",
      "Epoch 21/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.1184 - acc: 0.1769\n",
      "Epoch 22/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.1179 - acc: 0.1790\n",
      "Epoch 23/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1176 - acc: 0.1800\n",
      "Epoch 24/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1171 - acc: 0.1798\n",
      "Epoch 25/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1167 - acc: 0.1780\n",
      "Epoch 26/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1163 - acc: 0.1760\n",
      "Epoch 27/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.1158 - acc: 0.1761\n",
      "Epoch 28/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.1153 - acc: 0.1730\n",
      "Epoch 29/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1148 - acc: 0.1761\n",
      "Epoch 30/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1143 - acc: 0.1750\n",
      "Epoch 31/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.1137 - acc: 0.1742\n",
      "Epoch 32/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.1131 - acc: 0.1739\n",
      "Epoch 33/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1125 - acc: 0.1696\n",
      "Epoch 34/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.1119 - acc: 0.1706\n",
      "Epoch 35/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1112 - acc: 0.1697\n",
      "Epoch 36/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1105 - acc: 0.1690\n",
      "Epoch 37/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.1098 - acc: 0.1688\n",
      "Epoch 38/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.1090 - acc: 0.1665\n",
      "Epoch 39/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1082 - acc: 0.1675\n",
      "Epoch 40/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.1074 - acc: 0.1658\n",
      "Epoch 41/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.1064 - acc: 0.1648\n",
      "Epoch 42/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.1054 - acc: 0.1659\n",
      "Epoch 43/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.1044 - acc: 0.1672\n",
      "Epoch 44/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.1034 - acc: 0.1655\n",
      "Epoch 45/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.1022 - acc: 0.1678\n",
      "Epoch 46/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.1011 - acc: 0.1698\n",
      "Epoch 47/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0999 - acc: 0.1702\n",
      "Epoch 48/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0987 - acc: 0.1711\n",
      "Epoch 49/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0975 - acc: 0.1724\n",
      "Epoch 50/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0962 - acc: 0.1745\n",
      "Epoch 51/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0951 - acc: 0.1788\n",
      "Epoch 52/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0939 - acc: 0.1790\n",
      "Epoch 53/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0927 - acc: 0.1788\n",
      "Epoch 54/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0916 - acc: 0.1806\n",
      "Epoch 55/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0905 - acc: 0.1788\n",
      "Epoch 56/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0893 - acc: 0.1827\n",
      "Epoch 57/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0882 - acc: 0.1823\n",
      "Epoch 58/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0872 - acc: 0.1846\n",
      "Epoch 59/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0861 - acc: 0.1867\n",
      "Epoch 60/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0851 - acc: 0.1794\n",
      "Epoch 61/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0841 - acc: 0.1809\n",
      "Epoch 62/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0831 - acc: 0.1864\n",
      "Epoch 63/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0822 - acc: 0.1905\n",
      "Epoch 64/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0814 - acc: 0.1900\n",
      "Epoch 65/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0807 - acc: 0.1862\n",
      "Epoch 66/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0799 - acc: 0.1932\n",
      "Epoch 67/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0793 - acc: 0.1946\n",
      "Epoch 68/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0787 - acc: 0.1966\n",
      "Epoch 69/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0782 - acc: 0.1972\n",
      "Epoch 70/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0776 - acc: 0.1988\n",
      "Epoch 71/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0771 - acc: 0.1972\n",
      "Epoch 72/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0767 - acc: 0.2000\n",
      "Epoch 73/500\n",
      "10001/10001 [==============================] - 0s 33us/step - loss: 0.0763 - acc: 0.1986\n",
      "Epoch 74/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0760 - acc: 0.2030\n",
      "Epoch 75/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0757 - acc: 0.2027\n",
      "Epoch 76/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0754 - acc: 0.1962\n",
      "Epoch 77/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0751 - acc: 0.2049\n",
      "Epoch 78/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0749 - acc: 0.2031\n",
      "Epoch 79/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0746 - acc: 0.1940\n",
      "Epoch 80/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0744 - acc: 0.2125\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0742 - acc: 0.2079\n",
      "Epoch 82/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0740 - acc: 0.2024\n",
      "Epoch 83/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0738 - acc: 0.2027\n",
      "Epoch 84/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0737 - acc: 0.2085\n",
      "Epoch 85/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0736 - acc: 0.2088\n",
      "Epoch 86/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0734 - acc: 0.2079\n",
      "Epoch 87/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0733 - acc: 0.2131\n",
      "Epoch 88/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0732 - acc: 0.2072\n",
      "Epoch 89/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0730 - acc: 0.2078\n",
      "Epoch 90/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0729 - acc: 0.2071\n",
      "Epoch 91/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0729 - acc: 0.2138\n",
      "Epoch 92/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0727 - acc: 0.2103\n",
      "Epoch 93/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0727 - acc: 0.2104\n",
      "Epoch 94/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0726 - acc: 0.2082\n",
      "Epoch 95/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0724 - acc: 0.2049\n",
      "Epoch 96/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0724 - acc: 0.2033\n",
      "Epoch 97/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0724 - acc: 0.2033\n",
      "Epoch 98/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0722 - acc: 0.2083\n",
      "Epoch 99/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0722 - acc: 0.2135\n",
      "Epoch 100/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0721 - acc: 0.2043\n",
      "Epoch 101/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0720 - acc: 0.2140\n",
      "Epoch 102/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0720 - acc: 0.2047\n",
      "Epoch 103/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0720 - acc: 0.2109\n",
      "Epoch 104/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0719 - acc: 0.2051\n",
      "Epoch 105/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0719 - acc: 0.2029\n",
      "Epoch 106/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0718 - acc: 0.2168\n",
      "Epoch 107/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0718 - acc: 0.2085\n",
      "Epoch 108/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0717 - acc: 0.2139\n",
      "Epoch 109/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0717 - acc: 0.2063\n",
      "Epoch 110/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0716 - acc: 0.2031\n",
      "Epoch 111/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0716 - acc: 0.2088\n",
      "Epoch 112/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0716 - acc: 0.2134\n",
      "Epoch 113/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0715 - acc: 0.2028\n",
      "Epoch 114/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0715 - acc: 0.2031\n",
      "Epoch 115/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0714 - acc: 0.2086\n",
      "Epoch 116/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0714 - acc: 0.2021\n",
      "Epoch 117/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0714 - acc: 0.2045\n",
      "Epoch 118/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0714 - acc: 0.2085\n",
      "Epoch 119/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0713 - acc: 0.2101\n",
      "Epoch 120/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0712 - acc: 0.2059\n",
      "Epoch 121/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0713 - acc: 0.2079\n",
      "Epoch 122/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0713 - acc: 0.2033\n",
      "Epoch 123/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0712 - acc: 0.2040\n",
      "Epoch 124/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0712 - acc: 0.2103\n",
      "Epoch 125/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0713 - acc: 0.2002\n",
      "Epoch 126/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0711 - acc: 0.2040\n",
      "Epoch 127/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0711 - acc: 0.2085\n",
      "Epoch 128/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0711 - acc: 0.2034\n",
      "Epoch 129/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0711 - acc: 0.2004\n",
      "Epoch 130/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0711 - acc: 0.2066\n",
      "Epoch 131/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0711 - acc: 0.2129\n",
      "Epoch 132/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0710 - acc: 0.2042\n",
      "Epoch 133/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0711 - acc: 0.2100\n",
      "Epoch 134/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0710 - acc: 0.2039\n",
      "Epoch 135/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0711 - acc: 0.2112\n",
      "Epoch 136/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0710 - acc: 0.2227\n",
      "Epoch 137/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0710 - acc: 0.1992\n",
      "Epoch 138/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0710 - acc: 0.1962\n",
      "Epoch 139/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0710 - acc: 0.2093\n",
      "Epoch 140/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0709 - acc: 0.2039\n",
      "Epoch 141/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0710 - acc: 0.2049\n",
      "Epoch 142/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0709 - acc: 0.2085\n",
      "Epoch 143/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0708 - acc: 0.2027\n",
      "Epoch 144/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0709 - acc: 0.2059\n",
      "Epoch 145/500\n",
      "10001/10001 [==============================] - 0s 33us/step - loss: 0.0710 - acc: 0.2058\n",
      "Epoch 146/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0709 - acc: 0.2076\n",
      "Epoch 147/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0708 - acc: 0.2050\n",
      "Epoch 148/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0710 - acc: 0.2018\n",
      "Epoch 149/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0707 - acc: 0.2042\n",
      "Epoch 150/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0709 - acc: 0.2007\n",
      "Epoch 151/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0709 - acc: 0.1950\n",
      "Epoch 152/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0709 - acc: 0.2007\n",
      "Epoch 153/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.2054\n",
      "Epoch 154/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0709 - acc: 0.1915\n",
      "Epoch 155/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.2096\n",
      "Epoch 156/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0709 - acc: 0.2038\n",
      "Epoch 157/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0708 - acc: 0.2011\n",
      "Epoch 158/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0708 - acc: 0.2057\n",
      "Epoch 159/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0709 - acc: 0.2057\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.2054\n",
      "Epoch 161/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0708 - acc: 0.2054\n",
      "Epoch 162/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0708 - acc: 0.2015\n",
      "Epoch 163/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0706 - acc: 0.2084\n",
      "Epoch 164/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0710 - acc: 0.2028\n",
      "Epoch 165/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0708 - acc: 0.1927\n",
      "Epoch 166/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.2169\n",
      "Epoch 167/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.2123\n",
      "Epoch 168/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0708 - acc: 0.2147\n",
      "Epoch 169/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0707 - acc: 0.2038\n",
      "Epoch 170/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0708 - acc: 0.1950\n",
      "Epoch 171/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.2006\n",
      "Epoch 172/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.1948\n",
      "Epoch 173/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2027\n",
      "Epoch 174/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.1967\n",
      "Epoch 175/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.1983\n",
      "Epoch 176/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.1966\n",
      "Epoch 177/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0708 - acc: 0.1997\n",
      "Epoch 178/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.2028\n",
      "Epoch 179/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.1963\n",
      "Epoch 180/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.1934\n",
      "Epoch 181/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0709 - acc: 0.1950\n",
      "Epoch 182/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0706 - acc: 0.2053\n",
      "Epoch 183/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2001\n",
      "Epoch 184/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.2078\n",
      "Epoch 185/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.2045\n",
      "Epoch 186/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1963\n",
      "Epoch 187/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.2048\n",
      "Epoch 188/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.2012\n",
      "Epoch 189/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0708 - acc: 0.2089\n",
      "Epoch 190/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2000\n",
      "Epoch 191/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.1908\n",
      "Epoch 192/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.2042\n",
      "Epoch 193/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.2038\n",
      "Epoch 194/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.2059\n",
      "Epoch 195/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2045\n",
      "Epoch 196/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.1978\n",
      "Epoch 197/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1889\n",
      "Epoch 198/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1888\n",
      "Epoch 199/500\n",
      "10001/10001 [==============================] - 0s 24us/step - loss: 0.0707 - acc: 0.1916\n",
      "Epoch 200/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.2018\n",
      "Epoch 201/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1936\n",
      "Epoch 202/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.1997\n",
      "Epoch 203/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1997\n",
      "Epoch 204/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1988\n",
      "Epoch 205/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.1974\n",
      "Epoch 206/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.2070\n",
      "Epoch 207/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.2023\n",
      "Epoch 208/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0706 - acc: 0.1954\n",
      "Epoch 209/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0705 - acc: 0.1975\n",
      "Epoch 210/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0706 - acc: 0.2019\n",
      "Epoch 211/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0706 - acc: 0.1968\n",
      "Epoch 212/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0706 - acc: 0.1964\n",
      "Epoch 213/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.1868\n",
      "Epoch 214/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.1990\n",
      "Epoch 215/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0707 - acc: 0.1989\n",
      "Epoch 216/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.2020\n",
      "Epoch 217/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.1899\n",
      "Epoch 218/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.2092\n",
      "Epoch 219/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1932\n",
      "Epoch 220/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1955\n",
      "Epoch 221/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.2005\n",
      "Epoch 222/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0705 - acc: 0.1896\n",
      "Epoch 223/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0705 - acc: 0.2012\n",
      "Epoch 224/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0706 - acc: 0.1910\n",
      "Epoch 225/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0705 - acc: 0.1811\n",
      "Epoch 226/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.2038\n",
      "Epoch 227/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.2033\n",
      "Epoch 228/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1960\n",
      "Epoch 229/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1982\n",
      "Epoch 230/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1982\n",
      "Epoch 231/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1994\n",
      "Epoch 232/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.2036\n",
      "Epoch 233/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0706 - acc: 0.1892\n",
      "Epoch 234/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0704 - acc: 0.2083\n",
      "Epoch 235/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.2049\n",
      "Epoch 236/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.1880\n",
      "Epoch 237/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1872\n",
      "Epoch 238/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2215\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.2057\n",
      "Epoch 240/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2001\n",
      "Epoch 241/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1883\n",
      "Epoch 242/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0705 - acc: 0.1984\n",
      "Epoch 243/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.2013\n",
      "Epoch 244/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0707 - acc: 0.1942\n",
      "Epoch 245/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.2080\n",
      "Epoch 246/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.2026\n",
      "Epoch 247/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0705 - acc: 0.1979\n",
      "Epoch 248/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.2040\n",
      "Epoch 249/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.1933\n",
      "Epoch 250/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0704 - acc: 0.1946\n",
      "Epoch 251/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0705 - acc: 0.1927\n",
      "Epoch 252/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0706 - acc: 0.2000\n",
      "Epoch 253/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0706 - acc: 0.1991\n",
      "Epoch 254/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0705 - acc: 0.2078\n",
      "Epoch 255/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.2118\n",
      "Epoch 256/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0706 - acc: 0.2057\n",
      "Epoch 257/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.1991\n",
      "Epoch 258/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1999\n",
      "Epoch 259/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2040\n",
      "Epoch 260/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.2032\n",
      "Epoch 261/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1756\n",
      "Epoch 262/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0708 - acc: 0.1870\n",
      "Epoch 263/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2058\n",
      "Epoch 264/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2030\n",
      "Epoch 265/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1967\n",
      "Epoch 266/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2088\n",
      "Epoch 267/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.1962\n",
      "Epoch 268/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.2025\n",
      "Epoch 269/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.1961\n",
      "Epoch 270/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.2026\n",
      "Epoch 271/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1988\n",
      "Epoch 272/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1951\n",
      "Epoch 273/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0703 - acc: 0.2074\n",
      "Epoch 274/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1955\n",
      "Epoch 275/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.1951\n",
      "Epoch 276/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1957\n",
      "Epoch 277/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1958\n",
      "Epoch 278/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1977\n",
      "Epoch 279/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2060\n",
      "Epoch 280/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2053\n",
      "Epoch 281/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.2039\n",
      "Epoch 282/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0706 - acc: 0.2011\n",
      "Epoch 283/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1952\n",
      "Epoch 284/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.1964\n",
      "Epoch 285/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1936\n",
      "Epoch 286/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1949\n",
      "Epoch 287/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.1834\n",
      "Epoch 288/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2050\n",
      "Epoch 289/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2112\n",
      "Epoch 290/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.2018\n",
      "Epoch 291/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2112\n",
      "Epoch 292/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0703 - acc: 0.1992\n",
      "Epoch 293/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1916\n",
      "Epoch 294/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0708 - acc: 0.2048\n",
      "Epoch 295/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.1937\n",
      "Epoch 296/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2210\n",
      "Epoch 297/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1866\n",
      "Epoch 298/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1955\n",
      "Epoch 299/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.1857\n",
      "Epoch 300/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.2019\n",
      "Epoch 301/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.1893\n",
      "Epoch 302/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0705 - acc: 0.2182\n",
      "Epoch 303/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0705 - acc: 0.1917\n",
      "Epoch 304/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0703 - acc: 0.2001\n",
      "Epoch 305/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.2232\n",
      "Epoch 306/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.1919\n",
      "Epoch 307/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.1967\n",
      "Epoch 308/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.2070\n",
      "Epoch 309/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0707 - acc: 0.2030\n",
      "Epoch 310/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1952\n",
      "Epoch 311/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.2064\n",
      "Epoch 312/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2060\n",
      "Epoch 313/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2074\n",
      "Epoch 314/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.2059\n",
      "Epoch 315/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.1924\n",
      "Epoch 316/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1915\n",
      "Epoch 317/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1946\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2047\n",
      "Epoch 319/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0703 - acc: 0.1936\n",
      "Epoch 320/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.2064\n",
      "Epoch 321/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0708 - acc: 0.1883\n",
      "Epoch 322/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1978\n",
      "Epoch 323/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2026\n",
      "Epoch 324/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1962\n",
      "Epoch 325/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.1994\n",
      "Epoch 326/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2024\n",
      "Epoch 327/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0708 - acc: 0.1981\n",
      "Epoch 328/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0702 - acc: 0.2044\n",
      "Epoch 329/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1974\n",
      "Epoch 330/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2008\n",
      "Epoch 331/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1892\n",
      "Epoch 332/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1905\n",
      "Epoch 333/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2091\n",
      "Epoch 334/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1976\n",
      "Epoch 335/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.2006\n",
      "Epoch 336/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0703 - acc: 0.1991\n",
      "Epoch 337/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.2034\n",
      "Epoch 338/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.2010\n",
      "Epoch 339/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.1923\n",
      "Epoch 340/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0702 - acc: 0.1957\n",
      "Epoch 341/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0707 - acc: 0.2074\n",
      "Epoch 342/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.1991\n",
      "Epoch 343/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0705 - acc: 0.1883\n",
      "Epoch 344/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1889\n",
      "Epoch 345/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.1950\n",
      "Epoch 346/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.2174\n",
      "Epoch 347/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.1963\n",
      "Epoch 348/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.2148\n",
      "Epoch 349/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0706 - acc: 0.1969\n",
      "Epoch 350/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0706 - acc: 0.1803\n",
      "Epoch 351/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.2082\n",
      "Epoch 352/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0702 - acc: 0.2013\n",
      "Epoch 353/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.2045\n",
      "Epoch 354/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.1822\n",
      "Epoch 355/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.1937\n",
      "Epoch 356/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0707 - acc: 0.1899\n",
      "Epoch 357/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.2123\n",
      "Epoch 358/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.1959\n",
      "Epoch 359/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.2044\n",
      "Epoch 360/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0703 - acc: 0.1929\n",
      "Epoch 361/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.1908\n",
      "Epoch 362/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.1948\n",
      "Epoch 363/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1987\n",
      "Epoch 364/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.1953\n",
      "Epoch 365/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.1999\n",
      "Epoch 366/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2025\n",
      "Epoch 367/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2011\n",
      "Epoch 368/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.1983\n",
      "Epoch 369/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.1976\n",
      "Epoch 370/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0705 - acc: 0.1990\n",
      "Epoch 371/500\n",
      "10001/10001 [==============================] - 0s 33us/step - loss: 0.0705 - acc: 0.2047\n",
      "Epoch 372/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.2008\n",
      "Epoch 373/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0704 - acc: 0.1993\n",
      "Epoch 374/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0705 - acc: 0.1830\n",
      "Epoch 375/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0704 - acc: 0.2027\n",
      "Epoch 376/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.2049\n",
      "Epoch 377/500\n",
      "10001/10001 [==============================] - 0s 33us/step - loss: 0.0704 - acc: 0.2030\n",
      "Epoch 378/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0707 - acc: 0.1958\n",
      "Epoch 379/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2052\n",
      "Epoch 380/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0702 - acc: 0.1964\n",
      "Epoch 381/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.2081\n",
      "Epoch 382/500\n",
      "10001/10001 [==============================] - 0s 36us/step - loss: 0.0706 - acc: 0.2076\n",
      "Epoch 383/500\n",
      "10001/10001 [==============================] - 0s 43us/step - loss: 0.0702 - acc: 0.1863\n",
      "Epoch 384/500\n",
      "10001/10001 [==============================] - 0s 42us/step - loss: 0.0704 - acc: 0.1927\n",
      "Epoch 385/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0705 - acc: 0.2230\n",
      "Epoch 386/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0705 - acc: 0.1941\n",
      "Epoch 387/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0705 - acc: 0.2098\n",
      "Epoch 388/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0703 - acc: 0.2010\n",
      "Epoch 389/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.2022\n",
      "Epoch 390/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0705 - acc: 0.1958\n",
      "Epoch 391/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.1963\n",
      "Epoch 392/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.1906\n",
      "Epoch 393/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0705 - acc: 0.2018\n",
      "Epoch 394/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0703 - acc: 0.1965\n",
      "Epoch 395/500\n",
      "10001/10001 [==============================] - 0s 50us/step - loss: 0.0703 - acc: 0.2044\n",
      "Epoch 396/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0705 - acc: 0.1964\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2126\n",
      "Epoch 398/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2020\n",
      "Epoch 399/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.2059\n",
      "Epoch 400/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.1990\n",
      "Epoch 401/500\n",
      "10001/10001 [==============================] - 0s 33us/step - loss: 0.0703 - acc: 0.2087\n",
      "Epoch 402/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0703 - acc: 0.2018\n",
      "Epoch 403/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.1961\n",
      "Epoch 404/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2041\n",
      "Epoch 405/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1990\n",
      "Epoch 406/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1962\n",
      "Epoch 407/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2031\n",
      "Epoch 408/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.1830\n",
      "Epoch 409/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.2027\n",
      "Epoch 410/500\n",
      "10001/10001 [==============================] - 0s 34us/step - loss: 0.0704 - acc: 0.2043\n",
      "Epoch 411/500\n",
      "10001/10001 [==============================] - 0s 39us/step - loss: 0.0704 - acc: 0.2105: 0s - loss: 0.0703 - acc: 0.2\n",
      "Epoch 412/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0705 - acc: 0.2089\n",
      "Epoch 413/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0703 - acc: 0.2043\n",
      "Epoch 414/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.1992\n",
      "Epoch 415/500\n",
      "10001/10001 [==============================] - 0s 33us/step - loss: 0.0703 - acc: 0.2046\n",
      "Epoch 416/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.1801\n",
      "Epoch 417/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.1980\n",
      "Epoch 418/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.2106\n",
      "Epoch 419/500\n",
      "10001/10001 [==============================] - 0s 34us/step - loss: 0.0703 - acc: 0.2154\n",
      "Epoch 420/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0704 - acc: 0.1991\n",
      "Epoch 421/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0703 - acc: 0.2148\n",
      "Epoch 422/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2001\n",
      "Epoch 423/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0707 - acc: 0.1972\n",
      "Epoch 424/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2020\n",
      "Epoch 425/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0703 - acc: 0.1999\n",
      "Epoch 426/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.2097\n",
      "Epoch 427/500\n",
      "10001/10001 [==============================] - 0s 37us/step - loss: 0.0704 - acc: 0.1944\n",
      "Epoch 428/500\n",
      "10001/10001 [==============================] - 0s 41us/step - loss: 0.0703 - acc: 0.2044\n",
      "Epoch 429/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0704 - acc: 0.1865\n",
      "Epoch 430/500\n",
      "10001/10001 [==============================] - 0s 33us/step - loss: 0.0705 - acc: 0.2043\n",
      "Epoch 431/500\n",
      "10001/10001 [==============================] - 0s 43us/step - loss: 0.0704 - acc: 0.1930\n",
      "Epoch 432/500\n",
      "10001/10001 [==============================] - 0s 43us/step - loss: 0.0704 - acc: 0.2037\n",
      "Epoch 433/500\n",
      "10001/10001 [==============================] - 0s 34us/step - loss: 0.0705 - acc: 0.2062\n",
      "Epoch 434/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.2006\n",
      "Epoch 435/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0702 - acc: 0.1894\n",
      "Epoch 436/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2141\n",
      "Epoch 437/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0706 - acc: 0.2056\n",
      "Epoch 438/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.1972\n",
      "Epoch 439/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.2036\n",
      "Epoch 440/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.1972\n",
      "Epoch 441/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.2008\n",
      "Epoch 442/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0704 - acc: 0.1947\n",
      "Epoch 443/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2170\n",
      "Epoch 444/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0704 - acc: 0.1995\n",
      "Epoch 445/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0703 - acc: 0.1951\n",
      "Epoch 446/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2060\n",
      "Epoch 447/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.2023\n",
      "Epoch 448/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.2041\n",
      "Epoch 449/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1957\n",
      "Epoch 450/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.1947\n",
      "Epoch 451/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0703 - acc: 0.1901\n",
      "Epoch 452/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0706 - acc: 0.1941\n",
      "Epoch 453/500\n",
      "10001/10001 [==============================] - 0s 34us/step - loss: 0.0704 - acc: 0.2101\n",
      "Epoch 454/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0703 - acc: 0.2031\n",
      "Epoch 455/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.1965\n",
      "Epoch 456/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.1934\n",
      "Epoch 457/500\n",
      "10001/10001 [==============================] - 0s 25us/step - loss: 0.0705 - acc: 0.2041\n",
      "Epoch 458/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0704 - acc: 0.2030\n",
      "Epoch 459/500\n",
      "10001/10001 [==============================] - 0s 33us/step - loss: 0.0705 - acc: 0.2050\n",
      "Epoch 460/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0702 - acc: 0.1960\n",
      "Epoch 461/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0706 - acc: 0.2017\n",
      "Epoch 462/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0705 - acc: 0.2032\n",
      "Epoch 463/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.2020\n",
      "Epoch 464/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.2032\n",
      "Epoch 465/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.1984\n",
      "Epoch 466/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.2014\n",
      "Epoch 467/500\n",
      "10001/10001 [==============================] - 0s 31us/step - loss: 0.0704 - acc: 0.1995\n",
      "Epoch 468/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0703 - acc: 0.1792\n",
      "Epoch 469/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.2007\n",
      "Epoch 470/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0703 - acc: 0.2129\n",
      "Epoch 471/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0706 - acc: 0.2026\n",
      "Epoch 472/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.2047\n",
      "Epoch 473/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.2074\n",
      "Epoch 474/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0704 - acc: 0.1882\n",
      "Epoch 475/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.1834\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0705 - acc: 0.2008\n",
      "Epoch 477/500\n",
      "10001/10001 [==============================] - 0s 27us/step - loss: 0.0702 - acc: 0.2225\n",
      "Epoch 478/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0703 - acc: 0.2040\n",
      "Epoch 479/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0703 - acc: 0.2044\n",
      "Epoch 480/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0706 - acc: 0.1942\n",
      "Epoch 481/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0706 - acc: 0.2002\n",
      "Epoch 482/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0703 - acc: 0.1944\n",
      "Epoch 483/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0703 - acc: 0.1964\n",
      "Epoch 484/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0704 - acc: 0.1950\n",
      "Epoch 485/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0706 - acc: 0.2060\n",
      "Epoch 486/500\n",
      "10001/10001 [==============================] - 0s 26us/step - loss: 0.0703 - acc: 0.1974\n",
      "Epoch 487/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0703 - acc: 0.2027\n",
      "Epoch 488/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0708 - acc: 0.2091\n",
      "Epoch 489/500\n",
      "10001/10001 [==============================] - 0s 28us/step - loss: 0.0703 - acc: 0.1996\n",
      "Epoch 490/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0702 - acc: 0.1957\n",
      "Epoch 491/500\n",
      "10001/10001 [==============================] - 0s 29us/step - loss: 0.0704 - acc: 0.1980\n",
      "Epoch 492/500\n",
      "10001/10001 [==============================] - 0s 30us/step - loss: 0.0706 - acc: 0.1984\n",
      "Epoch 493/500\n",
      "10001/10001 [==============================] - 0s 47us/step - loss: 0.0703 - acc: 0.1971\n",
      "Epoch 494/500\n",
      "10001/10001 [==============================] - 0s 47us/step - loss: 0.0703 - acc: 0.1961\n",
      "Epoch 495/500\n",
      "10001/10001 [==============================] - 0s 47us/step - loss: 0.0704 - acc: 0.2037\n",
      "Epoch 496/500\n",
      "10001/10001 [==============================] - 0s 45us/step - loss: 0.0705 - acc: 0.2104\n",
      "Epoch 497/500\n",
      "10001/10001 [==============================] - 0s 48us/step - loss: 0.0704 - acc: 0.1960\n",
      "Epoch 498/500\n",
      "10001/10001 [==============================] - 0s 39us/step - loss: 0.0704 - acc: 0.1927\n",
      "Epoch 499/500\n",
      "10001/10001 [==============================] - 0s 42us/step - loss: 0.0703 - acc: 0.2013\n",
      "Epoch 500/500\n",
      "10001/10001 [==============================] - 0s 32us/step - loss: 0.0704 - acc: 0.2068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb311274a8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, label_equalsize, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4, 11, 11, 14])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.vstack([train,train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_equalsize = np.vstack([label_equalsize,label_equalsize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_equalsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_genelization(k=3,loops = 10000):\n",
    "    temp = ''.join(random.choices(string.ascii_uppercase, k))\n",
    "    ciphertext, ciphernum, plainnum = caeserde_1(temp)\n",
    "\n",
    "    a = letter_position_matrix(plainnum)\n",
    "    b = letter_position_matrix(ciphernum)\n",
    "\n",
    "    label_smaller = np.array(plainnum)\n",
    "    # flatten label and training set\n",
    "    label_equalsize = a.flatten()\n",
    "    train = b.flatten()\n",
    "    for i in range(loops):\n",
    "        temp = ''.join(random.choices(string.ascii_uppercase, k))\n",
    "        ciphertext, ciphernum, plainnum = caeserde_1(temp)\n",
    "        a = letter_position_matrix(plainnum)\n",
    "        b = letter_position_matrix(ciphernum)\n",
    "        label_smaller = np.vstack([label_smaller,np.array(plainnum)])\n",
    "        # flatten label and training set\n",
    "        label_equalsize = np.vstack([label_equalsize,a.flatten()])\n",
    "        train = np.vstack([train,b.flatten()])\n",
    "    return(train,label_equalsize,label_smaller)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,label_equalsize,label_smaller = data_genelization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_equalsize.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "784px",
    "left": "30px",
    "top": "180px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
