{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caesar Ciphermodelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning structure 1: One input vs one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for one two one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are going to train it in our model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(26, input_dim=1, name=\"test1\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, init='uniform', name = 'test1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5)) drop out doesn't help\n",
    "\n",
    "model.add(Dense(26, name = 'test2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test4'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test5'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, name = 'test6'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "# Try other metrics\n",
    "# model.compile(loss='mse', optimizer='sgd', metrics=['mse', 'mae', 'mape', 'cosine', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",x_as_vector = False, y_as_vector = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 210.9215 - acc: 0.0385\n",
      "Epoch 2/250\n",
      "26/26 [==============================] - 0s 128us/step - loss: 200.5929 - acc: 0.0385\n",
      "Epoch 3/250\n",
      "26/26 [==============================] - 0s 130us/step - loss: 172.2927 - acc: 0.0385\n",
      "Epoch 4/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 146.3232 - acc: 0.0385\n",
      "Epoch 5/250\n",
      "26/26 [==============================] - 0s 133us/step - loss: 122.6608 - acc: 0.0385\n",
      "Epoch 6/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 100.6445 - acc: 0.0385\n",
      "Epoch 7/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 85.2447 - acc: 0.0385\n",
      "Epoch 8/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 75.5784 - acc: 0.0385\n",
      "Epoch 9/250\n",
      "26/26 [==============================] - 0s 172us/step - loss: 70.6439 - acc: 0.0385\n",
      "Epoch 10/250\n",
      "26/26 [==============================] - 0s 149us/step - loss: 68.4071 - acc: 0.0385\n",
      "Epoch 11/250\n",
      "26/26 [==============================] - 0s 164us/step - loss: 67.3769 - acc: 0.0385\n",
      "Epoch 12/250\n",
      "26/26 [==============================] - 0s 214us/step - loss: 66.9286 - acc: 0.3462\n",
      "Epoch 13/250\n",
      "26/26 [==============================] - 0s 165us/step - loss: 66.7387 - acc: 0.6154\n",
      "Epoch 14/250\n",
      "26/26 [==============================] - 0s 163us/step - loss: 66.6612 - acc: 0.7308\n",
      "Epoch 15/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 66.6300 - acc: 0.7692\n",
      "Epoch 16/250\n",
      "26/26 [==============================] - 0s 191us/step - loss: 66.6187 - acc: 0.8462\n",
      "Epoch 17/250\n",
      "26/26 [==============================] - 0s 172us/step - loss: 66.6201 - acc: 0.8462\n",
      "Epoch 18/250\n",
      "26/26 [==============================] - 0s 166us/step - loss: 66.6306 - acc: 0.7308\n",
      "Epoch 19/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 66.6608 - acc: 0.7692\n",
      "Epoch 20/250\n",
      "26/26 [==============================] - 0s 183us/step - loss: 66.6760 - acc: 0.6923\n",
      "Epoch 21/250\n",
      "26/26 [==============================] - 0s 185us/step - loss: 66.7072 - acc: 0.6923\n",
      "Epoch 22/250\n",
      "26/26 [==============================] - 0s 193us/step - loss: 66.6643 - acc: 0.6538\n",
      "Epoch 23/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 66.6617 - acc: 0.7692\n",
      "Epoch 24/250\n",
      "26/26 [==============================] - 0s 218us/step - loss: 66.6245 - acc: 0.8462\n",
      "Epoch 25/250\n",
      "26/26 [==============================] - 0s 170us/step - loss: 66.6130 - acc: 0.8462\n",
      "Epoch 26/250\n",
      "26/26 [==============================] - 0s 185us/step - loss: 66.5963 - acc: 0.8462\n",
      "Epoch 27/250\n",
      "26/26 [==============================] - 0s 183us/step - loss: 66.5909 - acc: 0.8462\n",
      "Epoch 28/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5880 - acc: 0.8462\n",
      "Epoch 29/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 66.5856 - acc: 0.8462\n",
      "Epoch 30/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5842 - acc: 0.8462\n",
      "Epoch 31/250\n",
      "26/26 [==============================] - 0s 158us/step - loss: 66.5832 - acc: 0.8462\n",
      "Epoch 32/250\n",
      "26/26 [==============================] - 0s 181us/step - loss: 66.5825 - acc: 0.8462\n",
      "Epoch 33/250\n",
      "26/26 [==============================] - 0s 182us/step - loss: 66.5820 - acc: 0.8462\n",
      "Epoch 34/250\n",
      "26/26 [==============================] - 0s 167us/step - loss: 66.5816 - acc: 0.8462\n",
      "Epoch 35/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5813 - acc: 0.8462\n",
      "Epoch 36/250\n",
      "26/26 [==============================] - 0s 191us/step - loss: 66.5810 - acc: 0.8462\n",
      "Epoch 37/250\n",
      "26/26 [==============================] - 0s 166us/step - loss: 66.5808 - acc: 0.8462\n",
      "Epoch 38/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5807 - acc: 0.8462\n",
      "Epoch 39/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5805 - acc: 0.8462\n",
      "Epoch 40/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5804 - acc: 0.8462\n",
      "Epoch 41/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 66.5803 - acc: 0.8462\n",
      "Epoch 42/250\n",
      "26/26 [==============================] - 0s 197us/step - loss: 66.5801 - acc: 0.8462\n",
      "Epoch 43/250\n",
      "26/26 [==============================] - 0s 166us/step - loss: 66.5800 - acc: 0.8462\n",
      "Epoch 44/250\n",
      "26/26 [==============================] - 0s 155us/step - loss: 66.5799 - acc: 0.8462\n",
      "Epoch 45/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5798 - acc: 0.8462\n",
      "Epoch 46/250\n",
      "26/26 [==============================] - 0s 172us/step - loss: 66.5798 - acc: 0.8462\n",
      "Epoch 47/250\n",
      "26/26 [==============================] - 0s 218us/step - loss: 66.5797 - acc: 0.8462\n",
      "Epoch 48/250\n",
      "26/26 [==============================] - 0s 198us/step - loss: 66.5796 - acc: 0.8462\n",
      "Epoch 49/250\n",
      "26/26 [==============================] - 0s 176us/step - loss: 66.5795 - acc: 0.8462\n",
      "Epoch 50/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 66.5795 - acc: 0.8462\n",
      "Epoch 51/250\n",
      "26/26 [==============================] - 0s 201us/step - loss: 66.5794 - acc: 0.8462\n",
      "Epoch 52/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 66.5793 - acc: 0.8462\n",
      "Epoch 53/250\n",
      "26/26 [==============================] - 0s 167us/step - loss: 66.5793 - acc: 0.8462\n",
      "Epoch 54/250\n",
      "26/26 [==============================] - 0s 186us/step - loss: 66.5792 - acc: 0.8462\n",
      "Epoch 55/250\n",
      "26/26 [==============================] - 0s 193us/step - loss: 66.5791 - acc: 0.8462\n",
      "Epoch 56/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5791 - acc: 0.8462\n",
      "Epoch 57/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5790 - acc: 0.8462\n",
      "Epoch 58/250\n",
      "26/26 [==============================] - 0s 185us/step - loss: 66.5790 - acc: 0.8462\n",
      "Epoch 59/250\n",
      "26/26 [==============================] - 0s 255us/step - loss: 66.5789 - acc: 0.8462\n",
      "Epoch 60/250\n",
      "26/26 [==============================] - 0s 167us/step - loss: 66.5789 - acc: 0.8462\n",
      "Epoch 61/250\n",
      "26/26 [==============================] - 0s 189us/step - loss: 66.5789 - acc: 0.8462\n",
      "Epoch 62/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5788 - acc: 0.8462\n",
      "Epoch 63/250\n",
      "26/26 [==============================] - 0s 234us/step - loss: 66.5787 - acc: 0.8462\n",
      "Epoch 64/250\n",
      "26/26 [==============================] - 0s 176us/step - loss: 66.5786 - acc: 0.8462\n",
      "Epoch 65/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 66.5785 - acc: 0.8462\n",
      "Epoch 66/250\n",
      "26/26 [==============================] - 0s 140us/step - loss: 66.5785 - acc: 0.8462\n",
      "Epoch 67/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 66.5784 - acc: 0.8462\n",
      "Epoch 68/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 66.5783 - acc: 0.8462\n",
      "Epoch 69/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5783 - acc: 0.8462\n",
      "Epoch 70/250\n",
      "26/26 [==============================] - 0s 162us/step - loss: 66.5782 - acc: 0.8462\n",
      "Epoch 71/250\n",
      "26/26 [==============================] - 0s 181us/step - loss: 66.5782 - acc: 0.8462\n",
      "Epoch 72/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5781 - acc: 0.8462\n",
      "Epoch 73/250\n",
      "26/26 [==============================] - 0s 135us/step - loss: 66.5781 - acc: 0.8462\n",
      "Epoch 74/250\n",
      "26/26 [==============================] - 0s 195us/step - loss: 66.5780 - acc: 0.8462\n",
      "Epoch 75/250\n",
      "26/26 [==============================] - 0s 171us/step - loss: 66.5780 - acc: 0.8462\n",
      "Epoch 76/250\n",
      "26/26 [==============================] - 0s 169us/step - loss: 66.5779 - acc: 0.8462\n",
      "Epoch 77/250\n",
      "26/26 [==============================] - 0s 182us/step - loss: 66.5779 - acc: 0.8462\n",
      "Epoch 78/250\n",
      "26/26 [==============================] - 0s 187us/step - loss: 66.5779 - acc: 0.8462\n",
      "Epoch 79/250\n",
      "26/26 [==============================] - 0s 195us/step - loss: 66.5778 - acc: 0.8462\n",
      "Epoch 80/250\n",
      "26/26 [==============================] - 0s 175us/step - loss: 66.5778 - acc: 0.8462\n",
      "Epoch 81/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5778 - acc: 0.8462\n",
      "Epoch 82/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 66.5777 - acc: 0.8462\n",
      "Epoch 83/250\n",
      "26/26 [==============================] - 0s 175us/step - loss: 66.5777 - acc: 0.8462\n",
      "Epoch 84/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5777 - acc: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 66.5777 - acc: 0.8462\n",
      "Epoch 86/250\n",
      "26/26 [==============================] - 0s 168us/step - loss: 66.5776 - acc: 0.8462\n",
      "Epoch 87/250\n",
      "26/26 [==============================] - 0s 183us/step - loss: 66.5776 - acc: 0.8462\n",
      "Epoch 88/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 66.5776 - acc: 0.8462\n",
      "Epoch 89/250\n",
      "26/26 [==============================] - 0s 165us/step - loss: 66.5776 - acc: 0.8462\n",
      "Epoch 90/250\n",
      "26/26 [==============================] - 0s 180us/step - loss: 66.5775 - acc: 0.8462\n",
      "Epoch 91/250\n",
      "26/26 [==============================] - 0s 156us/step - loss: 66.5775 - acc: 0.8462\n",
      "Epoch 92/250\n",
      "26/26 [==============================] - 0s 190us/step - loss: 66.5775 - acc: 0.8462\n",
      "Epoch 93/250\n",
      "26/26 [==============================] - 0s 176us/step - loss: 66.5775 - acc: 0.8462\n",
      "Epoch 94/250\n",
      "26/26 [==============================] - 0s 164us/step - loss: 66.5775 - acc: 0.8462\n",
      "Epoch 95/250\n",
      "26/26 [==============================] - 0s 174us/step - loss: 66.5774 - acc: 0.8462\n",
      "Epoch 96/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5774 - acc: 0.8462\n",
      "Epoch 97/250\n",
      "26/26 [==============================] - 0s 171us/step - loss: 66.5774 - acc: 0.8462\n",
      "Epoch 98/250\n",
      "26/26 [==============================] - 0s 163us/step - loss: 66.5774 - acc: 0.8462\n",
      "Epoch 99/250\n",
      "26/26 [==============================] - 0s 169us/step - loss: 66.5774 - acc: 0.8462\n",
      "Epoch 100/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5774 - acc: 0.8462\n",
      "Epoch 101/250\n",
      "26/26 [==============================] - 0s 143us/step - loss: 66.5774 - acc: 0.8462\n",
      "Epoch 102/250\n",
      "26/26 [==============================] - 0s 165us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 103/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 104/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 105/250\n",
      "26/26 [==============================] - 0s 149us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 106/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 107/250\n",
      "26/26 [==============================] - 0s 163us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 108/250\n",
      "26/26 [==============================] - 0s 145us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 109/250\n",
      "26/26 [==============================] - 0s 160us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 110/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 111/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 112/250\n",
      "26/26 [==============================] - 0s 173us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 113/250\n",
      "26/26 [==============================] - 0s 169us/step - loss: 66.5773 - acc: 0.8462\n",
      "Epoch 114/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 115/250\n",
      "26/26 [==============================] - 0s 163us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 116/250\n",
      "26/26 [==============================] - 0s 162us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 117/250\n",
      "26/26 [==============================] - 0s 165us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 118/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 119/250\n",
      "26/26 [==============================] - 0s 161us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 120/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 121/250\n",
      "26/26 [==============================] - 0s 160us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 122/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 123/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 124/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 125/250\n",
      "26/26 [==============================] - 0s 161us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 126/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 127/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 128/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 129/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 130/250\n",
      "26/26 [==============================] - 0s 169us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 131/250\n",
      "26/26 [==============================] - 0s 155us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 132/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 133/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 134/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 135/250\n",
      "26/26 [==============================] - 0s 145us/step - loss: 66.5772 - acc: 0.8462\n",
      "Epoch 136/250\n",
      "26/26 [==============================] - 0s 139us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 137/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 138/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 139/250\n",
      "26/26 [==============================] - 0s 175us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 140/250\n",
      "26/26 [==============================] - 0s 175us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 141/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 142/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 143/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 144/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 145/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 146/250\n",
      "26/26 [==============================] - 0s 162us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 147/250\n",
      "26/26 [==============================] - 0s 160us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 148/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 149/250\n",
      "26/26 [==============================] - 0s 145us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 150/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 151/250\n",
      "26/26 [==============================] - 0s 136us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 152/250\n",
      "26/26 [==============================] - 0s 141us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 153/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 154/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 155/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 156/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 157/250\n",
      "26/26 [==============================] - 0s 137us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 158/250\n",
      "26/26 [==============================] - 0s 158us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 159/250\n",
      "26/26 [==============================] - 0s 158us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 160/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 161/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 162/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 163/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 164/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 165/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 166/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 167/250\n",
      "26/26 [==============================] - 0s 155us/step - loss: 66.5771 - acc: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 169/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 170/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 171/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 172/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 173/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 174/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 175/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 176/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 177/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 178/250\n",
      "26/26 [==============================] - 0s 145us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 179/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 180/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 181/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 182/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 183/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 184/250\n",
      "26/26 [==============================] - 0s 166us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 185/250\n",
      "26/26 [==============================] - 0s 155us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 186/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 187/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 188/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 189/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 190/250\n",
      "26/26 [==============================] - 0s 164us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 191/250\n",
      "26/26 [==============================] - 0s 143us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 192/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 193/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 194/250\n",
      "26/26 [==============================] - 0s 158us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 195/250\n",
      "26/26 [==============================] - 0s 156us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 196/250\n",
      "26/26 [==============================] - 0s 143us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 197/250\n",
      "26/26 [==============================] - 0s 167us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 198/250\n",
      "26/26 [==============================] - 0s 169us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 199/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 200/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 201/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 202/250\n",
      "26/26 [==============================] - 0s 166us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 203/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 204/250\n",
      "26/26 [==============================] - 0s 163us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 205/250\n",
      "26/26 [==============================] - 0s 167us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 206/250\n",
      "26/26 [==============================] - 0s 165us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 207/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 208/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 209/250\n",
      "26/26 [==============================] - 0s 139us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 210/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 211/250\n",
      "26/26 [==============================] - 0s 158us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 212/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 213/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 214/250\n",
      "26/26 [==============================] - 0s 162us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 215/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 216/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 217/250\n",
      "26/26 [==============================] - 0s 149us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 218/250\n",
      "26/26 [==============================] - 0s 141us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 219/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 220/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 221/250\n",
      "26/26 [==============================] - 0s 136us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 222/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 223/250\n",
      "26/26 [==============================] - 0s 143us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 224/250\n",
      "26/26 [==============================] - 0s 161us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 225/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 226/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 227/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 228/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 229/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 230/250\n",
      "26/26 [==============================] - 0s 143us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 231/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 232/250\n",
      "26/26 [==============================] - 0s 153us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 233/250\n",
      "26/26 [==============================] - 0s 172us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 234/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 235/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 236/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 237/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 238/250\n",
      "26/26 [==============================] - 0s 140us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 239/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 66.5770 - acc: 0.8462\n",
      "Epoch 240/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 241/250\n",
      "26/26 [==============================] - 0s 143us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 242/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 243/250\n",
      "26/26 [==============================] - 0s 155us/step - loss: 66.5771 - acc: 0.8462\n",
      "Epoch 244/250\n",
      "26/26 [==============================] - 0s 156us/step - loss: 66.5770 - acc: 0.8462\n",
      "Epoch 245/250\n",
      "26/26 [==============================] - 0s 149us/step - loss: 66.5770 - acc: 0.8462\n",
      "Epoch 246/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 66.5770 - acc: 0.8462\n",
      "Epoch 247/250\n",
      "26/26 [==============================] - 0s 158us/step - loss: 66.5770 - acc: 0.8462\n",
      "Epoch 248/250\n",
      "26/26 [==============================] - 0s 149us/step - loss: 66.5770 - acc: 0.8462\n",
      "Epoch 249/250\n",
      "26/26 [==============================] - 0s 156us/step - loss: 66.5770 - acc: 0.8462\n",
      "Epoch 250/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 66.5770 - acc: 0.8462\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(x_train)/25, np.array(y_train), epochs = 250);#, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that: the acc is not reliable! Let's see the prediction results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ],\n",
       "       [ 0.30710387],\n",
       "       [ 2.334606  ],\n",
       "       [ 3.168542  ],\n",
       "       [ 4.025012  ],\n",
       "       [ 4.9450293 ],\n",
       "       [ 5.8202157 ],\n",
       "       [ 6.76533   ],\n",
       "       [ 7.671235  ],\n",
       "       [ 8.798743  ],\n",
       "       [ 9.64561   ],\n",
       "       [10.684941  ],\n",
       "       [11.557153  ],\n",
       "       [12.411064  ],\n",
       "       [13.374146  ],\n",
       "       [14.209664  ],\n",
       "       [15.174772  ],\n",
       "       [16.09178   ],\n",
       "       [16.995977  ],\n",
       "       [17.90018   ],\n",
       "       [18.804382  ],\n",
       "       [19.649502  ],\n",
       "       [20.591091  ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(x_train)/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "26/26 [==============================] - 1s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.990168571472168, 0.5384615659713745]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array(x_train)/25, np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",x_as_vector = False, y_as_vector = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb302d7f98>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# let change the prediction into int, see the confusion matrix\n",
    "array = confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25)))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obivously, the preformance for the last 3 shift is super terrible, that is to say, the model doesn't learn the shift at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look every layer output distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "# Set one layer as output we can get every layers' information given the input\n",
    "\n",
    "dense1_layer_model = Model(inputs=model.input,outputs=model.get_layer('test1').output)\n",
    "dense2_layer_model = Model(inputs=model.input,outputs=model.get_layer('test2').output)\n",
    "dense3_layer_model = Model(inputs=model.input,outputs=model.get_layer('test3').output)\n",
    "dense4_layer_model = Model(inputs=model.input,outputs=model.get_layer('test4').output)\n",
    "dense5_layer_model = Model(inputs=model.input,outputs=model.get_layer('test5').output)\n",
    "dense6_layer_model = Model(inputs=model.input,outputs=model.get_layer('test6').output)\n",
    "\n",
    "dense1_output = dense1_layer_model.predict(x_train)\n",
    "dense2_output = dense2_layer_model.predict(x_train)\n",
    "dense3_output = dense3_layer_model.predict(x_train)\n",
    "dense4_output = dense4_layer_model.predict(x_train)\n",
    "dense5_output = dense5_layer_model.predict(x_train)\n",
    "dense6_output = dense6_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are outputs for every layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6540859,  1.6317863,  1.5486274,  2.1778924,  1.550421 ,\n",
       "       -1.3439058, -1.4507976,  1.4593638,  1.651958 ,  1.2462304,\n",
       "       -1.0742825,  3.8927724, -1.5030813, -1.2671727, -5.6202264,\n",
       "       -1.7355103,  3.6116486, -1.8402138,  1.1256803,  1.1363708,\n",
       "        0.6707269, -1.257008 ,  1.2651299, -1.3189449, -1.438244 ,\n",
       "       -2.0975277], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense1_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense1_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.20709825,  14.430357  ,  13.512449  ,   0.92500806,\n",
       "        23.559223  ,   8.727803  ,   8.110909  , -11.185008  ,\n",
       "         9.719049  ,  44.062954  ,  -9.880723  ,  15.472969  ,\n",
       "       -13.067398  ,  22.101526  ,  -8.482821  ,  -5.6224585 ,\n",
       "         5.437292  , -11.951555  ,  14.404685  ,   3.5512338 ,\n",
       "       -12.2006445 , -13.181555  , -18.619743  ,  16.09866   ,\n",
       "         1.2781961 , -14.934793  ], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEVBJREFUeJzt3X+MZWV9x/H3pyw//NkFd0Dcxe7SrLZqbCUjobU1VDQCGpcm0qyxdbUkm6q1Wmt0KYmkf5CAbbSatpqtbFkSww9Ry6ZqLVIpaVIWBwQEVmQFCyMrOwZBrQmIfPvHPWuuw92d2fuDWZ55v5LJnPOc5977vU/gM88+95xzU1VIktr1K0tdgCRpsgx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuNWLHUBAKtWraq1a9cudRmS9LRy0003/aCqphbqd0gE/dq1a5mZmVnqMiTpaSXJ/y6mn0s3ktQ4g16SGrdg0CfZlmRvktvntb8nyV1J7kjykb72c5Ps7o69fhJFS5IWbzFr9JcA/wBcuq8hyR8AG4CXV9WjSY7t2l8CbAReCrwA+GqSF1XVz8dduCRpcRac0VfV9cBD85rfCVxYVY92ffZ27RuAy6vq0aq6F9gNnDzGeiVJB2nYNfoXAb+fZGeS/0ryyq59NXB/X7/Zrk2StESGPb1yBXA0cArwSuDKJCcCGdB34FdYJdkMbAZ44QtfOGQZkqSFDDujnwU+Xz03Ak8Aq7r2E/r6rQEeGPQEVbW1qqaranpqasHz/SVJQxo26P8VeA1AkhcBRwA/AHYAG5McmWQdsB64cRyFSpKGs+DSTZLLgFOBVUlmgfOBbcC27pTLx4BN1fuW8TuSXAncCTwOvNszbp7+1m754qL6fffCN0y4EknDWDDoq+ot+zn0x/vpfwFwwShFSZLGxytjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1bsGgT7Ityd7u+2HnH/tAkkqyqttPkk8k2Z3ktiQnTaJoSdLiLWZGfwlw+vzGJCcArwPu62s+A1jf/WwGPjl6iZKkUSwY9FV1PfDQgEMfAz4IVF/bBuDS6rkBWJnk+LFUKkkaylBr9EneBHyvqm6dd2g1cH/f/mzXNug5NieZSTIzNzc3TBmSpEU46KBP8kzgPODDgw4PaKsBbVTV1qqarqrpqampgy1DkrRIK4Z4zK8D64BbkwCsAW5OcjK9GfwJfX3XAA+MWqQkaXgHPaOvqm9W1bFVtbaq1tIL95Oq6vvADuBt3dk3pwCPVNWe8ZYsSToYizm98jLgf4AXJ5lNcs4Bun8JuAfYDfwz8K6xVClJGtqCSzdV9ZYFjq/t2y7g3aOXJUkaF6+MlaTGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYt5qsEtyXZm+T2vra/TfKtJLcl+UKSlX3Hzk2yO8ldSV4/qcIlSYuzmBn9JcDp89quAV5WVS8Hvg2cC5DkJcBG4KXdY/4pyWFjq1aSdNAWDPqquh54aF7bf1TV493uDcCabnsDcHlVPVpV99L7kvCTx1ivJOkgjWON/k+BL3fbq4H7+47Ndm2SpCUyUtAnOQ94HPjMvqYB3Wo/j92cZCbJzNzc3ChlSJIOYOigT7IJeCPw1qraF+azwAl93dYADwx6fFVtrarpqpqempoatgxJ0gKGCvokpwMfAt5UVT/tO7QD2JjkyCTrgPXAjaOXKUka1oqFOiS5DDgVWJVkFjif3lk2RwLXJAG4oar+rKruSHIlcCe9JZ13V9XPJ1W8JGlhCwZ9Vb1lQPPFB+h/AXDBKEVJksbHK2MlqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQsGfZJtSfYmub2v7Zgk1yS5u/t9dNeeJJ9IsjvJbUlOmmTxkqSFLWZGfwlw+ry2LcC1VbUeuLbbBziD3heCrwc2A58cT5mSpGEtGPRVdT3w0LzmDcD2bns7cFZf+6XVcwOwMsnx4ypWknTwhl2jP66q9gB0v4/t2lcD9/f1m+3aJElLZNwfxmZAWw3smGxOMpNkZm5ubsxlSJL2GTboH9y3JNP93tu1zwIn9PVbAzww6AmqamtVTVfV9NTU1JBlSJIWMmzQ7wA2ddubgKv72t/WnX1zCvDIviUeSdLSWLFQhySXAacCq5LMAucDFwJXJjkHuA84u+v+JeBMYDfwU+AdE6hZknQQFgz6qnrLfg6dNqBvAe8etShJ0vh4ZawkNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1bqSgT/KXSe5IcnuSy5IclWRdkp1J7k5yRZIjxlWsJOngDR30SVYDfwFMV9XLgMOAjcBFwMeqaj3wQ+CccRQqSRrOqEs3K4BnJFkBPBPYA7wGuKo7vh04a8TXkCSNYOigr6rvAX8H3Ecv4B8BbgIerqrHu26zwOpRi5QkDW+UpZujgQ3AOuAFwLOAMwZ0rf08fnOSmSQzc3Nzw5YhSVrAKEs3rwXuraq5qvoZ8Hngd4GV3VIOwBrggUEPrqqtVTVdVdNTU1MjlCFJOpBRgv4+4JQkz0wS4DTgTuBrwJu7PpuAq0crUZI0ilHW6HfS+9D1ZuCb3XNtBT4EvD/JbuB5wMVjqFOSNKQVC3fZv6o6Hzh/XvM9wMmjPK8kaXy8MlaSGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaN1LQJ1mZ5Kok30qyK8nvJDkmyTVJ7u5+Hz2uYiVJB2/UGf3HgX+vqt8AfgvYBWwBrq2q9cC13b4kaYkM/Z2xSZ4LvBp4O0BVPQY8lmQDcGrXbTtwHb0vDFfj1m754oJ9vnvhG56CSiT1G2VGfyIwB/xLkm8k+XSSZwHHVdUegO73sWOoU5I0pFGCfgVwEvDJqnoF8H8cxDJNks1JZpLMzM3NjVCGJOlARgn6WWC2qnZ2+1fRC/4HkxwP0P3eO+jBVbW1qqaranpqamqEMiRJBzJ00FfV94H7k7y4azoNuBPYAWzq2jYBV49UoSRpJEN/GNt5D/CZJEcA9wDvoPfH48ok5wD3AWeP+BqSpBGMFPRVdQswPeDQaaM8ryRpfLwyVpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjRr3XjXRQFvPlJOAXlEjjZNAvY4sNXUlPby7dSFLjDHpJapxBL0mNc42+Qa69S+rnjF6SGueM/mnEmbqkYYw8o09yWJJvJPm3bn9dkp1J7k5yRfd9spKkJTKOpZv3Arv69i8CPlZV64EfAueM4TUkSUMaKeiTrAHeAHy62w/wGuCqrst24KxRXkOSNJpRZ/R/D3wQeKLbfx7wcFU93u3PAqsHPTDJ5iQzSWbm5uZGLEOStD9DB32SNwJ7q+qm/uYBXWvQ46tqa1VNV9X01NTUsGVIkhYwylk3rwLelORM4CjgufRm+CuTrOhm9WuAB0YvU5I0rKGDvqrOBc4FSHIq8IGqemuSzwJvBi4HNgFXj6FOLTPe5VIan0lcMPUh4P1JdtNbs794Aq8hSVqksVwwVVXXAdd12/cAJ4/jeSVJo/PK2EOEV71KmhTvdSNJjTPoJalxBr0kNc6gl6TG+WHshPkh62R5vr20MGf0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOK+M1bLgFbRazpzRS1Ljhp7RJzkBuBR4PvAEsLWqPp7kGOAKYC3wXeCPquqHo5d6aPEeNpKeLkZZunkc+KuqujnJc4CbklwDvB24tqouTLIF2ELve2SlQ55LPGrR0Es3VbWnqm7utn8M7AJWAxuA7V237cBZoxYpSRreWNbok6wFXgHsBI6rqj3Q+2MAHDuO15AkDWfkoE/ybOBzwPuq6kcH8bjNSWaSzMzNzY1ahiRpP0YK+iSH0wv5z1TV57vmB5Mc3x0/Htg76LFVtbWqpqtqempqapQyJEkHMHTQJwlwMbCrqj7ad2gHsKnb3gRcPXx5kqRRjXLWzauAPwG+meSWru2vgQuBK5OcA9wHnD1aiZKkUQwd9FX130D2c/i0YZ9XkjReXhkrSY3zXjfSEBZzYZUXVelQ4Yxekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DgvmJrHrwiU1Bpn9JLUOGf00oT4/bM6VBj00hLzD4ImzaCXnib8g6BhuUYvSY1bNjN6z6bRcuHMX/NNLOiTnA58HDgM+HRVXTiJ1zHAJenAJhL0SQ4D/hF4HTALfD3Jjqq6cxKvJ2lp+a+IJzuUxmRSM/qTgd1VdQ9AksuBDYBBLx0iluJfw/4LfGlM6sPY1cD9ffuzXZsk6Sk2qRl9BrTVL3VINgObu92fJLlrQrUMYxXwg6Uu4hDkuAzmuDyZYzLYk8YlF430fL+2mE6TCvpZ4IS+/TXAA/0dqmorsHVCrz+SJDNVNb3UdRxqHJfBHJcnc0wGW6pxmdTSzdeB9UnWJTkC2AjsmNBrSZIOYCIz+qp6PMmfA1+hd3rltqq6YxKvJUk6sImdR19VXwK+NKnnn7BDcknpEOC4DOa4PJljMtiSjEuqauFekqSnLe91I0mNW/ZBn+TsJHckeSLJ9Lxj5ybZneSuJK/vaz+9a9udZMtTX/VTa7m9335JtiXZm+T2vrZjklyT5O7u99Fde5J8ohun25KctHSVT1aSE5J8Lcmu7v+f93bty3pskhyV5MYkt3bj8jdd+7okO7txuaI7SYUkR3b7u7vjaydSWFUt6x/gN4EXA9cB033tLwFuBY4E1gHfoffB8mHd9onAEV2flyz1+5jg+Cyr9zvg/b8aOAm4va/tI8CWbnsLcFG3fSbwZXrXkZwC7Fzq+ic4LscDJ3XbzwG+3f0/s6zHpnt/z+62Dwd2du/3SmBj1/4p4J3d9ruAT3XbG4ErJlHXsp/RV9Wuqhp0sdYG4PKqerSq7gV207u1wy9u71BVjwH7bu/QquX2fn9JVV0PPDSveQOwvdveDpzV135p9dwArExy/FNT6VOrqvZU1c3d9o+BXfSufl/WY9O9v590u4d3PwW8Briqa58/LvvG6yrgtCSDLjgdybIP+gPY320cltvtHZbb+12M46pqD/QCDzi2a1+WY9UtN7yC3ux12Y9NksOS3ALsBa6h9y/ih6vq8a5L/3v/xbh0xx8BnjfumpbF/eiTfBV4/oBD51XV1ft72IC2YvAfx5ZPXVrwdhb6hWU3VkmeDXwOeF9V/egAk9FlMzZV9XPgt5OsBL5Ab3n4Sd2630/JuCyLoK+q1w7xsAPdxuGAt3dozIK3s1iGHkxyfFXt6ZYf9nbty2qskhxOL+Q/U1Wf75odm05VPZzkOnpr9CuTrOhm7f3vfd+4zCZZAfwqT14qHJlLN/u3A9jYfSq+DlgP3Mjyu73Dcnu/i7ED2NRtbwKu7mt/W3eGySnAI/uWMVrTrSNfDOyqqo/2HVrWY5NkqpvJk+QZwGvpfX7xNeDNXbf547JvvN4M/Gd1n8yO1VJ/Sr3UP8Af0vur+ijwIPCVvmPn0Vtfuws4o6/9THpnGXyH3vLPkr+PCY/Rsnq/8977ZcAe4Gfdfyfn0FtDvRa4u/t9TNc39L5w5zvAN+k7i6u1H+D36C0x3Abc0v2cudzHBng58I1uXG4HPty1n0hvorgb+CxwZNd+VLe/uzt+4iTq8spYSWqcSzeS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxv0/B4IGSf0/MxcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense2_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense2_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.4410836 ,  -9.105474  ,  15.676118  ,  -9.318669  ,\n",
       "         8.748841  ,   5.7373047 ,  20.637873  ,  -1.5980177 ,\n",
       "        -3.6565766 ,  32.927288  ,  15.425644  ,  -1.0056641 ,\n",
       "       -28.894276  , -14.092319  ,  10.26556   ,  -0.24153621,\n",
       "        22.914541  ,  -6.516087  ,   8.239942  ,  23.500017  ,\n",
       "        -1.3756721 ,  26.277464  ,   4.524889  , -16.894114  ,\n",
       "       -11.700851  , -11.768911  ], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense3_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense3_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.383335 ,   7.911746 , -38.15727  , -24.108694 ,  21.895624 ,\n",
       "        18.938076 , -11.388611 ,  -9.488577 ,  -2.2501006,  -4.944135 ,\n",
       "        17.008898 , -19.984873 , -23.141445 ,  17.605324 ,   7.3482776,\n",
       "        -3.8314319,  10.94987  ,  -8.8120575, -15.924946 ,  -7.4452796,\n",
       "       -13.437435 ,  16.968836 ,  19.50152  , -47.44281  ,  23.04432  ,\n",
       "        -7.126564 ], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADgtJREFUeJzt3X+IZWd9x/H3p9lGq0WyayZp3Eg3wmINhWIYJK0gYkTzQ9wUDEREFw3sP1rtD2jWBpo/2kLSllqFoizGdgVrKrFlt8RWt1uD9A/TTjTVxGizRpus2WZH/NVWUIPf/jFn9XYzk5m5P3J3vvN+weWe85zn3vN9mJ3PPHvOPeemqpAk9fUz8y5AkjRbBr0kNWfQS1JzBr0kNWfQS1JzBr0kNWfQS1JzBr0kNWfQS1JzO+ZdAMCFF15Ye/bsmXcZkrSl3Hfffd+sqoX1+p0TQb9nzx6WlpbmXYYkbSlJ/nMj/Tx0I0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNnRNXxkqajT0H795Qv6/fdt2MK9E8OaOXpOYMeklqzqCXpOYMeklqzqCXpOYMeklqzqCXpOYMeklqzqCXpOYMeklqzqCXpOYMeklqzqCXpOYMeklqzqCXpOYMeklqzqCXpOYMeklqzqCXpObWDfokH0pyOskDI227khxL8vDwvHNoT5L3JTmR5AtJrphl8ZKk9W1kRv9XwNVntR0EjlfVXuD4sA5wDbB3eBwA3j+dMiVJ41o36KvqM8C3zmreBxwelg8D14+0f7hWfBa4IMkl0ypWkrR54x6jv7iqTgEMzxcN7buBx0b6nRzaJElzMu2TsVmlrVbtmBxIspRkaXl5ecplSJLOGDfonzhzSGZ4Pj20nwReONLvUuDx1d6gqg5V1WJVLS4sLIxZhiRpPeMG/VFg/7C8Hzgy0v6W4dM3VwLfPXOIR5I0HzvW65Dko8ArgQuTnARuBW4DPpbkJuBR4Iah+yeAa4ETwPeBt86gZknSJqwb9FX1xjU2XbVK3wLePmlRkqTpWTfoJZ1b9hy8e94laIvxFgiS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1NxEQZ/kt5I8mOSBJB9N8uwklyW5N8nDSf4myfnTKlaStHljB32S3cA7gcWq+mXgPOBG4HbgPVW1F/g2cNM0CpUkjWfSQzc7gJ9LsgN4DnAKeBVw17D9MHD9hPuQJE1g7KCvqm8Afwo8ykrAfxe4D/hOVT05dDsJ7F7t9UkOJFlKsrS8vDxuGZKkdUxy6GYnsA+4DHgB8FzgmlW61mqvr6pDVbVYVYsLCwvjliFJWsckh25eDXytqpar6kfA3wK/BlwwHMoBuBR4fMIaJUkTmCToHwWuTPKcJAGuAr4EfBp4w9BnP3BkshIlSZOY5Bj9vaycdP0c8MXhvQ4BNwO/neQE8HzgjinUKUka0471u6ytqm4Fbj2r+RHgZZO8ryRperwyVpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKaM+glqTmDXpKa2zHvAiSt2HPw7nmXoKac0UtScxMFfZILktyV5MtJHkryq0l2JTmW5OHheee0ipUkbd6kM/r3Av9YVb8E/ArwEHAQOF5Ve4Hjw7okaU7GDvokzwNeAdwBUFU/rKrvAPuAw0O3w8D1kxYpSRrfJDP6FwHLwF8m+XySDyZ5LnBxVZ0CGJ4vmkKdkqQxTRL0O4ArgPdX1UuB/2UTh2mSHEiylGRpeXl5gjIkSU9nkqA/CZysqnuH9btYCf4nklwCMDyfXu3FVXWoqharanFhYWGCMiRJT2fsoK+q/wIeS/Lioekq4EvAUWD/0LYfODJRhZKkiUx6wdRvAB9Jcj7wCPBWVv54fCzJTcCjwA0T7kOSNIGJgr6q7gcWV9l01STvK0maHq+MlaTmDHpJas6gl6TmDHpJas6gl6TmDHpJas6gl6TmDHpJas6gl6TmDHpJas6gl6TmJr2pmaSnsefg3fMuQXJGL0ndGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1Jw3NZO0KRu9UdvXb7tuxpVoo5zRS1JzBr0kNWfQS1JzEx+jT3IesAR8o6pel+Qy4E5gF/A54M1V9cNJ9yNpdvyClN6mMaN/F/DQyPrtwHuqai/wbeCmKexDkjSmiYI+yaXAdcAHh/UArwLuGrocBq6fZB+SpMlMOqP/c+B3gR8P688HvlNVTw7rJ4Hdq70wyYEkS0mWlpeXJyxDkrSWsYM+yeuA01V132jzKl1rtddX1aGqWqyqxYWFhXHLkCStY5KTsS8HXp/kWuDZwPNYmeFfkGTHMKu/FHh88jIlSeMae0ZfVe+uqkurag9wI/DPVfUm4NPAG4Zu+4EjE1cpSRrbLG6BcDNwZ5I/BD4P3DGDfUg6x23mI5veLmG2phL0VXUPcM+w/Ajwsmm8ryRpcl4ZK0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNGfSS1JxBL0nNzeKmZlJ7fseqthJn9JLUnEEvSc0Z9JLUnEEvSc0Z9JLUnEEvSc0Z9JLUnEEvSc15wZSkudvoBWhfv+26GVfSkzN6SWrOGb008LYG6soZvSQ154xe0paxmf91eTz/p5zRS1JzBr0kNTd20Cd5YZJPJ3koyYNJ3jW070pyLMnDw/PO6ZUrSdqsSWb0TwK/U1UvAa4E3p7kcuAgcLyq9gLHh3VJ0pyMfTK2qk4Bp4bl/07yELAb2Ae8cuh2GLgHuHmiKiVpk7wI66emcow+yR7gpcC9wMXDH4EzfwwumsY+JEnjmTjok/w88HHgN6vqe5t43YEkS0mWlpeXJy1DkrSGiYI+yc+yEvIfqaq/HZqfSHLJsP0S4PRqr62qQ1W1WFWLCwsLk5QhSXoaYx+jTxLgDuChqvqzkU1Hgf3AbcPzkYkqlKQZ2g4XYU1yZezLgTcDX0xy/9D2e6wE/MeS3AQ8CtwwWYmSpElM8qmbfwGyxuarxn1fSdJ0eWWsJDVn0EtScwa9JDVn0EtScwa9JDVn0EtSc37DlNrzu2C13Tmjl6TmDHpJas6gl6TmPEavLcnj7tLGOaOXpOYMeklqzqCXpOYMeklqzpOxmjlPnKqLjf5bPte+icoZvSQ1Z9BLUnMGvSQ1Z9BLUnMGvSQ1Z9BLUnMGvSQ15+foJWnKNnPtyDPxmXuD/hlyrv3g17JV6pS0cR66kaTmnNFvYfOefXtrA2lrcEYvSc3NZEaf5GrgvcB5wAer6rZZ7Ad6zmq3yntK2hqmPqNPch7wF8A1wOXAG5NcPu39SJI2ZhYz+pcBJ6rqEYAkdwL7gC/NYF+b4qxW0nY0i2P0u4HHRtZPDm2SpDmYxYw+q7TVUzolB4ADw+r/JPnKDGqZtguBb867iGfQdhqvY+3rnB5vbp/o5b+4kU6zCPqTwAtH1i8FHj+7U1UdAg7NYP8zk2SpqhbnXcczZTuN17H2td3Gu5pZHLr5N2BvksuSnA/cCBydwX4kSRsw9Rl9VT2Z5B3AJ1n5eOWHqurBae9HkrQxM/kcfVV9AvjELN57zrbUoaYp2E7jdax9bbfxPkWqnnKeVJLUiLdAkKTmDPo1JPmDJF9Icn+STyV5wdCeJO9LcmLYfsXIa/YneXh47J9f9ZuT5E+SfHkYz98luWBk27uHsX4lyWtH2q8e2k4kOTifyseT5IYkDyb5cZLFs7a1G++oLuM4I8mHkpxO8sBI264kx4bfw2NJdg7ta/7utldVPlZ5AM8bWX4n8IFh+VrgH1i5XuBK4N6hfRfwyPC8c1jeOe9xbHCsrwF2DMu3A7cPy5cD/w48C7gM+CorJ9jPG5ZfBJw/9Ll83uPYxHhfArwYuAdYHGlvOd6R8bUYx1ljegVwBfDASNsfAweH5YMj/55X/d3dDg9n9Guoqu+NrD6Xn170tQ/4cK34LHBBkkuA1wLHqupbVfVt4Bhw9TNa9Jiq6lNV9eSw+llWrn2AlbHeWVU/qKqvASdYucXFT25zUVU/BM7c5mJLqKqHqmq1C/RajndEl3H8RFV9BvjWWc37gMPD8mHg+pH21X532zPon0aSP0ryGPAm4PeH5rVu8dDl1g9vY2XWA/3Herbu4+0yjvVcXFWnAIbni4b27TL+p9jWXzyS5J+AX1hl0y1VdaSqbgFuSfJu4B3Arax9i4cN3fphXtYb69DnFuBJ4CNnXrZK/2L1CcI5M1bY2HhXe9kqbVtivBt0Tv8bfQZs2/Fv66CvqldvsOtfA3ezEvRr3eLhJPDKs9rvmbjIKVlvrMPJ49cBV9VwQJOnv53Fure5mKdN/GxHbdnxbtCGbk/SwBNJLqmqU8OhmdND+3YZ/1N46GYNSfaOrL4e+PKwfBR4y3AG/0rgu8N/Dz8JvCbJzuEs/2uGtnPe8EUxNwOvr6rvj2w6CtyY5FlJLgP2Av9K39tcdB9vl3Gs5yhw5lNv+4EjI+2r/e72N++zwefqA/g48ADwBeDvgd1De1j5YpWvAl/k/39q422snMA7Abx13mPYxFhPsHLs8v7h8YGRbbcMY/0KcM1I+7XAfwzbbpn3GDY53l9nZXb3A+AJ4JOdx3vW2FuMY2Q8HwVOAT8afqY3Ac8HjgMPD8+7hr5r/u52f3hlrCQ156EbSWrOoJek5gx6SWrOoJek5gx6SWrOoJek5gx6SWrOoJek5v4P1mvenIGIipkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense4_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense4_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.6460342 ,  -6.9541936 , -30.293108  , -26.003756  ,\n",
       "        19.519     , -11.760382  ,   4.5482254 ,  15.267869  ,\n",
       "        -0.96279   ,  -0.94411707,   9.45656   , -21.578396  ,\n",
       "        -4.788699  ,   6.3600054 ,   8.470503  ,   0.7370778 ,\n",
       "        -3.7022514 ,   6.7021246 ,  -8.5262985 , -28.127478  ,\n",
       "       -18.253525  , -11.355206  ,  -9.129753  ,  17.139364  ,\n",
       "        -5.8101177 ,  -4.6135945 ], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense5_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense5_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.595436], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense6_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you noticed that we used batch normalisation in the above model, how about the results without BatchNormalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(26, input_dim=1, name=\"test1\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, init='uniform', name = 'test1'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test2'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test3'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test4'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test5'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, name = 'test6'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 211.2580 - acc: 0.0385\n",
      "Epoch 2/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 175.3639 - acc: 0.0385\n",
      "Epoch 3/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 2692.5881 - acc: 0.0000e+00\n",
      "Epoch 4/250\n",
      "26/26 [==============================] - 0s 46us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 5/250\n",
      "26/26 [==============================] - 0s 41us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 6/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 7/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 8/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 9/250\n",
      "26/26 [==============================] - 0s 43us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 10/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 11/250\n",
      "26/26 [==============================] - 0s 66us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 12/250\n",
      "26/26 [==============================] - 0s 61us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 13/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 14/250\n",
      "26/26 [==============================] - 0s 76us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 15/250\n",
      "26/26 [==============================] - 0s 58us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 16/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 17/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 18/250\n",
      "26/26 [==============================] - 0s 68us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 19/250\n",
      "26/26 [==============================] - 0s 73us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 20/250\n",
      "26/26 [==============================] - 0s 68us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 21/250\n",
      "26/26 [==============================] - 0s 69us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 22/250\n",
      "26/26 [==============================] - 0s 74us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 23/250\n",
      "26/26 [==============================] - 0s 82us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 24/250\n",
      "26/26 [==============================] - 0s 59us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 25/250\n",
      "26/26 [==============================] - 0s 70us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 26/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 27/250\n",
      "26/26 [==============================] - 0s 59us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 28/250\n",
      "26/26 [==============================] - 0s 79us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 29/250\n",
      "26/26 [==============================] - 0s 66us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 30/250\n",
      "26/26 [==============================] - 0s 75us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 31/250\n",
      "26/26 [==============================] - 0s 67us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 32/250\n",
      "26/26 [==============================] - 0s 64us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 33/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 34/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 35/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 36/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 37/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 38/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 39/250\n",
      "26/26 [==============================] - 0s 63us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 40/250\n",
      "26/26 [==============================] - 0s 85us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 41/250\n",
      "26/26 [==============================] - 0s 76us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 42/250\n",
      "26/26 [==============================] - 0s 86us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 43/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 44/250\n",
      "26/26 [==============================] - 0s 72us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 45/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 46/250\n",
      "26/26 [==============================] - 0s 74us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 47/250\n",
      "26/26 [==============================] - 0s 86us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 48/250\n",
      "26/26 [==============================] - 0s 80us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 49/250\n",
      "26/26 [==============================] - 0s 82us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 50/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 51/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 52/250\n",
      "26/26 [==============================] - 0s 87us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 53/250\n",
      "26/26 [==============================] - 0s 63us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 54/250\n",
      "26/26 [==============================] - 0s 62us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 55/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 56/250\n",
      "26/26 [==============================] - 0s 85us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 57/250\n",
      "26/26 [==============================] - 0s 68us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 58/250\n",
      "26/26 [==============================] - 0s 72us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 59/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 60/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 61/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 62/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 63/250\n",
      "26/26 [==============================] - 0s 62us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 64/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 65/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 66/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 67/250\n",
      "26/26 [==============================] - 0s 113us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 68/250\n",
      "26/26 [==============================] - 0s 112us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 69/250\n",
      "26/26 [==============================] - 0s 66us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 70/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 71/250\n",
      "26/26 [==============================] - 0s 58us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 72/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 73/250\n",
      "26/26 [==============================] - 0s 93us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 74/250\n",
      "26/26 [==============================] - 0s 63us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 75/250\n",
      "26/26 [==============================] - 0s 99us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 76/250\n",
      "26/26 [==============================] - 0s 73us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 77/250\n",
      "26/26 [==============================] - 0s 80us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 78/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 79/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 80/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 81/250\n",
      "26/26 [==============================] - 0s 66us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 82/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 83/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 84/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/250\n",
      "26/26 [==============================] - 0s 58us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 86/250\n",
      "26/26 [==============================] - 0s 59us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 87/250\n",
      "26/26 [==============================] - 0s 64us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 88/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 89/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 90/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 91/250\n",
      "26/26 [==============================] - 0s 89us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 92/250\n",
      "26/26 [==============================] - 0s 66us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 93/250\n",
      "26/26 [==============================] - 0s 61us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 94/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 95/250\n",
      "26/26 [==============================] - 0s 45us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 96/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 97/250\n",
      "26/26 [==============================] - 0s 72us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 98/250\n",
      "26/26 [==============================] - 0s 64us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 99/250\n",
      "26/26 [==============================] - 0s 67us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 100/250\n",
      "26/26 [==============================] - 0s 78us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 101/250\n",
      "26/26 [==============================] - 0s 64us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 102/250\n",
      "26/26 [==============================] - 0s 93us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 103/250\n",
      "26/26 [==============================] - 0s 85us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 104/250\n",
      "26/26 [==============================] - 0s 67us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 105/250\n",
      "26/26 [==============================] - 0s 80us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 106/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 107/250\n",
      "26/26 [==============================] - 0s 76us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 108/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 109/250\n",
      "26/26 [==============================] - 0s 66us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 110/250\n",
      "26/26 [==============================] - 0s 70us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 111/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 112/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 113/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 114/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 115/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 116/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 117/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 118/250\n",
      "26/26 [==============================] - 0s 58us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 119/250\n",
      "26/26 [==============================] - 0s 63us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 120/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 121/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 122/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 123/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 124/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 125/250\n",
      "26/26 [==============================] - 0s 75us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 126/250\n",
      "26/26 [==============================] - 0s 69us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 127/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 128/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 129/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 130/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 131/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 132/250\n",
      "26/26 [==============================] - 0s 59us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 133/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 134/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 135/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 136/250\n",
      "26/26 [==============================] - 0s 97us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 137/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 138/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 139/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 140/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 141/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 142/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 143/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 144/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 145/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 146/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 147/250\n",
      "26/26 [==============================] - 0s 46us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 148/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 149/250\n",
      "26/26 [==============================] - 0s 58us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 150/250\n",
      "26/26 [==============================] - 0s 46us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 151/250\n",
      "26/26 [==============================] - 0s 42us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 152/250\n",
      "26/26 [==============================] - 0s 58us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 153/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 154/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 155/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 156/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 157/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 158/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 159/250\n",
      "26/26 [==============================] - 0s 59us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 160/250\n",
      "26/26 [==============================] - 0s 45us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 161/250\n",
      "26/26 [==============================] - 0s 46us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 162/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 163/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 164/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 165/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 166/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 167/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 169/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 170/250\n",
      "26/26 [==============================] - 0s 64us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 171/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 172/250\n",
      "26/26 [==============================] - 0s 62us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 173/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 174/250\n",
      "26/26 [==============================] - 0s 44us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 175/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 176/250\n",
      "26/26 [==============================] - 0s 46us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 177/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 178/250\n",
      "26/26 [==============================] - 0s 45us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 179/250\n",
      "26/26 [==============================] - 0s 58us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 180/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 181/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 182/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 183/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 184/250\n",
      "26/26 [==============================] - 0s 74us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 185/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 186/250\n",
      "26/26 [==============================] - 0s 73us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 187/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 188/250\n",
      "26/26 [==============================] - 0s 59us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 189/250\n",
      "26/26 [==============================] - 0s 59us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 190/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 191/250\n",
      "26/26 [==============================] - 0s 66us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 192/250\n",
      "26/26 [==============================] - 0s 98us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 193/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 194/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 195/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 196/250\n",
      "26/26 [==============================] - 0s 63us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 197/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 198/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 199/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 200/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 201/250\n",
      "26/26 [==============================] - 0s 53us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 202/250\n",
      "26/26 [==============================] - 0s 54us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 203/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 204/250\n",
      "26/26 [==============================] - 0s 45us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 205/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 206/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 207/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 208/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 209/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 210/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 211/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 212/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 213/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 214/250\n",
      "26/26 [==============================] - 0s 51us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 215/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 216/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 217/250\n",
      "26/26 [==============================] - 0s 88us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 218/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 219/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 220/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 221/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 222/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 223/250\n",
      "26/26 [==============================] - 0s 46us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 224/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 225/250\n",
      "26/26 [==============================] - 0s 72us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 226/250\n",
      "26/26 [==============================] - 0s 49us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 227/250\n",
      "26/26 [==============================] - 0s 45us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 228/250\n",
      "26/26 [==============================] - 0s 58us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 229/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 230/250\n",
      "26/26 [==============================] - 0s 48us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 231/250\n",
      "26/26 [==============================] - 0s 72us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 232/250\n",
      "26/26 [==============================] - 0s 62us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 233/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 234/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 235/250\n",
      "26/26 [==============================] - 0s 50us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 236/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 237/250\n",
      "26/26 [==============================] - 0s 47us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 238/250\n",
      "26/26 [==============================] - 0s 59us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 239/250\n",
      "26/26 [==============================] - 0s 56us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 240/250\n",
      "26/26 [==============================] - 0s 66us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 241/250\n",
      "26/26 [==============================] - 0s 64us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 242/250\n",
      "26/26 [==============================] - 0s 64us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 243/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 244/250\n",
      "26/26 [==============================] - 0s 55us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 245/250\n",
      "26/26 [==============================] - 0s 60us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 246/250\n",
      "26/26 [==============================] - 0s 75us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 247/250\n",
      "26/26 [==============================] - 0s 52us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 248/250\n",
      "26/26 [==============================] - 0s 57us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 249/250\n",
      "26/26 [==============================] - 0s 64us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 250/250\n",
      "26/26 [==============================] - 0s 46us/step - loss: 212.5000 - acc: 0.0385\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(x_train), np.array(y_train), epochs = 250);#, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(x_train)/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",x_as_vector = False, y_as_vector = False)\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb311034a8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGfCAYAAACNytIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXucVWW9/z+fyMtQQFmdzEvSRU9pFBpW6olKulBUTqEFNXg6YURkHfUnnSSOmBRRId3MaOJUEoV2JSvTTl66ajEFgaiZmRfUsrQJs46p8/39sffYdmbWXvvyPGt918Pn3Wu9mr32Xu/1cTYz+5nn9qWZQQghhBCiLB5WdgAhhBBC7NqoMSKEEEKIUlFjRAghhBClosaIEEIIIUpFjREhhBBClIoaI0IIIYQoFTVGhBBCCNEyJD9L8g6SV2U8T5IfJ3k9ya0kD8tzqjEihBBCiHb4PICZTZ5/OYAD68cCAJ/KE6oxIoQQQoiWMbMfAriryUuOAbDOalwJ4FEkn9DM+fCQAcfivj/d0PUWrz37PD9EFCGEEKIQ7v/HrSzyfiE+a4fZ/XFPeStqPRrD9JtZfxuKfQHc0vB4R/3c7VkXRG+MCCGEEKI61Bse7TQ+RjJWQ6xpY0mNESGEEKLqDD1QdoJGdgDYv+HxfgBua3aB5owIIYQQIiQXADi+vqrmeQD+YmaZQzRAyY2RpStWY/qsOejtW9ix42UvfSG2X/VDXHv1j/GuxW8v1SNHeIenLHL4zZKSw1MWOeJ5gmND4Y4cSG4AcAWAfyW5g+R8kgtJDn+YXwjgBgDXA/gMgEW5TrP25ryQPArAG8yspXeh2aSagS3bML6nB0uWr8LG9WsyHVkTWB/2sIfhmu0/wsxXzMWOHbfjyisuRN+8Rbjmmt+0Ei2oR47wDk9Z5PCbJSWHpyxydOcpfALr7dcEm8C62xOeXmh2oMWeEZJTSX6I5I0A3gfg2hA3nzZ1CiZNnNDx9c85/FD89rc34ne/uxn33Xcfvvzlb+LVr3pZKR45wjs8ZZHDb5aUHJ6yyBHPI0aT2RgheRDJ00leA+Bs1Jbp0MxeZGafKCxhE/bZd2/csuOfc2J23Ho79tln71I8coR3eMoih98sKTk8ZZEjnicGZkPBjjJo1jNyLYAZAF5lZv9Wb4C0NF2X5AKSAyQH1q7bECJn1n1GnWt32CmUR47wDk9Z5PCbJSWHpyxyxPNEYWgo3FECzZb2zgYwB8BlJC8CcB7GXjs8isY1yiE3YhnJrTtux/777fPg4/32fQJuv/0PpXjkCO/wlEUOv1lScnjKIkc8jxhNZs+ImX3DzF4P4GkALgdwMoDHk/wUyZcWlK8pmwa24KlPfRImT94fu+22G173umPwrW9/rxSPHOEdnrLI4TdLSg5PWeSI54lCgatpYpC76ZmZ3QPgiwC+SHIvAMcBeDeArt+BxctWYtPmrRgc3IkZvX1YNH8eZrcxGeiBBx7Af560FBd+50sY97CH4fPnno+rr76u7RwhPHKEd3jKIoffLCk5PGWRI54nCr42PWubtpf2totq0wghhNjVKHpp7z9u+mW42jQHHFb40l5tBy+EEEJUnZKGV0KhxogQQghRdUpaBRMK1aYRQgghRKmoZ0QIIYSoOGVtVhYKNUaEEEKIqqNhms5R1V45qpRFDr9ZUnJ4yiJHPI94KKUu7VXVXjmqkkUOv1lScnjKIkd3nqKX9t573Y+DfZjvcdC/+azaGwtV7ZWjKlnk8JslJYenLHLE80Rh6IFwRwm03Rgh+ViOVS2oBDxVYpQjvMNTFjn8ZknJ4SmLHPE8YjRNGyMkn0fycpJfJ3koyasAXAXgDyRnNrlOVXvl6NrhKYscfrOk5PCURY54nigkXpvmbABLAEwCcCmAl5vZlSSfBmADgIvGukhVe+XQe5O2w1OWlByessgRzxOFxFfTPNzMvmdmXwHwezO7EgDM7Nr40fLxVIlRjvAOT1nk8JslJYenLHLE84jR5PWMNDa1/j7iua57PFS1V46qZJHDb5aUHJ6yyBHPE4WKb3rWdGkvyQcA3AOAAHoA/G34KQB7mtlueTdQ1V4hhBC7GoUv7d16cbilvc98ma+qvWY2rqggQgghhNg10XbwQgghRMUxK2d/kFCoMSKEEEJUnYrPGSl1B1YhhBBCCPWMCCGEEFWn4vuMqDEihBBCVB0N03TO0hWrMX3WHPT2LezY4akstBzhHZ6yyOE3S0oOT1nkiOcJTsUL5TXdZyQEzfYZGdiyDeN7erBk+SpsXL8m05G1z4hKdqft8JRFDr9ZUnJ4yiJHd56i9xn5v01fC/ZhvufhswvfZySvUN5TSR41xvnnk3xKtzefNnUKJk2c0PH1nspCyxHe4SmLHH6zpOTwlEWOeJ4oVLxQXt4wzUcB3D3G+b/XnysVT2Wh5Qjv8JRFDr9ZUnJ4yiJHPE8UhobCHSWQ1xiZbGZbR540swEAk7MuIrmA5ADJgbXrNnQZMRtPZaHlCO/wlEUOv1lScnjKIkc8jxhN3mqaPZs815P1hJn1A+gHwtSmycJTWWg5wjs8ZZHDb5aUHJ6yyBHPE4XEV9NsIvmWkSdJzgfwiziRWsdTWWg5wjs8ZZHDb5aUHJ6yyBHPE4WKD9Pk9YycBOAbJN+IfzY+pgHYHcBrur354mUrsWnzVgwO7sSM3j4smj8Ps9uYDOSpLLQc4R2essjhN0tKDk9Z5IjnEaNpaWkvyRcBeEb94XYzu7TVG4QYpsla2iuEEEJ4pPClvT/6Qrilvc+fV/jS3pZ2YDWzywBcFjmLEEIIITqg6lV7VShPCCGEEKWi2jRCCCFE1VGhPCGEEEKUSuJLe4UQQgghoqKqvQE9coR3eMoih98sKTk8ZZEjnic4Fd9nRFV7A3nkCO/wlEUOv1lScnjKIkd3nqKX9v79+2uCfZj3vHihr6q9sVHVXjmqkkUOv1lScnjKIkc8jxhNy40Rko8j+biYYdrFUyVGOcI7PGWRw2+WlByessgRzxOFig/TNG2MsMYZJP8E4FoA15H8I8nTi4nXHE+VGOUI7/CURQ6/WVJyeMoiRzxPFGwo3FECeT0jJwE4CsDhZvYYM3s0gOcCOIrkyVkXkVxAcoDkwNp1GwLGfSieKjHKEd7hKYscfrOk5PCURY54HjGavMbI8QDmmtnvhk+Y2Q0A+urPjYmZ9ZvZNDObdsLxc8MkHQNPlRjlCO/wlEUOv1lScnjKIkc8TxQqPkyTt+nZbmb2p5EnzeyPJHfr9uaq2itHVbLI4TdLSg5PWeSI54lCxXdgbbq0l+Qvzeywdp9rRFV7hRBC7GoUvrT3Ox8Nt7R31knuqvY+i+TOMc4TwJ4R8gghhBCiXSq+HXzTxoiZjSsqiBBCCCE6pOLDNKpNI4QQQohSUdVeIYQQouqkPEwjhBBCiAqgYRohhBBCiM4ptTGydMVqTJ81B719Czt2eCoLLUd4h6cscvjNkpLDUxY54nmCU/Ht4JvuMxKCZvuMDGzZhvE9PViyfBU2rl+T6cjaZ0Qlu9N2eMoih98sKTk8ZZGjO0/h+4x89X3h9hk5dmnh+4yU2jMybeoUTJo4oePrPZWFliO8w1MWOfxmScnhKYsc8TxiNHlVe9/V8PVxI55bEStUq3gqCy1HeIenLHL4zZKSw1MWOeJ5olDx2jR5PSNzGr4+bcRzM7MuKqpqr6ey0HKEd3jKIoffLCk5PGWRI54nCmbhjhLIW9rLjK/HevwgZtYPoB8IU5smC09loeUI7/CURQ6/WVJyeMoiRzyPGE1ez4hlfD3W48LxVBZajvAOT1nk8JslJYenLHLE80Sh4sM0rRbKI4CehqJ5QQrlLV62Eps2b8Xg4E7M6O3DovnzMLuNyUCeykLLEd7hKYscfrOk5PCURY54nihUfNOzUpf2tkrW0l4hhBDCI4Uv7f3if4db2vvG5YUv7dV28EIIIUTVUW0aIYQQQpRKxYdpVJtGCCGEEC1DcibJX5O8nuS7x3j+iSQvI7mZ5FaSr8hzqjEihBBCVJ2C9hkhOQ7AJwG8HMDBAOaSPHjEy5YC+LKZHYrafmXn5MXXMI0QQghRdYobpnkOgOvN7AYAIHkegGMAXN3wGgMwsf71JAC3IQf1jAghhBDiQRp3Ua8fCxqe3hfALQ2Pd9TPNXIGgD6SOwBcCOAdefcstTGydMVqTJ81B719Czt2eCoLLUd4h6cscvjNkpLDUxY54nmCE3DTMzPrN7NpDUd/w53GWvY7cmxnLoDPm9l+AF4B4Askm9fCK3OfkYEt2zC+pwdLlq/CxvVrMh1Z+4yoZHfaDk9Z5PCbJSWHpyxydOcpfJ+RtaeE22fkhNWZ2UkeAeAMM3tZ/fFpAGBmH2h4zXYAM83slvrjGwA8z8zuyPLmVe19Ylv/BW0ybeoUTJo4oePrPZWFliO8w1MWOfxmScnhKYsc8TwVZxOAA0k+ieTuqE1QvWDEa24GMAMASD4dtR3b/9hMmjdMs3H4C5JfazdxbDyVhZYjvMNTFjn8ZknJ4SmLHPE8MbAhC3Y0vY/Z/QBOBHAxgGtQWzWzneSZJF9df9n/A/AWkr8CsAHAmyxnGKadqr1PznntPy+qTXZZAADnnPU+nHD83FYvbQtPZaHlCO/wlEUOv1lScnjKIkc8TxQK3PTMzC5EbWJq47nTG76+GsBR7TjzGiPNqvZmX1Sb7NIPhKlNk4WnstByhHd4yiKH3ywpOTxlkSOeR4wmb5jmWSR3krwbwDPrX+8keXdDBd/S8FQWWo7wDk9Z5PCbJSWHpyxyxPNEwYbCHSXQtGfEzMbFvPniZSuxafNWDA7uxIzePiyaPw+z25gM5KkstBzhHZ6yyOE3S0oOT1nkiOeJQs5cD++UurS3VbKW9gohhBAeKXpp798+eWKwD/Pxbz+70OyAtoMXQgghqk/Fq/aqMSKEEEJUHTVGhBBCCFEqXpYYd4gK5QkhhBCiVNQzIoQQQlSdig/TqGpvQI8c4R2essjhN0tKDk9Z5IjnCc6QhTtKQFV7A3nkCO/wlEUOv1lScnjKIkd3nsKX9q46IdzS3lPXFr60t9SeEVXtlaMqWeTwmyUlh6cscsTzRKHiO7A2bYyQPIbk2xse/4zkDfXj2PjxmuOpEqMc4R2essjhN0tKDk9Z5IjniULFh2nyekbeBeCChsd7ADgcwAsBvC3rIpILSA6QHFi7bkPXIZvcZ9Q5VclMx+Epixx+s6Tk8JRFjngeMZq81TS7m9ktDY9/bGZ3AriT5COyLlLVXjn03qTt8JQlJYenLHLE88TAEl9N8+jGB2Z2YsPDx4WP0x6eKjHKEd7hKYscfrOk5PCURY54nihUfJgmr2fkZyTfYmafaTxJ8q0Aft7tzVW1V46qZJHDb5aUHJ6yyBHPI0bTdGkvyX8BsBHAvQB+WT/9bNTmjvSaWW7/lKr2CiGE2NUoemnvPe/rC9al8Yil631V7TWzOwAcSfJoAIfUT3/HzC6NnkwIIYQQrVHS8EooWtoOvt74UANECCGEEMFRbRohhBCi6lR8NY0aI0IIIUTVqfgwTanbwQshhBBCqGdECCGEqDol1ZQJRak9I0tXrMb0WXPQ27ewY4enstByhHd4yiKH3ywpOTxlkSOeJzgV3/Ss6T4jIWi2z8jAlm0Y39ODJctXYeP6NZmOrH1GVLI7bYenLHL4zZKSw1MWObrzFL7PyHuOC7fPyPu/Uvg+I6X2jEybOgWTJk7o+HpPZaHlCO/wlEUOv1lScnjKIkc8TwxsaCjYUQZNGyMkP0Hy41lHUSGz8FQWWo7wDk9Z5PCbJSWHpyxyxPNEoeLDNHk9IwMAflE/Xt3w9fAxJiQXkBwgObB23YZQWce6z6hzKtmdjsNTFjn8ZknJ4SmLHPE8YjR528GfO/w1yZMaH+dc1w+gHwhTmyYLT2Wh5Qjv8JRFDr9ZUnJ4yiJHPE8UdqF9Rtz9l3oqCy1HeIenLHL4zZKSw1MWOeJ5omBD4Y4SKHWfkcXLVmLT5q0YHNyJGb19WDR/Hma3MRnIU1loOcI7PGWRw2+WlByessgRzyNG03RpL8m78c8ekfEA/jb8FAAzs4l5NwgxTJO1tFcIIYTwSNFLe/96yquDjV48cvUFhS/tzZsz0vm6WyGEEEIUgu1Cc0aEEEIIIYKj2jRCCCFE1al4z4gaI0IIIUTVKWnn1FBomEYIIYQQpaKeESGEEKLqVHyYptSekaUrVmP6rDno7VvYscNTWWg5wjs8ZZHDb5aUHJ6yyBHPE5yK16Zpus9ICJrtMzKwZRvG9/RgyfJV2Lh+TaYja58RlexO2+Epixx+s6Tk8JRFju48Re8zcvfCmcE+zCesuajwfUZK7RmZNnUKJk3sfCsTT2Wh5Qjv8JRFDr9ZUnJ4yiJHPE8MzCzYUQZNGyMk7ya5c4zjbpI7iwqZhaey0HKEd3jKIoffLCk5PGWRI54nChUfpmnaGDGzCWY2cYxjQrOt4EkuIDlAcmDtug3hU//zPmNlLsUjR3iHpyxy+M2SksNTFjniecRooqymMbN+AP1AmNo0WXgqCy1HeIenLHL4zZKSw1MWOeJ5oqDVNOXhqSy0HOEdnrLI4TdLSg5PWeSI54mBDVmwowxK3Wdk8bKV2LR5KwYHd2JGbx8WzZ+H2W1MBvJUFlqO8A5PWeTwmyUlh6cscsTziNGUurS3VbKW9gohhBAeKXpp71/+fUawD/NJ515S+NJe7cAqhBBCVJ1ql6ap9pwRIYQQQlQf9YwIIYQQFaesiaehUGNECCGEqDoVb4xomEYIIYQQpaKqvQE9coR3eMoih98sKTk8ZZEjnic4QwGPElDV3kAeOcI7PGWRw2+WlByessjRnafopb1/Pu6FwT7MH/2Vy/1U7W1SJG8nyT+SvJLkjG5urqq9clQlixx+s6Tk8JRFjngeMZrMxkiTInkTAewN4K0APlZY0jHwVIlRjvAOT1nk8JslJYenLHLE80Sh4sM0Hc0ZMbMHzOxXAD4x1vOq2iuH3pu0HZ6ypOTwlEWOeJ4Y7NK1aczs0xnnVbVXDr03CTs8ZUnJ4SmLHPE8YjSVXtrrqRKjHOEdnrLI4TdLSg5PWeSI54lCxYdpVLU3kEeO8A5PWeTwmyUlh6cscsTzxMAqXptGVXuFEEKIwBS9tPfOWS8I9mH+mO/8wM/SXiGEEEKIIlBtGiGEEKLiVH2YRo0RIYQQoupUvDGiYRohhBBClIp6RoQQQoiKU/VhGvWMCCGEEBXHhsIdeZCcSfLXJK8n+e6M17yO5NUkt5P8Up6z1MbI0hWrMX3WHPT2LezY4akstBzhHZ6yyOE3S0oOT1nkiOepKiTHAfgkgJcDOBjAXJIHj3jNgQBOA3CUmR0C4KRcb5n7jAxs2YbxPT1YsnwVNq5fk+nI2mdEJbvTdnjKIoffLCk5PGWRoztP0fuM/OFF4fYZefxl2fuMkDwCwBlm9rL649MAwMw+0PCaDwG4zszWtnrPpj0jJPdr8tyrWr1JFtOmTsGkiRM6vt5TWWg5wjs8ZZHDb5aUHJ6yyBHPEwVjsKOx2G39WNBwp30B3NLweEf9XCMHATiI5E9IXklyZl78vGGaS0hOHnmS5JsBfDRPHhtPZaHlCO/wlEUOv1lScnjKIkc8j3fMrN/MpjUc/Q1Pj9VrMrJX5uEADgTwQgBzAawl+ahm98xrjJwM4H/r4z+1FLUumZMBvCDrosZW1dp1G3Ju0TmeykLLEd7hKYscfrOk5PCURY54nhgUOIF1B4D9Gx7vB+C2MV7zTTO7z8x+B+DXqDVOMmm6tNfMLiR5L4DvkuwFcAKAwwFMN7M/N7muH0A/EKY2TRaeykLLEd7hKYscfrOk5PCURY54nhjYUGFTVDYBOJDkkwDcCmAOgDeMeM1G1HpEPk/ysagN29zQTJq7msbMLgHwJgCXA3gygBnNGiJF4qkstBzhHZ6yyOE3S0oOT1nkiOepMmZ2P4ATAVwM4BoAXzaz7STPJPnq+ssuBnAnyasBXAZgsZnd2czbtGeE5N2ojQURwB4AZgC4g7W+KjOzid38Ry1ethKbNm/F4OBOzOjtw6L58zC7jclAnspCyxHe4SmLHH6zpOTwlEWOeJ4YFLnpmZldCODCEedOb/jaAJxSP1qi1KW9rZK1tFcIIYTwSNFLe2894uhgH+b7XnFpodkB7cAqhBBCiJJRbRohhBCi4lS9No0aI0IIIUTFKXA1TRQ0TCOEEEKIUlHPiBBCCFFxnOy91jFqjAghhBAVR8M0XbB0xWpMnzUHvX0LO3Z4KgstR3iHpyxy+M2SksNTFjniecRDKXWfkYEt2zC+pwdLlq/CxvVrMh1Z+4yoZHfaDk9Z5PCbJSWHpyxydOcpep+RG6e+JNiH+eQt/1udfUZIntTtzadNnYJJEyd0fL2nstByhHd4yiKH3ywpOTxlkSOeJwZm4Y4y6GaYpuVtXmPhqSy0HOEdnrLI4TdLSg5PWeSI5xGj6aYxktmNQ3IByQGSA2vXbejiFjkBHJWFliO8w1MWOfxmScnhKYsc8TwxsCEGO8qgm9U0me+AmfUD6AfC1KbJwlNZaDnCOzxlkcNvlpQcnrLIEc8TA7OEV9OQvJvkzjGOuwHs0+zaIvBUFlqO8A5PWeTwmyUlh6cscsTziNE07Rkxs85nl7bA4mUrsWnzVgwO7sSM3j4smj8Ps9uYDOSpLLQc4R2essjhN0tKDk9Z5IjniUHVa9OUurS3VbKW9gohhBAeKXpp73VPnxnsw/ygay6qztJeIYQQQogQaDt4IYQQouJUfQKrGiNCCCFExVFtGiGEEEKILlDPiBBCCFFxnOy91jGq2hvQI0d4h6cscvjNkpLDUxY54nlCU/UdWFW1N5BHjvAOT1nk8JslJYenLHJ05yl6ae/VT5kV7MP84N9+Z9da2quqvXJUJYscfrOk5PCURY54nhgMGYMdZVDpCayeKjHKEd7hKYscfrOk5PCURY54nhiYMdhRBk0nsJK8oNnzZvbqjOsWAFgAAOec9T6ccPzcjgM2w1MlRjnCOzxlkcNvlpQcnrLIEc8jRpO3muYIALcA2ADgZwBaajKpaq8cem/SdnjKkpLDUxY54nliUPU2Ud4wzd4AlgB4BoCPAXgJgD+Z2Q/M7Aexw+XhqRKjHOEdnrLI4TdLSg5PWeSI54lB1eeM5FXtfQDARQAuIrkHgLkALid5ppl9otubq2qvHFXJIoffLCk5PGWRI55HjCZ3aW+9ETILtYbIZAAXAPismd3ayg1UtVcIIcSuRtFLezc/8ZhgAzWH3vzNwrtH8iawnovaEM13AbzXzK4qJJUQQgghWqbqc0byJrDOA3APgIMAvLNhJjEBmJlNjJhNCCGEELsAeXNGKr0PiRBCCLErUNbE01CoUJ4QQghRccrarCwU6vkQQgghRKmoZ0QIIYSoOFUfpim1Z2TpitWYPmsOevsWduzwVBZajvAOT1nk8JslJYenLHLE84TGAh5lkLvPSLc022dkYMs2jO/pwZLlq7Bx/ZpMR9Y+IyrZnbbDUxY5/GZJyeEpixzdeYreZ+SnT5gd7MP8yNu/Vng3S6k9I9OmTsGkiRM6vt5TWWg5wjs8ZZHDb5aUHJ6yyBHPI0bTtDFC8vQmx38XFTILT2Wh5Qjv8JRFDr9ZUnJ4yiJHPE8MzBjsKIO8npF7xjgMwHwA/5V1EckFJAdIDqxdtyFU1rHuM+qcSnan4/CURQ6/WVJyeMoiRzxPDIYCHmWQt+nZWcNfk5wA4D8BvBnAeQDOanJdP4B+IExtmiw8lYWWI7zDUxY5/GZJyeEpixzxPGI0uXNGSO5F8n0AtqLWeDnMzP7LzO6Ini4HT2Wh5Qjv8JRFDr9ZUnJ4yiJHPE8MDAx2lEFeobwPA3gtar0cU8zsryFvvnjZSmzavBWDgzsxo7cPi+bPw+w2JgN5KgstR3iHpyxy+M2SksNTFjnieWIw5GO0qGOaLu0lOQTgXgD346HLj1sulBdimCZraa8QQgjhkaKX9l7++OOCNUde+IevFN49okJ5QgghRMUZKml4JRTaDl4IIYSoOGXN9QiFej6EEEIIUSrqGRFCCCEqTln7g4RCjREhhBCi4miYpgtUtVeOKmWRw2+WlByessgRzyMeiqr2BvLIEd7hKYscfrOk5PCURY7uPEUv7b3o8XOCfZjP/MN5Pqv2ktyT5DNIHkJyz1A3V9VeOaqSRQ6/WVJyeMoiRzxPDKpemyavau/DSX4IwA4A5wJYD+AWkh8iuVsRAZvhqRKjHOEdnrLI4TdLSg5PWeSI5xGjyesZ+TCAvQA8ycyebWaHAngKgEcBWJV1kar2yqH3Jm2HpywpOTxlkSOeJwZJ16YB8EoAB1nDd9vMdpJ8G4BrUaviOwpV7ZVD703aDk9ZUnJ4yiJHPE8Mhqq9mCa3Z8RsjGafmT2Ah9aqKQVPlRjlCO/wlEUOv1lScnjKIkc8jxhNXs/I1SSPN7N1jSdJ9qHWM9IVqtorR1WyyOE3S0oOT1nkiOeJQdVr0+RV7d0XwNcB/B3AL1DrDTkcQA+A15jZrXk3UNVeIYQQuxpFL+3duPcbgo1W9P7+S+6q9t4K4LkkjwZwCAAC+K6ZXVJEOCGEEEKkT0vbwZvZpQAujZxFCCGEEB2g2jRCCCGEKJWhMZYdV4lSa9MIIYQQQqhnRAghhKg4pe+10SVqjAghhBAVp+pzRkodplm6YjWmz5qD3r6FHTs8lYWWI7zDUxY5/GZJyeEpixzxPOKhNN1nJATN9hkZ2LIN43t6sGT5KmxcvybTkbXPiEp2p+3wlEUOv1lScnjKIkd3nqL3GdmwzxuDfZjPve2Lhc+GLbVnZNrUKZg0cULH13sqCy1HeIenLHL4zZKSw1MWOeJ5YjAEBjvKoGljhOSeJE8ieTbJt5J0NcfEU1loOcI7PGWRw2+WlByessgRz1N1SM4k+WuS15N8d5PXHUvSSE7Lc+b1jJwLYBqAbQBeDuCsFoMuIDlAcmDtug2tXNIRnspCyxHe4SmLHH6zpOTwlEWOeJ4YWMCjGSTHAfgkam2CgwHMJXnwGK+bAOCdAH7WSv68no6DzWxKXfw/AH7eitTM+gH0A2Fq02ThqSy0HOEd4/pYAAAeeElEQVQdnrLI4TdLSg5PWeSI54nBUHGjK88BcL2Z3QAAJM8DcAyAq0e8bjmADwE4tRVpXs/IfcNfmNn9LUctCE9loeUI7/CURQ6/WVJyeMoiRzyPdxpHN+rHgoan9wVwS8PjHfVzjdcfCmB/M/t2q/fM6xl5Fsmdw34APfXHBGBmNrHVG43F4mUrsWnzVgwO7sSM3j4smj8Ps9uYDOSpLLQc4R2essjhN0tKDk9Z5IjniUHIfUYaRzfGYKw+mAdHQEg+DMBHALypnXuWurS3VbKW9gohhBAeKXpp7+f27Qv2Yf4ft67PzE7yCABnmNnL6o9PAwAz+0D98SQAvwXw1/olewO4C8CrzWwgy6vaNEIIIYRolU0ADiT5JJK7A5gD4ILhJ83sL2b2WDObbGaTAVyJnIYIoO3ghRBCiMpT1ARWM7uf5IkALgYwDsBnzWw7yTMBDJjZBc0NY6PGiBBCCFFxiqxNY2YXArhwxLnTM177wlacGqYRQgghRKmoZ0QIIYSoOFWv2qvGiBBCCFFxrJySMsEodZhm6YrVmD5rDnr7Fnbs8FQWWo7wDk9Z5PCbJSWHpyxyxPOIh9LSPiMkxwN4av3hr83s3lZv0GyfkYEt2zC+pwdLlq/CxvVrMh1Z+4yoZHfaDk9Z5PCbJSWHpyxydOcpep+Rc/YPt8/Ioluy9xmJRV7V3t1IfhS17V4/h1rhvBuGq/TVt3ztmGlTp2DSxAkdX++pLLQc4R2essjhN0tKDk9Z5IjnicFQwKMM8oZpzgLwSAAHmNmzzexQAE8H8GSSnwLw9dgBm+GpLLQc4R2essjhN0tKDk9Z5IjnEaPJa4y8AsBbzOzu4RNmthPA21DbdW3uWBc1FtlZu25DsLBj3GfUOZXsTsfhKYscfrOk5PCURY54nhhYwKMM8lbTDNkY32kze4DkH83syrEuaiyyE6I2TRaeykLLEd7hKYscfrOk5PCURY54nhgUtQNrLPJ6Rq4mefzIkyT7AFwTJ1LreCoLLUd4h6cscvjNkpLDUxY54nnEaPJ6Rt4O4Osk3wzgF6j14BwOoAfAa7q9+eJlK7Fp81YMDu7EjN4+LJo/D7PbmAzkqSy0HOEdnrLI4TdLSg5PWeSI54lB1Tc9a3Vp79EADgFAANvN7JJWbxBimCZraa8QQgjhkaKX9p71xHBLe//fzcUv7W1pB1YzuxTApZGzCCGEEGIXRNvBCyGEEBXHx5qezlFjRAghhKg4VV9No8aIEEIIUXGqPoG11EJ5QgghhBCq2hvQI0d4h6cscvjNkpLDUxY54nlCU/UdWFta2tsNqtorh96b9ByesqTk8JRFju48RS/tff8Bbwz2Yf6em77oq2pvbFS1V46qZJHDb5aUHJ6yyBHPI0bTUWOE5DiSbwwdpl08VWKUI7zDUxY5/GZJyeEpixzxPDEYCniUQdPGCMmJJE8jeTbJl7LGOwDcAOB1Ta5T1V45unZ4yiKH3ywpOTxlkSOeJwZVnzOSt7T3CwD+DOAKACcAWAxgdwDHmNmWrItUtVcOvTdpOzxlScnhKYsc8TxiNHnDNE82szeZ2acBzAUwDcArmzVEisRTJUY5wjs8ZZHDb5aUHJ6yyBHPE4OqD9Pk9YzcN/yFmT1A8ndmdneom6tqrxxVySKH3ywpOTxlkSOeJwZV34G16dJekg8AuGf4IYAeAH+rf21mNjHvBqraK4QQYlej6KW9p08Ot7T3zBuLX9rbtGfEzMYVFUQIIYQQnTFU8VJ5qk0jhBBCVJxqN0VUm0YIIYQQJaOeESGEEKLiVL1qrxojQgghRMWp+pwRDdMIIYQQolRKbYwsXbEa02fNQW/fwo4dnspCyxHe4SmLHH6zpOTwlEWOeJ7QVH07+Kb7jISg2T4jA1u2YXxPD5YsX4WN69dkOrL2GVHJ7rQdnrLI4TdLSg5PWeTozlP0PiOnTp4b7MN81Y0bCt9nJK9Q3uEk9254fDzJb5L8OMm9ur35tKlTMGnihI6v91QWWo7wDk9Z5PCbJSWHpyxyxPOI0eQN03wawD8AgOR0ACsBrAPwF9QL4ZWJp7LQcoR3eMoih98sKTk8ZZEjnicGQ7BgRxnkNUbGmdld9a9fD6DfzL5mZv8N4KlZF5FcQHKA5MDadRtCZR3rPqPOqWR3Og5PWeTwmyUlh6cscsTzxKDqc0bylvaOI/lwM7sfwAwAC1q51sz6Ue85CVGbJgtPZaHlCO/wlEUOv1lScnjKIkc8jxhNXs/IBgA/IPlNAH8H8CMAIPlU1IZqSsVTWWg5wjs8ZZHDb5aUHJ6yyBHPE4OhgEcZ5BXKez/JSwA8AcD37J/9UQ8D8I5ub7542Ups2rwVg4M7MaO3D4vmz8PsNiYDeSoLLUd4h6cscvjNkpLDUxY54nliYBXf9KzUpb2tkrW0VwghhPBI0Ut73zn59cE+zD9+4/mFL+3VdvBCCCFExVFtGiGEEEKUimrTCCGEEEJ0gXpGhBBCiIpT7X4RNUaEEEKIyqNhGiGEEEKILshsjJCM3muydMVqTJ81B719Czt2eCoLLUd4h6cscvjNkpLDUxY54nlCU/VNzzL3GSH5SzM7rNsbNNtnZGDLNozv6cGS5auwcf2aTEfWPiMq2Z22w1MWOfxmScnhKYsc3XmK3mfkhMnHBhunWXvjVwvfZ6TZME30MNOmTsGkiRM6vt5TWWg5wjs8ZZHDb5aUHJ6yyBHPI0bTrDHyOJKnZB2FJWyCp7LQcoR3eMoih98sKTk8ZZEjnicGVR+madYYGQfgkQAmZByZkFxAcoDkwNp1G0JlHes+o86pZHc6Dk9Z5PCbJSWHpyxyxPPEwAL+rwyaTVK93czO7ERqZv0A+oEwtWmy8FQWWo7wDk9Z5PCbJSWHpyxyxPOI0ZQ6Z6RbPJWFliO8w1MWOfxmScnhKYsc8TwxqPowTbOekRmxb7542Ups2rwVg4M7MaO3D4vmz8PsNiYDeSoLLUd4h6cscvjNkpLDUxY54nliMORkuKhTMpf2hiLEME3W0l4hhBDCI0Uv7Z13wGuDfZh/4aavFz4you3ghRBCiIpT7X4RNUaEEEKIyqPaNEIIIYQQXaCeESGEEKLilLU/SCjUGBFCCCEqTllLckNR6jCNqvbKUaUscvjNkpLDUxY54nnEQyl1aa+q9spRlSxy+M2SksNTFjm68xS9tPe4A44J9mH+lZu+6apqb3RUtVeOqmSRw2+WlByessgRzxODqtemadoYGaNa78kk55F8UlEBm+GpEqMc4R2essjhN0tKDk9Z5IjnEaPJ6xkZWal3IoBpAL5Lck7WRaraK4fem7QdnrKk5PCURY54nhikXJsGZvbesc6T3AvA9wGcl3GdqvbKofcmYYenLCk5PGWRI54nBl4aRZ3S0ZwRM7sLDqr6eqrEKEd4h6cscvjNkpLDUxY54nmqDsmZJH9N8nqS7x7j+VNIXk1yK8lLSB6Q5+xonxGSRwP4cyfXNqKqvXJUJYscfrOk5PCURY54nhgUtR08yXEAPgngJQB2ANhE8gIzu7rhZZsBTDOzv5F8G4APAXh9U2+zrh2S2zC6/s5eAG4DcLyZXZsXXFV7hRBC7GoUvbT3VU98ZbDWyLdu/nZmdpJHADjDzF5Wf3waAJjZBzJefyiAs83sqGb3zOsZeeWIxwbgTjO7J+c6IYQQQhREyCW5JBcAWNBwqr8+FxQA9gVwS8NzOwA8t4luPoDv5t0zbwLrTXkCIYQQQqRD4yKUMRir12TMlhDJPtRW4L4g756qTSOEEEJUnKLmjKDWE7J/w+P9UJu68RBIvhjAewC8wMzuzZOqMSKEEEJUnAKX9m4CcGB989NbAcwB8IbGF9TniXwawEwzu6MVaanbwQshhBCiOpjZ/QBOBHAxgGsAfNnMtpM8k+Sr6y/7MIBHAvgKyS0kL8jzqmdECCGEqDhF7pxqZhcCuHDEudMbvn5xu85Se0aWrliN6bPmoLdvYccOT2Wh5Qjv8JRFDr9ZUnJ4yiJHPE9oql4or+k+IyFots/IwJZtGN/TgyXLV2Hj+jWZjqx9RlSyO22Hpyxy+M2SksNTFjm68xS9z8hL958Z7MP8e7dcVPgO65k9IyTPJnlkzJtPmzoFkyZO6Ph6T2Wh5Qjv8JRFDr9ZUnJ4yiJHPE8MhmDBjjJoNkzzGwBnkbyR5AdJTi0qVKt4KgstR3iHpyxy+M2SksNTFjnieWJgZsGOMshsjJjZx8zsCNQ2K7kLwOdIXkPydJIHNZOSXEBygOTA2nUbAkd+yH1GnVPJ7nQcnrLI4TdLSg5PWeSI5xGjyV1NU9+F9YMAPlhfO/xZAMsAjGtyzYO7t4WoTZOFp7LQcoR3eMoih98sKTk8ZZEjnicGZQ2vhCJ3NQ3J3Ui+iuQXUdtf/joAs6MnawFPZaHlCO/wlEUOv1lScnjKIkc8Twyqvpoms2eE5EsAzAUwC8DPAZwHYEHIInmLl63Eps1bMTi4EzN6+7Bo/jzMbmMykKey0HKEd3jKIoffLCk5PGWRI55HjCZzaS/JywB8CcDXzOyuTm8QYpgma2mvEEII4ZGil/ZO33dGsC6NH956SeFLezN7RszsRUUGEUIIIURnVHvGiGrTCCGEEKJkVJtGCCGEqDhVX02jxogQQghRcareGNEwjRBCCCFKRVV7A3rkCO/wlEUOv1lScnjKIkc8T2iqvh28qvYG8sgR3uEpixx+s6Tk8JRFju48RS/tfc4+Lwj2Yf7z237gp2ovAJA8ieThJKPMLVHVXjmqkkUOv1lScnjKIkc8jxhN3jDNfgA+BuAOkpeTXEFyFsm9CsiWi6dKjHKEd3jKIoffLCk5PGWRI54nBsluBw8AZnYqAJDcHcA0AEcCeDOAz5AcNLOD40fMxlMlRjnCOzxlkcNvlpQcnrLIEc8TAy85OqXVCaw9ACYCmFQ/bgPws6wXk1xAcoDkwNp1G7pPmYGnSoxyhHd4yiKH3ywpOTxlkSOeR4wmb85IP8mfADgfwBEAfgrgODObZmb/kXWdmfXXXzPthOPnhk3cgKdKjHKEd3jKIoffLCk5PGWRI54nBkOwYEcZ5E1MfSKAPQD8BsCtAHYAGAx1c1XtlaMqWeTwmyUlh6cscsTzxKDqwzS5S3tZGyQ7BLX5IkcCeAaAuwBcYWbL8m6gqr1CCCF2NYpe2nvo3kcFa41s/v1P/FTtHcZqrZWrSA4C+Ev9eCWA5wDIbYwIIYQQIi5V3w6+aWOE5DtR6w05CsB9AH4C4AoAnwWwLXo6IYQQQuRS1pLcUOT1jEwG8FUAJ5vZ7fHjCCGEEGJXI2+fkVOKCiKEEEKIzhiq+ATWKNu8CyGEEKI4qj5MU2rVXiGEEEKIUhsjS1esxvRZc9Dbt7Bjh6ey0HKEd3jKIoffLCk5PGWRI54nNENmwY4yyN1npFua7TMysGUbxvf0YMnyVdi4fk2mI2ufEZXsTtvhKYscfrOk5PCURY7uPEXvM/K0fzk82If5tXdsKnyfkcyeEZL7N3kuyC5k06ZOwaSJEzq+3lNZaDnCOzxlkcNvlpQcnrLIEc8jRtNsmOYHJN9F8sFJriQfT3I9gNXxo+XjqSy0HOEdnrLI4TdLSg5PWeSI54lB1YdpmjVGng3gKQA2kzya5H8C+Dlqm549t5m0qKq9nspCyxHe4SmLHH6zpOTwlEWOeJ4YWMD/lUHm0l4z+zOAt9YbId8HcBuA55nZjjypmfUD6AfC1KbJwlNZaDnCOzxlkcNvlpQcnrLIEc8jRtNszsijSH4awH8AmInaTqzfJXl0UeHy8FQWWo7wDk9Z5PCbJSWHpyxyxPPEoOrDNM02PfslgHMAvN3M7gfwPZJTAZxD8iYzm9vtzRcvW4lNm7dicHAnZvT2YdH8eZjdxmQgT2Wh5Qjv8JRFDr9ZUnJ4yiJHPE8Mqr7pWebSXpL7ZQ3JkHyLmX2mlRuEGKbJWtorhBBCeKTopb1PfuyhwVojN/xpc+FLe5vNGcmcG9JqQ0QIIYQQ8TEbKjtCV6g2jRBCCFFxhio+TKPaNEIIIYQoFfWMCCGEEBXHy34nnaLGiBBCCFFxNEwjhBBCCNEFpTZGlq5Yjemz5qC3b2HHDk9loeUI7/CURQ6/WVJyeMoiRzxPaMws2FEGzfYZuRDAIjO7sZsbNNtnZGDLNozv6cGS5auwcf2aTEfWPiMq2Z22w1MWOfxmScnhKYsc3XmK3mfkCY86OFgr4vbBqwvfZ6RZz8jnUdt19T0kd4tx82lTp2DSxAkdX++pLLQc4R2essjhN0tKDk9Z5IjnEaPJbIyY2ZcBHApgIoABkqeSPGX4KCxhEzyVhZYjvMNTFjn8ZknJ4SmLHPE8Mah61d68OSP3AbgHwB4AJow4MiG5gOQAyYG16zYECZpxn1HnVLI7HYenLHL4zZKSw1MWOeJ5YlD1OSOZS3tJzgSwGsAFAA4zs7+1KjWzfgD9QJjaNFl4KgstR3iHpyxy+M2SksNTFjnieWKQ8tLe9wA4zsze3U5DpEg8lYWWI7zDUxY5/GZJyeEpixzxPGI0zQrlRS+Vu3jZSmzavBWDgzsxo7cPi+bPw+w2JgN5KgstR3iHpyxy+M2SksNTFjnieWLgZbioUzKX9oYixDBN1tJeIYQQwiNFL+3da8KBwT7M77r7N66W9gohhBBCREe1aYQQQoiKU/VhGjVGhBBCiIqT8moaIYQQQojoqGdECCGEqDhVH6ZR1d6AHjnCOzxlkcNvlpQcnrLIEc8TmiGzYEcZlLq0V1V75ahKFjn8ZknJ4SmLHN15il7a+8jxTwr2Yf7Xv/3O19Jekpk7kJE8rtubq2qvHFXJIoffLCk5PGWRI54nBqkXyruQ5GUk9x3judNiBGoHT5UY5Qjv8JRFDr9ZUnJ4yiJHPE8Mqj5Mk9cY2QrgSwCuHKMnJLMbR1V75dB7k7bDU5aUHJ6yyBHPI0aTt5rGzOwzJH8A4IskXwHg7fXCeZnvgKr2yqH3Jm2HpywpOTxlkSOeJwZVbxS1tJrGzK4DcASAPwDYTPK5UVO1iKdKjHKEd3jKIoffLCk5PGWRI54nBlWfM5LXM/Jgn5SZ3Q/g3SQvArABwOO6vbmq9spRlSxy+M2SksNTFjniecRomi7tJdlrZhvHOP9oAG81s5V5N1DVXiGEELsaRS/t3X2P/YJ1afzj3h2+lvaO1RCpn/9zKw0RIYQQQsTHzIIdeZCcSfLXJK8n+e4xnt+D5Pn1539GcnKeU7VphBBCCNESJMcB+CSAlwM4GMBckgePeNl8AH82s6cC+AiAD+Z51RgRQgghKo4FPHJ4DoDrzewGM/sHgPMAHDPiNccAOLf+9VcBzOBY66If8h8QsGuniy6hBXKEdXjKIoffLHL4zZKSw1MWLw7PB4AFAAYajgUNzx0LYG3D43kAzh5x/VUA9mt4/FsAj212Ty89IwvkCO4I5ZEjvCOUR47wjlAeOeJ4UnK4xcz6zWxaw9Hf8PRYPRwjO1Raec1D8NIYEUIIIYR/dgDYv+HxfgBuy3oNyYcDmATgrmZSNUaEEEII0SqbABxI8kkkdwcwB8AFI15zAYB/r399LIBLrT5ek0XepmdF0Z//EjlK8sgR3hHKI0d4RyiPHHE8KTkqiZndT/JEABcDGAfgs2a2neSZAAbM7AIA/wPgCySvR61HZE6et+mmZ0IIIYQQsdEwjRBCCCFKRY0RIYQQQpRKqY0Rkq8haSSf1oXjAZJbSP6K5C9JHtmBY2+S55H8LcmrSV5I8qAOMmyv5ziFZNvf2wbP8DFqm90OPZPbvP7xJL9E8gaSvyB5BcnXtOn464jHbyJ5djuOZr6iHY3XknwFyd+QfGKRGerXG8kvNDx+OMk/kvx2m46zGh6fSvKMDrLsR/Kb9e/Fb0l+rD6hrR3H8L/Vq0h+heT4LnPcQPJsknt0keNbJB/Vbo665z313wNb6762KpyTfEzDz+3vSd7a8Lil7y3JySSvGnHuDJKntpHjcpIvG3HuJJLntHj9R0ie1PD4YpJrGx6fRfKUFl37k/wdyb3qjx9df3xAa/81AGv8mOTLG869jrXCr606XjPi9+oWkkONTtE5ZfeMzAXwY7QwuaUJfzezqWb2LACnAfhAOxeTJIBvALjczJ5iZgcDWALg8R1kOATASwC8AsCydnKM8Awfndb/Gem5sdUL69+PjQB+aGZPNrNno/b+7NdhlqQgOQPAJwDMNLObS4hwD4BnkOypP34JgFvbdNwL4LUkH9tpiPq/k68D2GhmBwI4CMAjAby/TdXwv9VnAPgHgIVd5jgQQA+AD3WR4y4Ab2/zepA8AsArARxmZs8E8GIAt7TjMLM7h39uAawB8JGGn+N/tJupCzZg9O/lOfXzrfBTAEcCQP0Ps8cCOKTh+SMB/KQVkZndAuBTAIZ/H64E0G9mN7WYBfWVHAsBrCa5J8lHoPZvteX32cy+0fh7FcA5AH6E2kRO0SWlNUZIPhLAUajtYd9NY6SRiQD+3OY1LwJwn5mtGT5hZlvM7EedBDCzO1DbEOfE+i/KqnE0gH+M+H7cZGafKDGTC0g+H8BnAMwys9+WGOW7AGbVv56L1j8ghrkftdUAJ3eR4WgA/2dmnwMAM3ug7ntzJ70bdX4E4KmBchxf/x3TCVcA2LeD654A4E9mdm89y5/MbOT+C1XhqwBeOdzDVO9d3Qe1Px5b4SeoN0ZQa4RcBeDueq/GHgCeDmBzG3k+AuB59d6WfwNwVs7rR2FmVwH4FoD/Qu2PxXWd/hyz1nN+OoB5ZjbUiUM8lDJ7RnoBXGRm1wG4i+RhHXp66t1l1wJYC2B5m9c/A8AvOrz3mJjZDah9b/+lzUuH/1uGj9d3GKHR8402rz0EwC87vG9Whi0AzgzgLJM9AHwTQK+ZXVtylvMAzCG5J4BnAvhZB45PAngjyUkdZjgEI35uzGwngJvRfoNieGOklwPYFijHjR3mGAdgBkbvm9AK3wOwP8nrSJ5D8gUdOFxgZncC+DmAmfVTcwCcn7dXRMP1twG4vz6UeSRqDbyfATgCwDQAW9vp6TGz+wAsRq1RclIXvUTvBfAG1P6ttdt7BgAguRuALwE4taTe0SQpszEyF7Vfqqj//9wOPcPdq09D7QdnnZMeiU4yjBxeOb/Dezd62prrMRKSn2RtHsymLjJMRe2viCpzH2pdz/PLDmJmWwFMRu1n5sIOHTsBrAPwzg5jEGNv75x1PoueemN1ALWGzP8EzNEOwznuBLAXgP9t83qY2V8BPBu1ntE/Ajif5Jva9QQg6/vf7j4OjUM17QzRDDPcOzLcGLmi4fFP23QBtQbE7aj9AdkRZnYPgPMBfGG4B6sDlgPYbmbn5b5StEwpjRGSj0Gte3UtyRtRa/G+vttGhJldgdrY5OPauGw7ar9AgkHyyQAeAHBHSG9BbAfwYC+Vmb0dtb8U2/mepsgQgNcBOJzkkrLDoPaX+yq0/wHRyEdRa1w9ooNrt6P2F+6DkJyI2hbQ7XR9NzZa39HBX7xZOR4P4Nft5gBwAIDd0cGcEaA2TGRml5vZMgAnApjdiadL7gTw6BHn9gLwpzY9G1GrtnoYgB4za7fHdHjeyBTUhmmuRK1npOX5IsOQnIra/KjnATiZ5BPazNLIUP1oG5IvRO09PbGL+4sxKKtn5FjUxusOMLPJZrY/gN+hNhbYMaytyhmH2g9jq1wKYA+Sb2nwHN5pFyvJx6E28ezsVrs0nXEpgD1Jvq3hXKdzAJLCzP6G2gTFN5Isu4fkswDONLN2hzUexMzuAvBldNbbcwmA8SSPBx4c3jgLwOfr36eiyMpxtpn9vV2Zmf0Ftd6iU+vd8S1D8l9JHthwaiqAlidZhqLeQ3N7fbI16qtQZqL1+R6NnstR+7fWSaP3J6j9vNxVb6TdBeBRqDVIrmhVUv8j9VOoDc/cDODDqDXEC4XkowF8DsDxZnZ30fdPnbIaI3NRW8HSyNdQG8trlwfnJqDW/fbv9UlsLVFvMLwGwEtYW564HcAZGF34p5UM2wF8H7Wx4/e2cf1Iz/DR6Wqajql/P3oBvKC+fO7nAM5FbdJXZanPSei0W/ZB6r9QZwJYSvKYDhTjSe5oOFpa3jhGjh1m9rFOrh3BWaj1JrZ7/+Gfm+NI/gbAdQD+D7WVaIXRkOPYeo47AQyZWburehqdmwH8Cu1PrH8kgHNZ2x5gK4CDUftdUgbHo/ZvdAtqf2C8t8PJmhsAPAv/HFJvh22o/du6csS5v5hZO700bwFws5kND52dA+BpJczJWYjaPMBPBZrbJxrQdvBil4DkswB8xsyeU3YWEQ/W9hnaAOC1ZhZ0YroQIh5qjIjkIbkQta73k8zse2XnEUII8VDUGBFCCCFEqZS9A6sQQgghdnHUGBFCCCFEqagxIoQQQohSUWNECCGEEKWixogQQgghSuX/A0x9dCtb/GtdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# let change the prediction into int, see the confusion matrix\n",
    "array = confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25)))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1_layer_model = Model(inputs=model.input,outputs=model.get_layer('test1').output)\n",
    "dense2_layer_model = Model(inputs=model.input,outputs=model.get_layer('test2').output)\n",
    "dense3_layer_model = Model(inputs=model.input,outputs=model.get_layer('test3').output)\n",
    "dense4_layer_model = Model(inputs=model.input,outputs=model.get_layer('test4').output)\n",
    "dense5_layer_model = Model(inputs=model.input,outputs=model.get_layer('test5').output)\n",
    "dense6_layer_model = Model(inputs=model.input,outputs=model.get_layer('test6').output)\n",
    "\n",
    "\n",
    "dense1_output = dense1_layer_model.predict(x_train)\n",
    "dense2_output = dense2_layer_model.predict(x_train)\n",
    "dense3_output = dense3_layer_model.predict(x_train)\n",
    "dense4_output = dense4_layer_model.predict(x_train)\n",
    "dense5_output = dense5_layer_model.predict(x_train)\n",
    "dense6_output = dense6_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.9238837e-02, -1.8250652e-01, -5.8367535e-02, -6.2052488e-02,\n",
       "       -7.5971390e+01, -3.7069912e+01,  8.1990042e+00, -1.9958968e-01,\n",
       "       -7.8417474e-01, -5.3420931e-02, -5.8570340e-02, -7.4948096e-01,\n",
       "       -5.3487915e+01, -1.0705551e+02, -9.3844466e-02, -4.8224869e+01,\n",
       "       -1.6527846e-02, -1.4729333e-01, -7.7643272e+01, -2.5923800e-01,\n",
       "       -1.9545226e-01, -1.3883923e+02, -4.1257548e-01, -1.2102090e+02,\n",
       "       -1.3372168e-01, -7.2250724e-01], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense1_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.4308245e+00, -1.3167095e+00, -2.0611078e+01,  7.2056597e-01,\n",
       "       -1.6920118e-01, -8.2904844e+00, -1.5575854e+01, -2.0557809e+00,\n",
       "        2.1778649e-02, -2.8207676e+00, -3.4150314e+01,  3.7151611e-01,\n",
       "       -3.9398643e+01,  1.0846401e-01,  1.4916307e-01, -2.4802241e+00,\n",
       "       -4.1994057e+00,  1.7429384e+00, -2.4374142e+01, -1.7313551e+01,\n",
       "        2.6455194e-01, -4.0643677e+01, -2.7025650e+00, -1.9350550e+00,\n",
       "       -2.5000780e+00, -1.5448533e+01], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAC9JJREFUeJzt3F2MXHUdxvHnoVuoLxiBDoiUdTWigSAWs6ChUaRBU8CAGl8g0WBCslcmmBhNDVdekIgkxJh4YQMEjAKaCEoQpBWoDZEiW6DQFxBsUGsbuoQQqShS+Hkxp8nSzu75b3vOmfmR7yfZ7Gx7dvfJUL6dnjmzjggBAPI4YtgDAAALQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACQz1sYXXbp0aUxMTLTxpQHgLWnTpk0vRESv5NhWwj0xMaHp6ek2vjQAvCXZ/lvpsZwqAYBkCDcAJEO4ASAZwg0AyRBuAEim6KoS289JelnS65L2RcRkm6MAAHNbyOWA50XEC60tAQAU4VQJACRTGu6QtNb2JttTbQ4CAMyv9FTJiojYZft4SetsPxURG2YfUAV9SpLGx8cPedDE6t8d8ueOmud+cNGwJwAjj//nF67oEXdE7Kre75F0h6SzBxyzJiImI2Ky1yt6uT0A4BDUhtv2O2wfvf+2pM9K2tL2MADAYCWnSk6QdIft/cffEhG/b3UVAGBOteGOiB2SPtrBFgBAAS4HBIBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQTHG4bS+y/Zjtu9ocBACY30IecV8paXtbQwAAZYrCbXuZpIskXd/uHABAndJH3D+S9F1Jb7S4BQBQYKzuANufk7QnIjbZ/vQ8x01JmpKk8fHxxgZmNrH6d8OeAOAtqOQR9wpJF9t+TtJtklba/vmBB0XEmoiYjIjJXq/X8EwAwH614Y6I70XEsoiYkHSppPsj4mutLwMADMR13ACQTO057tkiYr2k9a0sAQAU4RE3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJFMbbttLbP/Z9mbbW21/v4thAIDBxgqOeVXSyojYa3uxpAdt3xMRG1veBgAYoDbcERGS9lYfLq7eos1RAIC5FZ3jtr3I9uOS9khaFxEPtzsLADCXonBHxOsRsVzSMkln2z79wGNsT9metj09MzPT9E4AQGVBV5VExEuS1ktaNeD31kTEZERM9nq9huYBAA5UclVJz/a7q9tvk3S+pKfaHgYAGKzkqpITJd1se5H6of9VRNzV7iwAwFxKrip5QtKZHWwBABTglZMAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJKpDbftk20/YHu77a22r+xiGABgsLGCY/ZJ+nZEPGr7aEmbbK+LiG0tbwMADFD7iDsidkfEo9XtlyVtl3RS28MAAIMt6By37QlJZ0p6uI0xAIB6xeG2/U5Jv5b0rYj414Dfn7I9bXt6ZmamyY0AgFmKwm17sfrR/kVE3D7omIhYExGTETHZ6/Wa3AgAmKXkqhJLukHS9oi4rv1JAID5lDziXiHp65JW2n68eruw5V0AgDnUXg4YEQ9KcgdbAAAFeOUkACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJFMbbts32t5je0sXgwAA8yt5xH2TpFUt7wAAFKoNd0RskPRiB1sAAAUaO8dte8r2tO3pmZmZpr4sAOAAjYU7ItZExGRETPZ6vaa+LADgAFxVAgDJEG4ASKbkcsBbJT0k6cO2d9q+ov1ZAIC5jNUdEBGXdTEEAFCGUyUAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIpCrftVbaftv2s7dVtjwIAzK023LYXSfqJpAsknSbpMtuntT0MADBYySPusyU9GxE7IuJ/km6TdEm7swAAcykJ90mS/jHr453VrwEAhmCs4BgP+LU46CB7StJU9eFe20/XfN2lkl4o+P6jiO3DwfbuZd0tDWG7rzmsT39f6YEl4d4p6eRZHy+TtOvAgyJijaQ1pd/Y9nRETJYeP0rYPhxs717W3VLu7XVKTpU8IukU2++3faSkSyXd2e4sAMBcah9xR8Q+29+UdK+kRZJujIitrS8DAAxUcqpEEXG3pLsb/t7Fp1VGENuHg+3dy7pbyr19Xo446HlGAMAI4yXvAJBMZ+G2/WXbW22/YXvOZ3pt32h7j+0tXW2rs4DtI/ejAWwfa3ud7Weq98fMcdw1trdUb1/teucgC9j+w+q/z3bbP7Y96BLWTpVst32e7cdnvf3X9ueHsXfWptL7fNz22uo+32Z7otulAzeVbn991n2e8kKLLh9xb5H0RUkbao67SdKq1tcsTO32Ef7RAKsl3RcRp0i6r/r4TWxfJOljkpZL+rik79h+V6crByvZfo6kFZLOkHS6pLMkndvlyDnUbo+IByJieUQsl7RS0iuS1nY78yC1uys/k3RtRJyq/qur93S0bz6l2/+z/36PiIu7m9eczsIdEdsjou5FOYqIDZJe7GBSscLto/qjAS6RdHN1+2ZJgx7RnSbpjxGxLyL+LWmzRuMvz5LtIWmJpCMlHSVpsaTnO1k3v5Lts31J0j0R8Uqrq+rV7q4ekIxFxDpJioi9I7BbWvh9nhbnuJszqj8a4ISI2C1J1fvjBxyzWdIFtt9ue6mk8/TmF10NS+32iHhI0gOSdldv90bE9k5XDlZyv892qaRbW19Vr2T3hyS9ZPt224/Zvrb6F+ewld7nS2xP29447FNTh6rocsBStv8g6T0DfuuqiPhtk9+raQ1sL/rRAG2Yb3vJ50fEWttnSfqTpBlJD0na19zCuR3udtsflHSq+q/olaR1tj9V/cutVYe7fdbXOVHSR9R/rUTrGtg9JumTks6U9HdJv5T0DUk3NLFvPg3d5+MRscv2ByTdb/vJiPhrMwu70Wi4I+L8Jr9elxrYXvSjAdow33bbz9s+MSJ2V4EYeC4yIq6WdHX1ObdIeqaVsQd/38Pd/gVJGyNib/U590j6hOqfSzlsTdzvla9IuiMiXmt85AAN7N4p6bGI2FF9zm/Uv89bD3dDf9Z3Ve932F6v/l9AqcLNqZLmjOqPBrhT0uXV7cslHfSvB9uLbB9X3T5D/Sf6hv0kmVSwXf1HfOfaHrO9WP0nJkfhVEnJ9v0u02icJpHKdj8i6RjbverjlZK2dbCtTsmf9WNsH1XdXqr+E9ujsH1hIqKTN/UfGe2U9Kr6Tx7dW/36eyXdPeu4W9U/V/ladfwVXW1sYPuFkv6i/t/eVw17d7XpOPWfYX+men9s9euTkq6vbi9R/w/vNkkbJS0f9u4FbF8k6afqx3qbpOuGvbt0e/XxhKR/Sjpi2JsXuPszkp6Q9KT6V4IdmWG7pHOqzZur90Pvy6G88cpJAEiGUyUAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJL5P2ZfbwxZyW/EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense2_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.4867115 ,  0.26226214, -1.5446477 , -1.577042  , -0.5159017 ,\n",
       "       -0.13904814,  0.02964948, -3.916411  ,  0.14969423, -2.3855681 ,\n",
       "        1.2621495 , -0.7511888 , -0.98879224,  0.04043617, -0.292926  ,\n",
       "       -0.1381304 , -1.4789919 , -2.5657327 ,  0.4231301 , -0.71274835,\n",
       "       -0.18500642, -6.2457457 , -1.7779039 , -2.495369  ,  0.10857083,\n",
       "       -3.5623665 ], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense3_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9410502 , -0.2966314 , -0.5965823 ,  0.04212134, -0.11281076,\n",
       "       -0.10721641, -0.26541516, -0.22773685,  0.28652653, -0.6434395 ,\n",
       "       -0.33888716, -0.19774866, -0.21851924, -0.26353082,  0.7559446 ,\n",
       "        0.18789333, -0.0943763 , -0.14748389,  0.31416503, -0.5535672 ,\n",
       "       -0.20845275, -0.27123374,  0.19636331,  0.09369849, -0.441437  ,\n",
       "        0.4456302 ], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense4_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.9480869e-02, -3.7565637e-01, -1.6990352e+00,  2.6742068e-01,\n",
       "        1.6284688e-01, -1.3024731e-01, -2.0482988e+00, -9.8533608e-02,\n",
       "       -9.7551197e-03, -5.3102002e-02, -7.7356204e-02, -2.1484625e-01,\n",
       "       -1.4148009e-01,  7.0867404e-02, -2.2128186e+00, -1.7777636e+00,\n",
       "       -1.0023483e-01, -7.4646497e-01, -4.6801925e-02, -2.9010728e-01,\n",
       "       -3.1623608e-01,  1.4861729e-03, -9.2101145e-01,  1.4620858e-01,\n",
       "       -3.0994147e-01,  2.0815910e-01], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAC9JJREFUeJzt3F2MXHUdxvHnoVuoLxiBDoiUdTWigSAWs6ChUaRBU8CAGl8g0WBCslcmmBhNDVdekIgkxJh4YQMEjAKaCEoQpBWoDZEiW6DQFxBsUGsbuoQQqShS+Hkxp8nSzu75b3vOmfmR7yfZ7Gx7dvfJUL6dnjmzjggBAPI4YtgDAAALQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACQz1sYXXbp0aUxMTLTxpQHgLWnTpk0vRESv5NhWwj0xMaHp6ek2vjQAvCXZ/lvpsZwqAYBkCDcAJEO4ASAZwg0AyRBuAEim6KoS289JelnS65L2RcRkm6MAAHNbyOWA50XEC60tAQAU4VQJACRTGu6QtNb2JttTbQ4CAMyv9FTJiojYZft4SetsPxURG2YfUAV9SpLGx8cPedDE6t8d8ueOmud+cNGwJwAjj//nF67oEXdE7Kre75F0h6SzBxyzJiImI2Ky1yt6uT0A4BDUhtv2O2wfvf+2pM9K2tL2MADAYCWnSk6QdIft/cffEhG/b3UVAGBOteGOiB2SPtrBFgBAAS4HBIBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQTHG4bS+y/Zjtu9ocBACY30IecV8paXtbQwAAZYrCbXuZpIskXd/uHABAndJH3D+S9F1Jb7S4BQBQYKzuANufk7QnIjbZ/vQ8x01JmpKk8fHxxgZmNrH6d8OeAOAtqOQR9wpJF9t+TtJtklba/vmBB0XEmoiYjIjJXq/X8EwAwH614Y6I70XEsoiYkHSppPsj4mutLwMADMR13ACQTO057tkiYr2k9a0sAQAU4RE3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJFMbbttLbP/Z9mbbW21/v4thAIDBxgqOeVXSyojYa3uxpAdt3xMRG1veBgAYoDbcERGS9lYfLq7eos1RAIC5FZ3jtr3I9uOS9khaFxEPtzsLADCXonBHxOsRsVzSMkln2z79wGNsT9metj09MzPT9E4AQGVBV5VExEuS1ktaNeD31kTEZERM9nq9huYBAA5UclVJz/a7q9tvk3S+pKfaHgYAGKzkqpITJd1se5H6of9VRNzV7iwAwFxKrip5QtKZHWwBABTglZMAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJKpDbftk20/YHu77a22r+xiGABgsLGCY/ZJ+nZEPGr7aEmbbK+LiG0tbwMADFD7iDsidkfEo9XtlyVtl3RS28MAAIMt6By37QlJZ0p6uI0xAIB6xeG2/U5Jv5b0rYj414Dfn7I9bXt6ZmamyY0AgFmKwm17sfrR/kVE3D7omIhYExGTETHZ6/Wa3AgAmKXkqhJLukHS9oi4rv1JAID5lDziXiHp65JW2n68eruw5V0AgDnUXg4YEQ9KcgdbAAAFeOUkACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJFMbbts32t5je0sXgwAA8yt5xH2TpFUt7wAAFKoNd0RskPRiB1sAAAUaO8dte8r2tO3pmZmZpr4sAOAAjYU7ItZExGRETPZ6vaa+LADgAFxVAgDJEG4ASKbkcsBbJT0k6cO2d9q+ov1ZAIC5jNUdEBGXdTEEAFCGUyUAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIpCrftVbaftv2s7dVtjwIAzK023LYXSfqJpAsknSbpMtuntT0MADBYySPusyU9GxE7IuJ/km6TdEm7swAAcykJ90mS/jHr453VrwEAhmCs4BgP+LU46CB7StJU9eFe20/XfN2lkl4o+P6jiO3DwfbuZd0tDWG7rzmsT39f6YEl4d4p6eRZHy+TtOvAgyJijaQ1pd/Y9nRETJYeP0rYPhxs717W3VLu7XVKTpU8IukU2++3faSkSyXd2e4sAMBcah9xR8Q+29+UdK+kRZJujIitrS8DAAxUcqpEEXG3pLsb/t7Fp1VGENuHg+3dy7pbyr19Xo446HlGAMAI4yXvAJBMZ+G2/WXbW22/YXvOZ3pt32h7j+0tXW2rs4DtI/ejAWwfa3ud7Weq98fMcdw1trdUb1/teucgC9j+w+q/z3bbP7Y96BLWTpVst32e7cdnvf3X9ueHsXfWptL7fNz22uo+32Z7otulAzeVbn991n2e8kKLLh9xb5H0RUkbao67SdKq1tcsTO32Ef7RAKsl3RcRp0i6r/r4TWxfJOljkpZL+rik79h+V6crByvZfo6kFZLOkHS6pLMkndvlyDnUbo+IByJieUQsl7RS0iuS1nY78yC1uys/k3RtRJyq/qur93S0bz6l2/+z/36PiIu7m9eczsIdEdsjou5FOYqIDZJe7GBSscLto/qjAS6RdHN1+2ZJgx7RnSbpjxGxLyL+LWmzRuMvz5LtIWmJpCMlHSVpsaTnO1k3v5Lts31J0j0R8Uqrq+rV7q4ekIxFxDpJioi9I7BbWvh9nhbnuJszqj8a4ISI2C1J1fvjBxyzWdIFtt9ue6mk8/TmF10NS+32iHhI0gOSdldv90bE9k5XDlZyv892qaRbW19Vr2T3hyS9ZPt224/Zvrb6F+ewld7nS2xP29447FNTh6rocsBStv8g6T0DfuuqiPhtk9+raQ1sL/rRAG2Yb3vJ50fEWttnSfqTpBlJD0na19zCuR3udtsflHSq+q/olaR1tj9V/cutVYe7fdbXOVHSR9R/rUTrGtg9JumTks6U9HdJv5T0DUk3NLFvPg3d5+MRscv2ByTdb/vJiPhrMwu70Wi4I+L8Jr9elxrYXvSjAdow33bbz9s+MSJ2V4EYeC4yIq6WdHX1ObdIeqaVsQd/38Pd/gVJGyNib/U590j6hOqfSzlsTdzvla9IuiMiXmt85AAN7N4p6bGI2FF9zm/Uv89bD3dDf9Z3Ve932F6v/l9AqcLNqZLmjOqPBrhT0uXV7cslHfSvB9uLbB9X3T5D/Sf6hv0kmVSwXf1HfOfaHrO9WP0nJkfhVEnJ9v0u02icJpHKdj8i6RjbverjlZK2dbCtTsmf9WNsH1XdXqr+E9ujsH1hIqKTN/UfGe2U9Kr6Tx7dW/36eyXdPeu4W9U/V/ladfwVXW1sYPuFkv6i/t/eVw17d7XpOPWfYX+men9s9euTkq6vbi9R/w/vNkkbJS0f9u4FbF8k6afqx3qbpOuGvbt0e/XxhKR/Sjpi2JsXuPszkp6Q9KT6V4IdmWG7pHOqzZur90Pvy6G88cpJAEiGUyUAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJL5P2ZfbwxZyW/EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense5_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.53542924], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense6_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions converge to a small namber without batch normalisation which shows that batch normalisation can make the data has a wider distribution which might save more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some non-linear activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(26, input_dim=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(500))# maybe more neurons\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(26))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 197.9565 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 166us/step - loss: 156.7421 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 116us/step - loss: 106.3304 - acc: 0.0385\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 111us/step - loss: 87.8662 - acc: 0.0385\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 190us/step - loss: 80.7302 - acc: 0.0385\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 138us/step - loss: 87.7600 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 131us/step - loss: 84.1209 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 114us/step - loss: 76.6968 - acc: 0.0385\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 119us/step - loss: 70.3073 - acc: 0.0385\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 112us/step - loss: 66.3115 - acc: 0.0769\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 121us/step - loss: 62.7037 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 141us/step - loss: 57.2631 - acc: 0.0385\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 172us/step - loss: 55.0344 - acc: 0.0385\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 123us/step - loss: 65.3895 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 129us/step - loss: 76.6729 - acc: 0.0769\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 115us/step - loss: 52.1484 - acc: 0.0385\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 42.4100 - acc: 0.0385\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 117us/step - loss: 29.5873 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 149us/step - loss: 28.8598 - acc: 0.1923\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 115us/step - loss: 55.6135 - acc: 0.0385\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 114us/step - loss: 67.4644 - acc: 0.0769\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 135us/step - loss: 29.2123 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 128us/step - loss: 18.3495 - acc: 0.0769\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 120us/step - loss: 18.8903 - acc: 0.1923\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 130us/step - loss: 26.4498 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 136us/step - loss: 30.5414 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 130us/step - loss: 23.0456 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 134us/step - loss: 19.8035 - acc: 0.1538\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 134us/step - loss: 16.5957 - acc: 0.1154\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 122us/step - loss: 15.3696 - acc: 0.1538\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 128us/step - loss: 14.3366 - acc: 0.1923\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 149us/step - loss: 13.9183 - acc: 0.1538\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 131us/step - loss: 13.8903 - acc: 0.2692\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 122us/step - loss: 14.5581 - acc: 0.0769\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 125us/step - loss: 16.9619 - acc: 0.1154\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 117us/step - loss: 17.2063 - acc: 0.0385\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 109us/step - loss: 20.3665 - acc: 0.0385\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 136us/step - loss: 13.9427 - acc: 0.0769\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 131us/step - loss: 13.4159 - acc: 0.1154\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 119us/step - loss: 12.7506 - acc: 0.1154\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 119us/step - loss: 12.5829 - acc: 0.3077\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 12.3285 - acc: 0.1538\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 137us/step - loss: 12.2422 - acc: 0.3846\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 158us/step - loss: 12.1274 - acc: 0.1923\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 121us/step - loss: 12.0812 - acc: 0.3846\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 126us/step - loss: 12.0090 - acc: 0.1923\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 112us/step - loss: 12.0043 - acc: 0.3846\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 124us/step - loss: 11.9763 - acc: 0.1923\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 177us/step - loss: 12.0067 - acc: 0.3077\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 194us/step - loss: 11.9883 - acc: 0.1923\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 12.0669 - acc: 0.2692\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 139us/step - loss: 12.0799 - acc: 0.1538\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 12.2250 - acc: 0.1538\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 12.2013 - acc: 0.1154\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 12.4305 - acc: 0.1154\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 224us/step - loss: 12.3445 - acc: 0.1154\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 158us/step - loss: 11.6174 - acc: 0.3077\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 11.2023 - acc: 0.0769\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 162us/step - loss: 11.3340 - acc: 0.1538\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 133us/step - loss: 11.5818 - acc: 0.0769\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 166us/step - loss: 13.2498 - acc: 0.0769\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 127us/step - loss: 12.8990 - acc: 0.0769\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 133us/step - loss: 15.2111 - acc: 0.0769\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 211us/step - loss: 11.7315 - acc: 0.1154\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 147us/step - loss: 11.6798 - acc: 0.0769\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 10.4505 - acc: 0.1538\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 139us/step - loss: 10.2478 - acc: 0.1923\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 148us/step - loss: 9.8559 - acc: 0.1923\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 153us/step - loss: 9.7617 - acc: 0.3462\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 124us/step - loss: 9.5993 - acc: 0.1923\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 131us/step - loss: 9.5460 - acc: 0.3462\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 139us/step - loss: 9.4610 - acc: 0.2692\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 221us/step - loss: 9.4295 - acc: 0.3846\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 134us/step - loss: 9.3778 - acc: 0.2692\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 124us/step - loss: 9.3744 - acc: 0.3462\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 136us/step - loss: 9.3476 - acc: 0.2692\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 9.3629 - acc: 0.3462\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 151us/step - loss: 9.3537 - acc: 0.1923\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 113us/step - loss: 9.3983 - acc: 0.3077\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 126us/step - loss: 9.4042 - acc: 0.1154\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 121us/step - loss: 9.5371 - acc: 0.1923\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 183us/step - loss: 9.5638 - acc: 0.1154\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 152us/step - loss: 9.7942 - acc: 0.1538\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 117us/step - loss: 9.7622 - acc: 0.1154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 140us/step - loss: 10.1085 - acc: 0.1154\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 120us/step - loss: 9.9372 - acc: 0.1154\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 10.2785 - acc: 0.1154\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 125us/step - loss: 9.8846 - acc: 0.1154\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 116us/step - loss: 10.0744 - acc: 0.1154\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 123us/step - loss: 9.6371 - acc: 0.1154\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 233us/step - loss: 9.7154 - acc: 0.1538\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 126us/step - loss: 9.4132 - acc: 0.1154\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 129us/step - loss: 9.4462 - acc: 0.1923\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 156us/step - loss: 9.2265 - acc: 0.1154\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 149us/step - loss: 9.2400 - acc: 0.2692\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 138us/step - loss: 9.0847 - acc: 0.1538\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 114us/step - loss: 9.0902 - acc: 0.3077\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 121us/step - loss: 9.0024 - acc: 0.1923\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 164us/step - loss: 9.0274 - acc: 0.3077\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 153us/step - loss: 8.9571 - acc: 0.1923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb31e6e048>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x_train), np.array(y_train), epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",x_as_vector = False, y_as_vector = False)\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb311a7860>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# let change the prediction into int, see the confusion matrix\n",
    "array = confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25)))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not amazing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial caeser function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More data might be helpful? So how about create some?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caeser funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, Caeser encryption function is $(n+3) mod 26$. key = 3 in this situation, but generally we can chose key as any integer number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit it by using sigmoid function, we can see in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return(1/(1 + math.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_caeser_function(x):\n",
    "    s1 = sigmoid(-30*(x-22.5))\n",
    "    s2 = sigmoid(30*(x-22.5))\n",
    "    y = (x+3)*s1+(x-23)*s2\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.953457900066243e-06"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_caeser_function(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3e535b38>]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,26,.01), list(map(ai_caeser_function,np.arange(0,26,.01))),'-')\n",
    "plt.plot(np.arange(0,26,1), list(map(ai_caeser_function,np.arange(0,26,1))), 'g.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = (x-3)sigmoid(-30(x-22.5))+(x-23)sigmoid(30(x-22.5))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fail to do: build a similar neural network structure for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use more data generated by this function to train the neural networks, let's see the if the prediction for one input one output model will be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2000, input_dim=1, name=\"test1\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, init='uniform', name = 'test1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test4'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test5'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, name = 'test6'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.  , 3.01, 3.02, ..., 2.97, 2.98, 2.99])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(ai_caeser_function, np.arange(0,26,.01))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2600/2600 [==============================] - 3s 1ms/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "2600/2600 [==============================] - 0s 68us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "2600/2600 [==============================] - 0s 77us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "2600/2600 [==============================] - 0s 85us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "2600/2600 [==============================] - 0s 81us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "2600/2600 [==============================] - 0s 82us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "2600/2600 [==============================] - 0s 85us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "2600/2600 [==============================] - 0s 86us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "2600/2600 [==============================] - 0s 81us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "2600/2600 [==============================] - 0s 77us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "2600/2600 [==============================] - 0s 78us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "2600/2600 [==============================] - 0s 91us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "2600/2600 [==============================] - 0s 79us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "2600/2600 [==============================] - 0s 85us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "2600/2600 [==============================] - 0s 81us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "2600/2600 [==============================] - 0s 92us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "2600/2600 [==============================] - 0s 87us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "2600/2600 [==============================] - 0s 73us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "2600/2600 [==============================] - 0s 83us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "2600/2600 [==============================] - 0s 77us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "2600/2600 [==============================] - 0s 78us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "2600/2600 [==============================] - 0s 77us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "2600/2600 [==============================] - 0s 94us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "2600/2600 [==============================] - 0s 88us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "2600/2600 [==============================] - 0s 79us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "2600/2600 [==============================] - 0s 87us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "2600/2600 [==============================] - 0s 87us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "2600/2600 [==============================] - 0s 78us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "2600/2600 [==============================] - 0s 83us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "2600/2600 [==============================] - 0s 82us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "2600/2600 [==============================] - 0s 65us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "2600/2600 [==============================] - 0s 69us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "2600/2600 [==============================] - 0s 73us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "2600/2600 [==============================] - 0s 82us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "2600/2600 [==============================] - 0s 73us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "2600/2600 [==============================] - 0s 83us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "2600/2600 [==============================] - 0s 64us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "2600/2600 [==============================] - 0s 61us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "2600/2600 [==============================] - 0s 73us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "2600/2600 [==============================] - 0s 70us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "2600/2600 [==============================] - 0s 63us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "2600/2600 [==============================] - 0s 60us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "2600/2600 [==============================] - 0s 69us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "2600/2600 [==============================] - 0s 89us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "2600/2600 [==============================] - 0s 86us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "2600/2600 [==============================] - 0s 78us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "2600/2600 [==============================] - 0s 104us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "2600/2600 [==============================] - 0s 115us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "2600/2600 [==============================] - 0s 118us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "2600/2600 [==============================] - 0s 123us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "2600/2600 [==============================] - 0s 92us/step - loss: 211.7203 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a481ac2e8>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.arange(0,26,.01)/25, np.array(list(map(ai_caeser_function, np.arange(0,26,.01)))), epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it doesn't work amazing even we get enough data. If we have enough time, we will try to find a better structure for our networks to fit this function appropriately (roughly ideas is to set the sigmoid as an activation function for a layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What neurons learned for different period?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will **take a long time** to run. We recommond to download the results/ folder in the main page, and if you open tensorboard by `tensorboard --logdir=results/`, you can see how the function change and how the loss reducing. Bacially, the loss will stay at 9, as the last 3 shifts are too hard to fit. If we trained 5000 times, the loss will decrease to 6, and start to learn something new as the pictures show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xihajun/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Training our universal approximator\n",
      "batch: 100, loss: 43.954262\n",
      "batch: 200, loss: 19.234653\n",
      "batch: 300, loss: 10.666520\n",
      "batch: 400, loss: 9.649702\n",
      "batch: 500, loss: 9.367650\n",
      "batch: 600, loss: 9.268389\n",
      "batch: 700, loss: 9.143136\n",
      "batch: 800, loss: 9.262796\n",
      "batch: 900, loss: 9.267904\n",
      "batch: 1000, loss: 9.429953\n",
      "Plotting graphs\n"
     ]
    }
   ],
   "source": [
    "# this code is just for 1000 epochs\n",
    "# By modify the code from here: https://blog.metaflow.fr/tensorflow-howto-a-universal-approximator-inside-a-neural-net-bb034430b71e#.cves3pv8h\n",
    "%run neurons.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100: (the one above is the \"caeser\" function, another one is the prediction function)\n",
    "<img src=\"./images/100.png\" width=\"400\" height=\"300\">\n",
    "\n",
    "1000: (the one above is the \"caeser\" function, another one is the prediction function)\n",
    "<img src=\"./images/1000.png\" width=\"400\" height=\"300\">\n",
    "\n",
    "5000: (the one above is the \"caeser\" function, another one is the prediction function)\n",
    "<img src=\"./images/5000.png\" width=\"400\" height=\"300\">\n",
    "\n",
    "20000: (the one above is the \"caeser\" function, another one is the prediction function)\n",
    "<img src=\"./images/20000.png\" width=\"400\" height=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more, we tried use neurals more than 500 but it doesn't help anymore no matter for the loss reducing or function fitting effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning structure 2: One input vs 26 output (as a classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\", x_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 1 y_train: 26\n"
     ]
    }
   ],
   "source": [
    "x_train\n",
    "print(\"x_train:\",1,\"y_train:\",y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building\n",
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(26, activation='relu'))\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.6984 - acc: 0.4556\n",
      "Epoch 2/300\n",
      "52/52 [==============================] - 0s 84us/step - loss: 0.6834 - acc: 0.5747\n",
      "Epoch 3/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.6690 - acc: 0.6487\n",
      "Epoch 4/300\n",
      "52/52 [==============================] - 0s 84us/step - loss: 0.6520 - acc: 0.6960\n",
      "Epoch 5/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.6335 - acc: 0.7234\n",
      "Epoch 6/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.6134 - acc: 0.7515\n",
      "Epoch 7/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.5899 - acc: 0.7870\n",
      "Epoch 8/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.5660 - acc: 0.7870\n",
      "Epoch 9/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.5414 - acc: 0.7870\n",
      "Epoch 10/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.5162 - acc: 0.7870\n",
      "Epoch 11/300\n",
      "52/52 [==============================] - 0s 95us/step - loss: 0.4907 - acc: 0.7885\n",
      "Epoch 12/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.4661 - acc: 0.7914\n",
      "Epoch 13/300\n",
      "52/52 [==============================] - 0s 92us/step - loss: 0.4436 - acc: 0.8136\n",
      "Epoch 14/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.4198 - acc: 0.8565\n",
      "Epoch 15/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.3944 - acc: 0.8565\n",
      "Epoch 16/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.3675 - acc: 0.8728\n",
      "Epoch 17/300\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.3411 - acc: 0.8935\n",
      "Epoch 18/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.3157 - acc: 0.9349\n",
      "Epoch 19/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.2914 - acc: 0.9615\n",
      "Epoch 20/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.2723 - acc: 0.9615\n",
      "Epoch 21/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.2592 - acc: 0.9615\n",
      "Epoch 22/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.2531 - acc: 0.9615\n",
      "Epoch 23/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.2487 - acc: 0.9615\n",
      "Epoch 24/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.2455 - acc: 0.9615\n",
      "Epoch 25/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.2427 - acc: 0.9615\n",
      "Epoch 26/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.2403 - acc: 0.9615\n",
      "Epoch 27/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.2384 - acc: 0.9615\n",
      "Epoch 28/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.2363 - acc: 0.9615\n",
      "Epoch 29/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.2336 - acc: 0.9615\n",
      "Epoch 30/300\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.2309 - acc: 0.9615\n",
      "Epoch 31/300\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.2280 - acc: 0.9615\n",
      "Epoch 32/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.2254 - acc: 0.9615\n",
      "Epoch 33/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.2232 - acc: 0.9615\n",
      "Epoch 34/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.2212 - acc: 0.9615\n",
      "Epoch 35/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.2196 - acc: 0.9615\n",
      "Epoch 36/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.2181 - acc: 0.9615\n",
      "Epoch 37/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.2165 - acc: 0.9615\n",
      "Epoch 38/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.2150 - acc: 0.9615\n",
      "Epoch 39/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.2136 - acc: 0.9615\n",
      "Epoch 40/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.2122 - acc: 0.9615\n",
      "Epoch 41/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.2105 - acc: 0.9615\n",
      "Epoch 42/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.2090 - acc: 0.9615\n",
      "Epoch 43/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.2076 - acc: 0.9615\n",
      "Epoch 44/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.2060 - acc: 0.9615\n",
      "Epoch 45/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.2045 - acc: 0.9615\n",
      "Epoch 46/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.2029 - acc: 0.9615\n",
      "Epoch 47/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.2014 - acc: 0.9615\n",
      "Epoch 48/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1999 - acc: 0.9615\n",
      "Epoch 49/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1983 - acc: 0.9615\n",
      "Epoch 50/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1964 - acc: 0.9615\n",
      "Epoch 51/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1950 - acc: 0.9615\n",
      "Epoch 52/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1932 - acc: 0.9615\n",
      "Epoch 53/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1916 - acc: 0.9615\n",
      "Epoch 54/300\n",
      "52/52 [==============================] - 0s 89us/step - loss: 0.1894 - acc: 0.9615\n",
      "Epoch 55/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1874 - acc: 0.9615\n",
      "Epoch 56/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1856 - acc: 0.9615\n",
      "Epoch 57/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1840 - acc: 0.9615\n",
      "Epoch 58/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1822 - acc: 0.9615\n",
      "Epoch 59/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.1805 - acc: 0.9615\n",
      "Epoch 60/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1785 - acc: 0.9615\n",
      "Epoch 61/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1771 - acc: 0.9615\n",
      "Epoch 62/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1753 - acc: 0.9615\n",
      "Epoch 63/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1739 - acc: 0.9615\n",
      "Epoch 64/300\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.1723 - acc: 0.9615\n",
      "Epoch 65/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1709 - acc: 0.9615\n",
      "Epoch 66/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1696 - acc: 0.9615\n",
      "Epoch 67/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1683 - acc: 0.9615\n",
      "Epoch 68/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1671 - acc: 0.9615\n",
      "Epoch 69/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.1660 - acc: 0.9615\n",
      "Epoch 70/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1649 - acc: 0.9615\n",
      "Epoch 71/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1640 - acc: 0.9615\n",
      "Epoch 72/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1632 - acc: 0.9615\n",
      "Epoch 73/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1623 - acc: 0.9615\n",
      "Epoch 74/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1615 - acc: 0.9615\n",
      "Epoch 75/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1608 - acc: 0.9615\n",
      "Epoch 76/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1600 - acc: 0.9615\n",
      "Epoch 77/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1593 - acc: 0.9615\n",
      "Epoch 78/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1586 - acc: 0.9615\n",
      "Epoch 79/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1581 - acc: 0.9615\n",
      "Epoch 80/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1575 - acc: 0.9615\n",
      "Epoch 81/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1571 - acc: 0.9615\n",
      "Epoch 82/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1564 - acc: 0.9615\n",
      "Epoch 83/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1561 - acc: 0.9615\n",
      "Epoch 84/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1556 - acc: 0.9615\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 101us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 86/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1547 - acc: 0.9615\n",
      "Epoch 87/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1541 - acc: 0.9615\n",
      "Epoch 88/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1537 - acc: 0.9615\n",
      "Epoch 89/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1531 - acc: 0.9615\n",
      "Epoch 90/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1527 - acc: 0.9615\n",
      "Epoch 91/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1523 - acc: 0.9615\n",
      "Epoch 92/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1518 - acc: 0.9615\n",
      "Epoch 93/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1514 - acc: 0.9615\n",
      "Epoch 94/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1509 - acc: 0.9615\n",
      "Epoch 95/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1505 - acc: 0.9615\n",
      "Epoch 96/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1502 - acc: 0.9615\n",
      "Epoch 97/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1498 - acc: 0.9615\n",
      "Epoch 98/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1493 - acc: 0.9615\n",
      "Epoch 99/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1489 - acc: 0.9615\n",
      "Epoch 100/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1483 - acc: 0.9615\n",
      "Epoch 101/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1480 - acc: 0.9615\n",
      "Epoch 102/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.1475 - acc: 0.9615\n",
      "Epoch 103/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.1472 - acc: 0.9615\n",
      "Epoch 104/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1467 - acc: 0.9615\n",
      "Epoch 105/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.1463 - acc: 0.9615\n",
      "Epoch 106/300\n",
      "52/52 [==============================] - 0s 92us/step - loss: 0.1459 - acc: 0.9615\n",
      "Epoch 107/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1453 - acc: 0.9615\n",
      "Epoch 108/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1450 - acc: 0.9615\n",
      "Epoch 109/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1446 - acc: 0.9615\n",
      "Epoch 110/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1439 - acc: 0.9615\n",
      "Epoch 111/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1435 - acc: 0.9615\n",
      "Epoch 112/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1431 - acc: 0.9615\n",
      "Epoch 113/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1425 - acc: 0.9615\n",
      "Epoch 114/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1424 - acc: 0.9615\n",
      "Epoch 115/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1417 - acc: 0.9615\n",
      "Epoch 116/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1415 - acc: 0.9615\n",
      "Epoch 117/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1409 - acc: 0.9615\n",
      "Epoch 118/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1406 - acc: 0.9615\n",
      "Epoch 119/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1401 - acc: 0.9615\n",
      "Epoch 120/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1396 - acc: 0.9615\n",
      "Epoch 121/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1394 - acc: 0.9615\n",
      "Epoch 122/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1390 - acc: 0.9615\n",
      "Epoch 123/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1385 - acc: 0.9615\n",
      "Epoch 124/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1383 - acc: 0.9615\n",
      "Epoch 125/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1379 - acc: 0.9615\n",
      "Epoch 126/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1378 - acc: 0.9615\n",
      "Epoch 127/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1371 - acc: 0.9615\n",
      "Epoch 128/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1370 - acc: 0.9615\n",
      "Epoch 129/300\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1378 - acc: 0.961 - 0s 106us/step - loss: 0.1366 - acc: 0.9615\n",
      "Epoch 130/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.1363 - acc: 0.9615\n",
      "Epoch 131/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1356 - acc: 0.9615\n",
      "Epoch 132/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1353 - acc: 0.9615\n",
      "Epoch 133/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1349 - acc: 0.9615\n",
      "Epoch 134/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1345 - acc: 0.9615\n",
      "Epoch 135/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1341 - acc: 0.9615\n",
      "Epoch 136/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1339 - acc: 0.9615\n",
      "Epoch 137/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1337 - acc: 0.9615\n",
      "Epoch 138/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1333 - acc: 0.9615\n",
      "Epoch 139/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1330 - acc: 0.9615\n",
      "Epoch 140/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1326 - acc: 0.9615\n",
      "Epoch 141/300\n",
      "52/52 [==============================] - 0s 91us/step - loss: 0.1324 - acc: 0.9615\n",
      "Epoch 142/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1322 - acc: 0.9615\n",
      "Epoch 143/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.1315 - acc: 0.9615\n",
      "Epoch 144/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1314 - acc: 0.9615\n",
      "Epoch 145/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1309 - acc: 0.9615\n",
      "Epoch 146/300\n",
      "52/52 [==============================] - 0s 89us/step - loss: 0.1309 - acc: 0.9615\n",
      "Epoch 147/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1304 - acc: 0.9615\n",
      "Epoch 148/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1300 - acc: 0.9615\n",
      "Epoch 149/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1297 - acc: 0.9615\n",
      "Epoch 150/300\n",
      "52/52 [==============================] - 0s 90us/step - loss: 0.1295 - acc: 0.9615\n",
      "Epoch 151/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1292 - acc: 0.9615\n",
      "Epoch 152/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1286 - acc: 0.9615\n",
      "Epoch 153/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.1285 - acc: 0.9615\n",
      "Epoch 154/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1285 - acc: 0.9615\n",
      "Epoch 155/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1279 - acc: 0.9615\n",
      "Epoch 156/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1278 - acc: 0.9615\n",
      "Epoch 157/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1272 - acc: 0.9615\n",
      "Epoch 158/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.1268 - acc: 0.9615\n",
      "Epoch 159/300\n",
      "52/52 [==============================] - 0s 87us/step - loss: 0.1266 - acc: 0.9615\n",
      "Epoch 160/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 161/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1256 - acc: 0.9615\n",
      "Epoch 162/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1254 - acc: 0.9615\n",
      "Epoch 163/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1251 - acc: 0.9615\n",
      "Epoch 164/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1253 - acc: 0.9615\n",
      "Epoch 165/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1247 - acc: 0.9615\n",
      "Epoch 166/300\n",
      "52/52 [==============================] - 0s 87us/step - loss: 0.1244 - acc: 0.9615\n",
      "Epoch 167/300\n",
      "52/52 [==============================] - 0s 87us/step - loss: 0.1241 - acc: 0.9615\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 106us/step - loss: 0.1236 - acc: 0.9615\n",
      "Epoch 169/300\n",
      "52/52 [==============================] - 0s 85us/step - loss: 0.1235 - acc: 0.9615\n",
      "Epoch 170/300\n",
      "52/52 [==============================] - 0s 91us/step - loss: 0.1232 - acc: 0.9615\n",
      "Epoch 171/300\n",
      "52/52 [==============================] - 0s 90us/step - loss: 0.1229 - acc: 0.9615\n",
      "Epoch 172/300\n",
      "52/52 [==============================] - 0s 90us/step - loss: 0.1224 - acc: 0.9615\n",
      "Epoch 173/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1223 - acc: 0.9615\n",
      "Epoch 174/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1219 - acc: 0.9615\n",
      "Epoch 175/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1217 - acc: 0.9615\n",
      "Epoch 176/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1214 - acc: 0.9615\n",
      "Epoch 177/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1213 - acc: 0.9615\n",
      "Epoch 178/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1209 - acc: 0.9615\n",
      "Epoch 179/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1207 - acc: 0.9615\n",
      "Epoch 180/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1204 - acc: 0.9615\n",
      "Epoch 181/300\n",
      "52/52 [==============================] - 0s 89us/step - loss: 0.1200 - acc: 0.9615\n",
      "Epoch 182/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1199 - acc: 0.9615\n",
      "Epoch 183/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1197 - acc: 0.9615\n",
      "Epoch 184/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.1195 - acc: 0.9615\n",
      "Epoch 185/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1190 - acc: 0.9615\n",
      "Epoch 186/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1189 - acc: 0.9615\n",
      "Epoch 187/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1186 - acc: 0.9615\n",
      "Epoch 188/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1183 - acc: 0.9615\n",
      "Epoch 189/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1180 - acc: 0.9615\n",
      "Epoch 190/300\n",
      "52/52 [==============================] - 0s 91us/step - loss: 0.1179 - acc: 0.9615\n",
      "Epoch 191/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1176 - acc: 0.9615\n",
      "Epoch 192/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1171 - acc: 0.9615\n",
      "Epoch 193/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1169 - acc: 0.9615\n",
      "Epoch 194/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1166 - acc: 0.9615\n",
      "Epoch 195/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1167 - acc: 0.9615\n",
      "Epoch 196/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1158 - acc: 0.9615\n",
      "Epoch 197/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1155 - acc: 0.9615\n",
      "Epoch 198/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1152 - acc: 0.9615\n",
      "Epoch 199/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1151 - acc: 0.9615\n",
      "Epoch 200/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1148 - acc: 0.9615\n",
      "Epoch 201/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1145 - acc: 0.9615\n",
      "Epoch 202/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1142 - acc: 0.9615\n",
      "Epoch 203/300\n",
      "52/52 [==============================] - 0s 95us/step - loss: 0.1137 - acc: 0.9615\n",
      "Epoch 204/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1139 - acc: 0.9615\n",
      "Epoch 205/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1135 - acc: 0.9615\n",
      "Epoch 206/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.1132 - acc: 0.9615\n",
      "Epoch 207/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1125 - acc: 0.9615\n",
      "Epoch 208/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.1125 - acc: 0.9615\n",
      "Epoch 209/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1123 - acc: 0.9615\n",
      "Epoch 210/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1120 - acc: 0.9615\n",
      "Epoch 211/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1117 - acc: 0.9615\n",
      "Epoch 212/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1113 - acc: 0.9615\n",
      "Epoch 213/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1113 - acc: 0.9615\n",
      "Epoch 214/300\n",
      "52/52 [==============================] - 0s 91us/step - loss: 0.1109 - acc: 0.9615\n",
      "Epoch 215/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1104 - acc: 0.9615\n",
      "Epoch 216/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1103 - acc: 0.9615\n",
      "Epoch 217/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1101 - acc: 0.9615\n",
      "Epoch 218/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.1093 - acc: 0.9615\n",
      "Epoch 219/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1092 - acc: 0.9615\n",
      "Epoch 220/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1096 - acc: 0.9615\n",
      "Epoch 221/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1092 - acc: 0.9615\n",
      "Epoch 222/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1094 - acc: 0.9615\n",
      "Epoch 223/300\n",
      "52/52 [==============================] - 0s 89us/step - loss: 0.1084 - acc: 0.9615\n",
      "Epoch 224/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1082 - acc: 0.9615\n",
      "Epoch 225/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1077 - acc: 0.9615\n",
      "Epoch 226/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1077 - acc: 0.9615\n",
      "Epoch 227/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1076 - acc: 0.9615\n",
      "Epoch 228/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1073 - acc: 0.9615\n",
      "Epoch 229/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1075 - acc: 0.9615\n",
      "Epoch 230/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1078 - acc: 0.9615\n",
      "Epoch 231/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1064 - acc: 0.9615\n",
      "Epoch 232/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.1059 - acc: 0.9615\n",
      "Epoch 233/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1067 - acc: 0.9615\n",
      "Epoch 234/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1059 - acc: 0.9615\n",
      "Epoch 235/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1057 - acc: 0.9615\n",
      "Epoch 236/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1047 - acc: 0.9615\n",
      "Epoch 237/300\n",
      "52/52 [==============================] - 0s 92us/step - loss: 0.1040 - acc: 0.9615\n",
      "Epoch 238/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1038 - acc: 0.9615\n",
      "Epoch 239/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1031 - acc: 0.9615\n",
      "Epoch 240/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1033 - acc: 0.9615\n",
      "Epoch 241/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1031 - acc: 0.9615\n",
      "Epoch 242/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1025 - acc: 0.9615\n",
      "Epoch 243/300\n",
      "52/52 [==============================] - 0s 95us/step - loss: 0.1020 - acc: 0.9615\n",
      "Epoch 244/300\n",
      "52/52 [==============================] - 0s 92us/step - loss: 0.1017 - acc: 0.9615\n",
      "Epoch 245/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1018 - acc: 0.9615\n",
      "Epoch 246/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.1016 - acc: 0.9615\n",
      "Epoch 247/300\n",
      "52/52 [==============================] - 0s 90us/step - loss: 0.1007 - acc: 0.9615\n",
      "Epoch 248/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1001 - acc: 0.9615\n",
      "Epoch 249/300\n",
      "52/52 [==============================] - 0s 87us/step - loss: 0.1001 - acc: 0.9615\n",
      "Epoch 250/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.1003 - acc: 0.9615\n",
      "Epoch 251/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.0998 - acc: 0.9615\n",
      "Epoch 252/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 92us/step - loss: 0.0987 - acc: 0.9615\n",
      "Epoch 253/300\n",
      "52/52 [==============================] - 0s 92us/step - loss: 0.0990 - acc: 0.9615\n",
      "Epoch 254/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.0994 - acc: 0.9615\n",
      "Epoch 255/300\n",
      "52/52 [==============================] - 0s 89us/step - loss: 0.0989 - acc: 0.9615\n",
      "Epoch 256/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.0979 - acc: 0.9615\n",
      "Epoch 257/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.0981 - acc: 0.9615\n",
      "Epoch 258/300\n",
      "52/52 [==============================] - 0s 95us/step - loss: 0.0975 - acc: 0.9615\n",
      "Epoch 259/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.0974 - acc: 0.9615\n",
      "Epoch 260/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.0967 - acc: 0.9615\n",
      "Epoch 261/300\n",
      "52/52 [==============================] - 0s 95us/step - loss: 0.0963 - acc: 0.9615\n",
      "Epoch 262/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.0967 - acc: 0.9615\n",
      "Epoch 263/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.0974 - acc: 0.9615\n",
      "Epoch 264/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.0980 - acc: 0.9630\n",
      "Epoch 265/300\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.0991 - acc: 0.9630\n",
      "Epoch 266/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.0981 - acc: 0.9630\n",
      "Epoch 267/300\n",
      "52/52 [==============================] - 0s 146us/step - loss: 0.0968 - acc: 0.9615\n",
      "Epoch 268/300\n",
      "52/52 [==============================] - 0s 149us/step - loss: 0.0988 - acc: 0.9623\n",
      "Epoch 269/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.0954 - acc: 0.9630\n",
      "Epoch 270/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.0942 - acc: 0.9630\n",
      "Epoch 271/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.0946 - acc: 0.9630\n",
      "Epoch 272/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.0934 - acc: 0.9630\n",
      "Epoch 273/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.0933 - acc: 0.9630\n",
      "Epoch 274/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.0933 - acc: 0.9630\n",
      "Epoch 275/300\n",
      "52/52 [==============================] - 0s 92us/step - loss: 0.0926 - acc: 0.9630\n",
      "Epoch 276/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.0927 - acc: 0.9630\n",
      "Epoch 277/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.0921 - acc: 0.9615\n",
      "Epoch 278/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.0917 - acc: 0.9601\n",
      "Epoch 279/300\n",
      "52/52 [==============================] - 0s 93us/step - loss: 0.0928 - acc: 0.9601\n",
      "Epoch 280/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.0913 - acc: 0.9615\n",
      "Epoch 281/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.0912 - acc: 0.9615\n",
      "Epoch 282/300\n",
      "52/52 [==============================] - 0s 88us/step - loss: 0.0908 - acc: 0.9630\n",
      "Epoch 283/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.0916 - acc: 0.9630\n",
      "Epoch 284/300\n",
      "52/52 [==============================] - 0s 91us/step - loss: 0.0909 - acc: 0.9630\n",
      "Epoch 285/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.0911 - acc: 0.9630\n",
      "Epoch 286/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.0901 - acc: 0.9630\n",
      "Epoch 287/300\n",
      "52/52 [==============================] - 0s 91us/step - loss: 0.0898 - acc: 0.9630\n",
      "Epoch 288/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.0902 - acc: 0.9630\n",
      "Epoch 289/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.0892 - acc: 0.9630\n",
      "Epoch 290/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.0884 - acc: 0.9630\n",
      "Epoch 291/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.0887 - acc: 0.9630\n",
      "Epoch 292/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.0887 - acc: 0.9630\n",
      "Epoch 293/300\n",
      "52/52 [==============================] - 0s 94us/step - loss: 0.0880 - acc: 0.9623\n",
      "Epoch 294/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.0874 - acc: 0.9615\n",
      "Epoch 295/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.0871 - acc: 0.9615\n",
      "Epoch 296/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.0868 - acc: 0.9615\n",
      "Epoch 297/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.0876 - acc: 0.9615\n",
      "Epoch 298/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.0862 - acc: 0.9615\n",
      "Epoch 299/300\n",
      "52/52 [==============================] - 0s 97us/step - loss: 0.0877 - acc: 0.9630\n",
      "Epoch 300/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.0870 - acc: 0.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb311aae10>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return (I2L[index])\n",
    "\n",
    "def predict_results(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index = np.argmax(predictions, axis=1)\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index))\n",
    "\n",
    "    return (prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = 'IAMREALLYGOOD'\n",
    "text, x_train, y_train = caeserde(mystr,x_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: IAMREALLYGOOD\n",
      "Cipertext: LDPUHDOOBJRRG\n",
      "Prediction: IANQEALLXFNND\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\",mystr)\n",
    "print(\"Cipertext:\",text)\n",
    "print(\"Prediction:\",\"\".join(predict_results(model, x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde('ABCDEFGHIJKLMNOPQRSTUVWXYZ', x_as_vector=False, y_as_vector=False)\n",
    "\n",
    "predictions = model.predict_classes(x_train)\n",
    "\n",
    "#print(confusion_matrix(y_train, predictions.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb311aad30>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_train, predictions.astype(int))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 26 outputs, the results seems better than 1 output by using the binary cross entropy which are able get the 100% accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\", x_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(26, activation='relu'))\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "# categorical corssentropy for this model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 3.2567 - categorical_accuracy: 0.0577\n",
      "Epoch 2/600\n",
      "52/52 [==============================] - 0s 103us/step - loss: 3.2353 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/600\n",
      "52/52 [==============================] - 0s 103us/step - loss: 3.2244 - categorical_accuracy: 0.0385\n",
      "Epoch 4/600\n",
      "52/52 [==============================] - 0s 107us/step - loss: 3.2160 - categorical_accuracy: 0.0385\n",
      "Epoch 5/600\n",
      "52/52 [==============================] - 0s 106us/step - loss: 3.2112 - categorical_accuracy: 0.0385\n",
      "Epoch 6/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 3.2048 - categorical_accuracy: 0.0577\n",
      "Epoch 7/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 3.1943 - categorical_accuracy: 0.0769\n",
      "Epoch 8/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 3.1899 - categorical_accuracy: 0.0769\n",
      "Epoch 9/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 3.1857 - categorical_accuracy: 0.0769\n",
      "Epoch 10/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 3.1789 - categorical_accuracy: 0.0769\n",
      "Epoch 11/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 3.1734 - categorical_accuracy: 0.0769\n",
      "Epoch 12/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 3.1642 - categorical_accuracy: 0.0769\n",
      "Epoch 13/600\n",
      "52/52 [==============================] - 0s 153us/step - loss: 3.1568 - categorical_accuracy: 0.0962\n",
      "Epoch 14/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 3.1511 - categorical_accuracy: 0.0769\n",
      "Epoch 15/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 3.1434 - categorical_accuracy: 0.1154\n",
      "Epoch 16/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 3.1331 - categorical_accuracy: 0.1154\n",
      "Epoch 17/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 3.1256 - categorical_accuracy: 0.1538\n",
      "Epoch 18/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 3.1156 - categorical_accuracy: 0.1154\n",
      "Epoch 19/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 3.1112 - categorical_accuracy: 0.1154\n",
      "Epoch 20/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 3.1018 - categorical_accuracy: 0.1346\n",
      "Epoch 21/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 3.0906 - categorical_accuracy: 0.1538\n",
      "Epoch 22/600\n",
      "52/52 [==============================] - 0s 147us/step - loss: 3.0810 - categorical_accuracy: 0.1538\n",
      "Epoch 23/600\n",
      "52/52 [==============================] - 0s 220us/step - loss: 3.0728 - categorical_accuracy: 0.1538\n",
      "Epoch 24/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 3.0633 - categorical_accuracy: 0.1538\n",
      "Epoch 25/600\n",
      "52/52 [==============================] - 0s 142us/step - loss: 3.0523 - categorical_accuracy: 0.1923\n",
      "Epoch 26/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 3.0432 - categorical_accuracy: 0.2308\n",
      "Epoch 27/600\n",
      "52/52 [==============================] - 0s 148us/step - loss: 3.0316 - categorical_accuracy: 0.2308\n",
      "Epoch 28/600\n",
      "52/52 [==============================] - 0s 142us/step - loss: 3.0218 - categorical_accuracy: 0.2308\n",
      "Epoch 29/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 3.0120 - categorical_accuracy: 0.2308\n",
      "Epoch 30/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 2.9977 - categorical_accuracy: 0.2308\n",
      "Epoch 31/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 2.9872 - categorical_accuracy: 0.2308\n",
      "Epoch 32/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 2.9786 - categorical_accuracy: 0.1923\n",
      "Epoch 33/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 2.9621 - categorical_accuracy: 0.1923\n",
      "Epoch 34/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 2.9500 - categorical_accuracy: 0.2115\n",
      "Epoch 35/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 2.9377 - categorical_accuracy: 0.2308\n",
      "Epoch 36/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 2.9221 - categorical_accuracy: 0.2692\n",
      "Epoch 37/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 2.9098 - categorical_accuracy: 0.2500\n",
      "Epoch 38/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 2.8957 - categorical_accuracy: 0.2308\n",
      "Epoch 39/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 2.8791 - categorical_accuracy: 0.2692\n",
      "Epoch 40/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 2.8653 - categorical_accuracy: 0.2692\n",
      "Epoch 41/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 2.8491 - categorical_accuracy: 0.2308\n",
      "Epoch 42/600\n",
      "52/52 [==============================] - 0s 143us/step - loss: 2.8332 - categorical_accuracy: 0.2692\n",
      "Epoch 43/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 2.8170 - categorical_accuracy: 0.2692\n",
      "Epoch 44/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 2.7972 - categorical_accuracy: 0.2692\n",
      "Epoch 45/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 2.7807 - categorical_accuracy: 0.2692\n",
      "Epoch 46/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 2.7643 - categorical_accuracy: 0.2692\n",
      "Epoch 47/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 2.7455 - categorical_accuracy: 0.2115\n",
      "Epoch 48/600\n",
      "52/52 [==============================] - 0s 142us/step - loss: 2.7296 - categorical_accuracy: 0.2308\n",
      "Epoch 49/600\n",
      "52/52 [==============================] - 0s 108us/step - loss: 2.7133 - categorical_accuracy: 0.1731\n",
      "Epoch 50/600\n",
      "52/52 [==============================] - 0s 147us/step - loss: 2.6939 - categorical_accuracy: 0.2115\n",
      "Epoch 51/600\n",
      "52/52 [==============================] - 0s 105us/step - loss: 2.6734 - categorical_accuracy: 0.2308\n",
      "Epoch 52/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 2.6568 - categorical_accuracy: 0.2692\n",
      "Epoch 53/600\n",
      "52/52 [==============================] - 0s 153us/step - loss: 2.6387 - categorical_accuracy: 0.2308\n",
      "Epoch 54/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 2.6239 - categorical_accuracy: 0.1923\n",
      "Epoch 55/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 2.6059 - categorical_accuracy: 0.1538\n",
      "Epoch 56/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 2.5863 - categorical_accuracy: 0.1923\n",
      "Epoch 57/600\n",
      "52/52 [==============================] - 0s 140us/step - loss: 2.5679 - categorical_accuracy: 0.2115\n",
      "Epoch 58/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 2.5579 - categorical_accuracy: 0.2308\n",
      "Epoch 59/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 2.5304 - categorical_accuracy: 0.2308\n",
      "Epoch 60/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 2.5131 - categorical_accuracy: 0.1923\n",
      "Epoch 61/600\n",
      "52/52 [==============================] - 0s 139us/step - loss: 2.4953 - categorical_accuracy: 0.1538\n",
      "Epoch 62/600\n",
      "52/52 [==============================] - 0s 143us/step - loss: 2.4762 - categorical_accuracy: 0.1923\n",
      "Epoch 63/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 2.4624 - categorical_accuracy: 0.1538\n",
      "Epoch 64/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 2.4424 - categorical_accuracy: 0.2500\n",
      "Epoch 65/600\n",
      "52/52 [==============================] - 0s 141us/step - loss: 2.4318 - categorical_accuracy: 0.1923\n",
      "Epoch 66/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 2.4089 - categorical_accuracy: 0.2500\n",
      "Epoch 67/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 2.3927 - categorical_accuracy: 0.2500\n",
      "Epoch 68/600\n",
      "52/52 [==============================] - 0s 131us/step - loss: 2.3725 - categorical_accuracy: 0.2500\n",
      "Epoch 69/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 2.3547 - categorical_accuracy: 0.2308\n",
      "Epoch 70/600\n",
      "52/52 [==============================] - 0s 148us/step - loss: 2.3349 - categorical_accuracy: 0.2692\n",
      "Epoch 71/600\n",
      "52/52 [==============================] - 0s 134us/step - loss: 2.3197 - categorical_accuracy: 0.2885\n",
      "Epoch 72/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 137us/step - loss: 2.3001 - categorical_accuracy: 0.2692\n",
      "Epoch 73/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 2.2835 - categorical_accuracy: 0.2885\n",
      "Epoch 74/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 2.2694 - categorical_accuracy: 0.3077\n",
      "Epoch 75/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 2.2528 - categorical_accuracy: 0.3269\n",
      "Epoch 76/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 2.2379 - categorical_accuracy: 0.3654\n",
      "Epoch 77/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 2.2175 - categorical_accuracy: 0.3654\n",
      "Epoch 78/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 2.2062 - categorical_accuracy: 0.3077\n",
      "Epoch 79/600\n",
      "52/52 [==============================] - 0s 144us/step - loss: 2.1862 - categorical_accuracy: 0.3269\n",
      "Epoch 80/600\n",
      "52/52 [==============================] - 0s 140us/step - loss: 2.1740 - categorical_accuracy: 0.3462\n",
      "Epoch 81/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 2.1566 - categorical_accuracy: 0.3846\n",
      "Epoch 82/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 2.1393 - categorical_accuracy: 0.3846\n",
      "Epoch 83/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 2.1281 - categorical_accuracy: 0.3654\n",
      "Epoch 84/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 2.1155 - categorical_accuracy: 0.4038\n",
      "Epoch 85/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 2.0976 - categorical_accuracy: 0.4423\n",
      "Epoch 86/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 2.0853 - categorical_accuracy: 0.4808\n",
      "Epoch 87/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 2.0697 - categorical_accuracy: 0.3846\n",
      "Epoch 88/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 2.0565 - categorical_accuracy: 0.3654\n",
      "Epoch 89/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 2.0447 - categorical_accuracy: 0.4615\n",
      "Epoch 90/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 2.0189 - categorical_accuracy: 0.5192\n",
      "Epoch 91/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 2.0167 - categorical_accuracy: 0.5192\n",
      "Epoch 92/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 2.0058 - categorical_accuracy: 0.4423\n",
      "Epoch 93/600\n",
      "52/52 [==============================] - 0s 108us/step - loss: 1.9808 - categorical_accuracy: 0.5000\n",
      "Epoch 94/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 1.9829 - categorical_accuracy: 0.4231\n",
      "Epoch 95/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.9745 - categorical_accuracy: 0.4615\n",
      "Epoch 96/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.9502 - categorical_accuracy: 0.5192\n",
      "Epoch 97/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 1.9418 - categorical_accuracy: 0.4615\n",
      "Epoch 98/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 1.9189 - categorical_accuracy: 0.4231\n",
      "Epoch 99/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 1.9100 - categorical_accuracy: 0.5385\n",
      "Epoch 100/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 1.8954 - categorical_accuracy: 0.4423\n",
      "Epoch 101/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.8997 - categorical_accuracy: 0.5385\n",
      "Epoch 102/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 1.8804 - categorical_accuracy: 0.3846\n",
      "Epoch 103/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.8661 - categorical_accuracy: 0.3654\n",
      "Epoch 104/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 1.8596 - categorical_accuracy: 0.4231\n",
      "Epoch 105/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.8342 - categorical_accuracy: 0.5192\n",
      "Epoch 106/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.8392 - categorical_accuracy: 0.4615\n",
      "Epoch 107/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 1.8158 - categorical_accuracy: 0.4808\n",
      "Epoch 108/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 1.8056 - categorical_accuracy: 0.4231\n",
      "Epoch 109/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 1.7975 - categorical_accuracy: 0.4615\n",
      "Epoch 110/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 1.7791 - categorical_accuracy: 0.5000\n",
      "Epoch 111/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 1.7731 - categorical_accuracy: 0.5000\n",
      "Epoch 112/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 1.7688 - categorical_accuracy: 0.5000\n",
      "Epoch 113/600\n",
      "52/52 [==============================] - 0s 137us/step - loss: 1.7437 - categorical_accuracy: 0.5000\n",
      "Epoch 114/600\n",
      "52/52 [==============================] - 0s 134us/step - loss: 1.7407 - categorical_accuracy: 0.5385\n",
      "Epoch 115/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 1.7419 - categorical_accuracy: 0.4615\n",
      "Epoch 116/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.7283 - categorical_accuracy: 0.4615\n",
      "Epoch 117/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 1.7044 - categorical_accuracy: 0.5000\n",
      "Epoch 118/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 1.7128 - categorical_accuracy: 0.5000\n",
      "Epoch 119/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 1.6811 - categorical_accuracy: 0.5192\n",
      "Epoch 120/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 1.6675 - categorical_accuracy: 0.5385\n",
      "Epoch 121/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.6680 - categorical_accuracy: 0.5962\n",
      "Epoch 122/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 1.6588 - categorical_accuracy: 0.5962\n",
      "Epoch 123/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.6428 - categorical_accuracy: 0.5962\n",
      "Epoch 124/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 1.6353 - categorical_accuracy: 0.5385\n",
      "Epoch 125/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 1.6253 - categorical_accuracy: 0.5577\n",
      "Epoch 126/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.6125 - categorical_accuracy: 0.6538\n",
      "Epoch 127/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 1.6061 - categorical_accuracy: 0.5577\n",
      "Epoch 128/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 1.5989 - categorical_accuracy: 0.6154\n",
      "Epoch 129/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.5886 - categorical_accuracy: 0.7115\n",
      "Epoch 130/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 1.5871 - categorical_accuracy: 0.6154\n",
      "Epoch 131/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 1.5714 - categorical_accuracy: 0.6731\n",
      "Epoch 132/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 1.5650 - categorical_accuracy: 0.5769\n",
      "Epoch 133/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.5547 - categorical_accuracy: 0.5385\n",
      "Epoch 134/600\n",
      "52/52 [==============================] - 0s 106us/step - loss: 1.5483 - categorical_accuracy: 0.5962\n",
      "Epoch 135/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.5355 - categorical_accuracy: 0.5577\n",
      "Epoch 136/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 1.5304 - categorical_accuracy: 0.5000\n",
      "Epoch 137/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 1.5201 - categorical_accuracy: 0.5192\n",
      "Epoch 138/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 1.5145 - categorical_accuracy: 0.5962\n",
      "Epoch 139/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 1.5065 - categorical_accuracy: 0.5000\n",
      "Epoch 140/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 1.4984 - categorical_accuracy: 0.5962\n",
      "Epoch 141/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.4883 - categorical_accuracy: 0.6538\n",
      "Epoch 142/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.4841 - categorical_accuracy: 0.6538\n",
      "Epoch 143/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 119us/step - loss: 1.4750 - categorical_accuracy: 0.6923\n",
      "Epoch 144/600\n",
      "52/52 [==============================] - 0s 105us/step - loss: 1.4642 - categorical_accuracy: 0.7692\n",
      "Epoch 145/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 1.4614 - categorical_accuracy: 0.7115\n",
      "Epoch 146/600\n",
      "52/52 [==============================] - 0s 107us/step - loss: 1.4521 - categorical_accuracy: 0.6538\n",
      "Epoch 147/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.4452 - categorical_accuracy: 0.6731\n",
      "Epoch 148/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 1.4474 - categorical_accuracy: 0.6154\n",
      "Epoch 149/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 1.4332 - categorical_accuracy: 0.6346\n",
      "Epoch 150/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 1.4273 - categorical_accuracy: 0.6346\n",
      "Epoch 151/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.4189 - categorical_accuracy: 0.6731\n",
      "Epoch 152/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.4081 - categorical_accuracy: 0.6923\n",
      "Epoch 153/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 1.4014 - categorical_accuracy: 0.7308\n",
      "Epoch 154/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.3929 - categorical_accuracy: 0.7500\n",
      "Epoch 155/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 1.3852 - categorical_accuracy: 0.8077\n",
      "Epoch 156/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.3801 - categorical_accuracy: 0.8269\n",
      "Epoch 157/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.3835 - categorical_accuracy: 0.6538\n",
      "Epoch 158/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 1.3803 - categorical_accuracy: 0.7500\n",
      "Epoch 159/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 1.3905 - categorical_accuracy: 0.5962\n",
      "Epoch 160/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 1.3848 - categorical_accuracy: 0.5769\n",
      "Epoch 161/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 1.3991 - categorical_accuracy: 0.6154\n",
      "Epoch 162/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 1.3888 - categorical_accuracy: 0.5577\n",
      "Epoch 163/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.3618 - categorical_accuracy: 0.6538\n",
      "Epoch 164/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 1.3715 - categorical_accuracy: 0.5577\n",
      "Epoch 165/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.3524 - categorical_accuracy: 0.5192\n",
      "Epoch 166/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 1.3646 - categorical_accuracy: 0.6346\n",
      "Epoch 167/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 1.3459 - categorical_accuracy: 0.6154\n",
      "Epoch 168/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 1.3205 - categorical_accuracy: 0.7308\n",
      "Epoch 169/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.3175 - categorical_accuracy: 0.6923\n",
      "Epoch 170/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 1.3161 - categorical_accuracy: 0.6538\n",
      "Epoch 171/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 1.3324 - categorical_accuracy: 0.6923\n",
      "Epoch 172/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 1.3328 - categorical_accuracy: 0.6346\n",
      "Epoch 173/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 1.3204 - categorical_accuracy: 0.6154\n",
      "Epoch 174/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 1.3075 - categorical_accuracy: 0.6346\n",
      "Epoch 175/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.3222 - categorical_accuracy: 0.5385\n",
      "Epoch 176/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 1.2923 - categorical_accuracy: 0.6923\n",
      "Epoch 177/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.2794 - categorical_accuracy: 0.7500\n",
      "Epoch 178/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 1.2744 - categorical_accuracy: 0.6731\n",
      "Epoch 179/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 1.2648 - categorical_accuracy: 0.7115\n",
      "Epoch 180/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 1.2552 - categorical_accuracy: 0.6731\n",
      "Epoch 181/600\n",
      "52/52 [==============================] - 0s 107us/step - loss: 1.2536 - categorical_accuracy: 0.6731\n",
      "Epoch 182/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 1.2441 - categorical_accuracy: 0.7308\n",
      "Epoch 183/600\n",
      "52/52 [==============================] - 0s 108us/step - loss: 1.2432 - categorical_accuracy: 0.6923\n",
      "Epoch 184/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 1.2486 - categorical_accuracy: 0.6923\n",
      "Epoch 185/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 1.2332 - categorical_accuracy: 0.6923\n",
      "Epoch 186/600\n",
      "52/52 [==============================] - 0s 108us/step - loss: 1.2227 - categorical_accuracy: 0.6731\n",
      "Epoch 187/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 1.2222 - categorical_accuracy: 0.6923\n",
      "Epoch 188/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 1.2319 - categorical_accuracy: 0.6923\n",
      "Epoch 189/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 1.2056 - categorical_accuracy: 0.7308\n",
      "Epoch 190/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 1.1999 - categorical_accuracy: 0.6923\n",
      "Epoch 191/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 1.1991 - categorical_accuracy: 0.6538\n",
      "Epoch 192/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.1937 - categorical_accuracy: 0.7692\n",
      "Epoch 193/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 1.1932 - categorical_accuracy: 0.7308\n",
      "Epoch 194/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 1.1794 - categorical_accuracy: 0.6923\n",
      "Epoch 195/600\n",
      "52/52 [==============================] - 0s 104us/step - loss: 1.1771 - categorical_accuracy: 0.7308\n",
      "Epoch 196/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.1800 - categorical_accuracy: 0.7692\n",
      "Epoch 197/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 1.1720 - categorical_accuracy: 0.7885\n",
      "Epoch 198/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.1703 - categorical_accuracy: 0.6923\n",
      "Epoch 199/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.1662 - categorical_accuracy: 0.7115\n",
      "Epoch 200/600\n",
      "52/52 [==============================] - 0s 105us/step - loss: 1.1580 - categorical_accuracy: 0.7692\n",
      "Epoch 201/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 1.1639 - categorical_accuracy: 0.8077\n",
      "Epoch 202/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 1.1527 - categorical_accuracy: 0.7115\n",
      "Epoch 203/600\n",
      "52/52 [==============================] - 0s 105us/step - loss: 1.1574 - categorical_accuracy: 0.7500\n",
      "Epoch 204/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 1.1469 - categorical_accuracy: 0.6538\n",
      "Epoch 205/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 1.1374 - categorical_accuracy: 0.7692\n",
      "Epoch 206/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 1.1335 - categorical_accuracy: 0.7500\n",
      "Epoch 207/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.1356 - categorical_accuracy: 0.7692\n",
      "Epoch 208/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 1.1354 - categorical_accuracy: 0.7115\n",
      "Epoch 209/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.1283 - categorical_accuracy: 0.7308\n",
      "Epoch 210/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 1.1165 - categorical_accuracy: 0.7885\n",
      "Epoch 211/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 1.1108 - categorical_accuracy: 0.7692\n",
      "Epoch 212/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.1134 - categorical_accuracy: 0.8462\n",
      "Epoch 213/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 1.1015 - categorical_accuracy: 0.7692\n",
      "Epoch 214/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 113us/step - loss: 1.0972 - categorical_accuracy: 0.6923\n",
      "Epoch 215/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 1.1043 - categorical_accuracy: 0.7115\n",
      "Epoch 216/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.0922 - categorical_accuracy: 0.6731\n",
      "Epoch 217/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 1.0978 - categorical_accuracy: 0.7308\n",
      "Epoch 218/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.0924 - categorical_accuracy: 0.7885\n",
      "Epoch 219/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 1.0876 - categorical_accuracy: 0.8077\n",
      "Epoch 220/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 1.0793 - categorical_accuracy: 0.7308\n",
      "Epoch 221/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.0832 - categorical_accuracy: 0.8077\n",
      "Epoch 222/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.0693 - categorical_accuracy: 0.7500\n",
      "Epoch 223/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 1.0717 - categorical_accuracy: 0.7885\n",
      "Epoch 224/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 1.0723 - categorical_accuracy: 0.7500\n",
      "Epoch 225/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.0539 - categorical_accuracy: 0.7692\n",
      "Epoch 226/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.0557 - categorical_accuracy: 0.7885\n",
      "Epoch 227/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 1.0493 - categorical_accuracy: 0.7692\n",
      "Epoch 228/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 1.0421 - categorical_accuracy: 0.8077\n",
      "Epoch 229/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 1.0324 - categorical_accuracy: 0.8269\n",
      "Epoch 230/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.0373 - categorical_accuracy: 0.8654\n",
      "Epoch 231/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 1.0306 - categorical_accuracy: 0.8654\n",
      "Epoch 232/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 1.0340 - categorical_accuracy: 0.8077\n",
      "Epoch 233/600\n",
      "52/52 [==============================] - 0s 106us/step - loss: 1.0294 - categorical_accuracy: 0.8077\n",
      "Epoch 234/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 1.0239 - categorical_accuracy: 0.8077\n",
      "Epoch 235/600\n",
      "52/52 [==============================] - 0s 108us/step - loss: 1.0219 - categorical_accuracy: 0.8462\n",
      "Epoch 236/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 1.0241 - categorical_accuracy: 0.7692\n",
      "Epoch 237/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 1.0298 - categorical_accuracy: 0.7692\n",
      "Epoch 238/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 1.0232 - categorical_accuracy: 0.6538\n",
      "Epoch 239/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.0012 - categorical_accuracy: 0.7308\n",
      "Epoch 240/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.9971 - categorical_accuracy: 0.8077\n",
      "Epoch 241/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.9937 - categorical_accuracy: 0.7885\n",
      "Epoch 242/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 1.0013 - categorical_accuracy: 0.7692\n",
      "Epoch 243/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 1.0065 - categorical_accuracy: 0.7308\n",
      "Epoch 244/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.9938 - categorical_accuracy: 0.7500\n",
      "Epoch 245/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.9858 - categorical_accuracy: 0.6731\n",
      "Epoch 246/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.9786 - categorical_accuracy: 0.7692\n",
      "Epoch 247/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.9788 - categorical_accuracy: 0.7500\n",
      "Epoch 248/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.9760 - categorical_accuracy: 0.7885\n",
      "Epoch 249/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.9797 - categorical_accuracy: 0.7885\n",
      "Epoch 250/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.9764 - categorical_accuracy: 0.7500\n",
      "Epoch 251/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.9762 - categorical_accuracy: 0.7692\n",
      "Epoch 252/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.9648 - categorical_accuracy: 0.7692\n",
      "Epoch 253/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.9576 - categorical_accuracy: 0.7500\n",
      "Epoch 254/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.9699 - categorical_accuracy: 0.7308\n",
      "Epoch 255/600\n",
      "52/52 [==============================] - 0s 131us/step - loss: 1.0095 - categorical_accuracy: 0.6538\n",
      "Epoch 256/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 1.0401 - categorical_accuracy: 0.5962\n",
      "Epoch 257/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.9880 - categorical_accuracy: 0.7115\n",
      "Epoch 258/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.9587 - categorical_accuracy: 0.8269\n",
      "Epoch 259/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.9543 - categorical_accuracy: 0.7692\n",
      "Epoch 260/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.9471 - categorical_accuracy: 0.7885\n",
      "Epoch 261/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.9467 - categorical_accuracy: 0.7692\n",
      "Epoch 262/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.9539 - categorical_accuracy: 0.7500\n",
      "Epoch 263/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.9530 - categorical_accuracy: 0.7500\n",
      "Epoch 264/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.9427 - categorical_accuracy: 0.8269\n",
      "Epoch 265/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.9313 - categorical_accuracy: 0.7885\n",
      "Epoch 266/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.9303 - categorical_accuracy: 0.8077\n",
      "Epoch 267/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.9267 - categorical_accuracy: 0.8269\n",
      "Epoch 268/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.9153 - categorical_accuracy: 0.8462\n",
      "Epoch 269/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.9155 - categorical_accuracy: 0.8269\n",
      "Epoch 270/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.9073 - categorical_accuracy: 0.8654\n",
      "Epoch 271/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.8993 - categorical_accuracy: 0.9038\n",
      "Epoch 272/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.9039 - categorical_accuracy: 0.9231\n",
      "Epoch 273/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.9009 - categorical_accuracy: 0.8462\n",
      "Epoch 274/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.9006 - categorical_accuracy: 0.8077\n",
      "Epoch 275/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.8967 - categorical_accuracy: 0.8462\n",
      "Epoch 276/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.8872 - categorical_accuracy: 0.9038\n",
      "Epoch 277/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.8851 - categorical_accuracy: 0.8846\n",
      "Epoch 278/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.8901 - categorical_accuracy: 0.8269\n",
      "Epoch 279/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.8862 - categorical_accuracy: 0.7692\n",
      "Epoch 280/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.8853 - categorical_accuracy: 0.7692\n",
      "Epoch 281/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.8853 - categorical_accuracy: 0.8462\n",
      "Epoch 282/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.8780 - categorical_accuracy: 0.8462\n",
      "Epoch 283/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.8809 - categorical_accuracy: 0.8654\n",
      "Epoch 284/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.8782 - categorical_accuracy: 0.8269\n",
      "Epoch 285/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 168us/step - loss: 0.8827 - categorical_accuracy: 0.8462\n",
      "Epoch 286/600\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.8722 - categorical_accuracy: 0.8462\n",
      "Epoch 287/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.8751 - categorical_accuracy: 0.7885\n",
      "Epoch 288/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.8680 - categorical_accuracy: 0.8654\n",
      "Epoch 289/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.8674 - categorical_accuracy: 0.8846\n",
      "Epoch 290/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.8625 - categorical_accuracy: 0.8846\n",
      "Epoch 291/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 0.8668 - categorical_accuracy: 0.7692\n",
      "Epoch 292/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.8515 - categorical_accuracy: 0.8846\n",
      "Epoch 293/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.8420 - categorical_accuracy: 0.8846\n",
      "Epoch 294/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.8406 - categorical_accuracy: 0.9038\n",
      "Epoch 295/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.8344 - categorical_accuracy: 0.9615\n",
      "Epoch 296/600\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.8349 - categorical_accuracy: 0.8654\n",
      "Epoch 297/600\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.8381 - categorical_accuracy: 0.7885\n",
      "Epoch 298/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.8318 - categorical_accuracy: 0.8077\n",
      "Epoch 299/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.8253 - categorical_accuracy: 0.8846\n",
      "Epoch 300/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.8282 - categorical_accuracy: 0.9231\n",
      "Epoch 301/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.8160 - categorical_accuracy: 0.9615\n",
      "Epoch 302/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.8206 - categorical_accuracy: 0.9231\n",
      "Epoch 303/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.8159 - categorical_accuracy: 0.8846\n",
      "Epoch 304/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.8142 - categorical_accuracy: 0.9038\n",
      "Epoch 305/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.8144 - categorical_accuracy: 0.8846\n",
      "Epoch 306/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.8159 - categorical_accuracy: 0.8462\n",
      "Epoch 307/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.8125 - categorical_accuracy: 0.8654\n",
      "Epoch 308/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.8104 - categorical_accuracy: 0.8846\n",
      "Epoch 309/600\n",
      "52/52 [==============================] - 0s 148us/step - loss: 0.8060 - categorical_accuracy: 0.9038\n",
      "Epoch 310/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.8133 - categorical_accuracy: 0.8269\n",
      "Epoch 311/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.7992 - categorical_accuracy: 0.8846\n",
      "Epoch 312/600\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.8221 - categorical_accuracy: 0.8077\n",
      "Epoch 313/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.8877 - categorical_accuracy: 0.6538\n",
      "Epoch 314/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.9083 - categorical_accuracy: 0.5385\n",
      "Epoch 315/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 1.0024 - categorical_accuracy: 0.4231\n",
      "Epoch 316/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 1.3318 - categorical_accuracy: 0.4231\n",
      "Epoch 317/600\n",
      "52/52 [==============================] - 0s 142us/step - loss: 1.0591 - categorical_accuracy: 0.6538\n",
      "Epoch 318/600\n",
      "52/52 [==============================] - 0s 144us/step - loss: 1.0079 - categorical_accuracy: 0.4615\n",
      "Epoch 319/600\n",
      "52/52 [==============================] - 0s 140us/step - loss: 1.2258 - categorical_accuracy: 0.4423\n",
      "Epoch 320/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.9493 - categorical_accuracy: 0.6346\n",
      "Epoch 321/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.8531 - categorical_accuracy: 0.6923\n",
      "Epoch 322/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.9375 - categorical_accuracy: 0.5769\n",
      "Epoch 323/600\n",
      "52/52 [==============================] - 0s 146us/step - loss: 0.9392 - categorical_accuracy: 0.5192\n",
      "Epoch 324/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.8632 - categorical_accuracy: 0.6923\n",
      "Epoch 325/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.8606 - categorical_accuracy: 0.6923\n",
      "Epoch 326/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.8763 - categorical_accuracy: 0.6731\n",
      "Epoch 327/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.8069 - categorical_accuracy: 0.8846\n",
      "Epoch 328/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.7965 - categorical_accuracy: 0.8654\n",
      "Epoch 329/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.8119 - categorical_accuracy: 0.8462\n",
      "Epoch 330/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.7935 - categorical_accuracy: 0.8077\n",
      "Epoch 331/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.7811 - categorical_accuracy: 0.9231\n",
      "Epoch 332/600\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.7913 - categorical_accuracy: 0.8269\n",
      "Epoch 333/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.7809 - categorical_accuracy: 0.8462\n",
      "Epoch 334/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.7800 - categorical_accuracy: 0.8077\n",
      "Epoch 335/600\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.7769 - categorical_accuracy: 0.8269\n",
      "Epoch 336/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.7722 - categorical_accuracy: 0.8654\n",
      "Epoch 337/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.7598 - categorical_accuracy: 0.8654\n",
      "Epoch 338/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.7535 - categorical_accuracy: 0.8846\n",
      "Epoch 339/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.7530 - categorical_accuracy: 0.9231\n",
      "Epoch 340/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.7533 - categorical_accuracy: 0.9615\n",
      "Epoch 341/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.7496 - categorical_accuracy: 0.8846\n",
      "Epoch 342/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.7434 - categorical_accuracy: 0.9231\n",
      "Epoch 343/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.7466 - categorical_accuracy: 0.9231\n",
      "Epoch 344/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.7458 - categorical_accuracy: 0.9231\n",
      "Epoch 345/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.7380 - categorical_accuracy: 0.9615\n",
      "Epoch 346/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.7385 - categorical_accuracy: 0.9231\n",
      "Epoch 347/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.7338 - categorical_accuracy: 0.8846\n",
      "Epoch 348/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.7355 - categorical_accuracy: 0.9423\n",
      "Epoch 349/600\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.7307 - categorical_accuracy: 0.9615\n",
      "Epoch 350/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.7260 - categorical_accuracy: 0.9423\n",
      "Epoch 351/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.7260 - categorical_accuracy: 0.9615\n",
      "Epoch 352/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.7217 - categorical_accuracy: 0.9231\n",
      "Epoch 353/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.7222 - categorical_accuracy: 0.9615\n",
      "Epoch 354/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.7173 - categorical_accuracy: 0.9423\n",
      "Epoch 355/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.7162 - categorical_accuracy: 0.9231\n",
      "Epoch 356/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 125us/step - loss: 0.7147 - categorical_accuracy: 0.9231\n",
      "Epoch 357/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.7149 - categorical_accuracy: 0.8846\n",
      "Epoch 358/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.7130 - categorical_accuracy: 0.9038\n",
      "Epoch 359/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.7093 - categorical_accuracy: 0.9231\n",
      "Epoch 360/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.7090 - categorical_accuracy: 0.9231\n",
      "Epoch 361/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.7110 - categorical_accuracy: 0.9231\n",
      "Epoch 362/600\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.7068 - categorical_accuracy: 0.9423\n",
      "Epoch 363/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.7020 - categorical_accuracy: 0.9231\n",
      "Epoch 364/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.6997 - categorical_accuracy: 0.9038\n",
      "Epoch 365/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.6990 - categorical_accuracy: 0.9231\n",
      "Epoch 366/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.7050 - categorical_accuracy: 0.9231\n",
      "Epoch 367/600\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.7119 - categorical_accuracy: 0.90 - 0s 119us/step - loss: 0.7034 - categorical_accuracy: 0.8846\n",
      "Epoch 368/600\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.6948 - categorical_accuracy: 0.9423\n",
      "Epoch 369/600\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.6943 - categorical_accuracy: 0.9231\n",
      "Epoch 370/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.6937 - categorical_accuracy: 0.9615\n",
      "Epoch 371/600\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.6936 - categorical_accuracy: 0.9615\n",
      "Epoch 372/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.6872 - categorical_accuracy: 0.9231\n",
      "Epoch 373/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.6888 - categorical_accuracy: 0.9808\n",
      "Epoch 374/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.6804 - categorical_accuracy: 0.9231\n",
      "Epoch 375/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.6878 - categorical_accuracy: 0.8846\n",
      "Epoch 376/600\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.6817 - categorical_accuracy: 0.8846\n",
      "Epoch 377/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.6871 - categorical_accuracy: 0.9615\n",
      "Epoch 378/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.6933 - categorical_accuracy: 0.8846\n",
      "Epoch 379/600\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.6932 - categorical_accuracy: 0.9231\n",
      "Epoch 380/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.6803 - categorical_accuracy: 0.9231\n",
      "Epoch 381/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.6806 - categorical_accuracy: 0.9231\n",
      "Epoch 382/600\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.6777 - categorical_accuracy: 0.9038\n",
      "Epoch 383/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.6816 - categorical_accuracy: 0.8846\n",
      "Epoch 384/600\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.6837 - categorical_accuracy: 0.8846\n",
      "Epoch 385/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6738 - categorical_accuracy: 0.8846\n",
      "Epoch 386/600\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.6735 - categorical_accuracy: 0.9423\n",
      "Epoch 387/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.6685 - categorical_accuracy: 0.9231\n",
      "Epoch 388/600\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.6691 - categorical_accuracy: 0.93 - 0s 135us/step - loss: 0.6610 - categorical_accuracy: 0.9615\n",
      "Epoch 389/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.6627 - categorical_accuracy: 0.8846\n",
      "Epoch 390/600\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.6654 - categorical_accuracy: 0.8846\n",
      "Epoch 391/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.6618 - categorical_accuracy: 0.8846\n",
      "Epoch 392/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.6558 - categorical_accuracy: 0.8846\n",
      "Epoch 393/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.6512 - categorical_accuracy: 0.9231\n",
      "Epoch 394/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.6537 - categorical_accuracy: 0.9808\n",
      "Epoch 395/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.6452 - categorical_accuracy: 0.9231\n",
      "Epoch 396/600\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.6454 - categorical_accuracy: 0.9615\n",
      "Epoch 397/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.6498 - categorical_accuracy: 0.9231\n",
      "Epoch 398/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.6530 - categorical_accuracy: 0.8462\n",
      "Epoch 399/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.6459 - categorical_accuracy: 0.8077\n",
      "Epoch 400/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.6412 - categorical_accuracy: 0.8846\n",
      "Epoch 401/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.6427 - categorical_accuracy: 0.9231\n",
      "Epoch 402/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.6441 - categorical_accuracy: 0.9615\n",
      "Epoch 403/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6506 - categorical_accuracy: 0.9231\n",
      "Epoch 404/600\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.7308 - categorical_accuracy: 0.93 - 0s 114us/step - loss: 0.6446 - categorical_accuracy: 0.9615\n",
      "Epoch 405/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.6411 - categorical_accuracy: 0.9231\n",
      "Epoch 406/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.6519 - categorical_accuracy: 0.9231\n",
      "Epoch 407/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.6467 - categorical_accuracy: 0.8654\n",
      "Epoch 408/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6468 - categorical_accuracy: 0.9615\n",
      "Epoch 409/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6411 - categorical_accuracy: 0.9423\n",
      "Epoch 410/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6431 - categorical_accuracy: 0.9038\n",
      "Epoch 411/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.6413 - categorical_accuracy: 0.9231\n",
      "Epoch 412/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.6310 - categorical_accuracy: 0.8846\n",
      "Epoch 413/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.6259 - categorical_accuracy: 0.8846\n",
      "Epoch 414/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.6204 - categorical_accuracy: 0.9615\n",
      "Epoch 415/600\n",
      "52/52 [==============================] - 0s 150us/step - loss: 0.6200 - categorical_accuracy: 0.9231\n",
      "Epoch 416/600\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.6288 - categorical_accuracy: 0.9038\n",
      "Epoch 417/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6178 - categorical_accuracy: 0.8846\n",
      "Epoch 418/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6141 - categorical_accuracy: 0.9231\n",
      "Epoch 419/600\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.6157 - categorical_accuracy: 0.9615\n",
      "Epoch 420/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.6141 - categorical_accuracy: 0.9615\n",
      "Epoch 421/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6169 - categorical_accuracy: 0.9615\n",
      "Epoch 422/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.6146 - categorical_accuracy: 0.9615\n",
      "Epoch 423/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.6202 - categorical_accuracy: 0.9231\n",
      "Epoch 424/600\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.6139 - categorical_accuracy: 0.9615\n",
      "Epoch 425/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.6048 - categorical_accuracy: 0.9423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.6074 - categorical_accuracy: 0.9231\n",
      "Epoch 427/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.6072 - categorical_accuracy: 0.9038\n",
      "Epoch 428/600\n",
      "52/52 [==============================] - 0s 146us/step - loss: 0.6167 - categorical_accuracy: 0.9231\n",
      "Epoch 429/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.6073 - categorical_accuracy: 0.9231\n",
      "Epoch 430/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.6043 - categorical_accuracy: 1.0000\n",
      "Epoch 431/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.6161 - categorical_accuracy: 0.9231\n",
      "Epoch 432/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.5993 - categorical_accuracy: 0.9615\n",
      "Epoch 433/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.5940 - categorical_accuracy: 0.9231\n",
      "Epoch 434/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.5980 - categorical_accuracy: 0.9231\n",
      "Epoch 435/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.6079 - categorical_accuracy: 0.8846\n",
      "Epoch 436/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.6033 - categorical_accuracy: 0.8846\n",
      "Epoch 437/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.5909 - categorical_accuracy: 0.9615\n",
      "Epoch 438/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.5904 - categorical_accuracy: 1.0000\n",
      "Epoch 439/600\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.6021 - categorical_accuracy: 0.9423\n",
      "Epoch 440/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.6044 - categorical_accuracy: 0.9423\n",
      "Epoch 441/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.5833 - categorical_accuracy: 0.9615\n",
      "Epoch 442/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.6088 - categorical_accuracy: 0.9423\n",
      "Epoch 443/600\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.5971 - categorical_accuracy: 0.9038\n",
      "Epoch 444/600\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.5922 - categorical_accuracy: 0.8846\n",
      "Epoch 445/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.6140 - categorical_accuracy: 0.8654\n",
      "Epoch 446/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.6687 - categorical_accuracy: 0.8077\n",
      "Epoch 447/600\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.6533 - categorical_accuracy: 0.7885\n",
      "Epoch 448/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.6289 - categorical_accuracy: 0.8462\n",
      "Epoch 449/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.6315 - categorical_accuracy: 0.8462\n",
      "Epoch 450/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 0.5994 - categorical_accuracy: 0.9615\n",
      "Epoch 451/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.5846 - categorical_accuracy: 0.9231\n",
      "Epoch 452/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.5771 - categorical_accuracy: 0.9231\n",
      "Epoch 453/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.5853 - categorical_accuracy: 0.8846\n",
      "Epoch 454/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.5933 - categorical_accuracy: 0.9231\n",
      "Epoch 455/600\n",
      "52/52 [==============================] - 0s 148us/step - loss: 0.5925 - categorical_accuracy: 0.9231\n",
      "Epoch 456/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.5759 - categorical_accuracy: 0.9423\n",
      "Epoch 457/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.5719 - categorical_accuracy: 0.9038\n",
      "Epoch 458/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.5678 - categorical_accuracy: 0.9808\n",
      "Epoch 459/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.5617 - categorical_accuracy: 0.9423\n",
      "Epoch 460/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.5599 - categorical_accuracy: 0.9615\n",
      "Epoch 461/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.5577 - categorical_accuracy: 0.9615\n",
      "Epoch 462/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.5590 - categorical_accuracy: 1.0000\n",
      "Epoch 463/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.5542 - categorical_accuracy: 0.9423\n",
      "Epoch 464/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.5520 - categorical_accuracy: 1.0000\n",
      "Epoch 465/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.5555 - categorical_accuracy: 0.9423\n",
      "Epoch 466/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.5537 - categorical_accuracy: 1.0000\n",
      "Epoch 467/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.5479 - categorical_accuracy: 1.0000\n",
      "Epoch 468/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.5541 - categorical_accuracy: 0.9808\n",
      "Epoch 469/600\n",
      "52/52 [==============================] - 0s 149us/step - loss: 0.5587 - categorical_accuracy: 0.9423\n",
      "Epoch 470/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.5627 - categorical_accuracy: 0.9808\n",
      "Epoch 471/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.5547 - categorical_accuracy: 0.9231\n",
      "Epoch 472/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.5426 - categorical_accuracy: 0.9808\n",
      "Epoch 473/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.5429 - categorical_accuracy: 0.9615\n",
      "Epoch 474/600\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.5439 - categorical_accuracy: 0.9423\n",
      "Epoch 475/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.5445 - categorical_accuracy: 0.9615\n",
      "Epoch 476/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.5451 - categorical_accuracy: 0.9615\n",
      "Epoch 477/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.5388 - categorical_accuracy: 1.0000\n",
      "Epoch 478/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.5333 - categorical_accuracy: 1.0000\n",
      "Epoch 479/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.5372 - categorical_accuracy: 1.0000\n",
      "Epoch 480/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.5343 - categorical_accuracy: 0.9808\n",
      "Epoch 481/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.5432 - categorical_accuracy: 0.9615\n",
      "Epoch 482/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.5422 - categorical_accuracy: 0.9615\n",
      "Epoch 483/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.5593 - categorical_accuracy: 0.9423\n",
      "Epoch 484/600\n",
      "52/52 [==============================] - 0s 150us/step - loss: 0.5259 - categorical_accuracy: 0.9231\n",
      "Epoch 485/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.5266 - categorical_accuracy: 0.9808\n",
      "Epoch 486/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.5317 - categorical_accuracy: 0.9808\n",
      "Epoch 487/600\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.5223 - categorical_accuracy: 0.9808\n",
      "Epoch 488/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.5286 - categorical_accuracy: 0.9231\n",
      "Epoch 489/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.5353 - categorical_accuracy: 1.0000\n",
      "Epoch 490/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.5459 - categorical_accuracy: 0.9423\n",
      "Epoch 491/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.5499 - categorical_accuracy: 0.9231\n",
      "Epoch 492/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.5417 - categorical_accuracy: 0.9231\n",
      "Epoch 493/600\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.5481 - categorical_accuracy: 0.9423\n",
      "Epoch 494/600\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.5700 - categorical_accuracy: 0.9038\n",
      "Epoch 495/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.5555 - categorical_accuracy: 0.9038\n",
      "Epoch 496/600\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.5389 - categorical_accuracy: 0.9038\n",
      "Epoch 497/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 133us/step - loss: 0.5294 - categorical_accuracy: 0.9231\n",
      "Epoch 498/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.5162 - categorical_accuracy: 0.9231\n",
      "Epoch 499/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.5140 - categorical_accuracy: 0.9038\n",
      "Epoch 500/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.5221 - categorical_accuracy: 0.9423\n",
      "Epoch 501/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.5142 - categorical_accuracy: 0.9423\n",
      "Epoch 502/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.5035 - categorical_accuracy: 1.0000\n",
      "Epoch 503/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.5203 - categorical_accuracy: 0.9231\n",
      "Epoch 504/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.5183 - categorical_accuracy: 0.9423\n",
      "Epoch 505/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.5113 - categorical_accuracy: 0.9231\n",
      "Epoch 506/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.5122 - categorical_accuracy: 0.9808\n",
      "Epoch 507/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.4972 - categorical_accuracy: 1.0000\n",
      "Epoch 508/600\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.4981 - categorical_accuracy: 1.0000\n",
      "Epoch 509/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.5004 - categorical_accuracy: 1.0000\n",
      "Epoch 510/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.5004 - categorical_accuracy: 0.9615\n",
      "Epoch 511/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.5068 - categorical_accuracy: 1.0000\n",
      "Epoch 512/600\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.4932 - categorical_accuracy: 1.0000\n",
      "Epoch 513/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.4870 - categorical_accuracy: 1.0000\n",
      "Epoch 514/600\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.4985 - categorical_accuracy: 0.9808\n",
      "Epoch 515/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.4917 - categorical_accuracy: 0.9423\n",
      "Epoch 516/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.4854 - categorical_accuracy: 0.9808\n",
      "Epoch 517/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.4953 - categorical_accuracy: 0.9615\n",
      "Epoch 518/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.4829 - categorical_accuracy: 0.9615\n",
      "Epoch 519/600\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.4905 - categorical_accuracy: 0.9615\n",
      "Epoch 520/600\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.4945 - categorical_accuracy: 1.0000\n",
      "Epoch 521/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.4981 - categorical_accuracy: 0.9615\n",
      "Epoch 522/600\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.4851 - categorical_accuracy: 0.9808\n",
      "Epoch 523/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.4879 - categorical_accuracy: 0.9615\n",
      "Epoch 524/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.4858 - categorical_accuracy: 0.9231\n",
      "Epoch 525/600\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.4970 - categorical_accuracy: 0.9423\n",
      "Epoch 526/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.4889 - categorical_accuracy: 0.9231\n",
      "Epoch 527/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.4821 - categorical_accuracy: 0.9231\n",
      "Epoch 528/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.4912 - categorical_accuracy: 0.9615\n",
      "Epoch 529/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.4854 - categorical_accuracy: 0.9808\n",
      "Epoch 530/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.4800 - categorical_accuracy: 0.9615\n",
      "Epoch 531/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 0.4743 - categorical_accuracy: 0.9615\n",
      "Epoch 532/600\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.4851 - categorical_accuracy: 0.9231\n",
      "Epoch 533/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.4701 - categorical_accuracy: 1.0000\n",
      "Epoch 534/600\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.4713 - categorical_accuracy: 1.0000\n",
      "Epoch 535/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.4708 - categorical_accuracy: 0.9231\n",
      "Epoch 536/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.4679 - categorical_accuracy: 0.9808\n",
      "Epoch 537/600\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.4709 - categorical_accuracy: 0.9615\n",
      "Epoch 538/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.4669 - categorical_accuracy: 0.9615\n",
      "Epoch 539/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.4622 - categorical_accuracy: 0.9615\n",
      "Epoch 540/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.4654 - categorical_accuracy: 0.9615\n",
      "Epoch 541/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.4593 - categorical_accuracy: 0.9615\n",
      "Epoch 542/600\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.4576 - categorical_accuracy: 0.9615\n",
      "Epoch 543/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.4632 - categorical_accuracy: 0.9615\n",
      "Epoch 544/600\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.4535 - categorical_accuracy: 0.9808\n",
      "Epoch 545/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.4583 - categorical_accuracy: 0.9615\n",
      "Epoch 546/600\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.4700 - categorical_accuracy: 0.9231\n",
      "Epoch 547/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.4731 - categorical_accuracy: 0.9808\n",
      "Epoch 548/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.4676 - categorical_accuracy: 1.0000\n",
      "Epoch 549/600\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.4545 - categorical_accuracy: 1.0000\n",
      "Epoch 550/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.4479 - categorical_accuracy: 1.0000\n",
      "Epoch 551/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.4468 - categorical_accuracy: 1.0000\n",
      "Epoch 552/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.4574 - categorical_accuracy: 0.9615\n",
      "Epoch 553/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.4475 - categorical_accuracy: 0.9615\n",
      "Epoch 554/600\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.4503 - categorical_accuracy: 0.9615\n",
      "Epoch 555/600\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.4575 - categorical_accuracy: 0.9615\n",
      "Epoch 556/600\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.4570 - categorical_accuracy: 0.9231\n",
      "Epoch 557/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.4422 - categorical_accuracy: 1.0000\n",
      "Epoch 558/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.4440 - categorical_accuracy: 1.0000\n",
      "Epoch 559/600\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.4502 - categorical_accuracy: 1.0000\n",
      "Epoch 560/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.4712 - categorical_accuracy: 0.9231\n",
      "Epoch 561/600\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.5331 - categorical_accuracy: 0.8462\n",
      "Epoch 562/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.5351 - categorical_accuracy: 0.8077\n",
      "Epoch 563/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.5068 - categorical_accuracy: 0.9038\n",
      "Epoch 564/600\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.4541 - categorical_accuracy: 1.0000\n",
      "Epoch 565/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.4653 - categorical_accuracy: 0.9615\n",
      "Epoch 566/600\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.4640 - categorical_accuracy: 0.9615\n",
      "Epoch 567/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.5262 - categorical_accuracy: 0.8462\n",
      "Epoch 568/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 110us/step - loss: 0.6443 - categorical_accuracy: 0.7308\n",
      "Epoch 569/600\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.7504 - categorical_accuracy: 0.6346\n",
      "Epoch 570/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.7749 - categorical_accuracy: 0.6538\n",
      "Epoch 571/600\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.6246 - categorical_accuracy: 0.6538\n",
      "Epoch 572/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.6221 - categorical_accuracy: 0.7692\n",
      "Epoch 573/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.6075 - categorical_accuracy: 0.6731\n",
      "Epoch 574/600\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.5862 - categorical_accuracy: 0.7500\n",
      "Epoch 575/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.5711 - categorical_accuracy: 0.7692\n",
      "Epoch 576/600\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.5168 - categorical_accuracy: 0.8654\n",
      "Epoch 577/600\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.5323 - categorical_accuracy: 0.8077\n",
      "Epoch 578/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.5147 - categorical_accuracy: 0.8269\n",
      "Epoch 579/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.5150 - categorical_accuracy: 0.8846\n",
      "Epoch 580/600\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.4870 - categorical_accuracy: 0.8462\n",
      "Epoch 581/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.4618 - categorical_accuracy: 0.9615\n",
      "Epoch 582/600\n",
      "52/52 [==============================] - 0s 146us/step - loss: 0.4734 - categorical_accuracy: 0.9231\n",
      "Epoch 583/600\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.5186 - categorical_accuracy: 0.8654\n",
      "Epoch 584/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.4853 - categorical_accuracy: 0.8077\n",
      "Epoch 585/600\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.4800 - categorical_accuracy: 0.8654\n",
      "Epoch 586/600\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.5238 - categorical_accuracy: 0.8077\n",
      "Epoch 587/600\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.4906 - categorical_accuracy: 0.8846\n",
      "Epoch 588/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.4633 - categorical_accuracy: 0.8846\n",
      "Epoch 589/600\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.4633 - categorical_accuracy: 0.8846\n",
      "Epoch 590/600\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.4664 - categorical_accuracy: 0.9231\n",
      "Epoch 591/600\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.4635 - categorical_accuracy: 0.9038\n",
      "Epoch 592/600\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.4591 - categorical_accuracy: 0.9231\n",
      "Epoch 593/600\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.4657 - categorical_accuracy: 0.9038\n",
      "Epoch 594/600\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.4846 - categorical_accuracy: 0.8269\n",
      "Epoch 595/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4710 - categorical_accuracy: 0.9231\n",
      "Epoch 596/600\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4901 - categorical_accuracy: 0.8654\n",
      "Epoch 597/600\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.4932 - categorical_accuracy: 0.8462\n",
      "Epoch 598/600\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.4427 - categorical_accuracy: 0.9423\n",
      "Epoch 599/600\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.4545 - categorical_accuracy: 0.8654\n",
      "Epoch 600/600\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.4325 - categorical_accuracy: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3d44cf98>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = 'IAMREALLYGOOD'\n",
    "text, x_train, y_train = caeserde(mystr, x_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: IAMREALLYGOOD\n",
      "Cipertext: LDPUHDOOBJRRG\n",
      "Prediction: IAMREALLYGOOD\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\",mystr)\n",
    "print(\"Cipertext:\",text)\n",
    "print(\"Prediction:\",\"\".join(predict_results(model, x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde('ABCDEFGHIJKLMNOPQRSTUVWXYZ', x_as_vector=False, y_as_vector=False)\n",
    "\n",
    "predictions = model.predict_classes(x_train)\n",
    "\n",
    "#print(confusion_matrix(y_train, predictions.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3e0bacf8>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGfCAYAAACNytIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXucXWV5tq8nkcMEkyhqPQAaD1AFqUGDirR4SK3RqIyNaNAJtUbHGKlFP9NPYz6ipMXUhqgVNUaqolHwHGlFtBWxakEzmjThJCKiBKgoGINoFZjn+2Pvwc3M7PO79nrWm/vyt37O3rPXte61d8h+854ec3eEEEIIIcpiRtkBhBBCCLFvo8aIEEIIIUpFjREhhBBClIoaI0IIIYQoFTVGhBBCCFEqaowIIYQQolTUGBFCCCFEx5jZh83sFjO7vMnvzcz+2cyuNbOdZvbEdk41RoQQQgjRDR8FFrX4/XOBw+vHKPCBdkI1RoQQQgjRMe7+n8BtLV5yIvAxr3EZcD8ze2gr531SBpyOO39xXd9bvA497M9SRBFCCCEGwl2/v9EGeb0U37UT7P+gR7+GWo/GBJvdfXMXikOAGxoe764/d3OzEwpvjAghhBCiOtQbHt00PiYzXUOsZWNJjREhhBCi6ozfXXaCRnYDhzU8PhS4qdUJmjMihBBCiJRcAJxSX1XzVOBX7t50iAZKboysOXMjJyxeyvDIip4dz/mLZ3DF5f/J1Vd+i79b9bpSPXKkd0TKIkfcLDk5ImWRozhPcnw83dEGMzsPuBT4YzPbbWbLzWyFmU18mV8IXAdcC3wIWNnW6d7dnBczOx54mbt39Cm0mlQztmMXs4aGWL1uA1u3bGrqaDaBdcaMGVx1xTdZ9LyT2b37Zi679EJGlq3kqqt+2Em0pB450jsiZZEjbpacHJGyyNGfZ+ATWG++KtkE1v0e+riBZocOe0bMbL6ZvdPMrgf+Hrg6xcUXzD+auXNm93z+k489hh/96Hp+/OOfcuedd/LpT3+RF77gOaV45EjviJRFjrhZcnJEyiJHcR4xlaaNETM7wsxON7OrgLOpLdMxd3+mu793YAlb8LBDHsINu/8wJ2b3jTfzsIc9pBSPHOkdkbLIETdLTo5IWeQozlME7uPJjjJo1TNyNbAQeIG7/2m9AdLRdF0zGzWzMTMbO+dj56XI2ew6U57rdtgplUeO9I5IWeSImyUnR6QschTnKYTx8XRHCbRa2rsEWAp83cwuAs5n+rXDU2hco5xyI5bJ3Lj7Zg479GH3PD70kIdy880/K8UjR3pHpCxyxM2SkyNSFjmK84ipNO0ZcfcvuPtLgccClwBvAB5sZh8ws78YUL6WbBvbwWMe80jmzTuM/fbbj5e85ET+9d++WopHjvSOSFnkiJslJ0ekLHIU5ymEAa6mKYK2m565+x3AJ4BPmNnBwEnAm4G+P4FVa9ezbftO9uzZy8LhEVYuX8aSLiYD3X333fztaWu48EufZOaMGXz03E9x5ZXXdJ0jhUeO9I5IWeSImyUnR6QschTnKYRYm551TddLe7tFtWmEEELsawx6ae/vf/L9dLVpHvHEgS/t1XbwQgghRNUpaXglFYU3RlL0avz2pm+GyCGEEEKEpKRVMKlQbRohhBBClIqGaYQQQoiKU9ZmZalQY0QIIYSoOhqm6Z0U1Q9TVP5NlUWO9I5IWeSImyUnR6QschTnEfem8KW999n/kGkv0E31w1YTWPut/NttFjkG54iURY64WXJyRMoiR3+eQS/t/d0130r2ZX7AEX8as2pvEaSqfthv5d9UWeRI74iURY64WXJyRMoiR3GeQhi/O91RAl03RszsgTZdtaAuiVT9MEpVSDniZpEjbpacHJGyyFGcR0ylZWPEzJ5qZpeY2efN7Bgzuxy4HPiZmS1qcd49VXvHx+9o9popz5VV/TBKVUg54maRI26WnByRsshRnKcQMq9NczawGpgLXAw8190vM7PHAucBF013UmPV3mZzRiJVP4xSFVKOuFnkiJslJ0ekLHIU5ymEzFfT3Mfdv+runwH+x90vA3D3q/u9cKTqh1GqQsoRN4sccbPk5IiURY7iPGIq7XpGGptav530u776plJVP+y38m+qLHKkd0TKIkfcLDk5ImWRozhPIVR807OWS3vN7G7gDsCAIeA3E78CDnT3/dpdoNkwTTeoNo0QQogqMfClvTu/km5p7588J1bVXnefOaggQgghhNg30XbwQgghRMVxL2d/kFRUojGSYohFQz1CCCGypeJzRkqtTSOEEEIIUYmeESGEEEK0oOL7jKgxIoQQQlQdDdP0TpSy0GvO3MgJi5cyPLKip/NTZpEjbhY54mbJyREpixzFeZJT8UJ5LfcZSUGzfUYGXRa61QTWsR27mDU0xOp1G9i6ZVPT17WawBqlzHVOjkhZ5IibJSdHpCxy9OcZ9D4j/7vtc8m+zA88dsnA9xlpVyjvMWZ2/DTP/5mZPbqfC0cqC71g/tHMnTO76/NSZ5EjbhY54mbJyREpixzFeQqh4oXy2g3TvBu4fZrnf1v/Xc9EKgudgij3k5MjUhY54mbJyREpixzFeQphfDzdUQLtGiPz3H3n5CfdfQyY1+wkMxs1szEzGxsfv6PZa6Y8V1ZZ6BREuZ+cHJGyyBE3S06OSFnkKM4jptJuNc2BLX431OwX7r4Z2AzN54xEKgudgij3k5MjUhY54mbJyREpixzFeQoh89U028zs1ZOfNLPlwPf6uXCkstApiHI/OTkiZZEjbpacHJGyyFGcpxAqPkzTrmfkNOALZvZy/tD4WADsD7yonwtHKgu9au16tm3fyZ49e1k4PMLK5ctY0uWkpCj3k5MjUhY54mbJyREpixzFecRUOlraa2bPBB5ff3iFu1/c6QWaDdMMGtWmEUIIMSgGvrT3mx9Pt7T3z5YNfGlvRzuwuvvXga8XnEUIIYQQPVD1qr0qlCeEEEKIUtlnatOkGGLRUI8QQoiQqFCeEEIIIUol86W9QgghhBCFoqq9iTyq/FuMI1IWOeJmyckRKYscxXmSU/F9RvaZqr0pPKr8G/ezkUOfTQ6OSFnk6M8z6KW9v/2PTcm+zIf+fEWsqr1FklslRlX+Te+IlEWOuFlyckTKIkdxHjGVjhsjZvYgM3tQqgurEmMxOXJyRMoiR9wsOTkiZZGjOE8hVHyYpmVjxGq8zcx+AVwNXGNmPzez0/u9sCoxFpMjJ0ekLHLEzZKTI1IWOYrzFIKPpztKoF3PyGnA8cCx7v4Ad78/8BTgeDN7Q7OTzGzUzMbMbGx8/I5pX6NKjMXkyMkRKYsccbPk5IiURY7iPGIq7RojpwAnu/uPJ55w9+uAkfrvpsXdN7v7AndfMGPGQdO+RpUYi8mRkyNSFjniZsnJESmLHMV5CqHiwzTtNj3bz91/MflJd/+5me3Xz4Vzq8Soyr/pHZGyyBE3S06OSFnkKM5TCBXfgbXl0l4z+767P7Hb3zUSpWpvCrQdvBBCiE4Y+NLeL7073dLexaeFq9r7BDPbO83zBhxYQB4hhBBCdEvFt4Nv2Rhx95mDCiKEEEKIHqn4MI0K5XVBlMq/oOEeIYQQ+aDGiBBCCFF1ch6mEUIIIUQFqPgwTalVe4UQQgghSm2M5FYWul/HmjM3csLipQyPrOjp+qlyRHJEyiJH3Cw5OSJlkaM4T3Iqvh18y31GUtBsn5GqloXu19FqAuvYjl3MGhpi9boNbN2yqeX1mk1gjfK+VvGzkUOfTdmOSFnk6M8z8H1GPvv36fYZefGage8zUlrPSG5loVM4Fsw/mrlzZnd1ThE5ojgiZZEjbpacHJGyyFGcR0ylXdXev2v4+aRJvzuznwvnVhY6SmnpKPeS22cjR9wsOTkiZZGjOE8hVLw2TbuekaUNP79l0u8WNTupk6q9uZWFjlJaOsq95PbZyBE3S06OSFnkKM5TCO7pjhJo1xixJj9P9/geOqnam1tZ6CilpaPcS26fjRxxs+TkiJRFjuI8YirtGiPe5OfpHndFbmWho5SWjnIvuX02csTNkpMjUhY5ivMUQsWHaTotlGfAUEPRvL4L5eVWFjqFY9Xa9WzbvpM9e/aycHiElcuXsaTLyVFR7iW3z0aOuFlyckTKIkdxnkKo+KZnpS3t3VdRbRohhMifgS/t/cT/S7e09+XrBr60V9vBCyGEEFVHtWmEEEIIUSoVH6ZRY2TApBpeSTHco6EeIYQQ3WJmi4D3ADOBc9x9/aTfPxw4F7hf/TVvdvcLWzlVKE8IIYSoOgPaZ8TMZgLvA54LHAmcbGZHTnrZGuDT7n4Mtf3K3t8uvnpGhBBCiKozuGGaJwPXuvt1AGZ2PnAicGXDaxyYU/95LnATbVDPiBBCCCHuoXEX9fox2vDrQ4AbGh7vrj/XyNuAETPbDVwI/E27a5baGMmtLHQUx5ozN3LC4qUMj6zo6fxUOfTZ5O2IlCUnR6QschTnSU7CTc8ad1GvH5sbrjTdst/JYzsnAx9190OB5wEfN7PWtfDK2mekqmWhozhaTWAd27GLWUNDrF63ga1bNjV9XbMJrFHej0hZ5IibJSdHpCxy9OcZ+D4j57wx3T4jr9rYNLuZHQe8zd2fU3/8FgB3f0fDa64AFrn7DfXH1wFPdfdbmnnbVe19eFd30AW5lYWO4gBYMP9o5s6Z3fV5KXPos8nbESlLTo5IWeQozlNxtgGHm9kjzWx/ahNUL5j0mp8CCwHM7HHUdmz/eStpu2GarRM/mNnnuk3citzKQkdxpCDSvUTJIkfcLDk5ImWRozhPEfi4JztaXsf9LuBU4CvAVdRWzVxhZmeY2QvrL/s/wKvN7L+B84BXeJthmHaraRq7ah7V5rV/OKk22WUUwGbOZbrKvbmVhY7iSEGke4mSRY64WXJyRMoiR3GeQhjgpmf1PUMunPTc6Q0/Xwkc342zn6q9zU9qmPwyXUME8isLHcWRgkj3EiWLHHGz5OSIlEWO4jxiKu0aI08ws71mdjvwJ/Wf95rZ7Q0VfHsit7LQURwpiHQvUbLIETdLTo5IWeQozlMIPp7uKIGWwzTuPrOoC+dWFjqKA2DV2vVs276TPXv2snB4hJXLl7Gki0lWke4lShY54mbJyREpixzFeQqhzVyP6JS2tFf0h2rTCCFEXAa9tPc37zs12XftrNedPdDsoO3ghRBCiOqjqr1CCCGEKBU1RkQZpBhi0VCPEEJkQpQlxj2iQnlCCCGEKBX1jAghhBBVp+LDNKraGyxLFEeUyr+pPHKkd0TKkpMjUhY5ivMkZ9zTHSWgqr2BsqjybzEeOdI7ImXJyREpixz9eQa+tHfDq9It7X3TOQNf2ltaz0hulRhzckCMyr+pPHKkd0TKkpMjUhY5ivMUQsV3YG3ZGDGzE83sdQ2Pv2Nm19WPF/dz4dwqMebkSIE+m7wdkbLk5IiURY7iPIVQ8WGadj0jfwdc0PD4AOBY4BnAa5udZGajZjZmZmPj43c0e82U56pciTEnRwr02eTtiJQlJ0ekLHIU5xFTabeaZn93v6Hh8bfc/VbgVjObvhwvtaq9wGZoPmckt0qMOTlSoM8mb0ekLDk5ImWRozhPEXjmq2nu3/jA3U9tePigfi6cWyXGnBwp0GeTtyNSlpwckbLIUZynECo+TNOuZ+Q7ZvZqd/9Q45Nm9hrgu/1cOLdKjDk5IEbl31QeOdI7ImXJyREpixzFecRUWi7tNbM/ArYCvwO+X3/6SdTmjgy7e9v+KVXtjYu2gxdCiGIY9NLeO/5+JNl37UFrtsSq2uvutwBPM7NnAUfVn/6Su19ceDIhhBBCdEZJwyup6Gg7+HrjQw0QIYQQQiRHtWn2YVT5VwghMqHiq2nUGBFCCCGqTsWHaUotlCeEEEIIoZ4RIYQQouqUVFMmFaX2jORWFlqOe7PmzI2csHgpwyMrejo/ZRY50jsiZcnJESmLHMV5klPxTc9a7jOSgmb7jFS1LLQc96bVBNaxHbuYNTTE6nUb2LplU9PXtZrAWsX3ZF9wRMqSkyNSFjn68wx8n5G3npRun5F/+MzA9xkprWckt7LQckxlwfyjmTtndtfnpc4iR3pHpCw5OSJlkaM4TxH4+HiyowxaNkbM7L1m9s/Njn4unFtZaDmKIcr9yBE3S06OSFnkKM5TCBUfpmk3gXWs4ee3A2s7kZrZKDAKYDPnMmPG1AK/uZWFlqMYotyPHHGz5OSIlEWO4jxiKu22gz934mczO63xcZvzNgObofmckdzKQstRDFHuR464WXJyRMoiR3GeQtiH9hlJeqe5lYWWoxii3I8ccbPk5IiURY7iPIXg4+mOEihtn5HcykLLMZVVa9ezbftO9uzZy8LhEVYuX8aSLid7RbkfOeJmyckRKYscxXnEVFou7TWz2/lDj8gs4DcTvwLc3ee0u0CzYRqRB6pNI4QQUxn00t5fv/GFyb5r77vxgoEv7W03Z6S/dZlCCCGEKBzfh+aMCCGEEEIkR7VpRF+kGGLRUI8QQvRJxXtG1BgRQgghqk5JO6emQsM0QgghhCgV9YwIIYQQVafiwzSl9ozkVhZajvSONWdu5ITFSxkeWdHT+SmzyBE3S06OSFnkKM6TnIrXpmm5z0gKmu0zUtWy0HKkd7SawDq2YxezhoZYvW4DW7dsavq6VhNYq/ieRHdEypKTI1IWOfrzDHqfkdtXLEr2ZT5700UD32ektJ6R3MpCy5HeAbBg/tHMndPfdjdR7icnR6QsOTkiZZGjOE8RuHuyowxaNkbM7HYz2zvNcbuZ7e3nwrmVhZYjvSMVUe4nJ0ekLDk5ImWRozhPIVR8mKaQHVjNbBQYBbCZc5kx46DpXjPd9bq9Tt+OSFnkKIYo95OTI1KWnByRsshRnEdMpZDVNO6+GdgMzeeM5FYWWo70jlREuZ+cHJGy5OSIlEWO4jyFoNU0vZFbWWg50jtSEeV+cnJEypKTI1IWOYrzFIGPe7KjDErbZyS3stBypHcArFq7nm3bd7Jnz14WDo+wcvkylnQ5YSzK/eTkiJQlJ0ekLHIU5xFTKW1prxATqDaNECI3Br2091d/tTDZd+3cc7828KW92oFVCCGEqDrVLk2j2jRCCCGEKBf1jIjSSTHEoqEeIcS+TFkTT1OhxogQQghRdSreGNEwjRBCCCFKRVV7g2WRI71HlX+LcUTKkpMjUhY5ivMkZzzhUQKq2hsoixy9e1T5N+5nI4fe1xwc3XoGvbT3lyc9I9mX+f0/c0mcqr0tiuTtNbOfm9llZraw1wvnVolRjvSOVB5V/k3viJQlJ0ekLHIU5xFTadoYcffZ7j5nugN4CPAa4D29Xji3SoxypHek9PRLlPckiiNSlpwckbLIUZynECo+TNPTahp3vxv4bzN773S/V9VeOSJ9NimI8p5EcUTKkpMjUhY5ivMUQdWX9vY1gdXdP9jk+c3uvsDdF0zXEIH8KjHKkd6R0tMvUd6TKI5IWXJyRMoiR3EeMRVV7Q2URY7iPP0S5T2J4oiUJSdHpCxyFOcphH1xmCYFuVVilCO9I5VHlX/TOyJlyckRKYscxXmKwCtem0ZVe0UWaDt4IUQkBr2099bFT0/2XfuAL30jztJeIYQQQohBoNo0QgghRMWp+jCNGiMiC6JU/gUN9wghSqDijREN0wghhBCiVNQzIoQQQlScqg/TqGdECCGEqDg+nu5oh5ktMrMfmNm1ZvbmJq95iZldaWZXmNkn2zlLbYzkVhZajvSOKFnWnLmRExYvZXhkRU/XT5UjkiNSlpwckbLIUZynqpjZTOB9wHOBI4GTzezISa85HHgLcLy7HwWc1tZb1j4jVS0LLcfgHIPO0moC69iOXcwaGmL1ug1s3bKp5fWaTWCN8r5W8bPZVxyRssjRn2fQ+4z87Jnp9hl58Neb7zNiZscBb3P359QfvwXA3d/R8Jp3Ate4+zmdXrNlz4iZHdridy/o9CLTkVtZaDnSOyJlWTD/aObOmd3VOUXkiOKIlCUnR6QschTnKQS3ZIeZjZrZWMMx2nClQ4AbGh7vrj/XyBHAEWb2bTO7zMwWtYvfbpjma2Y2b/KTZvZK4N3t5K3IrSy0HOkd0bL0S5R7ye2zyckRKYscxXmi01jstn5sbvj1dL0mk3tl7gMcDjwDOBk4x8zu1+qa7RojbwD+vT7+U0tR65J5A/D0Zic1tqrGx+9o9popz1W5LLQc6R3RsvRLlHvJ7bPJyREpixzFeYpggBNYdwOHNTw+FLhpmtd80d3vdPcfAz+g1jhpSsulve5+oZn9DviymQ0DrwKOBU5w91+2OG8zsBmazxnJrSy0HOkd0bL0S5R7ye2zyckRKYscxXmKwMcHNkVlG3C4mT0SuBFYCrxs0mu2UusR+aiZPZDasM11raRtV9O4+9eAVwCXAI8CFrZqiHRKbmWh5UjviJalX6LcS26fTU6OSFnkKM5TZdz9LuBU4CvAVcCn3f0KMzvDzF5Yf9lXgFvN7Erg68Aqd7+1lbdlz4iZ3U5tLMiAA4CFwC1W66tyd5/T6w3lVhZajvSOSFlWrV3Ptu072bNnLwuHR1i5fBlLupy4FuVecvtscnJEyiJHcZ4iGOSmZ+5+IXDhpOdOb/jZgTfWj44obWmvENFQbRohRCoGvbT3xuOeley79pBLLx5odtAOrEIIIYQoGdWmEUIIISpO1WvTqDEiRJ1Uwysphns01COE6IYBrqYpBA3TCCGEEKJU1DMihBBCVJwge6/1jBojQgghRMXRME0f5FYWWo70jkhZUjjWnLmRExYvZXhkRU/np8qhzyauI1IWOYrziHtT2j4jVS0LLcfgHJGydONoNYF1bMcuZg0NsXrdBrZu2dT0dc0msEZ5PyJlyckRKYsc/XkGvc/I9fOfnezLfN6Of6/OPiNmdlo/F86tLLQc6R2RsqS6nwXzj2bunNldn5cyhz6buI5IWeQozlME7umOMuhnmKbjbV6nI7ey0HKkd0TKEqV0eKR7iZIlJ0ekLHIU5xFT6WcCa9NuHDMbBUYBbOZcZsw4aLrXTHmuymWh5UjviJQlSunwSPcSJUtOjkhZ5CjOUwRVn8DaT2Ok6Sfg7puBzdB8zkhuZaHlSO+IlCVK6fBI9xIlS06OSFnkKM5TBO7Vboy0HKYxs9vNbO80x+3Aw1qd247cykLLkd4RKUuU0uGR7iVKlpwckbLIUZxHTKVlz4i79z7Trg25lYWWI70jUpZU97Nq7Xq2bd/Jnj17WTg8wsrly1jSxQS4SPcSJUtOjkhZ5CjOUwRVr01T2tJeIXJFtWmEEINe2nvN4xYl+6494qqLqrO0VwghhBAiBdoOXojEpOjVUO+KEKIbqj6BVY0RIYQQouJUfWmvhmmEEEIIUSrqGRFCCCEqTpC913pGVXuDZZEjbpYojiiVf1N55IibRY7iPKnxcUt2lIGq9gbKIkfcLKr8W4xHjrhZ5OjPM+ilvVc+enGyL/Mjf/SlfWdpb26VGOVI74iUJYoDYlT+TeWRI24WOYrzFMG4W7KjDEprjORWiVGO9I5IWaI4UqDPJq4jUhY5ivMUgbslO8qg5QRWM7ug1e/d/YVNzlPVXjn6dkTKEsWRAn02cR2RsshRnEdMpd1qmuOAG4DzgO8AHTWZVLVXDn02xThSoM8mriNSFjmK8xRB1dtE7YZpHgKsBh4PvAd4NvALd/+Gu3+jnwvnVolRjvSOSFmiOFKgzyauI1IWOYrzFEHV54y0q9p7N3ARcJGZHQCcDFxiZme4+3v7uXBulRjlSO+IlCWKA2JU/k3lkSNuFjmK84iptF3aW2+ELKbWEJkHXAB82N1v7OQCqtorRPeoNo0Q1WbQS3u3P/zEZN+1x/z0iwPvHmk3gfVcakM0Xwbe7u6XDySVEEIIITqm6nNG2k1gXQbcARwBvL5hJrEB7u5zCswmhBBCiH2AdnNGVEhPiBJIMcSioR4h9h3KmniaChXKE0IIISpOWZuVpUI9H0IIIYQoFfWMCCGEEBWn6sM0pfaM5FYWWo70jkhZcnKsOXMjJyxeyvDIip7OT5lFjrhZ5CjOkxpPeJRB231G+qXZPiNVLQstx+AckbJU0dFqAuvYjl3MGhpi9boNbN2yqenrWk1greJ7Et0RKYsc/XkGvc/Ifz10SbIv86fd/LmBd7OU1jOSW1loOdI7ImXJyQGwYP7RzJ0zu+vzUmeRI24WOYrziKm0bIyY2ektjv/Xz4VzKwstR3pHpCw5OVIR5X5yckTKIkdxniJwt2RHGbSbwHrHNM/NAl4FPABYN91JZjYKjALYzLnMmHHQdK+Z8lyVy0LLkd4RKUtOjlREuZ+cHJGyyFGcpwjGyw7QJ+02PTtr4mczmw38LfBK4HzgrBbnbQY2Q/M5I7mVhZYjvSNSlpwcqYhyPzk5ImWRoziPmErbOSNmdrCZ/T2wk1rj5Ynu/n/d/ZZ+LpxbWWg50jsiZcnJkYoo95OTI1IWOYrzFIFjyY4yaFco75+Av6TWy3G0u/861YVzKwstR3pHpCw5OQBWrV3Ptu072bNnLwuHR1i5fBlLupyIF+V+cnJEyiJHcZ4iGI8xWtQzLZf2mtk48DvgLu69/LjjQnnNhmmEEMWi2jRClMegl/Ze8uCTkn3XPuNnnxl494gK5QkhhBAVZ7yk4ZVUaDt4IYQQouKUNdcjFWqMCJEpKYZYNNQjhBgEaowIIYQQFSfrfUaEEEIIEZ+qD9Ooam+wLHLEzSLHvVHl32IckbLIUZxH3BtV7Q2URY64WfZVhyr/6s+8HL15Br2096IHL032Zb7oZ+fHrNprZgea2ePN7CgzOzDFhXOrxChHekekLHJMRZV/0zsiZZGjOE8RjCc8yqBd1d77mNk7gd3AucAW4AYze6eZ7dfPhXOrxChHekekLHIUQ5T7ieKIlEWO4jxiKu16Rv4JOBh4pLs/yd2PAR4N3A/Y0OwkMxs1szEzGxsfn67wb36VGOVI74iURY5iiHI/URyRsshRnKcIsq5NAzwfOMIb3m1332tmrwWuplbFdwqq2iuHPpu8HamIcj9RHJGyyFGcpwjGq72Ypm3PiPs0zT53v5t716rpmtwqMcqR3hEpixzFEOV+ojgiZZGjOI+YSruekSvN7BRsA1gwAAAgAElEQVR3/1jjk2Y2Qq1npGdyq8QoR3pHpCxyTEWVf9M7ImWRozhPEVS9Nk27qr2HAJ8Hfgt8j1pvyLHAEPAid7+x3QVUtVeI6qLt4IXojUEv7d36kJcl+64d/p9PhqvaeyPwFDN7FnAUYMCX3f1rgwgnhBBCiPzpaDt4d78YuLjgLEIIIYToAdWmEUJkiyr/ClENxqdZdlwlSq1NI4QQQgihnhEhhBCi4lR9pYgaI0IIIUTFqfqckVKHaXIrCy1HekekLHKk96w5cyMnLF7K8MiKnjOkyBHJESmLHMV5xL1puc9ICprtM1LVstByDM4RKYscvXtaTWAd27GLWUNDrF63ga1bNjV9XasJrFHeE/2Zz9vRrWfQ+4yc97CXJ/syP/mmTwx8NmxpPSO5lYWWI70jUhY5ivEsmH80c+fM7vraqXNEcUTKIkdxniIYx5IdZdCyMWJmB5rZaWZ2tpm9xsySzTHJrSy0HOkdkbLIUZynX6K8J5HeVznSO1J6qo6ZLTKzH5jZtWb25have7GZuZktaOds1zNyLrAA2AU8Fzirw6CjZjZmZmPj43c0e82U56pcFlqO9I5IWeQoztMvUd6TSO+rHOkdKT1F4AmPVpjZTOB91NoERwInm9mR07xuNvB64Dud5G/X03Gkux9dF/8L8N1OpO6+GdgMzeeM5FYWWo70jkhZ5CjO0y9R3pNI76sc6R0pPUUwPrjRlScD17r7dQBmdj5wInDlpNetA94JvKkTabuekTsnfnD3uzqO2gG5lYWWI70jUhY5ivP0S5T3JNL7Kkd6R0pPdBpHN+rHaMOvDwFuaHi8u/5c4/nHAIe5+791es12PSNPMLO9E35gqP7YAHf3OZ1eaDK5lYWWI70jUhY5ivGsWruebdt3smfPXhYOj7By+TKWdDkhMMp7Eul9lSO9I6WnCFLuM9I4ujEN0/XB3DMCYmYzgHcBr+jmmqUt7RVC7BuoNo3YFxn00t6PHDKS7Lv2r2/c0jS7mR0HvM3dn1N//BYAd39H/fFc4EfAr+unPAS4DXihu48186o2jRBCCCE6ZRtwuJk90sz2B5YCF0z80t1/5e4PdPd57j4PuIw2DRHQdvBCCCFE5RnUBFZ3v8vMTgW+AswEPuzuV5jZGcCYu1/Q2jA9aowIIQolxRBLiqEe0HCPyJdB1qZx9wuBCyc9d3qT1z6jE6eGaYQQQghRKuoZEUIIISpO1av2qjEihBBCVBwvp6RMMkodpsmtLLQc6R2RssgRM8uaMzdywuKlDI+s6On6qXKkckTKIkdxHnFvOtpnxMxmAY+pP/yBu/+u0ws022ekqmWh5RicI1IWOcrN0moC69iOXcwaGmL1ug1s3bKp5fWaTWDdV99XOYr7bAa9z8j7D0u3z8jKG5rvM1IU7ar27mdm76a23etHqBXOu26iSl99y9eeyK0stBzpHZGyyBE3y4L5RzN3zuyuzikiR27vqxzFeYpgPOFRBu2Gac4C7gs8wt2f5O7HAI8DHmVmHwA+3+uFcysLLUd6R6QscsTO0i+R7iVKFjmK84iptJvA+jzgcG8Yy3H3vWb2WuAX1EoIT6FeVGcUwGbOZcaMg6Z7zZTnqlwWWo70jkhZ5IidpV8i3UuULHIU5ymCGCl6p11jZNyneafd/W4z+7m7XzbdSY1FdprNGcmtLLQc6R2RssgRO0u/RLqXKFnkKM5TBIPagbUo2g3TXGlmp0x+0sxGgKv6uXBuZaHlSO+IlEWO2Fn6JdK9RMkiR3EeMZV2PSOvAz5vZq8EvketJ+hYYAh4UT8Xzq0stBzpHZGyyBE3y6q169m2fSd79uxl4fAIK5cvY0mXkwqj3EukLHIU5ymCqm961unS3mcBRwEGXOHuX+v0As2GaYQQolNUm0ZUjUEv7T3r4emW9v6fnw5+aW9HO7C6+8XAxQVnEUIIIcQ+iLaDF0IIISpO1Ycg1BgRQoQn1fBKiuEeDfWIiFR9NY0aI0IIIUTFqfoE1lIL5QkhhBBCqGpvsCxyxM0iR9wsKRwpqv/qfc3bkdKTGk94lEFHS3v7QVV75dBnk58jUpZuHCmq/xZZ+TeVR470jm49g17a+w+PeHmyL/O3/uQTsar2FklulRjlSO+IlEWOuFlS3U+/1X/1vubtSOkRU+mpMWJmM83s5f1cOLdKjHKkd0TKIkfcLFEqqep9zduR0lME4wmPMmjZGDGzOWb2FjM728z+wmr8DXAd8JIW542a2ZiZjY2P39HsNVOeq3IlRjnSOyJlkSNuliiVVPW+5u1I6SmCqs8Zabe09+PAL4FLgVcBq4D9gRPdfUezk1S1Vw59Nnk7ImWJUklV72vejpQeMZV2wzSPcvdXuPsHgZOBBcDzWzVEOiW3SoxypHdEyiJH3CxRKqnqfc3bkdJTBFUfpmnXM3LnxA/ufreZ/djdb09x4dwqMcqR3hEpixxxs6S6n36r/+p9zduR0lMEVd+BteXSXjO7G5iY9GHAEPCb+s/u7nPaXUBVe4UQUdB28GJQDHpp7+nz0i3tPeP6wS/tbdkz4u4zBxVECCGEEL0xXvFSeapNI4QQQlScajdF1BgRQuxDpBhi0VCPEOlRY0QIIYSoOFWv2qvGiBBCCFFxqj5npNSqvUIIIYQQpTZGcisLLUd6R6QscsTNEsWx5syNnLB4KcMjK3o6P2UWOdI7UnpSU/Xt4FvuM5KCZvuMVLUstByDc0TKIkfcLIN2tJrAOrZjF7OGhli9bgNbt2xq+rpWE1ir+J7sC45uPYPeZ+RN805O9mW+4frzBr7PSLtCecea2UMaHp9iZl80s382s4P7uXBuZaHlSO+IlEWOuFmiOAAWzD+auXNmd31e6ixypHek9IiptBum+SDwewAzOwFYD3wM+BX1Qni9kltZaDnSOyJlkSNuliiOVES5HzmK8xTBOJ7sKIN2q2lmuvtt9Z9fCmx2988BnzOzpsXyzGwUGAWwmXOZMeOg6V4z5bkql4WWI70jUhY54maJ4khFlPuRozhPEcRI0TvtekZmmtlEg2UhcHHD75o2ZNx9s7svcPcF0zVEIL+y0HKkd0TKIkfcLFEcqYhyP3IU5xFTadcYOQ/4hpl9Efgt8E0AM3sMtaGansmtLLQc6R2RssgRN0sURyqi3I8cxXmKYDzhUQbtCuX9g5l9DXgo8FX/Q3/UDOBv+rlwbmWh5UjviJRFjrhZojgAVq1dz7btO9mzZy8Lh0dYuXwZS7qc4BjlfuQozlMEXvGBmtKW9gohRBVRbRrRCYNe2vv6eS9N9l37z9d/auBLe7UdvBBCCFFxVJtGCCGEEKVS9do0aowIIUQXpBhi0VCPEPdGjREhhBCi4lS7X0SNESGEEKLyVH2YptSqvUIIIYQQTRsjDTuvFkZuZaHlSO+IlEWOuFlycqw5cyMnLF7K8MiKns5PmUWO4jypqfqmZ033GTGz77v7E/u9QLN9RqpaFlqOwTkiZZEjbpYqOlpNYB3bsYtZQ0OsXreBrVs2NX1dqwmsVXxPoju69Qx6n5FXzXtxsnGac67/7MD3GWk1TFNomNzKQsuR3hEpixxxs+TkAFgw/2jmzpnd9Xmps8hRnEdMpVVj5EFm9sZmR78Xzq0stBzpHZGyyBE3S06OVES5n5wcKT1FUPVhmlbzQmYC96WHHhIzGwVGAWzmXKar3JtbWWg50jsiZZEjbpacHKmIcj85OVJ6iqDqtWlaNUZudvczepG6+2ZgMzSfM5JbWWg50jsiZZEjbpacHKmIcj85OVJ6xFRKmzOSW1loOdI7ImWRI26WnBypiHI/OTlSeoog52GahUVeOLey0HKkd0TKIkfcLDk5AFatXc+27TvZs2cvC4dHWLl8GUu6nCQZ5X5ycqT0FMF4kOGiXmm6tDcVzYZphBBiX0W1afJn0Et7lz3iL5N91378J58f+NJebQcvhBBCVJyq/6tfjREhhBgwUSr/gnpYckG1aYQQQlQSNUREFNQzIoQQQlScnPcZEUIIIUQFKGtJbipKHabJrRKjHOkdkbLIETdLTo4UHlX+LcaR0iPuTWlLe6taiVGOwTkiZZEjbpacHN14VPk37mcDg1/ae9IjTkz2Zf6Zn3wxVNXeQsmtEqMc6R2RssgRN0tOjlQeVf5N70jpKQJP+L8yaNkYmaZa7xvMbJmZPbLfC+dWiVGO9I5IWeSImyUnR0pPv0R5T6I4UnrEVNr1jMyedMwBFgBfNrOlzU4ys1EzGzOzsfHxO5q9ZspzVa7EKEd6R6QscsTNkpMjpadforwnURwpPUWQc20a3P3t0z1vZgcD/wGc3+Q8Ve2VQ59Nxo5IWXJypPT0S5T3JIojpacIojSKeqWnOSPufht9VvXNrRKjHOkdkbLIETdLTo6Unn6J8p5EcaT0VB0zW2RmPzCza83szdP8/o1mdqWZ7TSzr5nZI9o5e9pnxMyeBfyyl3MnyK0SoxzpHZGyyBE3S06OVB5V/k3vSOkpgkFtB29mM4H3Ac8GdgPbzOwCd7+y4WXbgQXu/hszey3wTuClLb2tunbMbBdT6+8cDNwEnOLuV7cLrqq9QgiRHlX+jc2gl/a+4OHPT/Zd+68//bem2c3sOOBt7v6c+uO3ALj7O5q8/hjgbHc/vtU12/WMPH/SYwdudffpZ6UKIYQQYuCkXJJrZqPAaMNTm+tzQQEOAW5o+N1u4CktdMuBL7e7ZrsJrD9pJxBCCCFEPjQuQpmG6XpNpm0JmdkItRW4T293TdWmEUKICpJiiEVDPfkwqDkj1HpCDmt4fCi1qRv3wsz+HHgr8HR3/107qRojQgghRMUZ4NLebcDh9c1PbwSWAi9rfEF9nsgHgUXufksn0lIL5QkhhBCiOrj7XcCpwFeAq4BPu/sVZnaGmb2w/rJ/Au4LfMbMdpjZBe286hkRQgghKs4gd0519wuBCyc9d3rDz3/erbPUnpHcykLLkd4RKYsccbPk5IiSZc2ZGzlh8VKGR1b0dP1UOSI5UnpSU/VCeS33GUlBs31GqloWWo7BOSJlkSNulpwcg87SagLr2I5dzBoaYvW6DWzdsqnp61pNYI3yvpbx2Qx6n5G/OGxRsi/zr95w0UCzQ4ueETM728yeVtSFcysLLUd6R6QscsTNkpMjUpYF849m7pzZXZ1TRI4ojpSeIhjHkx1l0GqY5ofAWWZ2vZn9o5nNT3nh3MpCy5HeESmLHHGz5OSIlqVfotxLpM+mKNw92VEGTRsj7v4edz+O2mYltwEfMbOrzOx0MzuildTMRs1szMzGxsen36w1t7LQcqR3RMoiR9wsOTmiZemXKPcS6bMR09N2Aqu7/8Td/9Hdj6G2lvhF1JbztDpns7svcPcFM2YcNO1rcisLLUd6R6QscsTNkpMjWpZ+iXIvkT6bosh5mAYAM9vPzF5gZp+gtr/8NcCSfi+cW1loOdI7ImWRI26WnBzRsvRLlHuJ9NkURdVX0zTdZ8TMng2cDCwGvgucD4ymKpKXW1loOdI7ImWRI26WnByRsqxau55t23eyZ89eFg6PsHL5MpZ0OVkzyr1E+mzE9DRd2mtmXwc+CXzO3W/r9QLNlvYKIYQoF9WmKY5BL+094ZCFyb5r//PGrw18aW/TnhF3f+YggwghhBCiN6r+r37VphFCCCFEqag2jRBC7KOkGGJJMdQDGu7pl7JWwaRCjREhhBCi4lS9MaJhGiGEEEKUiqr2BssiR9wscsTNkpMjUhZV/i3Ok5qqbwevqr2BssgRN4sccbPk5IiUZZCVf6H5nJEo70e3nkEv7X3yw56e7Mv8uzd9I07VXgAzO83MjjWz5HNLcqvEKEd6R6QscsTNkpMjUhZV/i3OI6bSbpjmUOA9wC1mdomZnWlmi83s4H4vnFslRjnSOyJlkSNulpwckbJEqVAb6V6ivCfTke128ADu/iYAM9sfWAA8DXgl8CEz2+PuR/Z64dwqMcqR3hEpixxxs+TkiJQlSoXaSPcS5T2Zjig5eqXTCaxDwBxgbv24CfhOsxeb2aiZjZnZ2Pj49KVscqvEKEd6R6QscsTNkpMjUpYoFWoj3UuU9yRH2s0Z2Wxm3wY+BRwH/BdwkrsvcPe/bnaeu2+uv2bBjBkHTfua3CoxypHeESmLHHGz5OSIlCVKhdpI9xLlPZmOcTzZUQbtJqY+HDgA+CFwI7Ab2JPiwrlVYpQjvSNSFjniZsnJESmLKv8W5ymCqg/TtF3aa7VBsqOozRd5GvB44DbgUndf2+4CqtorhBD5ou3gp2fQS3uPecjxyb5rt//Pt+NU7Z3Aa62Vy81sD/Cr+vF84MlA28aIEEIIIYql6tvBt2yMmNnrqfWGHA/cCXwbuBT4MLCr8HRCCCGEaEtZS3JT0a5nZB7wWeAN7n5z8XGEEEJUiVTDKymGe3Ib6tmXaLfPyBsHFUQIIYQQvTFe8Qmsybd5F0IIIcRgqfowTalVe4UQQgghSm2M5FYWWo70jkhZ5IibJSdHpCxRHGvO3MgJi5cyPLKip/NT5UjpSc24e7KjDNruM9IvzfYZqWpZaDkG54iURY64WXJyRMoyaEerCaxjO3Yxa2iI1es2sHXLpqavazaBtYzPZtD7jDz2j45N9mV+9S3bBr7PSNOeETM7rMXv+p6ynFtZaDnSOyJlkSNulpwckbJEcQAsmH80c+fM7vq81DlSecRUWg3TfMPM/s7M7pnkamYPNrMtwMZ+L5xbWWg50jsiZZEjbpacHJGyRHGkINJnUxRVH6Zp1Rh5EvBoYLuZPcvM/hb4LrVNz57SStpJ1d7cykLLkd4RKYsccbPk5IiUJYojBZE+m6LwhP8rg6ZLe939l8Br6o2Q/wBuAp7q7rvbSd19M7AZms8Zya0stBzpHZGyyBE3S06OSFmiOFIQ6bMR09Nqzsj9zOyDwF8Di6jtxPplM3tWigvnVhZajvSOSFnkiJslJ0ekLFEcKYj02RRF1YdpWm169n3g/cDr3P0u4KtmNh94v5n9xN1P7ufCuZWFliO9I1IWOeJmyckRKUsUB8CqtevZtn0ne/bsZeHwCCuXL2NJFxNHI302RVH1Tc+aLu01s0ObDcmY2avd/UOdXKDZMI0QQggxQW61aQa9tPdRDzwm2Xftdb/YPvClva3mjDSdG9JpQ0QIIYQQxeM+XnaEvlBtGiGEEKLijFd8mEaNESGEEKWTYoglt6GefQk1RoQQQoiKE2W/k15RY0QIIYSoOFUfpim1aq8QQgghRKmNkSjlqSNlkSNuFjniZsnJESlLTo41Z27khMVLGR5Z0dP5KbMUgbsnO8qg1T4jFwIr3f36fi7QbJ+RKCWuI2WRI24WOeJmyckRKUsVHa0msI7t2MWsoSFWr9vA1i2bmr6u1QTWbrIMep+Rh97vyGStiJv3XDnwfUZa9Yx8lNquq281s/1SXzhSeeooWeSIm0WOuFlyckTKkpMDYMH8o5k7Z3bX5xWRRUylaWPE3T8NHAPMAcbM7E1m9saJo98LRypPHSWLHHGzyBE3S06OSFlycqQiUpbJZFu1t86dwB3AAcBsoKMt3sxsFBgFsJlzmTHjoOleM+U5leyWI2oWOeJmyckRKUtOjlREyjKZKDl6pWljxMwWARuBC4AnuvtvOpW6+2ZgMzSfMxKpPHWULHLEzSJH3Cw5OSJlycmRikhZJpPz0t63Aie5+5u7aYh0SqTy1FGyyBE3ixxxs+TkiJQlJ0cqImXJjVaF8grdEzdSeeooWeSIm0WOuFlyckTKkpMDYNXa9WzbvpM9e/aycHiElcuXsaTLyaepshRB1Ydpmi7tTUWzYRohhBAiJZFq0wx6ae/Bsw9P9l172+0/DLW0VwghhBCicFSbRgghhKg4VR+mUWNECCFEFqQYYkkx1FMGOa+mEUIIIYQoHPWMCCGEEBWn6sM0qtobLIsccbPIETdLTo5IWeS4N6kq/xbBuHuyowxKW9obpSJkpCxyxM0iR9wsOTkiZdlXHSkq/wLs98BHDXR57H1nPTLZl/mvf/PjWEt7zazpjjBmdlI/F45UzTFKFjniZpEjbpacHJGyyDGVFJV/i6LqhfLaDdNcaGZfN7NDpvndW/q5cKRqjlGyyBE3ixxxs+TkiJRFjmpR9WGado2RncAngcum6Qlp2o1jZqNmNmZmY+PjdzR7zZTnVCVTjqhZ5IibJSdHpCxyiEHSrjHi7v4hYCHwd2b2ETObNfG7FidtdvcF7r5gxoyDpn1NpGqOUbLIETeLHHGz5OSIlEWOauHuyY4y6Gg1jbtfAxwH/AzYbmZP6ffCkao5RskiR9wscsTNkpMjUhY5qkXV54y022fknr4td78LeLOZXQScBzyonwtHquYYJYsccbPIETdLTo5IWeSYSorKv2J6Wi7tNbNhd986zfP3B17j7uvbXUBVe4UQQlSFVNvBD3pp7/4HHJrsu/b3v9sda2nvdA2R+vO/7KQhIoQQQojiGeScETNbZGY/MLNrzezN0/z+ADP7VP333zGzee2cqk0jhBBCiI4ws5nA+4DnAkcCJ5vZkZNethz4pbs/BngX8I/tvGqMCCGEEBXHEx5teDJwrbtf5+6/B84HTpz0mhOBc+s/fxZYaNOtr77XDSTs2umjS2hUjrSOSFnkiJtFjrhZcnJEyhLFEfkARoGxhmO04XcvBs5peLwMOHvS+ZcDhzY8/hHwwFbXjNIzMipHckcqjxzpHak8cqR3pPLIUYwnJ0dYvGGvsPqxueHX0/VwTO5Q6eQ19yJKY0QIIYQQ8dkNHNbw+FDgpmavMbP7AHOB21pJ1RgRQgghRKdsAw43s0ea2f7AUuCCSa+5APir+s8vBi72+nhNM9ptejYoNrd/iRwleeRI70jlkSO9I5VHjmI8OTkqibvfZWanAl8BZgIfdvcrzOwMYMzdLwD+Bfi4mV1LrUdkaTtvy03PhBBCCCGKRsM0QgghhCgVNUaEEEIIUSqlNkbM7EVm5mb22D4cd5vZDjP7bzP7vpk9rQfHQ8zsfDP7kZldaWYXmtkRPWS4op7jjWbW9Xvb4Jk4pmyz26NnXpfnP9jMPmlm15nZ98zsUjN7UZeOX096/AozO7sbRyvfoB2N55rZ88zsh2b28EFmqJ/vZvbxhsf3MbOfm9m/dek4q+Hxm8zsbT1kOdTMvlh/L35kZu+pT2jrxjHxZ/VyM/uMmc3qM8d1Zna2mR3QR45/NbP7dZuj7nlr/e+BnXVfVxXOzewBDf/d/o+Z3djwuKP31szmmdnlk557m5m9qYscl5jZcyY9d5qZvb/D899lZqc1PP6KmZ3T8PgsM3tjh67DzOzHZnZw/fH9648f0dndgNX4lpk9t+G5l1it8GunjhdN+nt1h5mNNzpF75TdM3Iy8C06mNzSgt+6+3x3fwLwFuAd3ZxsZgZ8AbjE3R/t7kcCq4EH95DhKODZwPOAtd3kmOSZOHqt/zPZc32nJ9bfj63Af7r7o9z9SdQ+n0N7zJIVZrYQeC+wyN1/WkKEO4DHm9lQ/fGzgRu7dPwO+Esze2CvIep/Tj4PbHX3w4EjgPsC/9ClauLP6uOB3wMr+sxxODAEvLOPHLcBr+vyfMzsOOD5wBPd/U+APwdu6Mbh7rdO/HcLbALe1fDf8e+7zdQH5zH17+Wl9ec74b+ApwHU/2H2QOCoht8/Dfh2JyJ3vwH4ADDx9+F6YLO7/6TDLNRXcqwANprZgWZ2ELU/qx1/zu7+hca/V4H3A9+kNpFT9ElpjREzuy9wPLU97PtpjDQyB/hll+c8E7jT3TdNPOHuO9y9p9KN7n4LtQ1xTq3/RVk1ngX8ftL78RN3f2+JmUJgZn8GfAhY7O4/KjHKl4HF9Z9PpvMviAnuorYa4A19ZHgW8L/u/hEAd7+77ntlL70bdb4JPCZRjlPqf8f0wqXAIT2c91DgF+7+u3qWX7j75P0XqsJngedP9DDVe1cfRu0fj53wbeqNEWqNkMuB2+u9GgcAjwO2d5HnXcBT670tfwqc1eb1U3D3y4F/Bf4vtX8sfqzX/46t1nN+OrDM3cd7cYh7U2bPyDBwkbtfA9xmZk/s0TNU7y67GjgHWNfl+Y8HvtfjtafF3a+j9t7+UZenTtzLxPHSHiM0er7Q5blHAd/v8brNMuwAzkjgLJMDgC8Cw+5+dclZzgeWmtmBwJ8A3+nB8T7g5WY2t8cMRzHpvxt33wv8lO4bFBMbIz0X2JUox/U95pgJLGTqvgmd8FXgMDO7xszeb2ZP78ERAne/FfgusKj+1FLgU+32img4/ybgrvpQ5tOoNfC+AxwHLAB2dtPT4+53AquoNUpO66OX6O3Ay6j9Weu29wwAM9sP+CTwppJ6R7OkzMbIydT+UqX+/yf36JnoXn0stf9wPhakR6KXDJOHVz7V47UbPV3N9ZiMmb3PavNgtvWRYT61f0VUmTupdT0vLzuIu+8E5lH7b+bCHh17gY8Br+8xhjH99s7Nnm/GUL2xOkatIfMvCXN0w0SOW4GDgX/v8nzc/dfAk6j1jP4c+JSZvaJbTwKavf/d7uPQOFTTzRDNBBO9IxONkUsbHv9Xly6oNSBupvYPyJ5w9zuATwEfn+jB6oF1wBXufn7bV4qOKaUxYmYPoNa9eo6ZXU+txfvSfhsR7n4ptbHJB3Vx2hXU/gJJhpk9CrgbuCWld0BcAdzTS+Xur6P2L8Vu3tMcGQdeAhxrZqvLDkPtX+4b6P4LopF3U2tcHdTDuVdQ+xfuPZjZHGpbQHfT9d3YaP2bHv7F2yzHg4EfdJsDeASwPz3MGYHaMJG7X+Lua4FTgSW9ePrkVuD+k547GPhFl56t1KqtPhEYcvdue0wn5o0cTW2Y5jJqPSMdzxeZwMzmU5sf9VTgDWb20C6zNDJeP7rGzJ5B7TM9tY/ri2koq2fkxdTG6x7h7vPc/TDgx9TGAnvGaqtyZlL7j7FTLgYOMLNXN3iO7bWL1cweRG3i2dmddmkG4w2cGaEAAAILSURBVGLgQDN7bcNzvc4ByAp3/w21CYovN7Oye0g+DJzh7t0Oa9yDu98GfJreenu+Bswys1PgnuGNs4CP1t+nQdEsx9nu/ttuZe7+K2q9RW+qd8d3jJn9sZkd3vDUfKDjSZapqPfQ3FyfbE19FcoiOp/v0ei5hNqftV4avd+m9t/LbfVG2m3A/ag1SC7tVFL/R+oHqA3P/BT4J2oN8YFiZvcHPgKc4u63D/r6uVNWY+RkaitYGvkctbG8brlnbgK17re/qk9i64h6g+FFwLOttjzxCuBtTC3800mGK4D/oDZ2/PYuzp/smTh6XU3TM/X3Yxh4en353HeBc6lN+qos9TkJvXbL3kP9L9RFwBozO7EHxSwz291wdLS8cZocu939Pb2cO4mzqPUmdnv9if9uTjKzHwLXAP9LbSXawGjI8eJ6jluBcXfvdlVPo3M78N90P7H+vsC5VtseYCdwJLW/S8rgFGp/RndQ+wfG23ucrHke8AT+MKTeDbuo/dm6bNJzv3L3bnppXg381N0nhs7eDzy2hDk5K6jNA/xAorl9ogFtBy/2CczsCcCH3P3JZWcRxWG1fYbOA/7S3ZNOTBdCFIcaIyJ7zGwFta7309z9q2XnEUIIcW/UGBFCCCFEqZS9A6sQQggh9nHUGBFCCCFEqagxIoQQQohSUWNECCGEEKWixogQQgghSuX/AzAQ315hjFBvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_train, predictions.astype(int))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "# seed seems not work for keras, might need to run more than once to get the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning structure 3: 26 inputs vs one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",y_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "# change sigomiod to softmax made acc increasing 100%\n",
    "model.add(Dense(1, activation='relu'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 211.9231 - acc: 0.0385\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 66us/step - loss: 211.0751 - acc: 0.0385\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 209.3372 - acc: 0.0385\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 64us/step - loss: 202.2992 - acc: 0.0385\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 77us/step - loss: 190.5963 - acc: 0.0385\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 55us/step - loss: 177.7210 - acc: 0.0769\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 65us/step - loss: 162.9270 - acc: 0.0385\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 145.3545 - acc: 0.0385\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 126.1160 - acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 106.2557 - acc: 0.0385\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 87.5653 - acc: 0.0385\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 121us/step - loss: 72.1056 - acc: 0.0385\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 61.1387 - acc: 0.0385\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 54.4503 - acc: 0.1154\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 50.7663 - acc: 0.0385\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 48.7158 - acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 47.3918 - acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 148us/step - loss: 46.3451 - acc: 0.0385\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 45.3960 - acc: 0.0385\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 44.4788 - acc: 0.0385\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 105us/step - loss: 43.5703 - acc: 0.0385\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 42.6658 - acc: 0.0385\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 41.7641 - acc: 0.0385\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 40.8621 - acc: 0.0385\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 39.9594 - acc: 0.0385\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 39.0544 - acc: 0.0385\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 145us/step - loss: 38.1477 - acc: 0.0385\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 128us/step - loss: 37.2378 - acc: 0.0385\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 36.3272 - acc: 0.0385\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 35.4144 - acc: 0.0385\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 34.4990 - acc: 0.0385\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 107us/step - loss: 33.5818 - acc: 0.0385\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 112us/step - loss: 32.6612 - acc: 0.0385\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 132us/step - loss: 31.7407 - acc: 0.0385\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 164us/step - loss: 30.8172 - acc: 0.0385\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 29.8941 - acc: 0.0385\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 116us/step - loss: 28.9707 - acc: 0.0385\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 28.0471 - acc: 0.0385\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 27.1274 - acc: 0.0385\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 26.2096 - acc: 0.0385\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 184us/step - loss: 25.2967 - acc: 0.0385\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 217us/step - loss: 24.3867 - acc: 0.0385\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 23.4820 - acc: 0.0385\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 176us/step - loss: 22.5844 - acc: 0.0385\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 185us/step - loss: 21.6928 - acc: 0.0385\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 20.8110 - acc: 0.0385\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 19.9399 - acc: 0.0385\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 126us/step - loss: 19.0788 - acc: 0.0385\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 18.2301 - acc: 0.0385\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 67us/step - loss: 17.3953 - acc: 0.0385\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 65us/step - loss: 16.5744 - acc: 0.0385\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 73us/step - loss: 15.7717 - acc: 0.0385\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 141us/step - loss: 14.9849 - acc: 0.0385\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 14.2173 - acc: 0.0385\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 13.4684 - acc: 0.0385\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 12.7412 - acc: 0.0385\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 107us/step - loss: 12.0358 - acc: 0.0385\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 122us/step - loss: 11.3496 - acc: 0.0385\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 10.6872 - acc: 0.0385\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 10.0481 - acc: 0.0769\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 159us/step - loss: 9.4346 - acc: 0.0769\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 146us/step - loss: 8.8461 - acc: 0.0769\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 8.2835 - acc: 0.0769\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 74us/step - loss: 7.7449 - acc: 0.0769\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 7.2316 - acc: 0.0769\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 6.7434 - acc: 0.0769\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 6.3033 - acc: 0.0769\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 5.8892 - acc: 0.0769\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 112us/step - loss: 5.5006 - acc: 0.0769\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 148us/step - loss: 5.1312 - acc: 0.0769\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 134us/step - loss: 4.7817 - acc: 0.0769\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 80us/step - loss: 4.4548 - acc: 0.0769\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 107us/step - loss: 4.1515 - acc: 0.1154\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 75us/step - loss: 3.8658 - acc: 0.1538\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 70us/step - loss: 3.5967 - acc: 0.1538\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 72us/step - loss: 3.3438 - acc: 0.1538\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 3.1057 - acc: 0.1538\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 2.8858 - acc: 0.1923\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 122us/step - loss: 2.6810 - acc: 0.2308\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 152us/step - loss: 2.4902 - acc: 0.2308\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 2.3101 - acc: 0.2308\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 2.1408 - acc: 0.2308\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 1.9828 - acc: 0.2308\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 1.8357 - acc: 0.2308\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 67us/step - loss: 1.6987 - acc: 0.2308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 61us/step - loss: 1.5726 - acc: 0.2308\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 63us/step - loss: 1.4587 - acc: 0.2308\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 1.3522 - acc: 0.2308\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 59us/step - loss: 1.2532 - acc: 0.2692\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 77us/step - loss: 1.1615 - acc: 0.2692\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 1.0764 - acc: 0.3077\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 135us/step - loss: 0.9973 - acc: 0.3077\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 0.9246 - acc: 0.3846\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 0.8570 - acc: 0.4231\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.7939 - acc: 0.4615\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 105us/step - loss: 0.7357 - acc: 0.5000\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.6818 - acc: 0.5000\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 168us/step - loss: 0.6324 - acc: 0.5000\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 121us/step - loss: 0.5879 - acc: 0.5000\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 167us/step - loss: 0.5471 - acc: 0.5000\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 164us/step - loss: 0.5086 - acc: 0.5385\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 0.4732 - acc: 0.5385\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 73us/step - loss: 0.4405 - acc: 0.5385\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 123us/step - loss: 0.4101 - acc: 0.5769\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.3819 - acc: 0.5769\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.3558 - acc: 0.6154\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 0.3322 - acc: 0.6538\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 73us/step - loss: 0.3099 - acc: 0.6923\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.2900 - acc: 0.6923\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 116us/step - loss: 0.2718 - acc: 0.6923\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 0.2548 - acc: 0.7308\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 0.2392 - acc: 0.7308\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 0.2246 - acc: 0.7692\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.2113 - acc: 0.8077\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 72us/step - loss: 0.1992 - acc: 0.8077\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 68us/step - loss: 0.1876 - acc: 0.8077\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 65us/step - loss: 0.1770 - acc: 0.8077\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.1671 - acc: 0.8077\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 0.1579 - acc: 0.8077\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 65us/step - loss: 0.1492 - acc: 0.8077\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 68us/step - loss: 0.1412 - acc: 0.8462\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 70us/step - loss: 0.1337 - acc: 0.8462\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 72us/step - loss: 0.1269 - acc: 0.8462\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 68us/step - loss: 0.1202 - acc: 0.8846\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 67us/step - loss: 0.1140 - acc: 0.8846\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 70us/step - loss: 0.1082 - acc: 0.9231\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.1028 - acc: 0.9231\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 0.0977 - acc: 0.9231\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 0.0929 - acc: 0.9231\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 80us/step - loss: 0.0888 - acc: 0.9231\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 75us/step - loss: 0.0844 - acc: 0.9231\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 80us/step - loss: 0.0804 - acc: 0.9231\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0767 - acc: 0.9231\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 0.0732 - acc: 0.9231\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 63us/step - loss: 0.0703 - acc: 0.9231\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 107us/step - loss: 0.0669 - acc: 0.9231\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 0.0639 - acc: 0.9231\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0612 - acc: 0.9231\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 70us/step - loss: 0.0588 - acc: 0.9231\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0569 - acc: 0.9231\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0543 - acc: 0.9231\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0523 - acc: 0.9231\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 0.0504 - acc: 0.9231\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 0.0485 - acc: 0.9231\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0469 - acc: 0.9231\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 0.0452 - acc: 0.9231\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 71us/step - loss: 0.0435 - acc: 0.9231\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 71us/step - loss: 0.0420 - acc: 0.9231\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0406 - acc: 0.9231\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0393 - acc: 0.9231\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0381 - acc: 0.9615\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 70us/step - loss: 0.0367 - acc: 0.9615\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 0.0356 - acc: 0.9615\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0345 - acc: 0.9615\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 72us/step - loss: 0.0333 - acc: 0.9615\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 0.0324 - acc: 0.9615\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 0.0316 - acc: 0.9615\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 75us/step - loss: 0.0305 - acc: 0.9615\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0296 - acc: 0.9615\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 0.0288 - acc: 0.9615\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 0.0279 - acc: 0.9615\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 117us/step - loss: 0.0272 - acc: 0.9615\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 61us/step - loss: 0.0267 - acc: 0.9615\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 0s 62us/step - loss: 0.0258 - acc: 0.9615\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 70us/step - loss: 0.0250 - acc: 0.9615\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 61us/step - loss: 0.0243 - acc: 0.9615\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 0.0237 - acc: 0.9615\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0231 - acc: 0.9615\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 64us/step - loss: 0.0225 - acc: 0.9615\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0220 - acc: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 65us/step - loss: 0.0216 - acc: 0.9615\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 72us/step - loss: 0.0210 - acc: 0.9615\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0204 - acc: 0.9615\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0199 - acc: 0.9615\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0194 - acc: 0.9615\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0190 - acc: 0.9615\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0186 - acc: 0.9615\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 73us/step - loss: 0.0182 - acc: 0.9615\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0178 - acc: 0.9615\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 71us/step - loss: 0.0174 - acc: 0.9615\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 0.0170 - acc: 0.9615\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0166 - acc: 0.9615\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.0163 - acc: 0.9615\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 0.0160 - acc: 0.9615\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0156 - acc: 0.9615\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 128us/step - loss: 0.0153 - acc: 0.9615\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0151 - acc: 0.9615\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 0.0147 - acc: 0.9615\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 67us/step - loss: 0.0144 - acc: 0.9615\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 63us/step - loss: 0.0141 - acc: 0.9615\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 72us/step - loss: 0.0138 - acc: 0.9615\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0135 - acc: 0.9615\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 64us/step - loss: 0.0132 - acc: 0.9615\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 74us/step - loss: 0.0129 - acc: 0.9615\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0127 - acc: 0.9615\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.0125 - acc: 0.9615\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0122 - acc: 0.9615\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 67us/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 131us/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 80us/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 129us/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 176us/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 126us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 146us/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 71us/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 105us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 74us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 68us/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 66us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 73us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 75us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 122us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 80us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 62us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 71us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 68us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 74us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 67us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 65us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 64us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 74us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 74us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 0.0040 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 71us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 77us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 77us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 72us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 80us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 65us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 69us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 66us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 80us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 67us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 70us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 77us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 78us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 66us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 67us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 64us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 71us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 68us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0018 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3c7b7128>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return (I2L[index])\n",
    "\n",
    "def predict_results(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index = np.argmax(predictions, axis=1)\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index))\n",
    "\n",
    "    return (prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20679247],\n",
       "       [ 1.0567062 ],\n",
       "       [ 1.9992906 ],\n",
       "       [ 2.99395   ],\n",
       "       [ 3.9879107 ],\n",
       "       [ 4.994105  ],\n",
       "       [ 5.9945054 ],\n",
       "       [ 6.993283  ],\n",
       "       [ 7.9956193 ],\n",
       "       [ 8.994582  ],\n",
       "       [ 9.994356  ],\n",
       "       [10.998659  ],\n",
       "       [11.999876  ],\n",
       "       [12.99347   ],\n",
       "       [13.996191  ],\n",
       "       [14.998209  ],\n",
       "       [15.995681  ],\n",
       "       [17.00182   ],\n",
       "       [18.000854  ],\n",
       "       [18.999104  ],\n",
       "       [20.003113  ],\n",
       "       [21.00059   ],\n",
       "       [21.998987  ],\n",
       "       [23.00387   ],\n",
       "       [24.003542  ],\n",
       "       [25.001612  ]], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the prediction is quite good compared with the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed doesn't help for keras, so might need to run more than once to get the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3dad88d0>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_train, np.rint(model.predict(x_train)))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_153 (Dense)            (None, 20)                540       \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the model just has 2 layers, we can still get good prediction results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning structure 4: 26 inputs vs 26 outputs (as a classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 26 y_train: 26\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train:\",x_train.shape[1],\"y_train:\",y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try structure without hidden layers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(y_train.shape[1], input_dim=x_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 0.1606 - acc: 0.9615\n",
      "Epoch 2/300\n",
      "52/52 [==============================] - 0s 87us/step - loss: 0.1605 - acc: 0.9615\n",
      "Epoch 3/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1603 - acc: 0.9615\n",
      "Epoch 4/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1602 - acc: 0.9615\n",
      "Epoch 5/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1601 - acc: 0.9615\n",
      "Epoch 6/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1599 - acc: 0.9615\n",
      "Epoch 7/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1598 - acc: 0.9615\n",
      "Epoch 8/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1597 - acc: 0.9615\n",
      "Epoch 9/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1596 - acc: 0.9615\n",
      "Epoch 10/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1595 - acc: 0.9615\n",
      "Epoch 11/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1593 - acc: 0.9615\n",
      "Epoch 12/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1592 - acc: 0.9615\n",
      "Epoch 13/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1591 - acc: 0.9615\n",
      "Epoch 14/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1590 - acc: 0.9615\n",
      "Epoch 15/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1588 - acc: 0.9615\n",
      "Epoch 16/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1587 - acc: 0.9615\n",
      "Epoch 17/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1586 - acc: 0.9615\n",
      "Epoch 18/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1585 - acc: 0.9615\n",
      "Epoch 19/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1583 - acc: 0.9615\n",
      "Epoch 20/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1582 - acc: 0.9615\n",
      "Epoch 21/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1581 - acc: 0.9615\n",
      "Epoch 22/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1580 - acc: 0.9615\n",
      "Epoch 23/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1578 - acc: 0.9615\n",
      "Epoch 24/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1577 - acc: 0.9615\n",
      "Epoch 25/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1576 - acc: 0.9615\n",
      "Epoch 26/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1575 - acc: 0.9615\n",
      "Epoch 27/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1573 - acc: 0.9615\n",
      "Epoch 28/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1572 - acc: 0.9615\n",
      "Epoch 29/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1571 - acc: 0.9615\n",
      "Epoch 30/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1570 - acc: 0.9615\n",
      "Epoch 31/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1568 - acc: 0.9615\n",
      "Epoch 32/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1567 - acc: 0.9615\n",
      "Epoch 33/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1566 - acc: 0.9615\n",
      "Epoch 34/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1565 - acc: 0.9615\n",
      "Epoch 35/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1564 - acc: 0.9615\n",
      "Epoch 36/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1562 - acc: 0.9615\n",
      "Epoch 37/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1561 - acc: 0.9615\n",
      "Epoch 38/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1560 - acc: 0.9615\n",
      "Epoch 39/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1559 - acc: 0.9615\n",
      "Epoch 40/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1557 - acc: 0.9615\n",
      "Epoch 41/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1556 - acc: 0.9615\n",
      "Epoch 42/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1555 - acc: 0.9615\n",
      "Epoch 43/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1554 - acc: 0.9615\n",
      "Epoch 44/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1552 - acc: 0.9615\n",
      "Epoch 45/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1551 - acc: 0.9615\n",
      "Epoch 46/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 47/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1549 - acc: 0.9615\n",
      "Epoch 48/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1547 - acc: 0.9615\n",
      "Epoch 49/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1546 - acc: 0.9615\n",
      "Epoch 50/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1545 - acc: 0.9615\n",
      "Epoch 51/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1544 - acc: 0.9615\n",
      "Epoch 52/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1542 - acc: 0.9615\n",
      "Epoch 53/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1541 - acc: 0.9615\n",
      "Epoch 54/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1540 - acc: 0.9615\n",
      "Epoch 55/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1539 - acc: 0.9615\n",
      "Epoch 56/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1538 - acc: 0.9615\n",
      "Epoch 57/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1536 - acc: 0.9615\n",
      "Epoch 58/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1535 - acc: 0.9615\n",
      "Epoch 59/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1534 - acc: 0.9615\n",
      "Epoch 60/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1533 - acc: 0.9615\n",
      "Epoch 61/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1531 - acc: 0.9615\n",
      "Epoch 62/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1530 - acc: 0.9615\n",
      "Epoch 63/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1529 - acc: 0.9615\n",
      "Epoch 64/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1528 - acc: 0.9615\n",
      "Epoch 65/300\n",
      "52/52 [==============================] - 0s 149us/step - loss: 0.1526 - acc: 0.9615\n",
      "Epoch 66/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1525 - acc: 0.9615\n",
      "Epoch 67/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1524 - acc: 0.9615\n",
      "Epoch 68/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1523 - acc: 0.9615\n",
      "Epoch 69/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1522 - acc: 0.9615\n",
      "Epoch 70/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1520 - acc: 0.9615\n",
      "Epoch 71/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1519 - acc: 0.9615\n",
      "Epoch 72/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1518 - acc: 0.9615\n",
      "Epoch 73/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1517 - acc: 0.9615\n",
      "Epoch 74/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1515 - acc: 0.9615\n",
      "Epoch 75/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1514 - acc: 0.9615\n",
      "Epoch 76/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1513 - acc: 0.9615\n",
      "Epoch 77/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1512 - acc: 0.9615\n",
      "Epoch 78/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1510 - acc: 0.9615\n",
      "Epoch 79/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1509 - acc: 0.9615\n",
      "Epoch 80/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1508 - acc: 0.9615\n",
      "Epoch 81/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1507 - acc: 0.9615\n",
      "Epoch 82/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1505 - acc: 0.9615\n",
      "Epoch 83/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1504 - acc: 0.9615\n",
      "Epoch 84/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1503 - acc: 0.9615\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 105us/step - loss: 0.1502 - acc: 0.9615\n",
      "Epoch 86/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1501 - acc: 0.9615\n",
      "Epoch 87/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1499 - acc: 0.9615\n",
      "Epoch 88/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1498 - acc: 0.9615\n",
      "Epoch 89/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1497 - acc: 0.9615\n",
      "Epoch 90/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1496 - acc: 0.9615\n",
      "Epoch 91/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1494 - acc: 0.9615\n",
      "Epoch 92/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1493 - acc: 0.9615\n",
      "Epoch 93/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1492 - acc: 0.9615\n",
      "Epoch 94/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1491 - acc: 0.9615\n",
      "Epoch 95/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1489 - acc: 0.9615\n",
      "Epoch 96/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1488 - acc: 0.9615\n",
      "Epoch 97/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1487 - acc: 0.9615\n",
      "Epoch 98/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1486 - acc: 0.9615\n",
      "Epoch 99/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1484 - acc: 0.9615\n",
      "Epoch 100/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1483 - acc: 0.9615\n",
      "Epoch 101/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1482 - acc: 0.9615\n",
      "Epoch 102/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1481 - acc: 0.9615\n",
      "Epoch 103/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1480 - acc: 0.9615\n",
      "Epoch 104/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1478 - acc: 0.9615\n",
      "Epoch 105/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1477 - acc: 0.9615\n",
      "Epoch 106/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1476 - acc: 0.9615\n",
      "Epoch 107/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1475 - acc: 0.9615\n",
      "Epoch 108/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1473 - acc: 0.9615\n",
      "Epoch 109/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1472 - acc: 0.9615\n",
      "Epoch 110/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1471 - acc: 0.9615\n",
      "Epoch 111/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1470 - acc: 0.9615\n",
      "Epoch 112/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1468 - acc: 0.9615\n",
      "Epoch 113/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1467 - acc: 0.9615\n",
      "Epoch 114/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1466 - acc: 0.9615\n",
      "Epoch 115/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1465 - acc: 0.9615\n",
      "Epoch 116/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1463 - acc: 0.9615\n",
      "Epoch 117/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1462 - acc: 0.9615\n",
      "Epoch 118/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1461 - acc: 0.9615\n",
      "Epoch 119/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1460 - acc: 0.9615\n",
      "Epoch 120/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1458 - acc: 0.9615\n",
      "Epoch 121/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1457 - acc: 0.9615\n",
      "Epoch 122/300\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1455 - acc: 0.961 - 0s 115us/step - loss: 0.1456 - acc: 0.9615\n",
      "Epoch 123/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1455 - acc: 0.9615\n",
      "Epoch 124/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1454 - acc: 0.9615\n",
      "Epoch 125/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1452 - acc: 0.9615\n",
      "Epoch 126/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1451 - acc: 0.9615\n",
      "Epoch 127/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1450 - acc: 0.9615\n",
      "Epoch 128/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1449 - acc: 0.9615\n",
      "Epoch 129/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1447 - acc: 0.9615\n",
      "Epoch 130/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1446 - acc: 0.9615\n",
      "Epoch 131/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1445 - acc: 0.9615\n",
      "Epoch 132/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1444 - acc: 0.9615\n",
      "Epoch 133/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1442 - acc: 0.9615\n",
      "Epoch 134/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1441 - acc: 0.9615\n",
      "Epoch 135/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1440 - acc: 0.9615\n",
      "Epoch 136/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1439 - acc: 0.9615\n",
      "Epoch 137/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1437 - acc: 0.9615\n",
      "Epoch 138/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1436 - acc: 0.9615\n",
      "Epoch 139/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1435 - acc: 0.9615\n",
      "Epoch 140/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1434 - acc: 0.9615\n",
      "Epoch 141/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1433 - acc: 0.9615\n",
      "Epoch 142/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1431 - acc: 0.9615\n",
      "Epoch 143/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1430 - acc: 0.9615\n",
      "Epoch 144/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1429 - acc: 0.9615\n",
      "Epoch 145/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1428 - acc: 0.9615\n",
      "Epoch 146/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1426 - acc: 0.9615\n",
      "Epoch 147/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1425 - acc: 0.9615\n",
      "Epoch 148/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1424 - acc: 0.9615\n",
      "Epoch 149/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1423 - acc: 0.9615\n",
      "Epoch 150/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1421 - acc: 0.9615\n",
      "Epoch 151/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1420 - acc: 0.9615\n",
      "Epoch 152/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1419 - acc: 0.9615\n",
      "Epoch 153/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1418 - acc: 0.9615\n",
      "Epoch 154/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1417 - acc: 0.9615\n",
      "Epoch 155/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1415 - acc: 0.9615\n",
      "Epoch 156/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1414 - acc: 0.9615\n",
      "Epoch 157/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1413 - acc: 0.9615\n",
      "Epoch 158/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1412 - acc: 0.9615\n",
      "Epoch 159/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1410 - acc: 0.9615\n",
      "Epoch 160/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1409 - acc: 0.9615\n",
      "Epoch 161/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1408 - acc: 0.9615\n",
      "Epoch 162/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1407 - acc: 0.9615\n",
      "Epoch 163/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1405 - acc: 0.9615\n",
      "Epoch 164/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1404 - acc: 0.9615\n",
      "Epoch 165/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1403 - acc: 0.9615\n",
      "Epoch 166/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1402 - acc: 0.9615\n",
      "Epoch 167/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1401 - acc: 0.9615\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 123us/step - loss: 0.1399 - acc: 0.9615\n",
      "Epoch 169/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1398 - acc: 0.9615\n",
      "Epoch 170/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1397 - acc: 0.9615\n",
      "Epoch 171/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1396 - acc: 0.9615\n",
      "Epoch 172/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1394 - acc: 0.9615\n",
      "Epoch 173/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1393 - acc: 0.9615\n",
      "Epoch 174/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1392 - acc: 0.9615\n",
      "Epoch 175/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1391 - acc: 0.9615\n",
      "Epoch 176/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1389 - acc: 0.9615\n",
      "Epoch 177/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1388 - acc: 0.9615\n",
      "Epoch 178/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1387 - acc: 0.9615\n",
      "Epoch 179/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1386 - acc: 0.9615\n",
      "Epoch 180/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1385 - acc: 0.9615\n",
      "Epoch 181/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1383 - acc: 0.9615\n",
      "Epoch 182/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1382 - acc: 0.9615\n",
      "Epoch 183/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1381 - acc: 0.9615\n",
      "Epoch 184/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1380 - acc: 0.9615\n",
      "Epoch 185/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1378 - acc: 0.9615\n",
      "Epoch 186/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1377 - acc: 0.9615\n",
      "Epoch 187/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1376 - acc: 0.9615\n",
      "Epoch 188/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1375 - acc: 0.9615\n",
      "Epoch 189/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1373 - acc: 0.9615\n",
      "Epoch 190/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1372 - acc: 0.9615\n",
      "Epoch 191/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1371 - acc: 0.9615\n",
      "Epoch 192/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1370 - acc: 0.9615\n",
      "Epoch 193/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1369 - acc: 0.9615\n",
      "Epoch 194/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1367 - acc: 0.9615\n",
      "Epoch 195/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1366 - acc: 0.9615\n",
      "Epoch 196/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1365 - acc: 0.9615\n",
      "Epoch 197/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1364 - acc: 0.9615\n",
      "Epoch 198/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1362 - acc: 0.9615\n",
      "Epoch 199/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1361 - acc: 0.9615\n",
      "Epoch 200/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1360 - acc: 0.9615\n",
      "Epoch 201/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1359 - acc: 0.9615\n",
      "Epoch 202/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1357 - acc: 0.9615\n",
      "Epoch 203/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1356 - acc: 0.9615\n",
      "Epoch 204/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1355 - acc: 0.9615\n",
      "Epoch 205/300\n",
      "52/52 [==============================] - 0s 150us/step - loss: 0.1354 - acc: 0.9615\n",
      "Epoch 206/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1353 - acc: 0.9615\n",
      "Epoch 207/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1351 - acc: 0.9615\n",
      "Epoch 208/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1350 - acc: 0.9615\n",
      "Epoch 209/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1349 - acc: 0.9615\n",
      "Epoch 210/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1348 - acc: 0.9615\n",
      "Epoch 211/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1346 - acc: 0.9615\n",
      "Epoch 212/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1345 - acc: 0.9615\n",
      "Epoch 213/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1344 - acc: 0.9615\n",
      "Epoch 214/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1343 - acc: 0.9615\n",
      "Epoch 215/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1341 - acc: 0.9615\n",
      "Epoch 216/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1340 - acc: 0.9615\n",
      "Epoch 217/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1339 - acc: 0.9615\n",
      "Epoch 218/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1338 - acc: 0.9615\n",
      "Epoch 219/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1337 - acc: 0.9615\n",
      "Epoch 220/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1335 - acc: 0.9615\n",
      "Epoch 221/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1334 - acc: 0.9615\n",
      "Epoch 222/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1333 - acc: 0.9615\n",
      "Epoch 223/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1332 - acc: 0.9615\n",
      "Epoch 224/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1330 - acc: 0.9615\n",
      "Epoch 225/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1329 - acc: 0.9615\n",
      "Epoch 226/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1328 - acc: 0.9615\n",
      "Epoch 227/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1327 - acc: 0.9615\n",
      "Epoch 228/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1325 - acc: 0.9615\n",
      "Epoch 229/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1324 - acc: 0.9615\n",
      "Epoch 230/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1323 - acc: 0.9615\n",
      "Epoch 231/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1322 - acc: 0.9615\n",
      "Epoch 232/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1321 - acc: 0.9615\n",
      "Epoch 233/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1319 - acc: 0.9615\n",
      "Epoch 234/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1318 - acc: 0.9615\n",
      "Epoch 235/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1317 - acc: 0.9615\n",
      "Epoch 236/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1316 - acc: 0.9615\n",
      "Epoch 237/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1314 - acc: 0.9615\n",
      "Epoch 238/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1313 - acc: 0.9615\n",
      "Epoch 239/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1312 - acc: 0.9615\n",
      "Epoch 240/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1311 - acc: 0.9615\n",
      "Epoch 241/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1309 - acc: 0.9615\n",
      "Epoch 242/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1308 - acc: 0.9615\n",
      "Epoch 243/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1307 - acc: 0.9615\n",
      "Epoch 244/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1306 - acc: 0.9615\n",
      "Epoch 245/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1305 - acc: 0.9615\n",
      "Epoch 246/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1303 - acc: 0.9615\n",
      "Epoch 247/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1302 - acc: 0.9615\n",
      "Epoch 248/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1301 - acc: 0.9615\n",
      "Epoch 249/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1300 - acc: 0.9615\n",
      "Epoch 250/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1298 - acc: 0.9615\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 104us/step - loss: 0.1297 - acc: 0.9615\n",
      "Epoch 252/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1296 - acc: 0.9615\n",
      "Epoch 253/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1295 - acc: 0.9615\n",
      "Epoch 254/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1293 - acc: 0.9615\n",
      "Epoch 255/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1292 - acc: 0.9615\n",
      "Epoch 256/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1291 - acc: 0.9615\n",
      "Epoch 257/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1290 - acc: 0.9615\n",
      "Epoch 258/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1289 - acc: 0.9615\n",
      "Epoch 259/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1287 - acc: 0.9615\n",
      "Epoch 260/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1286 - acc: 0.9615\n",
      "Epoch 261/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1285 - acc: 0.9615\n",
      "Epoch 262/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1284 - acc: 0.9615\n",
      "Epoch 263/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1282 - acc: 0.9615\n",
      "Epoch 264/300\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.1281 - acc: 0.9615\n",
      "Epoch 265/300\n",
      "52/52 [==============================] - 0s 199us/step - loss: 0.1280 - acc: 0.9615\n",
      "Epoch 266/300\n",
      "52/52 [==============================] - 0s 205us/step - loss: 0.1279 - acc: 0.9615\n",
      "Epoch 267/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1278 - acc: 0.9615\n",
      "Epoch 268/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1276 - acc: 0.9615\n",
      "Epoch 269/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.1275 - acc: 0.9615\n",
      "Epoch 270/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1274 - acc: 0.9615\n",
      "Epoch 271/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1273 - acc: 0.9615\n",
      "Epoch 272/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1271 - acc: 0.9615\n",
      "Epoch 273/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1270 - acc: 0.9615\n",
      "Epoch 274/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1269 - acc: 0.9615\n",
      "Epoch 275/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1268 - acc: 0.9615\n",
      "Epoch 276/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1267 - acc: 0.9615\n",
      "Epoch 277/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1265 - acc: 0.9615\n",
      "Epoch 278/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1264 - acc: 0.9615\n",
      "Epoch 279/300\n",
      "52/52 [==============================] - 0s 90us/step - loss: 0.1263 - acc: 0.9615\n",
      "Epoch 280/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 281/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1260 - acc: 0.9615\n",
      "Epoch 282/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1259 - acc: 0.9615\n",
      "Epoch 283/300\n",
      "52/52 [==============================] - 0s 92us/step - loss: 0.1258 - acc: 0.9615\n",
      "Epoch 284/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1257 - acc: 0.9615\n",
      "Epoch 285/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1255 - acc: 0.9615\n",
      "Epoch 286/300\n",
      "52/52 [==============================] - 0s 91us/step - loss: 0.1254 - acc: 0.9615\n",
      "Epoch 287/300\n",
      "52/52 [==============================] - 0s 84us/step - loss: 0.1253 - acc: 0.9615\n",
      "Epoch 288/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1252 - acc: 0.9615\n",
      "Epoch 289/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1251 - acc: 0.9615\n",
      "Epoch 290/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1249 - acc: 0.9615\n",
      "Epoch 291/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1248 - acc: 0.9615\n",
      "Epoch 292/300\n",
      "52/52 [==============================] - 0s 95us/step - loss: 0.1247 - acc: 0.9615\n",
      "Epoch 293/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1246 - acc: 0.9615\n",
      "Epoch 294/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1244 - acc: 0.9615\n",
      "Epoch 295/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1243 - acc: 0.9615\n",
      "Epoch 296/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1242 - acc: 0.9615\n",
      "Epoch 297/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1241 - acc: 0.9615\n",
      "Epoch 298/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1240 - acc: 0.9615\n",
      "Epoch 299/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1238 - acc: 0.9615\n",
      "Epoch 300/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1237 - acc: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5065ac18>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return (I2L[index])\n",
    "\n",
    "def predict_results(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index = np.argmax(predictions, axis=1)\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index))\n",
    "\n",
    "    return (prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = 'IAMREALLYGOOD'\n",
    "text, x_train, y_train = caeserde(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: IAMREALLYGOOD\n",
      "Cipertext: LDPUHDOOBJRRG\n",
      "Prediction: IAMREALLYGOOD\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\",mystr)\n",
    "print(\"Cipertext:\",text)\n",
    "print(\"Prediction:\",\"\".join(predict_results(model, x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a530a8438>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\", y_as_vector= False)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_train, model.predict_classes(x_train))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26 to 26 model has a best preformance for caeser decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_161 (Dense)            (None, 26)                702       \n",
      "=================================================================\n",
      "Total params: 702\n",
      "Trainable params: 702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a middle layer with different number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the neuralnum from 1 - 25, we can see the results in our report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnum = 25\n",
    "model = Sequential()\n",
    "model.add(Dense(neuralnum, input_dim=x_train.shape[1], activation='relu'))\n",
    "# change sigomiod to softmax made acc increasing 100%\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "52/52 [==============================] - 3s 57ms/step - loss: 0.6930 - acc: 0.5288\n",
      "Epoch 2/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.6893 - acc: 0.5518\n",
      "Epoch 3/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.6857 - acc: 0.5725\n",
      "Epoch 4/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.6821 - acc: 0.5947\n",
      "Epoch 5/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.6785 - acc: 0.6139\n",
      "Epoch 6/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.6749 - acc: 0.6361\n",
      "Epoch 7/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.6713 - acc: 0.6568\n",
      "Epoch 8/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.6677 - acc: 0.6812\n",
      "Epoch 9/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.6641 - acc: 0.7004\n",
      "Epoch 10/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.6604 - acc: 0.7101\n",
      "Epoch 11/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.6568 - acc: 0.7293\n",
      "Epoch 12/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.6531 - acc: 0.7441\n",
      "Epoch 13/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.6493 - acc: 0.7574\n",
      "Epoch 14/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.6456 - acc: 0.7633\n",
      "Epoch 15/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.6418 - acc: 0.7737\n",
      "Epoch 16/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.6378 - acc: 0.7899\n",
      "Epoch 17/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.6339 - acc: 0.7996\n",
      "Epoch 18/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.6300 - acc: 0.8129\n",
      "Epoch 19/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6259 - acc: 0.8217\n",
      "Epoch 20/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.6218 - acc: 0.8321\n",
      "Epoch 21/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.6176 - acc: 0.8425\n",
      "Epoch 22/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.6133 - acc: 0.8491\n",
      "Epoch 23/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.6091 - acc: 0.8609\n",
      "Epoch 24/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.6047 - acc: 0.8750\n",
      "Epoch 25/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.6002 - acc: 0.8846\n",
      "Epoch 26/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.5957 - acc: 0.8898\n",
      "Epoch 27/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.5911 - acc: 0.8979\n",
      "Epoch 28/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.5863 - acc: 0.8994\n",
      "Epoch 29/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.5816 - acc: 0.9046\n",
      "Epoch 30/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.5767 - acc: 0.9105\n",
      "Epoch 31/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.5717 - acc: 0.9149\n",
      "Epoch 32/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.5667 - acc: 0.9186\n",
      "Epoch 33/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.5615 - acc: 0.9223\n",
      "Epoch 34/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.5563 - acc: 0.9275\n",
      "Epoch 35/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.5509 - acc: 0.9320\n",
      "Epoch 36/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.5455 - acc: 0.9364\n",
      "Epoch 37/300\n",
      "52/52 [==============================] - 0s 195us/step - loss: 0.5400 - acc: 0.9364\n",
      "Epoch 38/300\n",
      "52/52 [==============================] - 0s 216us/step - loss: 0.5344 - acc: 0.9393\n",
      "Epoch 39/300\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.5288 - acc: 0.9438\n",
      "Epoch 40/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.5231 - acc: 0.9438\n",
      "Epoch 41/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.5173 - acc: 0.9527\n",
      "Epoch 42/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.5115 - acc: 0.9527\n",
      "Epoch 43/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.5055 - acc: 0.9519\n",
      "Epoch 44/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.4995 - acc: 0.9512\n",
      "Epoch 45/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.4936 - acc: 0.9549\n",
      "Epoch 46/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4875 - acc: 0.9556\n",
      "Epoch 47/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.4814 - acc: 0.9556\n",
      "Epoch 48/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.4753 - acc: 0.9571\n",
      "Epoch 49/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.4691 - acc: 0.9571\n",
      "Epoch 50/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4629 - acc: 0.9571\n",
      "Epoch 51/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.4566 - acc: 0.9586\n",
      "Epoch 52/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.4503 - acc: 0.9586\n",
      "Epoch 53/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.4440 - acc: 0.9586\n",
      "Epoch 54/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4377 - acc: 0.9593\n",
      "Epoch 55/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.4314 - acc: 0.9601\n",
      "Epoch 56/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.4251 - acc: 0.9601\n",
      "Epoch 57/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.4187 - acc: 0.9615\n",
      "Epoch 58/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.4124 - acc: 0.9615\n",
      "Epoch 59/300\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.4061 - acc: 0.9615\n",
      "Epoch 60/300\n",
      "52/52 [==============================] - 0s 183us/step - loss: 0.3997 - acc: 0.9615\n",
      "Epoch 61/300\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.3934 - acc: 0.9615\n",
      "Epoch 62/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.3870 - acc: 0.9615\n",
      "Epoch 63/300\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.3808 - acc: 0.9615\n",
      "Epoch 64/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.3745 - acc: 0.9615\n",
      "Epoch 65/300\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.3683 - acc: 0.9615\n",
      "Epoch 66/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.3622 - acc: 0.9615\n",
      "Epoch 67/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.3561 - acc: 0.9615\n",
      "Epoch 68/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.3501 - acc: 0.9615\n",
      "Epoch 69/300\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.3441 - acc: 0.9615\n",
      "Epoch 70/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.3383 - acc: 0.9615\n",
      "Epoch 71/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.3325 - acc: 0.9615\n",
      "Epoch 72/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.3269 - acc: 0.9615\n",
      "Epoch 73/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.3213 - acc: 0.9615\n",
      "Epoch 74/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.3158 - acc: 0.9615\n",
      "Epoch 75/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.3104 - acc: 0.9615\n",
      "Epoch 76/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.3052 - acc: 0.9615\n",
      "Epoch 77/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.3000 - acc: 0.9615\n",
      "Epoch 78/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.2949 - acc: 0.9615\n",
      "Epoch 79/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.2899 - acc: 0.9615\n",
      "Epoch 80/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.2851 - acc: 0.9615\n",
      "Epoch 81/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.2803 - acc: 0.9615\n",
      "Epoch 82/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.2757 - acc: 0.9615\n",
      "Epoch 83/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.2712 - acc: 0.9615\n",
      "Epoch 84/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.2668 - acc: 0.9615\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 132us/step - loss: 0.2625 - acc: 0.9615\n",
      "Epoch 86/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.2584 - acc: 0.9615\n",
      "Epoch 87/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.2544 - acc: 0.9615\n",
      "Epoch 88/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.2505 - acc: 0.9615\n",
      "Epoch 89/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.2467 - acc: 0.9615\n",
      "Epoch 90/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.2431 - acc: 0.9615\n",
      "Epoch 91/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.2395 - acc: 0.9615\n",
      "Epoch 92/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.2361 - acc: 0.9615\n",
      "Epoch 93/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.2328 - acc: 0.9615\n",
      "Epoch 94/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.2297 - acc: 0.9615\n",
      "Epoch 95/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.2266 - acc: 0.9615\n",
      "Epoch 96/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.2236 - acc: 0.9615\n",
      "Epoch 97/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.2208 - acc: 0.9615\n",
      "Epoch 98/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.2180 - acc: 0.9615\n",
      "Epoch 99/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.2154 - acc: 0.9615\n",
      "Epoch 100/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.2129 - acc: 0.9615\n",
      "Epoch 101/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.2104 - acc: 0.9615\n",
      "Epoch 102/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.2081 - acc: 0.9615\n",
      "Epoch 103/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.2058 - acc: 0.9615\n",
      "Epoch 104/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.2037 - acc: 0.9615\n",
      "Epoch 105/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.2016 - acc: 0.9615\n",
      "Epoch 106/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1996 - acc: 0.9615\n",
      "Epoch 107/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1977 - acc: 0.9615\n",
      "Epoch 108/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1958 - acc: 0.9615\n",
      "Epoch 109/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1940 - acc: 0.9615\n",
      "Epoch 110/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1923 - acc: 0.9615\n",
      "Epoch 111/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1907 - acc: 0.9615\n",
      "Epoch 112/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1891 - acc: 0.9615\n",
      "Epoch 113/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1876 - acc: 0.9615\n",
      "Epoch 114/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1862 - acc: 0.9615\n",
      "Epoch 115/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1848 - acc: 0.9615\n",
      "Epoch 116/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1835 - acc: 0.9615\n",
      "Epoch 117/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1822 - acc: 0.9615\n",
      "Epoch 118/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1810 - acc: 0.9615\n",
      "Epoch 119/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1798 - acc: 0.9615\n",
      "Epoch 120/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1787 - acc: 0.9615\n",
      "Epoch 121/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1776 - acc: 0.9615\n",
      "Epoch 122/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1766 - acc: 0.9615\n",
      "Epoch 123/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1756 - acc: 0.9615\n",
      "Epoch 124/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1746 - acc: 0.9615\n",
      "Epoch 125/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1737 - acc: 0.9615\n",
      "Epoch 126/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1728 - acc: 0.9615\n",
      "Epoch 127/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1719 - acc: 0.9615\n",
      "Epoch 128/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1711 - acc: 0.9615\n",
      "Epoch 129/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1703 - acc: 0.9615\n",
      "Epoch 130/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1695 - acc: 0.9615\n",
      "Epoch 131/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1688 - acc: 0.9615\n",
      "Epoch 132/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1681 - acc: 0.9615\n",
      "Epoch 133/300\n",
      "52/52 [==============================] - 0s 151us/step - loss: 0.1674 - acc: 0.9615\n",
      "Epoch 134/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1667 - acc: 0.9615\n",
      "Epoch 135/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1661 - acc: 0.9615\n",
      "Epoch 136/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1654 - acc: 0.9615\n",
      "Epoch 137/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1648 - acc: 0.9615\n",
      "Epoch 138/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1642 - acc: 0.9615\n",
      "Epoch 139/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1636 - acc: 0.9615\n",
      "Epoch 140/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1630 - acc: 0.9615\n",
      "Epoch 141/300\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.1625 - acc: 0.9615\n",
      "Epoch 142/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1620 - acc: 0.9615\n",
      "Epoch 143/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1614 - acc: 0.9615\n",
      "Epoch 144/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.1609 - acc: 0.9615\n",
      "Epoch 145/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1604 - acc: 0.9615\n",
      "Epoch 146/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1600 - acc: 0.9615\n",
      "Epoch 147/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1595 - acc: 0.9615\n",
      "Epoch 148/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1590 - acc: 0.9615\n",
      "Epoch 149/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1586 - acc: 0.9615\n",
      "Epoch 150/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1581 - acc: 0.9615\n",
      "Epoch 151/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1577 - acc: 0.9615\n",
      "Epoch 152/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.1573 - acc: 0.9615\n",
      "Epoch 153/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1569 - acc: 0.9615\n",
      "Epoch 154/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1565 - acc: 0.9615\n",
      "Epoch 155/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1561 - acc: 0.9615\n",
      "Epoch 156/300\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.1557 - acc: 0.9615\n",
      "Epoch 157/300\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.1553 - acc: 0.9615\n",
      "Epoch 158/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 159/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1546 - acc: 0.9615\n",
      "Epoch 160/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1542 - acc: 0.9615\n",
      "Epoch 161/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1539 - acc: 0.9615\n",
      "Epoch 162/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1535 - acc: 0.9615\n",
      "Epoch 163/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.1532 - acc: 0.9615\n",
      "Epoch 164/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1529 - acc: 0.9615\n",
      "Epoch 165/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1525 - acc: 0.9615\n",
      "Epoch 166/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1522 - acc: 0.9615\n",
      "Epoch 167/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1519 - acc: 0.9615\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 130us/step - loss: 0.1516 - acc: 0.9615\n",
      "Epoch 169/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1513 - acc: 0.9615\n",
      "Epoch 170/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1509 - acc: 0.9615\n",
      "Epoch 171/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1506 - acc: 0.9615\n",
      "Epoch 172/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1503 - acc: 0.9615\n",
      "Epoch 173/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1500 - acc: 0.9615\n",
      "Epoch 174/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1497 - acc: 0.9615\n",
      "Epoch 175/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1495 - acc: 0.9615\n",
      "Epoch 176/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1492 - acc: 0.9615\n",
      "Epoch 177/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1489 - acc: 0.9615\n",
      "Epoch 178/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1486 - acc: 0.9615\n",
      "Epoch 179/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1483 - acc: 0.9615\n",
      "Epoch 180/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1480 - acc: 0.9615\n",
      "Epoch 181/300\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.1477 - acc: 0.9615\n",
      "Epoch 182/300\n",
      "52/52 [==============================] - 0s 148us/step - loss: 0.1474 - acc: 0.9615\n",
      "Epoch 183/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1472 - acc: 0.9615\n",
      "Epoch 184/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1469 - acc: 0.9615\n",
      "Epoch 185/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1466 - acc: 0.9615\n",
      "Epoch 186/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1463 - acc: 0.9615\n",
      "Epoch 187/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1461 - acc: 0.9615\n",
      "Epoch 188/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1458 - acc: 0.9615\n",
      "Epoch 189/300\n",
      "52/52 [==============================] - 0s 149us/step - loss: 0.1455 - acc: 0.9615\n",
      "Epoch 190/300\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.1453 - acc: 0.9615\n",
      "Epoch 191/300\n",
      "52/52 [==============================] - 0s 153us/step - loss: 0.1450 - acc: 0.9615\n",
      "Epoch 192/300\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.1447 - acc: 0.9615\n",
      "Epoch 193/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1445 - acc: 0.9615\n",
      "Epoch 194/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.1442 - acc: 0.9615\n",
      "Epoch 195/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1439 - acc: 0.9615\n",
      "Epoch 196/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1437 - acc: 0.9615\n",
      "Epoch 197/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1434 - acc: 0.9615\n",
      "Epoch 198/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1432 - acc: 0.9615\n",
      "Epoch 199/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1429 - acc: 0.9615\n",
      "Epoch 200/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1426 - acc: 0.9615\n",
      "Epoch 201/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1424 - acc: 0.9615\n",
      "Epoch 202/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1421 - acc: 0.9615\n",
      "Epoch 203/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1419 - acc: 0.9615\n",
      "Epoch 204/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1416 - acc: 0.9615\n",
      "Epoch 205/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1413 - acc: 0.9615\n",
      "Epoch 206/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1411 - acc: 0.9615\n",
      "Epoch 207/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1408 - acc: 0.9615\n",
      "Epoch 208/300\n",
      "52/52 [==============================] - 0s 153us/step - loss: 0.1406 - acc: 0.9615\n",
      "Epoch 209/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1403 - acc: 0.9615\n",
      "Epoch 210/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1401 - acc: 0.9615\n",
      "Epoch 211/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1398 - acc: 0.9615\n",
      "Epoch 212/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1395 - acc: 0.9615\n",
      "Epoch 213/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1393 - acc: 0.9615\n",
      "Epoch 214/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1390 - acc: 0.9615\n",
      "Epoch 215/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1388 - acc: 0.9615\n",
      "Epoch 216/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1385 - acc: 0.9615\n",
      "Epoch 217/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1383 - acc: 0.9615\n",
      "Epoch 218/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1380 - acc: 0.9615\n",
      "Epoch 219/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1377 - acc: 0.9615\n",
      "Epoch 220/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1375 - acc: 0.9615\n",
      "Epoch 221/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1372 - acc: 0.9615\n",
      "Epoch 222/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1370 - acc: 0.9615\n",
      "Epoch 223/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1367 - acc: 0.9615\n",
      "Epoch 224/300\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.1365 - acc: 0.9615\n",
      "Epoch 225/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1362 - acc: 0.9615\n",
      "Epoch 226/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1359 - acc: 0.9615\n",
      "Epoch 227/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1357 - acc: 0.9615\n",
      "Epoch 228/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1354 - acc: 0.9615\n",
      "Epoch 229/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1352 - acc: 0.9615\n",
      "Epoch 230/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1349 - acc: 0.9615\n",
      "Epoch 231/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1347 - acc: 0.9615\n",
      "Epoch 232/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1344 - acc: 0.9615\n",
      "Epoch 233/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1341 - acc: 0.9615\n",
      "Epoch 234/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1339 - acc: 0.9615\n",
      "Epoch 235/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1336 - acc: 0.9615\n",
      "Epoch 236/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1334 - acc: 0.9615\n",
      "Epoch 237/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1331 - acc: 0.9615\n",
      "Epoch 238/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1328 - acc: 0.9615\n",
      "Epoch 239/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1326 - acc: 0.9615\n",
      "Epoch 240/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1323 - acc: 0.9615\n",
      "Epoch 241/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1321 - acc: 0.9615\n",
      "Epoch 242/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1318 - acc: 0.9615\n",
      "Epoch 243/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1315 - acc: 0.9615\n",
      "Epoch 244/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1313 - acc: 0.9615\n",
      "Epoch 245/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1310 - acc: 0.9615\n",
      "Epoch 246/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1308 - acc: 0.9615\n",
      "Epoch 247/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1305 - acc: 0.9615\n",
      "Epoch 248/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1302 - acc: 0.9615\n",
      "Epoch 249/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1300 - acc: 0.9615\n",
      "Epoch 250/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1297 - acc: 0.9615\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 136us/step - loss: 0.1294 - acc: 0.9615\n",
      "Epoch 252/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1292 - acc: 0.9615\n",
      "Epoch 253/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1289 - acc: 0.9615\n",
      "Epoch 254/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1286 - acc: 0.9615\n",
      "Epoch 255/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1284 - acc: 0.9615\n",
      "Epoch 256/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1281 - acc: 0.9615\n",
      "Epoch 257/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1278 - acc: 0.9615\n",
      "Epoch 258/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1276 - acc: 0.9615\n",
      "Epoch 259/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1273 - acc: 0.9615\n",
      "Epoch 260/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1270 - acc: 0.9615\n",
      "Epoch 261/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1267 - acc: 0.9615\n",
      "Epoch 262/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1265 - acc: 0.9615\n",
      "Epoch 263/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 264/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1259 - acc: 0.9615\n",
      "Epoch 265/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1256 - acc: 0.9615\n",
      "Epoch 266/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1254 - acc: 0.9615\n",
      "Epoch 267/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1251 - acc: 0.9615\n",
      "Epoch 268/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1248 - acc: 0.9615\n",
      "Epoch 269/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1245 - acc: 0.9615\n",
      "Epoch 270/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1243 - acc: 0.9615\n",
      "Epoch 271/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1240 - acc: 0.9615\n",
      "Epoch 272/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1237 - acc: 0.9615\n",
      "Epoch 273/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1234 - acc: 0.9615\n",
      "Epoch 274/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1231 - acc: 0.9615\n",
      "Epoch 275/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1228 - acc: 0.9615\n",
      "Epoch 276/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1226 - acc: 0.9615\n",
      "Epoch 277/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1223 - acc: 0.9615\n",
      "Epoch 278/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1220 - acc: 0.9615\n",
      "Epoch 279/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1217 - acc: 0.9615\n",
      "Epoch 280/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1214 - acc: 0.9615\n",
      "Epoch 281/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1211 - acc: 0.9615\n",
      "Epoch 282/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1208 - acc: 0.9615\n",
      "Epoch 283/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1206 - acc: 0.9615\n",
      "Epoch 284/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1203 - acc: 0.9615\n",
      "Epoch 285/300\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1201 - acc: 0.961 - 0s 129us/step - loss: 0.1200 - acc: 0.9615\n",
      "Epoch 286/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1197 - acc: 0.9615\n",
      "Epoch 287/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1194 - acc: 0.9615\n",
      "Epoch 288/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1191 - acc: 0.9615\n",
      "Epoch 289/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1188 - acc: 0.9615\n",
      "Epoch 290/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1185 - acc: 0.9615\n",
      "Epoch 291/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1182 - acc: 0.9615\n",
      "Epoch 292/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1179 - acc: 0.9615\n",
      "Epoch 293/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1176 - acc: 0.9615\n",
      "Epoch 294/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1173 - acc: 0.9615\n",
      "Epoch 295/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1170 - acc: 0.9615\n",
      "Epoch 296/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1167 - acc: 0.9615\n",
      "Epoch 297/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1165 - acc: 0.9615\n",
      "Epoch 298/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1162 - acc: 0.9615\n",
      "Epoch 299/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1158 - acc: 0.9615\n",
      "Epoch 300/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1156 - acc: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a553439b0>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a55783748>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text, x_test, y_test = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", y_as_vector= False)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_test, model.predict_classes(x_test))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try all possible num of neurons in the hidden layers, we will find that the funnel structure is not a suitable choice for our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences of letters modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 2 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function data_genelization in module myfun:\n",
      "\n",
      "data_genelization(sample_size=2, loops=1000, size=26, key=3, x_as_vector=False, y_as_vector=False)\n",
      "    data_genelization(sample_size = 2,loops = 1000, size = 26, key = 3, x_as_vector = False, y_as_vector = False):\n",
      "    return x_train, label with equual size, labels with 1 dimension\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_genelization)\n",
    "# forgive the spelling mistake, it should be generation\n",
    "# this function is to generate random training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling 1000 random sequences with length 2\n",
    "x_train, y_train, y_train_small = data_genelization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6609 - binary_accuracy: 0.7355\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.5519 - binary_accuracy: 0.9135\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.3407 - binary_accuracy: 0.9601\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.1922 - binary_accuracy: 0.9615\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.1680 - binary_accuracy: 0.9615\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.1644 - binary_accuracy: 0.9615\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.1621 - binary_accuracy: 0.9615\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.1603 - binary_accuracy: 0.9615\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.1588 - binary_accuracy: 0.9615\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.1573 - binary_accuracy: 0.9615\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.1557 - binary_accuracy: 0.9615\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.1540 - binary_accuracy: 0.9615\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.1523 - binary_accuracy: 0.9615\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1503 - binary_accuracy: 0.9615\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1482 - binary_accuracy: 0.9615\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1458 - binary_accuracy: 0.9615\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1433 - binary_accuracy: 0.9615\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1405 - binary_accuracy: 0.9615\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.1376 - binary_accuracy: 0.9615\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.1344 - binary_accuracy: 0.9615\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1310 - binary_accuracy: 0.9616\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1275 - binary_accuracy: 0.9617\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1239 - binary_accuracy: 0.9617\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1201 - binary_accuracy: 0.9618\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1162 - binary_accuracy: 0.9621\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1123 - binary_accuracy: 0.9622\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1083 - binary_accuracy: 0.9626\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.1042 - binary_accuracy: 0.9631\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1002 - binary_accuracy: 0.9638\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0963 - binary_accuracy: 0.9644\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0924 - binary_accuracy: 0.9652\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0886 - binary_accuracy: 0.9662\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0847 - binary_accuracy: 0.967 - 0s 66us/step - loss: 0.0849 - binary_accuracy: 0.9673\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0814 - binary_accuracy: 0.9686\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0779 - binary_accuracy: 0.9702\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0747 - binary_accuracy: 0.9712\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0715 - binary_accuracy: 0.9732\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0685 - binary_accuracy: 0.9744\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0655 - binary_accuracy: 0.9759\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0628 - binary_accuracy: 0.9769\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0600 - binary_accuracy: 0.9782\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0575 - binary_accuracy: 0.9794\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0549 - binary_accuracy: 0.9812\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0524 - binary_accuracy: 0.9822\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0501 - binary_accuracy: 0.9835\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0478 - binary_accuracy: 0.9846\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0457 - binary_accuracy: 0.9852\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0436 - binary_accuracy: 0.9862\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0416 - binary_accuracy: 0.9867\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0396 - binary_accuracy: 0.9873\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0379 - binary_accuracy: 0.9885\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0361 - binary_accuracy: 0.9896\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0344 - binary_accuracy: 0.9900\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0329 - binary_accuracy: 0.9907\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0314 - binary_accuracy: 0.9914\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0300 - binary_accuracy: 0.9916\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0286 - binary_accuracy: 0.9922\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0273 - binary_accuracy: 0.9927\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0261 - binary_accuracy: 0.9930\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0250 - binary_accuracy: 0.9934\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0239 - binary_accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0229 - binary_accuracy: 0.9941\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0219 - binary_accuracy: 0.9944\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0210 - binary_accuracy: 0.9946\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0201 - binary_accuracy: 0.9950\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0192 - binary_accuracy: 0.9952\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.0185 - binary_accuracy: 0.9953\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0177 - binary_accuracy: 0.9957\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.0169 - binary_accuracy: 0.9958\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0162 - binary_accuracy: 0.9961\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0156 - binary_accuracy: 0.9961\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.0149 - binary_accuracy: 0.9963\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.0143 - binary_accuracy: 0.9965\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0137 - binary_accuracy: 0.9968\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0131 - binary_accuracy: 0.9970\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0126 - binary_accuracy: 0.9971\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0121 - binary_accuracy: 0.9973\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0116 - binary_accuracy: 0.9974\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0111 - binary_accuracy: 0.9975\n",
      "Epoch 80/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0106 - binary_accuracy: 0.9977\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0102 - binary_accuracy: 0.9979\n",
      "Epoch 82/200\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0098 - binary_accuracy: 0.9981\n",
      "Epoch 83/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0094 - binary_accuracy: 0.9981\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0090 - binary_accuracy: 0.9983\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0087 - binary_accuracy: 0.9983\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0083 - binary_accuracy: 0.9984\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.0080 - binary_accuracy: 0.9985\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.0077 - binary_accuracy: 0.9985\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0074 - binary_accuracy: 0.9986\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0071 - binary_accuracy: 0.9987\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0068 - binary_accuracy: 0.9988\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0065 - binary_accuracy: 0.9989\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0063 - binary_accuracy: 0.9989\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0060 - binary_accuracy: 0.9990\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0058 - binary_accuracy: 0.9990\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0056 - binary_accuracy: 0.9991\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0054 - binary_accuracy: 0.9992\n",
      "Epoch 98/200\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0051 - binary_accuracy: 0.9992\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0049 - binary_accuracy: 0.9992\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0048 - binary_accuracy: 0.9992\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0046 - binary_accuracy: 0.9993\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0044 - binary_accuracy: 0.9995\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0042 - binary_accuracy: 0.9994\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0041 - binary_accuracy: 0.9995\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0039 - binary_accuracy: 0.9995\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0038 - binary_accuracy: 0.9995\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0036 - binary_accuracy: 0.9996\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0035 - binary_accuracy: 0.9995\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0034 - binary_accuracy: 0.9996\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0033 - binary_accuracy: 0.9997\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0032 - binary_accuracy: 0.9997\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0030 - binary_accuracy: 0.9998\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0029 - binary_accuracy: 0.9998\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0028 - binary_accuracy: 0.9998\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0027 - binary_accuracy: 0.9998\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0026 - binary_accuracy: 0.9998\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0025 - binary_accuracy: 0.9998\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0024 - binary_accuracy: 0.9999\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0023 - binary_accuracy: 0.9999\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0023 - binary_accuracy: 0.9999\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0022 - binary_accuracy: 0.9999\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0021 - binary_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0020 - binary_accuracy: 0.9999\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0010 - binary_accuracy: 1.0000\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0010 - binary_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 9.7466e-04 - binary_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 9.4375e-04 - binary_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 9.1543e-04 - binary_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 8.8831e-04 - binary_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 8.6660e-04 - binary_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 8.3751e-04 - binary_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 8.1315e-04 - binary_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 7.9372e-04 - binary_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 7.6942e-04 - binary_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 7.4801e-04 - binary_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 7.2518e-04 - binary_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 7.0446e-04 - binary_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 6.9158e-04 - binary_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 6.6578e-04 - binary_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 6.4470e-04 - binary_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 6.2957e-04 - binary_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 6.1202e-04 - binary_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 5.9723e-04 - binary_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 5.7943e-04 - binary_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 5.6149e-04 - binary_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 5.4661e-04 - binary_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 5.3276e-04 - binary_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 5.1935e-04 - binary_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 5.0489e-04 - binary_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 4.9267e-04 - binary_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 4.7820e-04 - binary_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 4.6636e-04 - binary_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 4.5307e-04 - binary_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 4.4312e-04 - binary_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 4.3030e-04 - binary_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 4.1932e-04 - binary_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 4.0941e-04 - binary_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 3.9836e-04 - binary_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 3.8856e-04 - binary_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 3.7722e-04 - binary_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 3.6798e-04 - binary_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 3.5879e-04 - binary_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 3.4966e-04 - binary_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 3.4302e-04 - binary_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 3.3155e-04 - binary_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 3.2308e-04 - binary_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 3.1475e-04 - binary_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 3.0792e-04 - binary_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 3.0027e-04 - binary_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 2.9206e-04 - binary_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 2.8587e-04 - binary_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 2.7924e-04 - binary_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.7101e-04 - binary_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 2.6510e-04 - binary_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 2.5922e-04 - binary_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 2.5196e-04 - binary_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.4593e-04 - binary_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 2.4061e-04 - binary_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 2.3543e-04 - binary_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.2856e-04 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a576472b0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index1, index2, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return ([I2L[index1], I2L[index2]])\n",
    "\n",
    "\n",
    "def predict_results_only_2(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index1 = np.argmax(predictions[:, 0:26], axis=1)\n",
    "    index2 = np.argmax(predictions[:, 26:52], axis=1)\n",
    "    label1 = np.argmax(y_train[:, 0:26], axis=1)\n",
    "    label2 = np.argmax(y_train[:, 26:52], axis=1)\n",
    "\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index1, index2))\n",
    "    label_list = list(map(num2str, label1, label2))\n",
    "\n",
    "    return (prediction_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(list1, list2):   \n",
    "    if \"\".join(list1) != \"\".join(list2):\n",
    "        return(\"\".join(list1), \"\".join(list2))\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "\n",
      "binary_accuracy: 99.82%\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test, y_test_small = data_genelization()\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "prediction_list, label_list = predict_results_only_2(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look the decoding results compared with the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZI ZI\n",
      "VN VN\n",
      "XR XR\n",
      "TO TO\n",
      "IK IK\n",
      "QB QB\n",
      "ZA ZA\n",
      "SM SM\n",
      "XC XC\n",
      "MJ MJ\n",
      "PM PM\n",
      "KP KP\n",
      "TR TR\n",
      "XW XW\n",
      "JF JF\n",
      "ZX ZX\n",
      "OJ OJ\n",
      "AH AH\n",
      "EJ EJ\n",
      "UA UA\n",
      "XP XP\n",
      "KV KV\n",
      "DZ DZ\n",
      "LY LY\n",
      "BO BO\n",
      "TS TS\n",
      "TP TP\n",
      "PJ PJ\n",
      "RE RE\n",
      "XN XN\n",
      "RM RM\n",
      "MG MG\n",
      "PP PP\n",
      "YK YK\n",
      "NU NU\n",
      "LK LK\n",
      "EG EG\n",
      "KS KS\n",
      "HM HM\n",
      "WR WR\n",
      "VB VB\n",
      "SG SG\n",
      "HS HS\n",
      "TZ TZ\n",
      "MH MH\n",
      "JK JK\n",
      "BE BE\n",
      "SX SX\n",
      "NJ NJ\n",
      "CE CE\n",
      "AF AF\n",
      "OB OB\n",
      "EP EP\n",
      "OW OW\n",
      "HW HW\n",
      "PL PL\n",
      "MV MV\n",
      "FO FO\n",
      "OW OW\n",
      "VI VI\n",
      "OQ OQ\n",
      "ET ET\n",
      "FD FD\n",
      "VA VA\n",
      "WE WE\n",
      "RG RG\n",
      "YA YA\n",
      "KZ KZ\n",
      "EN EN\n",
      "IF IF\n",
      "HL HL\n",
      "PN PN\n",
      "JL JL\n",
      "KK KK\n",
      "TT TT\n",
      "IP IP\n",
      "OP OP\n",
      "LT LT\n",
      "VM VM\n",
      "KY KY\n",
      "SE SE\n",
      "ET ET\n",
      "LG LG\n",
      "SK SK\n",
      "IM IM\n",
      "QW QW\n",
      "TT TT\n",
      "MO MO\n",
      "WF WF\n",
      "DX DX\n",
      "WY WY\n",
      "OZ OZ\n",
      "EA EA\n",
      "WF WF\n",
      "XN XN\n",
      "WL WL\n",
      "IX IX\n",
      "XM XM\n",
      "NZ NZ\n",
      "SS SS\n",
      "EX EX\n",
      "CE CE\n",
      "GL GL\n",
      "YF YF\n",
      "FH FH\n",
      "YA YA\n",
      "EX EX\n",
      "VK VK\n",
      "YT YT\n",
      "CD CD\n",
      "SG SG\n",
      "OA OA\n",
      "NO NO\n",
      "OQ OQ\n",
      "OQ OQ\n",
      "EH EH\n",
      "KN KN\n",
      "DR DR\n",
      "PB PF\n",
      "LU LU\n",
      "HW HW\n",
      "SS SS\n",
      "PD PD\n",
      "RM RM\n",
      "WU WM\n",
      "TC TC\n",
      "JR JR\n",
      "LF LF\n",
      "GR HE\n",
      "CF CF\n",
      "RQ RQ\n",
      "QE QE\n",
      "WW WW\n",
      "AM AM\n",
      "XM XM\n",
      "TI TI\n",
      "WD WD\n",
      "YB YB\n",
      "MY MY\n",
      "RR RR\n",
      "SG SG\n",
      "ID ID\n",
      "EI EI\n",
      "HC HC\n",
      "KM KM\n",
      "AK AK\n",
      "ET ET\n",
      "TQ TQ\n",
      "FI FI\n",
      "IA IA\n",
      "IC IC\n",
      "YZ YZ\n",
      "DO DO\n",
      "JQ JQ\n",
      "NJ NJ\n",
      "FR FR\n",
      "YF YF\n",
      "VN VN\n",
      "ZF ZF\n",
      "DD DD\n",
      "QT QT\n",
      "UZ UZ\n",
      "OH OH\n",
      "LN LN\n",
      "SB SB\n",
      "ZW ZW\n",
      "YK YK\n",
      "MY MY\n",
      "CT CT\n",
      "XV XV\n",
      "DT DT\n",
      "XK XK\n",
      "PT PT\n",
      "MQ MQ\n",
      "TV TV\n",
      "IG IG\n",
      "SI SI\n",
      "MM MM\n",
      "AP AP\n",
      "MW MW\n",
      "NS NS\n",
      "RL RL\n",
      "LN LN\n",
      "AP AP\n",
      "PI PI\n",
      "AC AC\n",
      "LW LW\n",
      "RL RL\n",
      "SS SS\n",
      "SJ SJ\n",
      "VG VG\n",
      "UL UL\n",
      "QL QL\n",
      "XC XC\n",
      "HZ HZ\n",
      "OG OG\n",
      "LC LC\n",
      "QG QG\n",
      "YW YW\n",
      "YT YT\n",
      "MO MO\n",
      "ZH ZH\n",
      "OL OL\n",
      "GL GL\n",
      "SH SH\n",
      "KL KL\n",
      "SN SN\n",
      "ER ER\n",
      "JN JN\n",
      "HX HX\n",
      "LT LT\n",
      "LB LB\n",
      "DU DU\n",
      "UG UG\n",
      "GP GP\n",
      "MJ MJ\n",
      "NH NH\n",
      "AE AE\n",
      "FJ FJ\n",
      "XJ XJ\n",
      "SV SV\n",
      "KX KX\n",
      "EW EW\n",
      "AO AO\n",
      "MU MU\n",
      "KG KG\n",
      "LA LA\n",
      "AF AF\n",
      "NZ NZ\n",
      "WW JW\n",
      "EE EE\n",
      "MF MF\n",
      "XJ XJ\n",
      "NQ NQ\n",
      "XF XF\n",
      "QQ QQ\n",
      "DC DC\n",
      "YV YV\n",
      "FZ FZ\n",
      "TV TV\n",
      "ND ND\n",
      "XH XH\n",
      "PC PC\n",
      "FB FB\n",
      "OO OO\n",
      "ML ML\n",
      "UL UL\n",
      "EY EY\n",
      "YV YV\n",
      "YG YG\n",
      "AY AY\n",
      "SU SU\n",
      "RZ RZ\n",
      "RM RM\n",
      "OF OF\n",
      "GY GY\n",
      "XL XL\n",
      "TV TV\n",
      "WF WF\n",
      "CD CD\n",
      "PQ PQ\n",
      "CQ CQ\n",
      "XB XB\n",
      "XQ XQ\n",
      "IZ IZ\n",
      "TW TW\n",
      "LW LW\n",
      "WB WB\n",
      "HD HD\n",
      "TJ TJ\n",
      "NS NS\n",
      "GS GS\n",
      "FA FA\n",
      "ME ME\n",
      "SD SD\n",
      "SE SE\n",
      "QK QK\n",
      "XL XL\n",
      "FK FK\n",
      "RE RE\n",
      "NM NM\n",
      "YB YB\n",
      "VH VH\n",
      "OX OX\n",
      "ZJ ZJ\n",
      "DJ DJ\n",
      "YI YI\n",
      "UB UB\n",
      "VR VR\n",
      "EA EA\n",
      "DQ DQ\n",
      "NC NC\n",
      "VM VM\n",
      "QX QX\n",
      "GQ GQ\n",
      "ZG ZG\n",
      "DG DG\n",
      "WK WK\n",
      "QK QK\n",
      "ZG ZG\n",
      "KG KG\n",
      "UF UF\n",
      "JF JF\n",
      "CE CE\n",
      "UN UN\n",
      "WO WO\n",
      "HU HU\n",
      "VH VH\n",
      "QU QU\n",
      "SG SG\n",
      "KR KR\n",
      "CU CU\n",
      "RO RO\n",
      "CA CA\n",
      "DJ DJ\n",
      "ZP ZP\n",
      "BU BU\n",
      "PE PE\n",
      "PM PM\n",
      "WL WL\n",
      "YN YN\n",
      "DQ DQ\n",
      "VR VR\n",
      "IL IL\n",
      "QN QN\n",
      "MT MT\n",
      "DR DR\n",
      "PB PB\n",
      "OV OV\n",
      "EC EC\n",
      "WK WK\n",
      "SR SR\n",
      "NS NS\n",
      "OY OY\n",
      "VJ VJ\n",
      "BP BP\n",
      "OI OI\n",
      "VV VV\n",
      "QO QO\n",
      "AJ AJ\n",
      "HR HR\n",
      "XD XD\n",
      "HB HB\n",
      "WU WM\n",
      "GS GS\n",
      "FE FE\n",
      "OO OO\n",
      "CJ CJ\n",
      "VI VI\n",
      "XI XI\n",
      "SJ SJ\n",
      "CI CI\n",
      "IH IH\n",
      "QO QO\n",
      "BU BU\n",
      "PV PV\n",
      "XM XM\n",
      "MO MO\n",
      "CB CB\n",
      "OQ OQ\n",
      "KA KA\n",
      "TQ TQ\n",
      "WF WF\n",
      "BU BU\n",
      "OJ OJ\n",
      "RY RY\n",
      "GJ GJ\n",
      "YC YC\n",
      "NO NO\n",
      "ZJ ZJ\n",
      "RR XY\n",
      "UQ UQ\n",
      "GJ GJ\n",
      "BW BW\n",
      "IJ IJ\n",
      "QA QA\n",
      "VG VG\n",
      "VL VL\n",
      "CP CP\n",
      "BN BN\n",
      "YW YW\n",
      "HR HR\n",
      "IZ IZ\n",
      "VS VS\n",
      "DV DV\n",
      "VI VI\n",
      "EA EA\n",
      "LR LR\n",
      "TG TG\n",
      "BM BM\n",
      "XH XH\n",
      "GU GU\n",
      "VP VP\n",
      "FY FY\n",
      "JG JG\n",
      "RI RI\n",
      "WL WL\n",
      "BV BV\n",
      "EE EE\n",
      "IS IS\n",
      "VG VG\n",
      "OS OS\n",
      "WW WW\n",
      "AS AS\n",
      "HY HY\n",
      "HY HY\n",
      "YV YV\n",
      "AA AA\n",
      "LD LD\n",
      "PE PE\n",
      "YT YT\n",
      "RG RG\n",
      "HT HT\n",
      "GO GO\n",
      "WQ WQ\n",
      "YG YG\n",
      "FY FY\n",
      "XM XM\n",
      "HH HH\n",
      "AC AC\n",
      "XC XC\n",
      "DU DU\n",
      "RX RX\n",
      "RR XY\n",
      "DC DC\n",
      "OU OU\n",
      "GU GU\n",
      "KG KG\n",
      "MG MG\n",
      "YZ YZ\n",
      "NH NH\n",
      "HX HX\n",
      "JV JV\n",
      "IL IL\n",
      "SM SM\n",
      "XG XG\n",
      "BQ BQ\n",
      "BO BO\n",
      "FI FI\n",
      "EU EU\n",
      "NS NS\n",
      "VP VP\n",
      "XR XR\n",
      "KT KT\n",
      "KA KA\n",
      "GR GR\n",
      "YE YE\n",
      "AH AH\n",
      "JV JV\n",
      "FU FU\n",
      "GI GI\n",
      "KP KP\n",
      "ZO ZO\n",
      "XQ XQ\n",
      "AX AX\n",
      "TD TD\n",
      "LV LV\n",
      "FC FC\n",
      "GU GU\n",
      "JF JF\n",
      "FB FB\n",
      "QJ QJ\n",
      "NY NY\n",
      "IY IY\n",
      "LS LS\n",
      "TX TX\n",
      "QG QG\n",
      "AR AR\n",
      "DU DU\n",
      "NB NB\n",
      "GW GW\n",
      "MI MI\n",
      "PW PW\n",
      "WJ WJ\n",
      "JQ JQ\n",
      "XI XI\n",
      "YP YP\n",
      "YL YL\n",
      "RD RD\n",
      "DJ DJ\n",
      "TM TM\n",
      "EZ EZ\n",
      "PV PV\n",
      "BJ BJ\n",
      "MF MF\n",
      "FI FI\n",
      "OU OU\n",
      "NG NG\n",
      "OP OP\n",
      "CQ CQ\n",
      "CZ CZ\n",
      "LH LH\n",
      "GZ GZ\n",
      "EQ EQ\n",
      "KZ KZ\n",
      "ST ST\n",
      "VQ VQ\n",
      "GN GN\n",
      "OQ OQ\n",
      "VS VS\n",
      "EI EI\n",
      "SM VU\n",
      "YK YK\n",
      "TW TW\n",
      "KW KW\n",
      "QH QH\n",
      "BH BH\n",
      "TJ TJ\n",
      "PK PK\n",
      "MI MI\n",
      "TQ TQ\n",
      "TL TL\n",
      "PN PN\n",
      "EQ EQ\n",
      "ON ON\n",
      "TV TV\n",
      "PU PU\n",
      "PI PI\n",
      "RX RX\n",
      "LB LB\n",
      "DK DK\n",
      "FS FS\n",
      "KW KW\n",
      "JF JF\n",
      "SQ SQ\n",
      "VE VE\n",
      "MS MS\n",
      "NV NV\n",
      "WU WU\n",
      "ED ED\n",
      "BC BC\n",
      "IH IH\n",
      "TU TU\n",
      "JG JG\n",
      "JJ JJ\n",
      "HN HN\n",
      "VJ VJ\n",
      "FR FR\n",
      "DR DR\n",
      "KP KP\n",
      "XW XW\n",
      "CO CO\n",
      "TM TM\n",
      "QF QF\n",
      "GL GL\n",
      "TJ TJ\n",
      "JP JP\n",
      "QY QY\n",
      "ML ML\n",
      "RM RM\n",
      "BN BN\n",
      "FQ FQ\n",
      "BM BM\n",
      "BV BV\n",
      "KB KB\n",
      "QI QI\n",
      "CU CU\n",
      "LQ LQ\n",
      "JY JY\n",
      "BO BO\n",
      "KO KO\n",
      "SA SA\n",
      "ME ME\n",
      "SG SG\n",
      "ZO ZO\n",
      "WZ WZ\n",
      "AW AW\n",
      "JC JC\n",
      "JT JT\n",
      "CJ CJ\n",
      "VC VC\n",
      "QW CW\n",
      "TE TE\n",
      "IG IG\n",
      "NK NK\n",
      "HS HS\n",
      "OY OY\n",
      "CS CS\n",
      "TS TS\n",
      "IJ IJ\n",
      "YE YE\n",
      "JM JM\n",
      "DK DK\n",
      "TG TG\n",
      "DI DI\n",
      "BG BG\n",
      "LO LO\n",
      "IX IX\n",
      "DP DP\n",
      "LK LK\n",
      "BL BL\n",
      "ZT ZT\n",
      "DZ DZ\n",
      "YC YC\n",
      "UG UG\n",
      "KV KV\n",
      "QN QN\n",
      "VC VC\n",
      "FB FB\n",
      "TX TX\n",
      "JX JX\n",
      "QO QO\n",
      "JY JY\n",
      "HN HN\n",
      "DG DG\n",
      "XF XF\n",
      "WS WS\n",
      "WD WD\n",
      "KJ KJ\n",
      "AS AS\n",
      "MG MG\n",
      "JL JL\n",
      "LA LA\n",
      "NK NK\n",
      "TT TT\n",
      "AW AW\n",
      "DT DT\n",
      "VN VN\n",
      "ED ED\n",
      "HX HX\n",
      "YD YD\n",
      "NF NF\n",
      "TJ TJ\n",
      "BQ BQ\n",
      "FQ FQ\n",
      "ZC ZC\n",
      "WQ WQ\n",
      "EP EP\n",
      "VP VP\n",
      "VT VT\n",
      "DO DO\n",
      "BW BW\n",
      "RA RA\n",
      "ET ET\n",
      "AW AW\n",
      "CV CV\n",
      "MN MN\n",
      "QO QO\n",
      "CB CB\n",
      "TZ TZ\n",
      "QB QB\n",
      "PX PX\n",
      "JJ JJ\n",
      "BD BD\n",
      "XN XN\n",
      "TC TC\n",
      "BR BR\n",
      "DK DK\n",
      "FM FM\n",
      "KY KY\n",
      "KP KP\n",
      "CA CA\n",
      "JL JL\n",
      "GI GI\n",
      "BD BD\n",
      "PU PU\n",
      "WC WC\n",
      "OI OI\n",
      "OX OX\n",
      "SM SM\n",
      "TX TX\n",
      "KD KD\n",
      "JZ JZ\n",
      "CT CT\n",
      "AH AH\n",
      "US US\n",
      "JZ JZ\n",
      "EA EA\n",
      "DN DN\n",
      "SV SV\n",
      "TZ TZ\n",
      "LV LV\n",
      "EZ EZ\n",
      "JP JP\n",
      "GH GH\n",
      "OQ OQ\n",
      "PK PK\n",
      "JR JR\n",
      "YO YO\n",
      "WR WR\n",
      "SS SS\n",
      "JN JN\n",
      "XV XV\n",
      "UT UT\n",
      "PD PD\n",
      "OE OE\n",
      "CB CB\n",
      "EI EI\n",
      "KQ KQ\n",
      "FK FK\n",
      "LI LI\n",
      "ZF ZF\n",
      "RS RS\n",
      "HF HF\n",
      "QP QP\n",
      "VO VO\n",
      "TA TA\n",
      "KR KR\n",
      "EQ EQ\n",
      "VN VX\n",
      "KW KW\n",
      "WI WI\n",
      "YE YE\n",
      "TZ TZ\n",
      "LT LT\n",
      "SU SU\n",
      "YI YI\n",
      "VI VI\n",
      "YP YP\n",
      "JA JA\n",
      "JY JY\n",
      "BG BG\n",
      "ZL ZL\n",
      "IL IL\n",
      "IK IK\n",
      "QJ QJ\n",
      "AK AK\n",
      "WU WU\n",
      "QG QG\n",
      "TK TK\n",
      "YX YX\n",
      "FV FV\n",
      "OI OI\n",
      "HV HV\n",
      "ZF ZF\n",
      "YA YA\n",
      "EO EO\n",
      "IU IU\n",
      "AC AC\n",
      "UA UA\n",
      "SF SF\n",
      "IU IU\n",
      "JG JG\n",
      "NN NN\n",
      "RF RF\n",
      "YS YS\n",
      "WD WD\n",
      "ZU ZU\n",
      "LF LF\n",
      "DU DU\n",
      "JY JY\n",
      "QJ QJ\n",
      "PI PI\n",
      "HZ HZ\n",
      "NH NH\n",
      "HB HB\n",
      "MB MB\n",
      "KX KX\n",
      "CT CT\n",
      "VM VM\n",
      "CQ CQ\n",
      "WX WX\n",
      "OA OA\n",
      "GU GU\n",
      "WQ WQ\n",
      "EW EW\n",
      "VA VA\n",
      "IP IP\n",
      "WF WF\n",
      "ZS ZS\n",
      "ZL ZL\n",
      "CR CR\n",
      "GK GK\n",
      "PI PI\n",
      "TU TU\n",
      "GR HE\n",
      "UJ UJ\n",
      "QT QT\n",
      "UH UH\n",
      "SM SM\n",
      "GS GS\n",
      "GW GW\n",
      "GD GD\n",
      "XH XH\n",
      "IU IU\n",
      "TR TR\n",
      "ET ET\n",
      "DE DE\n",
      "XB XB\n",
      "BO BO\n",
      "XV XV\n",
      "BY BY\n",
      "LQ LQ\n",
      "VM VM\n",
      "BW BW\n",
      "LB LB\n",
      "TB TB\n",
      "QP QP\n",
      "VL VL\n",
      "FG FG\n",
      "CF CF\n",
      "DA DA\n",
      "TH TH\n",
      "VY VY\n",
      "CZ CZ\n",
      "RX RX\n",
      "WD WD\n",
      "HA HA\n",
      "XO XO\n",
      "UE UE\n",
      "YF YF\n",
      "YM YM\n",
      "GK GK\n",
      "SH SH\n",
      "IQ IQ\n",
      "JG JG\n",
      "IR IR\n",
      "FV FV\n",
      "MH MH\n",
      "ZH ZH\n",
      "MS MS\n",
      "NQ NQ\n",
      "HL HL\n",
      "TK TK\n",
      "GG GG\n",
      "RZ RZ\n",
      "EL EL\n",
      "KP KP\n",
      "LH LH\n",
      "NR NR\n",
      "RR XY\n",
      "YJ YJ\n",
      "CO CO\n",
      "YK YK\n",
      "RR XY\n",
      "DX DX\n",
      "UY UY\n",
      "SH SH\n",
      "WP WP\n",
      "QA QA\n",
      "AM AM\n",
      "SJ SJ\n",
      "AW AW\n",
      "JA JA\n",
      "BM BM\n",
      "EX EX\n",
      "QG QG\n",
      "DC DC\n",
      "PA PA\n",
      "OP OP\n",
      "ZM ZM\n",
      "AF AF\n",
      "MV MV\n",
      "MW MW\n",
      "JR JR\n",
      "FS FS\n",
      "GR HE\n",
      "VI VI\n",
      "LT LT\n",
      "AX AX\n",
      "DO DO\n",
      "AE AE\n",
      "XQ XQ\n",
      "UK UK\n",
      "HA HA\n",
      "VP VP\n",
      "FA FA\n",
      "KX KX\n",
      "WX WX\n",
      "JS JS\n",
      "RV RV\n",
      "DM DM\n",
      "XT XT\n",
      "XO XO\n",
      "JY JY\n",
      "JD JD\n",
      "RR RR\n",
      "WY WY\n",
      "DH DH\n",
      "AL AL\n",
      "PG PG\n",
      "US US\n",
      "BT BT\n",
      "TR TR\n",
      "YR YR\n",
      "LQ LQ\n",
      "GM GM\n",
      "MF MF\n",
      "ZK ZK\n",
      "SW SW\n",
      "QN QN\n",
      "BS BS\n",
      "JG JG\n",
      "IJ IJ\n",
      "GT GT\n",
      "SM VU\n",
      "OZ OZ\n",
      "BX BX\n",
      "YU YU\n",
      "OF OF\n",
      "PZ PZ\n",
      "FV FV\n",
      "ZC ZC\n",
      "BV BV\n",
      "KZ KZ\n",
      "IC IC\n",
      "KK KK\n",
      "GE GE\n",
      "CS CS\n",
      "RV RV\n",
      "CR CR\n",
      "YM YM\n",
      "FL FL\n",
      "MM MM\n",
      "YM YM\n",
      "JT JT\n",
      "DK DK\n",
      "RN RN\n",
      "QK QK\n",
      "WX WX\n",
      "QZ QZ\n",
      "DL DL\n",
      "CP CP\n",
      "PX PX\n",
      "MR MR\n",
      "ZG ZG\n",
      "SP SP\n",
      "DL DL\n",
      "LM LM\n",
      "IG IG\n",
      "MR MR\n",
      "HQ HQ\n",
      "DU DU\n",
      "SD SD\n",
      "KI KI\n",
      "SI SI\n",
      "HD HD\n",
      "UM UM\n",
      "PB PB\n",
      "MQ MQ\n",
      "YC YC\n",
      "NO NO\n",
      "JX JX\n",
      "GV GV\n",
      "DE DE\n",
      "OS OS\n",
      "CN CN\n",
      "YE YE\n",
      "MF MF\n",
      "MU MU\n",
      "DH DH\n",
      "IY IY\n",
      "AX AX\n",
      "GR GR\n",
      "WQ WQ\n",
      "DX DX\n",
      "XA XA\n",
      "ZW ZW\n",
      "BF BF\n",
      "OC OC\n",
      "XQ XQ\n",
      "ZA ZA\n",
      "VE VE\n",
      "HC HC\n",
      "ZX ZX\n",
      "IC IC\n",
      "HU HU\n",
      "YD YD\n",
      "NF NF\n",
      "KZ KZ\n",
      "JH JH\n",
      "VD VD\n",
      "FA FA\n",
      "SS SS\n",
      "VW VW\n",
      "GK GK\n",
      "UZ UZ\n",
      "AZ AZ\n",
      "VY VY\n",
      "PY PY\n",
      "YF YF\n",
      "LP LP\n",
      "CI CI\n",
      "QI QI\n",
      "GX GX\n",
      "AZ AZ\n",
      "GB GB\n",
      "LM LM\n",
      "SS SS\n",
      "UO UO\n",
      "OG OG\n",
      "SZ SZ\n",
      "MR MR\n",
      "DA DA\n",
      "WZ WZ\n",
      "QA QA\n",
      "MZ MZ\n",
      "FJ FJ\n",
      "OM OM\n",
      "LH LH\n",
      "XD XD\n",
      "GS GS\n",
      "RR RR\n",
      "SQ SQ\n",
      "HC HC\n",
      "PH PH\n",
      "VZ VZ\n",
      "YD YD\n",
      "IJ IJ\n",
      "UU UU\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prediction_list)):\n",
    "    print(\"\".join(prediction_list[i]), \"\".join(label_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because seed doesn't help, every time the results might be different. In our report, we used this result to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PB', 'PF'),\n",
       " ('WU', 'WM'),\n",
       " ('GR', 'HE'),\n",
       " ('WW', 'JW'),\n",
       " ('RR', 'XY'),\n",
       " ('SM', 'VU'),\n",
       " ('QW', 'CW'),\n",
       " ('VN', 'VX')]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))\n",
    "output = []\n",
    "for x in diff:\n",
    "    if x not in output:\n",
    "        output.append(x)\n",
    "print(\"Errors:\")\n",
    "output.remove(True)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick an error see if the model can predict it well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [\"VN\"]\n",
    "for i in range(1000):\n",
    "    temp.append(\"SA\")\n",
    "x_test, y_test, y_test_small = data_test(temp)\n",
    "prediction_list, label_list = predict_results_only_2(model, x_test, y_test)\n",
    "diff = list(map(find_diff, prediction_list, label_list))\n",
    "output = []\n",
    "for x in diff:\n",
    "    if x not in output:\n",
    "        output.append(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 3 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 3 letters have 17576 different combinations, we set the for loop times to 20000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "x_train, y_train, y_train_small = data_genelization(sample_size = 3, loops = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 5s 235us/step - loss: 0.2133 - binary_accuracy: 0.9480\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.1229 - binary_accuracy: 0.9623\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.0816 - binary_accuracy: 0.9714\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 76us/step - loss: 0.0571 - binary_accuracy: 0.9810\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 1s 73us/step - loss: 0.0433 - binary_accuracy: 0.9863\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 1s 74us/step - loss: 0.0351 - binary_accuracy: 0.9894\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.0296 - binary_accuracy: 0.9914\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.0249 - binary_accuracy: 0.9930\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 1s 69us/step - loss: 0.0203 - binary_accuracy: 0.9944\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.0158 - binary_accuracy: 0.9957\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.0119 - binary_accuracy: 0.9969\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.0085 - binary_accuracy: 0.9980\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.0057 - binary_accuracy: 0.9988\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.0037 - binary_accuracy: 0.9994\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.0023 - binary_accuracy: 0.9997\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 1s 57us/step - loss: 0.0014 - binary_accuracy: 0.9999\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 9.2103e-04 - binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 1s 69us/step - loss: 5.9408e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 3.9398e-04 - binary_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 2.6408e-04 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a583c40f0>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index1, index2, index3, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return ([I2L[index1], I2L[index2], I2L[index3]])\n",
    "\n",
    "\n",
    "def predict_results_only_3(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index1 = np.argmax(predictions[:, 0:26], axis=1)\n",
    "    index2 = np.argmax(predictions[:, 26:52], axis=1)\n",
    "    index3 = np.argmax(predictions[:, 52:-1], axis=1)\n",
    "    label1 = np.argmax(y_train[:, 0:26], axis=1)\n",
    "    label2 = np.argmax(y_train[:, 26:52], axis=1)\n",
    "    label3 = np.argmax(y_train[:, 52:-1], axis=1)\n",
    "\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index1, index2, index3))\n",
    "    label_list = list(map(num2str, label1, label2, label3))\n",
    "\n",
    "    return (prediction_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(list1, list2):   \n",
    "    if \"\".join(list1) != \"\".join(list2):\n",
    "        return(\"\".join(list1), \"\".join(list2))\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test, y_test_small = data_genelization(sample_size = 3)\n",
    "prediction_list, label_list = predict_results_only_3(model, x_test, y_test)\n",
    "#prediction_list, label_list = predict_results_only_3(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 predictions:\n",
      "PSP PSP\n",
      "VAG VAG\n",
      "SQW SQW\n",
      "CLI CLI\n",
      "SPT SPT\n",
      "REE REE\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 6 predictions:\")\n",
    "for i in range(6):\n",
    "    print(\"\".join(prediction_list[i]), \"\".join(label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show some errors:\n",
      "('QFK', 'QFA')\n",
      "('LYK', 'LYA')\n",
      "('HUG', 'HUA')\n",
      "('WNK', 'WNA')\n",
      "('OJD', 'OJA')\n",
      "('FNK', 'FNA')\n",
      "The num of total errors: 33\n",
      "The accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))\n",
    "output = []\n",
    "for x in diff:\n",
    "    if x not in output:\n",
    "        output.append(x)\n",
    "print(\"Show some errors:\")\n",
    "output.remove(True)\n",
    "for i in range(6):\n",
    "    print(output[i])\n",
    "print(\"The num of total errors:\", len(output))\n",
    "print(\"The accuracy:\", 1-len(output)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 4 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6743 - binary_accuracy: 0.6908\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.5730 - binary_accuracy: 0.9254\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.3244 - binary_accuracy: 0.9588\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1773 - binary_accuracy: 0.9615\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1664 - binary_accuracy: 0.9615\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1640 - binary_accuracy: 0.9615\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1627 - binary_accuracy: 0.9615\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1618 - binary_accuracy: 0.9615\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1610 - binary_accuracy: 0.9615\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.1602 - binary_accuracy: 0.9615\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1594 - binary_accuracy: 0.9615\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1586 - binary_accuracy: 0.9615\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.1578 - binary_accuracy: 0.9615\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1568 - binary_accuracy: 0.9615\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1557 - binary_accuracy: 0.9615\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1546 - binary_accuracy: 0.9615\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1533 - binary_accuracy: 0.9615\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1520 - binary_accuracy: 0.9615\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1505 - binary_accuracy: 0.9615\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1489 - binary_accuracy: 0.9615\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1472 - binary_accuracy: 0.9615\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1454 - binary_accuracy: 0.9615\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1436 - binary_accuracy: 0.9615\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1416 - binary_accuracy: 0.9615\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.1397 - binary_accuracy: 0.9615\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.1377 - binary_accuracy: 0.9615\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1356 - binary_accuracy: 0.9615\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1336 - binary_accuracy: 0.9616\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1316 - binary_accuracy: 0.9616\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1296 - binary_accuracy: 0.9617\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1274 - binary_accuracy: 0.9617\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1252 - binary_accuracy: 0.9618\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1230 - binary_accuracy: 0.9619\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1209 - binary_accuracy: 0.9620\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1188 - binary_accuracy: 0.9622\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1167 - binary_accuracy: 0.9625\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.1148 - binary_accuracy: 0.9627\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1127 - binary_accuracy: 0.9629\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1109 - binary_accuracy: 0.9632\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1090 - binary_accuracy: 0.9636\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1072 - binary_accuracy: 0.9639\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1053 - binary_accuracy: 0.9645\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1036 - binary_accuracy: 0.9650\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1018 - binary_accuracy: 0.9655\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1000 - binary_accuracy: 0.9659\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0983 - binary_accuracy: 0.9663\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0966 - binary_accuracy: 0.9670\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0949 - binary_accuracy: 0.9675\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0932 - binary_accuracy: 0.9680\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0916 - binary_accuracy: 0.9683\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0900 - binary_accuracy: 0.9688\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0885 - binary_accuracy: 0.9695\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0869 - binary_accuracy: 0.9698\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0855 - binary_accuracy: 0.9704\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0840 - binary_accuracy: 0.9709\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0826 - binary_accuracy: 0.9715\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0813 - binary_accuracy: 0.9718\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0799 - binary_accuracy: 0.9723\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0786 - binary_accuracy: 0.9725\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0774 - binary_accuracy: 0.9731\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0762 - binary_accuracy: 0.9735\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0750 - binary_accuracy: 0.9741\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.0738 - binary_accuracy: 0.9745\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.0727 - binary_accuracy: 0.9751\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0717 - binary_accuracy: 0.9753\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0706 - binary_accuracy: 0.9759\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0695 - binary_accuracy: 0.9763\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0684 - binary_accuracy: 0.9767\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0675 - binary_accuracy: 0.9770\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0665 - binary_accuracy: 0.9773\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0655 - binary_accuracy: 0.9777\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0645 - binary_accuracy: 0.9781\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 0s 108us/step - loss: 0.0636 - binary_accuracy: 0.9785\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0627 - binary_accuracy: 0.9790\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0618 - binary_accuracy: 0.9794\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0609 - binary_accuracy: 0.9797\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0601 - binary_accuracy: 0.9800\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0592 - binary_accuracy: 0.9800\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0584 - binary_accuracy: 0.9805\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0576 - binary_accuracy: 0.9807\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0568 - binary_accuracy: 0.9809\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.0560 - binary_accuracy: 0.9815\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0553 - binary_accuracy: 0.9816\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0546 - binary_accuracy: 0.9818\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0539 - binary_accuracy: 0.9820\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0532 - binary_accuracy: 0.9823\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0525 - binary_accuracy: 0.9826\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0518 - binary_accuracy: 0.9828\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0512 - binary_accuracy: 0.9831\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0505 - binary_accuracy: 0.9832\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0500 - binary_accuracy: 0.9837\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0494 - binary_accuracy: 0.9837\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0488 - binary_accuracy: 0.9840\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0483 - binary_accuracy: 0.9841\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0478 - binary_accuracy: 0.9844\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0472 - binary_accuracy: 0.9846\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0466 - binary_accuracy: 0.9847\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.0461 - binary_accuracy: 0.9849\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0456 - binary_accuracy: 0.9850\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0451 - binary_accuracy: 0.9855\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0446 - binary_accuracy: 0.9854\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0442 - binary_accuracy: 0.9858\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0437 - binary_accuracy: 0.9860\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0431 - binary_accuracy: 0.9861\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0427 - binary_accuracy: 0.9862\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0423 - binary_accuracy: 0.9864\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0418 - binary_accuracy: 0.9868\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0413 - binary_accuracy: 0.9869\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0409 - binary_accuracy: 0.9869\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0405 - binary_accuracy: 0.9874\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0401 - binary_accuracy: 0.9875\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 0.0396 - binary_accuracy: 0.9876\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 0s 105us/step - loss: 0.0393 - binary_accuracy: 0.9878\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.0388 - binary_accuracy: 0.9877\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.0384 - binary_accuracy: 0.9879\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0381 - binary_accuracy: 0.9883\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0378 - binary_accuracy: 0.9883\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0373 - binary_accuracy: 0.9885\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0370 - binary_accuracy: 0.9883\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0366 - binary_accuracy: 0.9888\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 0s 98us/step - loss: 0.0363 - binary_accuracy: 0.9887\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0359 - binary_accuracy: 0.9888\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0356 - binary_accuracy: 0.9889\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0352 - binary_accuracy: 0.9892\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0349 - binary_accuracy: 0.9891\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0347 - binary_accuracy: 0.9892\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0343 - binary_accuracy: 0.9896\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0340 - binary_accuracy: 0.9894\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0337 - binary_accuracy: 0.9897\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0334 - binary_accuracy: 0.9897\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0330 - binary_accuracy: 0.9898\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0327 - binary_accuracy: 0.9899\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0325 - binary_accuracy: 0.9899\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0321 - binary_accuracy: 0.9901\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 0s 107us/step - loss: 0.0319 - binary_accuracy: 0.9903\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0316 - binary_accuracy: 0.9904\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 0s 105us/step - loss: 0.0314 - binary_accuracy: 0.9905\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0310 - binary_accuracy: 0.9906\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0307 - binary_accuracy: 0.9908\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0305 - binary_accuracy: 0.9909\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0302 - binary_accuracy: 0.9910\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0300 - binary_accuracy: 0.9911\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0297 - binary_accuracy: 0.9911\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0293 - binary_accuracy: 0.9912\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0292 - binary_accuracy: 0.9914\n",
      "Epoch 146/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0288 - binary_accuracy: 0.9914\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0287 - binary_accuracy: 0.9915\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0283 - binary_accuracy: 0.9917\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0281 - binary_accuracy: 0.9915\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0278 - binary_accuracy: 0.9918\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0276 - binary_accuracy: 0.9920\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0274 - binary_accuracy: 0.9921\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0271 - binary_accuracy: 0.9921\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0269 - binary_accuracy: 0.9921\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0268 - binary_accuracy: 0.9921\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0264 - binary_accuracy: 0.9921\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0262 - binary_accuracy: 0.9923\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0259 - binary_accuracy: 0.9924\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0257 - binary_accuracy: 0.9927\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0255 - binary_accuracy: 0.9925\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0253 - binary_accuracy: 0.9927\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0250 - binary_accuracy: 0.9929\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0249 - binary_accuracy: 0.9929\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0246 - binary_accuracy: 0.9929\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0244 - binary_accuracy: 0.9929\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0242 - binary_accuracy: 0.9931\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0240 - binary_accuracy: 0.9930\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0238 - binary_accuracy: 0.9933\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0236 - binary_accuracy: 0.9933\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0234 - binary_accuracy: 0.9934\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0231 - binary_accuracy: 0.9934\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0230 - binary_accuracy: 0.9935\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0228 - binary_accuracy: 0.9933\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0226 - binary_accuracy: 0.9935\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0224 - binary_accuracy: 0.9937\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0223 - binary_accuracy: 0.9935\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0220 - binary_accuracy: 0.9939\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0218 - binary_accuracy: 0.9937\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0218 - binary_accuracy: 0.9939\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0215 - binary_accuracy: 0.9940\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0213 - binary_accuracy: 0.9939\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0212 - binary_accuracy: 0.9941\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0210 - binary_accuracy: 0.9942\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0209 - binary_accuracy: 0.9942\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0207 - binary_accuracy: 0.9943\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0206 - binary_accuracy: 0.9943\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.0204 - binary_accuracy: 0.9942\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0202 - binary_accuracy: 0.9945\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0200 - binary_accuracy: 0.9945\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0199 - binary_accuracy: 0.9946\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.0197 - binary_accuracy: 0.9945\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 0.0196 - binary_accuracy: 0.9947\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 0s 114us/step - loss: 0.0194 - binary_accuracy: 0.9948\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 0s 108us/step - loss: 0.0193 - binary_accuracy: 0.9948\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 0.0192 - binary_accuracy: 0.9948\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 0s 107us/step - loss: 0.0190 - binary_accuracy: 0.9948\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.0188 - binary_accuracy: 0.9950\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0188 - binary_accuracy: 0.9948\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0186 - binary_accuracy: 0.9950\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0185 - binary_accuracy: 0.9951\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0183 - binary_accuracy: 0.9951\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 0.0182 - binary_accuracy: 0.9950\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0181 - binary_accuracy: 0.9951\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0179 - binary_accuracy: 0.9952\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0178 - binary_accuracy: 0.9953\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0177 - binary_accuracy: 0.9953\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0176 - binary_accuracy: 0.9953\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0174 - binary_accuracy: 0.9955\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0173 - binary_accuracy: 0.9953\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0173 - binary_accuracy: 0.9955\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0170 - binary_accuracy: 0.9955\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0170 - binary_accuracy: 0.9954\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0169 - binary_accuracy: 0.9956\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0167 - binary_accuracy: 0.9955\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0166 - binary_accuracy: 0.9957\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0164 - binary_accuracy: 0.9957\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0163 - binary_accuracy: 0.9958\n",
      "Epoch 218/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0163 - binary_accuracy: 0.9957\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0161 - binary_accuracy: 0.9958\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0160 - binary_accuracy: 0.9960\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0159 - binary_accuracy: 0.9957\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.0158 - binary_accuracy: 0.9959\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0157 - binary_accuracy: 0.9958\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0156 - binary_accuracy: 0.9960\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0154 - binary_accuracy: 0.9959\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0153 - binary_accuracy: 0.9962\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0153 - binary_accuracy: 0.9961\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0151 - binary_accuracy: 0.9961\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0150 - binary_accuracy: 0.9962\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0150 - binary_accuracy: 0.9962\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0149 - binary_accuracy: 0.9963\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0147 - binary_accuracy: 0.9964\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.0147 - binary_accuracy: 0.9963\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.0145 - binary_accuracy: 0.9963\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0144 - binary_accuracy: 0.9963\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0143 - binary_accuracy: 0.9964\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0143 - binary_accuracy: 0.9963\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0142 - binary_accuracy: 0.9965\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 0.0140 - binary_accuracy: 0.9964\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0140 - binary_accuracy: 0.9965\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0138 - binary_accuracy: 0.9966\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0138 - binary_accuracy: 0.9965\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0136 - binary_accuracy: 0.9967\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0136 - binary_accuracy: 0.9965\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0135 - binary_accuracy: 0.9967\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0134 - binary_accuracy: 0.9967\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0133 - binary_accuracy: 0.9967\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0132 - binary_accuracy: 0.9967\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0131 - binary_accuracy: 0.9968\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0130 - binary_accuracy: 0.9970\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0130 - binary_accuracy: 0.9968\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0128 - binary_accuracy: 0.9971\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0127 - binary_accuracy: 0.9970\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0127 - binary_accuracy: 0.9969\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0126 - binary_accuracy: 0.9970\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0124 - binary_accuracy: 0.9971\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0124 - binary_accuracy: 0.9970\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0124 - binary_accuracy: 0.9971\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0123 - binary_accuracy: 0.9971\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0122 - binary_accuracy: 0.9970\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0120 - binary_accuracy: 0.9971\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0120 - binary_accuracy: 0.9973\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0118 - binary_accuracy: 0.9972\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0118 - binary_accuracy: 0.9973\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0117 - binary_accuracy: 0.9972\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0117 - binary_accuracy: 0.9973\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0116 - binary_accuracy: 0.9974\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0115 - binary_accuracy: 0.9974\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0114 - binary_accuracy: 0.9972\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0114 - binary_accuracy: 0.9975\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0113 - binary_accuracy: 0.9974\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0112 - binary_accuracy: 0.9974\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0112 - binary_accuracy: 0.9973\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0110 - binary_accuracy: 0.9976\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0110 - binary_accuracy: 0.9975\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0109 - binary_accuracy: 0.9976\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0108 - binary_accuracy: 0.9976\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0108 - binary_accuracy: 0.9977\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0106 - binary_accuracy: 0.9976\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0105 - binary_accuracy: 0.9976\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0106 - binary_accuracy: 0.9976\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0105 - binary_accuracy: 0.9978\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0105 - binary_accuracy: 0.9977\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0103 - binary_accuracy: 0.9979\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0102 - binary_accuracy: 0.9978\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0102 - binary_accuracy: 0.9979\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0101 - binary_accuracy: 0.9979\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0101 - binary_accuracy: 0.9979\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0099 - binary_accuracy: 0.9979\n",
      "Epoch 290/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0099 - binary_accuracy: 0.9978\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0098 - binary_accuracy: 0.9979\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0098 - binary_accuracy: 0.9980\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.0097 - binary_accuracy: 0.9981\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0095 - binary_accuracy: 0.9981\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0096 - binary_accuracy: 0.9980\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0095 - binary_accuracy: 0.9981\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0094 - binary_accuracy: 0.9982\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0093 - binary_accuracy: 0.9982\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0093 - binary_accuracy: 0.9982\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0092 - binary_accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a585d7b70>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, y_test_small = data_genelization(sample_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11505960857868194, 0.9791249980926514]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify - Deep learning the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let strat with the simpliest model, say our alphabet has there letter ABC and the \"caeser\" function is to shift one place, ie. shift ABC to BCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size = 2,loops = 1000, size = 3, key = 1, x_as_vector = False, y_as_vector = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start at one middle layer\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=x_train.shape[1], activation='relu', name = \"input\"))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid', name = \"layer1\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1000/1000 [==============================] - 0s 383us/step - loss: 0.6871 - binary_accuracy: 0.5760\n",
      "Epoch 2/150\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.6657 - binary_accuracy: 0.5975\n",
      "Epoch 3/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6471 - binary_accuracy: 0.6115\n",
      "Epoch 4/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6296 - binary_accuracy: 0.6360\n",
      "Epoch 5/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6124 - binary_accuracy: 0.6602\n",
      "Epoch 6/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.5947 - binary_accuracy: 0.6923\n",
      "Epoch 7/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.5761 - binary_accuracy: 0.7293\n",
      "Epoch 8/150\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.5561 - binary_accuracy: 0.7473\n",
      "Epoch 9/150\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.5363 - binary_accuracy: 0.7772\n",
      "Epoch 10/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.5165 - binary_accuracy: 0.7977\n",
      "Epoch 11/150\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.4964 - binary_accuracy: 0.8012\n",
      "Epoch 12/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.4736 - binary_accuracy: 0.8370\n",
      "Epoch 13/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.4509 - binary_accuracy: 0.8370\n",
      "Epoch 14/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.4293 - binary_accuracy: 0.8413\n",
      "Epoch 15/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.4085 - binary_accuracy: 0.8535\n",
      "Epoch 16/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.3882 - binary_accuracy: 0.8582\n",
      "Epoch 17/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.3683 - binary_accuracy: 0.8727\n",
      "Epoch 18/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.3490 - binary_accuracy: 0.8727\n",
      "Epoch 19/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.3305 - binary_accuracy: 0.8862\n",
      "Epoch 20/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.3125 - binary_accuracy: 0.8920\n",
      "Epoch 21/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.2949 - binary_accuracy: 0.9078\n",
      "Epoch 22/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2779 - binary_accuracy: 0.9205\n",
      "Epoch 23/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.2618 - binary_accuracy: 0.9307\n",
      "Epoch 24/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2463 - binary_accuracy: 0.9495\n",
      "Epoch 25/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.2317 - binary_accuracy: 0.9538\n",
      "Epoch 26/150\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.2176 - binary_accuracy: 0.9667\n",
      "Epoch 27/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.2041 - binary_accuracy: 0.9792\n",
      "Epoch 28/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1911 - binary_accuracy: 0.9832\n",
      "Epoch 29/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1787 - binary_accuracy: 0.9832\n",
      "Epoch 30/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1669 - binary_accuracy: 0.9832\n",
      "Epoch 31/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1555 - binary_accuracy: 0.9832\n",
      "Epoch 32/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1450 - binary_accuracy: 0.9832\n",
      "Epoch 33/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1348 - binary_accuracy: 0.9832\n",
      "Epoch 34/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1252 - binary_accuracy: 0.9832\n",
      "Epoch 35/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1163 - binary_accuracy: 0.9832\n",
      "Epoch 36/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1079 - binary_accuracy: 0.9832\n",
      "Epoch 37/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1000 - binary_accuracy: 0.9978\n",
      "Epoch 38/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0926 - binary_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0857 - binary_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0793 - binary_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0735 - binary_accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0680 - binary_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0631 - binary_accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0586 - binary_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0544 - binary_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0505 - binary_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0470 - binary_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0438 - binary_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0409 - binary_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0382 - binary_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0357 - binary_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0334 - binary_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0314 - binary_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0295 - binary_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0277 - binary_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0261 - binary_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0247 - binary_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0233 - binary_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0220 - binary_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0209 - binary_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0198 - binary_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0188 - binary_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0178 - binary_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0170 - binary_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0161 - binary_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0154 - binary_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0147 - binary_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0140 - binary_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0134 - binary_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0128 - binary_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0122 - binary_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0117 - binary_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0112 - binary_accuracy: 1.0000\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0108 - binary_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0103 - binary_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0099 - binary_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0095 - binary_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0091 - binary_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0088 - binary_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0085 - binary_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0081 - binary_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0076 - binary_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0073 - binary_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0065 - binary_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0063 - binary_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0061 - binary_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0059 - binary_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0057 - binary_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0055 - binary_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0053 - binary_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0052 - binary_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0050 - binary_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0048 - binary_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0047 - binary_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0044 - binary_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0043 - binary_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0041 - binary_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0040 - binary_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0039 - binary_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0038 - binary_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0037 - binary_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0036 - binary_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0035 - binary_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0034 - binary_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0033 - binary_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0032 - binary_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0031 - binary_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0030 - binary_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0029 - binary_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0028 - binary_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0028 - binary_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0027 - binary_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0026 - binary_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0026 - binary_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0025 - binary_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0024 - binary_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0024 - binary_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0023 - binary_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0022 - binary_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0022 - binary_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0021 - binary_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0021 - binary_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0012 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2c3c9208>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what did the model learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 6)                 36        \n",
      "=================================================================\n",
      "Total params: 71\n",
      "Trainable params: 71\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our simple model structure:\n",
    "<img src=\"./images/simple.png\" width=\"400\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that we have 71 parameters. In the first layer, we have 30 weights and 5 biases. In the second layer, we have 30 weights and 6 biases which show as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.82606924,  0.8205743 , -2.2852252 ,  1.6901608 ,  1.1319901 ],\n",
       "        [ 1.3760408 ,  2.5458488 , -2.1797671 , -1.5172253 ,  1.0308439 ],\n",
       "        [-0.16585648, -0.2794935 ,  2.2665577 , -0.80191505,  1.6642292 ],\n",
       "        [-0.5681321 ,  1.5671    ,  2.4999106 ,  0.70694906, -2.2617538 ],\n",
       "        [ 2.1957273 , -2.2039256 ,  0.5776802 ,  1.5100118 , -0.7955079 ],\n",
       "        [-0.5618616 ,  0.95752865,  0.6824657 ,  0.3680279 ,  2.0694983 ]],\n",
       "       dtype=float32),\n",
       " array([1.3878925, 1.6281852, 1.6025935, 1.1489217, 1.1298584],\n",
       "       dtype=float32),\n",
       " array([[ 1.5484006 , -0.5972057 , -1.7155966 ,  2.036288  , -1.78507   ,\n",
       "         -1.5388893 ],\n",
       "        [ 1.1309438 , -1.8847716 , -0.26149613, -2.1800714 ,  0.05703444,\n",
       "          1.2034626 ],\n",
       "        [-1.292776  ,  2.1703794 , -1.2448043 , -0.38088757, -0.77099156,\n",
       "          0.731896  ],\n",
       "        [-2.5167356 , -1.4012274 ,  2.6635358 ,  0.7620649 , -1.3250663 ,\n",
       "         -0.17841093],\n",
       "        [-0.52961814,  0.6876993 , -0.24701497, -0.41188228,  2.614583  ,\n",
       "         -2.6184678 ]], dtype=float32),\n",
       " array([-0.28764233,  0.07647046, -0.3012865 , -0.0309343 , -0.8558167 ,\n",
       "         0.90004164], dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "biases = model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "# Set one layer as output we can get every layers' information given the input\n",
    "\n",
    "dense1_layer_model = Model(inputs=model.input,\n",
    "                                     outputs=model.get_layer('input').output)\n",
    "\n",
    "dense1_output = dense1_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.       , 3.4062881, 0.       , 3.2071104, 4.331347 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1299.,  468.,  116.,  349.,  214.,  541.,  118.,  229.,  114.,\n",
       "         328.,   99.,  448.,  236.,  224.,    0.,  101.,  116.]),\n",
       " array([0.       , 0.3746507, 0.7493014, 1.123952 , 1.4986027, 1.8732533,\n",
       "        2.247904 , 2.6225548, 2.9972055, 3.371856 , 3.7465067, 4.1211576,\n",
       "        4.495808 , 4.8704586, 5.2451096, 5.61976  , 5.994411 , 6.3690615],\n",
       "       dtype=float32),\n",
       " <a list of 17 Patch objects>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEDlJREFUeJzt3X+snmV9x/H3x1ZQcVqEI+vaZsXYuDGzDXLCcCSGWKcgxPKHLJBNO0bSLEGnY4kU9wfZFhPMFlETR9JQtGQMJKihUaYSkDj/ADlFJj+K0iCjZ0V7DD8UiWPod3+cq/GsPT2/ntPz9PR6v5KT576v+3ru+3tO2vM513X/eFJVSJL684phFyBJGg4DQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktSplcMuYCYnn3xyrV+/fthlSNKysmvXrp9U1chs/Y7qAFi/fj1jY2PDLkOSlpUk/zWXfk4BSVKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp47qO4EHtX7rVxdlP09ec/6i7EeSjiaOACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE7NGgBJbkiyP8nDU9r+KcljSb6X5MtJVk3ZdlWSPUm+n+TdU9rPbW17kmxd/G9FkjQfcxkBfB4496C2O4G3VtXvAz8ArgJIchpwMfB77T3/kmRFkhXAZ4HzgNOAS1pfSdKQzBoAVfUt4JmD2r5RVS+31XuBtW15E3BLVf1PVf0Q2AOc2b72VNUTVfUScEvrK0kaksU4B/CXwL+35TXA3inbxlvb4doPkWRLkrEkYxMTE4tQniRpOgMFQJK/A14GbjrQNE23mqH90MaqbVU1WlWjIyMjg5QnSZrBgj8QJslm4AJgY1Ud+GU+Dqyb0m0tsK8tH65dkjQECxoBJDkXuBJ4b1W9OGXTTuDiJMcnORXYAHwHuB/YkOTUJMcxeaJ452ClS5IGMesIIMnNwDnAyUnGgauZvOrneODOJAD3VtVfVdUjSW4FHmVyaujyqvpl288Hga8DK4AbquqRI/D9SJLmaNYAqKpLpmnePkP/jwMfn6b9DuCOeVUnSTpivBNYkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE7NGgBJbkiyP8nDU9rekOTOJI+31xNbe5J8JsmeJN9LcsaU92xu/R9PsvnIfDuSpLmaywjg88C5B7VtBe6qqg3AXW0d4DxgQ/vaAlwHk4EBXA38EXAmcPWB0JAkDcesAVBV3wKeOah5E7CjLe8ALpzSfmNNuhdYlWQ18G7gzqp6pqqeBe7k0FCRJC2hhZ4DOKWqngZor29s7WuAvVP6jbe2w7UfIsmWJGNJxiYmJhZYniRpNot9EjjTtNUM7Yc2Vm2rqtGqGh0ZGVnU4iRJv7bQAPhxm9qhve5v7ePAuin91gL7ZmiXJA3JQgNgJ3DgSp7NwO1T2j/QrgY6C3i+TRF9HXhXkhPbyd93tTZJ0pCsnK1DkpuBc4CTk4wzeTXPNcCtSS4DngIuat3vAN4D7AFeBC4FqKpnkvwjcH/r9w9VdfCJZUnSEpo1AKrqksNs2jhN3wIuP8x+bgBumFd1kqQjxjuBJalTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUQAGQ5G+SPJLk4SQ3J3lVklOT3Jfk8SRfSHJc63t8W9/Ttq9fjG9AkrQwCw6AJGuAvwZGq+qtwArgYuATwLVVtQF4FrisveUy4NmqejNwbesnSRqSQaeAVgKvTrISeA3wNPAO4La2fQdwYVve1NZp2zcmyYDHlyQt0IIDoKr+G/hn4Ckmf/E/D+wCnquql1u3cWBNW14D7G3vfbn1P+ng/SbZkmQsydjExMRCy5MkzWKQKaATmfyr/lTgt4ATgPOm6VoH3jLDtl83VG2rqtGqGh0ZGVloeZKkWQwyBfRO4IdVNVFV/wt8CfhjYFWbEgJYC+xry+PAOoC2/fXAMwMcX5I0gEEC4CngrCSvaXP5G4FHgW8C72t9NgO3t+WdbZ22/e6qOmQEIElaGoOcA7iPyZO5DwAPtX1tA64Erkiyh8k5/u3tLduBk1r7FcDWAeqWJA1o5exdDq+qrgauPqj5CeDMafr+ArhokONJkhaPdwJLUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKRODRQASVYluS3JY0l2J3lbkjckuTPJ4+31xNY3ST6TZE+S7yU5Y3G+BUnSQgw6Avg08LWq+h3gD4DdwFbgrqraANzV1gHOAza0ry3AdQMeW5I0gAUHQJLXAW8HtgNU1UtV9RywCdjRuu0ALmzLm4Aba9K9wKokqxdcuSRpIIOMAN4ETACfS/LdJNcnOQE4paqeBmivb2z91wB7p7x/vLVJkoZgkABYCZwBXFdVpwM/59fTPdPJNG11SKdkS5KxJGMTExMDlCdJmskgATAOjFfVfW39NiYD4ccHpnba6/4p/ddNef9aYN/BO62qbVU1WlWjIyMjA5QnSZrJggOgqn4E7E3ylta0EXgU2Alsbm2bgdvb8k7gA+1qoLOA5w9MFUmSlt7KAd//IeCmJMcBTwCXMhkqtya5DHgKuKj1vQN4D7AHeLH1lSQNyUABUFUPAqPTbNo4Td8CLh/keJKkxeOdwJLUKQNAkjplAEhSpwwASeqUASBJnRr0MlB1bv3Wry7Kfp685vxF2Y+kuXMEIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTPgpiDhbjcQc+6kDS0cYRgCR1ygCQpE45BSR1xKe3aipHAJLUKQNAkjplAEhSpwYOgCQrknw3yVfa+qlJ7kvyeJIvJDmutR/f1ve07esHPbYkaeEWYwTwYWD3lPVPANdW1QbgWeCy1n4Z8GxVvRm4tvWTJA3JQAGQZC1wPnB9Ww/wDuC21mUHcGFb3tTWads3tv6SpCEYdATwKeCjwK/a+knAc1X1clsfB9a05TXAXoC2/fnWX5I0BAsOgCQXAPuratfU5mm61hy2Td3vliRjScYmJiYWWp4kaRaDjADOBt6b5EngFianfj4FrEpy4AaztcC+tjwOrANo218PPHPwTqtqW1WNVtXoyMjIAOVJkmay4ACoqquqam1VrQcuBu6uqj8Dvgm8r3XbDNzelne2ddr2u6vqkBGAJGlpHIn7AK4Erkiyh8k5/u2tfTtwUmu/Ath6BI4tSZqjRXkWUFXdA9zTlp8Azpymzy+AixbjeJKkwXknsCR1ygCQpE4ZAJLUKT8PYJnxee6SFosjAEnqlAEgSZ0yACSpU54DkI4gz9noaOYIQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVM+DVTSvC3GU059wunwGQA6pvj4ZWnuFhwASdYBNwK/CfwK2FZVn07yBuALwHrgSeBPq+rZJAE+DbwHeBH4i6p6YLDyJS1XhvXwDXIO4GXgb6vqd4GzgMuTnAZsBe6qqg3AXW0d4DxgQ/vaAlw3wLElSQNa8Aigqp4Gnm7LP0uyG1gDbALOad12APcAV7b2G6uqgHuTrEqyuu1HS2yx/vqStHwtylVASdYDpwP3Aacc+KXeXt/Yuq0B9k5523hrkyQNwcABkOS1wBeBj1TVT2fqOk1bTbO/LUnGkoxNTEwMWp4k6TAGCoAkr2Tyl/9NVfWl1vzjJKvb9tXA/tY+Dqyb8va1wL6D91lV26pqtKpGR0ZGBilPkjSDBQdAu6pnO7C7qj45ZdNOYHNb3gzcPqX9A5l0FvC88/+SNDyD3AdwNvB+4KEkD7a2jwHXALcmuQx4CriobbuDyUtA9zB5GeilAxxbkjSgQa4C+jbTz+sDbJymfwGXL/R4kqTF5bOAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ3yE8GWiI9fnpk/Hx0rltMH3RgA0jQMJPXAKSBJ6pQjAGkZcERy5PX4M3YEIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdWrJAyDJuUm+n2RPkq1LfXxJ0qQlDYAkK4DPAucBpwGXJDltKWuQJE1a6hHAmcCeqnqiql4CbgE2LXENkiSWPgDWAHunrI+3NknSElvqzwPING31/zokW4AtbfWFJN8f4HgnAz8Z4P3DtJxrB+sftm7qzyeOcCXztyg/+wG/r9+eS6elDoBxYN2U9bXAvqkdqmobsG0xDpZkrKpGF2NfS2051w7WP2zWPzzLqfalngK6H9iQ5NQkxwEXAzuXuAZJEks8Aqiql5N8EPg6sAK4oaoeWcoaJEmTlvwzgavqDuCOJTrcokwlDclyrh2sf9isf3iWTe2pqtl7SZKOOT4KQpI6dUwGwHJ+3ESSG5LsT/LwsGtZiCTrknwzye4kjyT58LBrmo8kr0rynST/2er/+2HXNF9JViT5bpKvDLuW+UryZJKHkjyYZGzY9cxXklVJbkvyWPs/8LZh1zSTY24KqD1u4gfAnzB52en9wCVV9ehQC5ujJG8HXgBurKq3Drue+UqyGlhdVQ8k+Q1gF3DhMvr5Bzihql5I8krg28CHq+reIZc2Z0muAEaB11XVBcOuZz6SPAmMVtWyvIchyQ7gP6rq+nal42uq6rlh13U4x+IIYFk/bqKqvgU8M+w6Fqqqnq6qB9ryz4DdLKO7vWvSC231le1r2fyVlGQtcD5w/bBr6U2S1wFvB7YDVNVLR/Mvfzg2A8DHTRwlkqwHTgfuG24l89OmUB4E9gN3VtVyqv9TwEeBXw27kAUq4BtJdrWnAiwnbwImgM+1Kbjrk5ww7KJmciwGwKyPm9CRl+S1wBeBj1TVT4ddz3xU1S+r6g+ZvFP9zCTLYiouyQXA/qraNexaBnB2VZ3B5BODL29TosvFSuAM4LqqOh34OXBUn4M8FgNg1sdN6Mhqc+dfBG6qqi8Nu56FasP3e4Bzh1zKXJ0NvLfNo98CvCPJvw63pPmpqn3tdT/wZSandJeLcWB8yojxNiYD4ah1LAaAj5sYonYSdTuwu6o+Oex65ivJSJJVbfnVwDuBx4Zb1dxU1VVVtbaq1jP57/7uqvrzIZc1Z0lOaBcO0KZO3gUsm6vhqupHwN4kb2lNG4Gj+uKHJb8T+Ehb7o+bSHIzcA5wcpJx4Oqq2j7cqublbOD9wENtHh3gY+0O8OVgNbCjXU32CuDWqlp2l1MuU6cAX578G4KVwL9V1deGW9K8fQi4qf3x+QRw6ZDrmdExdxmoJGlujsUpIEnSHBgAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR16v8ABrhSk016NzsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense1_output[i] for i in range(1000)])\n",
    "plt.hist(a, bins='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2_layer_model = Model(inputs=model.input, outputs=model.get_layer('layer1').output)\n",
    "\n",
    "dense2_output = dense2_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4000.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0., 2000.]),\n",
       " array([1.9353628e-04, 7.1577862e-02, 1.4296219e-01, 2.1434651e-01,\n",
       "        2.8573084e-01, 3.5711515e-01, 4.2849949e-01, 4.9988380e-01,\n",
       "        5.7126814e-01, 6.4265245e-01, 7.1403676e-01, 7.8542107e-01,\n",
       "        8.5680544e-01, 9.2818975e-01, 9.9957407e-01], dtype=float32),\n",
       " <a list of 14 Patch objects>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dense2_output[1]\n",
    "a = np.hstack([dense2_output[i] for i in range(1000)])\n",
    "plt.hist(a, bins='auto') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, after calculating by two layers weights, the training data reduce the 1 value in the origin place and increase the value corresponding to the label place with value 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myfun import simpledata\n",
    "from myfun import simpledata_hidden\n",
    "# simpledata_hidden hides the combination AB\n",
    "x_train, y_train = simpledata_hidden()\n",
    "x_test, y_test = simpledata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start at one middle layer\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=x_train.shape[1], activation='relu', name = \"input\"))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid', name = \"layer1\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "801/801 [==============================] - 0s 259us/step - loss: 0.6962 - binary_accuracy: 0.5622\n",
      "Epoch 2/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.6801 - binary_accuracy: 0.5622\n",
      "Epoch 3/150\n",
      "801/801 [==============================] - 0s 39us/step - loss: 0.6648 - binary_accuracy: 0.5907\n",
      "Epoch 4/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.6499 - binary_accuracy: 0.6128\n",
      "Epoch 5/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.6345 - binary_accuracy: 0.6278\n",
      "Epoch 6/150\n",
      "801/801 [==============================] - 0s 42us/step - loss: 0.6190 - binary_accuracy: 0.6819\n",
      "Epoch 7/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.6035 - binary_accuracy: 0.7112\n",
      "Epoch 8/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.5863 - binary_accuracy: 0.7025\n",
      "Epoch 9/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.5658 - binary_accuracy: 0.7247\n",
      "Epoch 10/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.5432 - binary_accuracy: 0.7291\n",
      "Epoch 11/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.5217 - binary_accuracy: 0.7387\n",
      "Epoch 12/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.5009 - binary_accuracy: 0.7341\n",
      "Epoch 13/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.4810 - binary_accuracy: 0.7499\n",
      "Epoch 14/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.4621 - binary_accuracy: 0.7528\n",
      "Epoch 15/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.4443 - binary_accuracy: 0.7788\n",
      "Epoch 16/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.4275 - binary_accuracy: 0.8217\n",
      "Epoch 17/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.4115 - binary_accuracy: 0.8373\n",
      "Epoch 18/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.3958 - binary_accuracy: 0.8658\n",
      "Epoch 19/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.3808 - binary_accuracy: 0.8841\n",
      "Epoch 20/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.3668 - binary_accuracy: 0.8960\n",
      "Epoch 21/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.3536 - binary_accuracy: 0.8960\n",
      "Epoch 22/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.3409 - binary_accuracy: 0.8960\n",
      "Epoch 23/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.3287 - binary_accuracy: 0.8960\n",
      "Epoch 24/150\n",
      "801/801 [==============================] - 0s 39us/step - loss: 0.3169 - binary_accuracy: 0.8972\n",
      "Epoch 25/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.3051 - binary_accuracy: 0.9168\n",
      "Epoch 26/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.2936 - binary_accuracy: 0.9168\n",
      "Epoch 27/150\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.2823 - binary_accuracy: 0.9168\n",
      "Epoch 28/150\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.2709 - binary_accuracy: 0.9376\n",
      "Epoch 29/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.2598 - binary_accuracy: 0.9376\n",
      "Epoch 30/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.2489 - binary_accuracy: 0.9376\n",
      "Epoch 31/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.2383 - binary_accuracy: 0.9376\n",
      "Epoch 32/150\n",
      "801/801 [==============================] - 0s 39us/step - loss: 0.2277 - binary_accuracy: 0.9376\n",
      "Epoch 33/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.2171 - binary_accuracy: 0.9382\n",
      "Epoch 34/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.2070 - binary_accuracy: 0.9792\n",
      "Epoch 35/150\n",
      "801/801 [==============================] - 0s 38us/step - loss: 0.1971 - binary_accuracy: 0.9792\n",
      "Epoch 36/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.1874 - binary_accuracy: 0.9792\n",
      "Epoch 37/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.1783 - binary_accuracy: 0.9792\n",
      "Epoch 38/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.1692 - binary_accuracy: 0.9792\n",
      "Epoch 39/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.1606 - binary_accuracy: 0.9792\n",
      "Epoch 40/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.1522 - binary_accuracy: 0.9792\n",
      "Epoch 41/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.1442 - binary_accuracy: 0.9792\n",
      "Epoch 42/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.1364 - binary_accuracy: 0.9792\n",
      "Epoch 43/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.1291 - binary_accuracy: 0.9792\n",
      "Epoch 44/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.1223 - binary_accuracy: 0.9792\n",
      "Epoch 45/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.1157 - binary_accuracy: 0.9848\n",
      "Epoch 46/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.1095 - binary_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.1036 - binary_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0981 - binary_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.0928 - binary_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.0878 - binary_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.0831 - binary_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0787 - binary_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0745 - binary_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0706 - binary_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.0668 - binary_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0633 - binary_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0600 - binary_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0568 - binary_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0539 - binary_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0512 - binary_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0486 - binary_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0462 - binary_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0440 - binary_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0418 - binary_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0398 - binary_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0379 - binary_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0362 - binary_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0345 - binary_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0330 - binary_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0316 - binary_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0302 - binary_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0289 - binary_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0277 - binary_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0265 - binary_accuracy: 1.0000\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 33us/step - loss: 0.0254 - binary_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.0244 - binary_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0234 - binary_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.0225 - binary_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0216 - binary_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0208 - binary_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0200 - binary_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0193 - binary_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "801/801 [==============================] - 0s 28us/step - loss: 0.0186 - binary_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0179 - binary_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0172 - binary_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0166 - binary_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0160 - binary_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0155 - binary_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0150 - binary_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0145 - binary_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0140 - binary_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0135 - binary_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "801/801 [==============================] - 0s 23us/step - loss: 0.0131 - binary_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0127 - binary_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "801/801 [==============================] - 0s 23us/step - loss: 0.0123 - binary_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0119 - binary_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0115 - binary_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0112 - binary_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0108 - binary_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0105 - binary_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0102 - binary_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0099 - binary_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0096 - binary_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0093 - binary_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0090 - binary_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0088 - binary_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0085 - binary_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0083 - binary_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0081 - binary_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0076 - binary_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0074 - binary_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0072 - binary_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0067 - binary_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0065 - binary_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0063 - binary_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0062 - binary_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0060 - binary_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0059 - binary_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0057 - binary_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0056 - binary_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0054 - binary_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0053 - binary_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0052 - binary_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0050 - binary_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0049 - binary_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0048 - binary_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0047 - binary_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0046 - binary_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "801/801 [==============================] - 0s 29us/step - loss: 0.0044 - binary_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0043 - binary_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0042 - binary_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "801/801 [==============================] - 0s 32us/step - loss: 0.0041 - binary_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0040 - binary_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0039 - binary_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0038 - binary_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0037 - binary_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0036 - binary_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0035 - binary_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "801/801 [==============================] - 0s 28us/step - loss: 0.0035 - binary_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "801/801 [==============================] - 0s 29us/step - loss: 0.0034 - binary_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0033 - binary_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.0032 - binary_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.0032 - binary_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.0031 - binary_accuracy: 1.0000\n",
      "Epoch 149/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 32us/step - loss: 0.0030 - binary_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "801/801 [==============================] - 0s 29us/step - loss: 0.0030 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb28a93b70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 0s 12us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06111194011440023, 0.981502013121805]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that it cannot learn it well, so it maybe need to combine with some rule by using logic programming method to guide it. Say given AB, BA have similar structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad activation function and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we choose a bad activation function what would happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 3.6653 - categorical_accuracy: 0.2120\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 3.5776 - categorical_accuracy: 0.2120\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 3.5016 - categorical_accuracy: 0.3370\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 3.4364 - categorical_accuracy: 0.3500\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 3.3696 - categorical_accuracy: 0.2830\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 3.2995 - categorical_accuracy: 0.2120\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 3.2234 - categorical_accuracy: 0.2120\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 3.1440 - categorical_accuracy: 0.2120\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 3.0622 - categorical_accuracy: 0.2540\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.9762 - categorical_accuracy: 0.3230\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 2.8866 - categorical_accuracy: 0.3230\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 2.7943 - categorical_accuracy: 0.3390\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 2.6932 - categorical_accuracy: 0.4610\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 2.5884 - categorical_accuracy: 0.4610\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 2.4892 - categorical_accuracy: 0.4610\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 2.3944 - categorical_accuracy: 0.4610\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.3104 - categorical_accuracy: 0.4610\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.2364 - categorical_accuracy: 0.4610\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.1700 - categorical_accuracy: 0.4610\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.1109 - categorical_accuracy: 0.3910\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.0582 - categorical_accuracy: 0.3570\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.0106 - categorical_accuracy: 0.3570\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.9678 - categorical_accuracy: 0.3570\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.9279 - categorical_accuracy: 0.3570\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.8916 - categorical_accuracy: 0.3570\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.8586 - categorical_accuracy: 0.3570\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.8269 - categorical_accuracy: 0.3570\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 1.7972 - categorical_accuracy: 0.3570\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.7689 - categorical_accuracy: 0.4030\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 1.7420 - categorical_accuracy: 0.3570\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.7162 - categorical_accuracy: 0.3570\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.6917 - categorical_accuracy: 0.3970\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.6686 - categorical_accuracy: 0.4490\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.6462 - categorical_accuracy: 0.5120\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.6246 - categorical_accuracy: 0.4660\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.6042 - categorical_accuracy: 0.5370\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.5850 - categorical_accuracy: 0.5810\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.5672 - categorical_accuracy: 0.5190\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.5504 - categorical_accuracy: 0.6740\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.5352 - categorical_accuracy: 0.6260\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.5210 - categorical_accuracy: 0.6470\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.5083 - categorical_accuracy: 0.6740\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.4967 - categorical_accuracy: 0.6740\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.4864 - categorical_accuracy: 0.6740\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.4771 - categorical_accuracy: 0.6740\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.4687 - categorical_accuracy: 0.6740\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.4613 - categorical_accuracy: 0.6740\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.4546 - categorical_accuracy: 0.6280\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4488 - categorical_accuracy: 0.6270\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4436 - categorical_accuracy: 0.6670\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4390 - categorical_accuracy: 0.6210\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4349 - categorical_accuracy: 0.5850\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.4312 - categorical_accuracy: 0.6380\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4279 - categorical_accuracy: 0.5960\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4250 - categorical_accuracy: 0.6050\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4224 - categorical_accuracy: 0.6390\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4200 - categorical_accuracy: 0.5780\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4178 - categorical_accuracy: 0.5630\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.4158 - categorical_accuracy: 0.6530\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.4140 - categorical_accuracy: 0.5830\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4124 - categorical_accuracy: 0.5820\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4109 - categorical_accuracy: 0.5630\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.4095 - categorical_accuracy: 0.5030\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.4083 - categorical_accuracy: 0.6100\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4071 - categorical_accuracy: 0.5940\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.4060 - categorical_accuracy: 0.5550\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.4051 - categorical_accuracy: 0.5630\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4041 - categorical_accuracy: 0.6750\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.4033 - categorical_accuracy: 0.5740\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 1.4025 - categorical_accuracy: 0.6430\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 46us/step - loss: 1.4017 - categorical_accuracy: 0.7110\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 1.4011 - categorical_accuracy: 0.5740\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 1.4004 - categorical_accuracy: 0.6570\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 1.3998 - categorical_accuracy: 0.5610\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.3992 - categorical_accuracy: 0.6420\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.3987 - categorical_accuracy: 0.6180\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.3982 - categorical_accuracy: 0.5980\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.3977 - categorical_accuracy: 0.7040\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.3973 - categorical_accuracy: 0.5670\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.3968 - categorical_accuracy: 0.6790\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.3964 - categorical_accuracy: 0.6310\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 1.3960 - categorical_accuracy: 0.5760\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.3957 - categorical_accuracy: 0.5800\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 1.3953 - categorical_accuracy: 0.6260\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.3950 - categorical_accuracy: 0.6130\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.3947 - categorical_accuracy: 0.5450\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 1.3944 - categorical_accuracy: 0.5640\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1.3941 - categorical_accuracy: 0.6420\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 1.3939 - categorical_accuracy: 0.6060\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 1.3936 - categorical_accuracy: 0.5910\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.3934 - categorical_accuracy: 0.6380\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.3931 - categorical_accuracy: 0.5980\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.3929 - categorical_accuracy: 0.5640\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.3927 - categorical_accuracy: 0.5990\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 1.3925 - categorical_accuracy: 0.5540\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.3923 - categorical_accuracy: 0.6200\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.3921 - categorical_accuracy: 0.5490\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.3920 - categorical_accuracy: 0.5880\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 1.3918 - categorical_accuracy: 0.5510\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 1.3916 - categorical_accuracy: 0.5970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a585eec88>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the accuracy cannot converge to 1 because the softmax and categorical cross entropy treat the output as a distribution, however, it is not a classfication problem. This time our output has two value should be 1, so it is not suitable to use softmax and categorical crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6919137e-04, 4.9912450e-01, 1.3113728e-04, 4.9975443e-01,\n",
       "       2.6179088e-04, 3.5900806e-04], dtype=float32)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000536238076"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.predict(x_train)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Robustness testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import misslabeled_data_genelization\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index1, index2, size=26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return ([I2L[index1], I2L[index2]])\n",
    "\n",
    "\n",
    "def predict_results_only_2(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index1 = np.argmax(predictions[:, 0:26], axis=1)\n",
    "    index2 = np.argmax(predictions[:, 26:52], axis=1)\n",
    "    label1 = np.argmax(y_train[:, 0:26], axis=1)\n",
    "    label2 = np.argmax(y_train[:, 26:52], axis=1)\n",
    "\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index1, index2))\n",
    "    label_list = list(map(num2str, label1, label2))\n",
    "\n",
    "    return (prediction_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(list1, list2, ifprint = False):\n",
    "    if \"\".join(list1) != \"\".join(list2):\n",
    "        if ifprint == True:\n",
    "            print(\"\".join(list1), \"\".join(list2))\n",
    "        return (\"\".join(list1), \"\".join(list2))\n",
    "    else:\n",
    "        return (True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function misslabeled_data_genelization in module myfun:\n",
      "\n",
      "misslabeled_data_genelization(sample_size=2, loops=1000, size=26, key=3, prob=0.1, x_as_vector=False, y_as_vector=False)\n",
      "    data_genelization(sample_size = 2,loops = 1000, size = 26, key = 3, x_as_vector = False, y_as_vector = False):\n",
      "    return x_train, label with equual size, labels with 1 dimension\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(misslabeled_data_genelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = misslabeled_data_genelization(loops=10000, prob=0)\n",
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10000/10000 [==============================] - 1s 58us/step - loss: 0.2733 - acc: 0.9253\n",
      "Epoch 2/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1459 - acc: 0.9615\n",
      "Epoch 3/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1144 - acc: 0.9622\n",
      "Epoch 4/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0816 - acc: 0.9690\n",
      "Epoch 5/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0575 - acc: 0.9792\n",
      "Epoch 6/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0397 - acc: 0.9866\n",
      "Epoch 7/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0267 - acc: 0.9922\n",
      "Epoch 8/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0180 - acc: 0.9955\n",
      "Epoch 9/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0121 - acc: 0.9974\n",
      "Epoch 10/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0081 - acc: 0.9987\n",
      "Epoch 11/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0054 - acc: 0.9994\n",
      "Epoch 12/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0036 - acc: 0.9997\n",
      "Epoch 13/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0025 - acc: 0.9999\n",
      "Epoch 14/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 15/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 16/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 8.6940e-04 - acc: 1.0000\n",
      "Epoch 17/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 6.4030e-04 - acc: 1.0000\n",
      "Epoch 18/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 4.7999e-04 - acc: 1.0000\n",
      "Epoch 19/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 3.6524e-04 - acc: 1.0000\n",
      "Epoch 20/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 2.8181e-04 - acc: 1.0000\n",
      "Epoch 21/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 2.1865e-04 - acc: 1.0000\n",
      "Epoch 22/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.7182e-04 - acc: 1.0000\n",
      "Epoch 23/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.3591e-04 - acc: 1.0000\n",
      "Epoch 24/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0813e-04 - acc: 1.0000\n",
      "Epoch 25/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 8.6493e-05 - acc: 1.0000\n",
      "Epoch 26/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 6.9610e-05 - acc: 1.0000\n",
      "Epoch 27/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 5.6196e-05 - acc: 1.0000\n",
      "Epoch 28/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 4.5588e-05 - acc: 1.0000\n",
      "Epoch 29/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.7033e-05 - acc: 1.0000\n",
      "Epoch 30/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.0210e-05 - acc: 1.0000\n",
      "Epoch 31/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.4694e-05 - acc: 1.0000\n",
      "Epoch 32/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 2.0271e-05 - acc: 1.0000\n",
      "Epoch 33/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.6651e-05 - acc: 1.0000\n",
      "Epoch 34/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.3710e-05 - acc: 1.0000\n",
      "Epoch 35/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.1309e-05 - acc: 1.0000\n",
      "Epoch 36/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 9.3405e-06 - acc: 1.0000\n",
      "Epoch 37/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 7.7300e-06 - acc: 1.0000\n",
      "Epoch 38/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 6.4087e-06 - acc: 1.0000\n",
      "Epoch 39/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 5.3226e-06 - acc: 1.0000\n",
      "Epoch 40/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 4.4261e-06 - acc: 1.0000\n",
      "Epoch 41/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 3.6833e-06 - acc: 1.0000\n",
      "Epoch 42/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 3.0772e-06 - acc: 1.0000\n",
      "Epoch 43/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.5746e-06 - acc: 1.0000\n",
      "Epoch 44/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.1571e-06 - acc: 1.0000\n",
      "Epoch 45/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.8133e-06 - acc: 1.0000\n",
      "Epoch 46/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.5278e-06 - acc: 1.0000\n",
      "Epoch 47/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.2922e-06 - acc: 1.0000\n",
      "Epoch 48/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0960e-06 - acc: 1.0000\n",
      "Epoch 49/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 9.3311e-07 - acc: 1.0000\n",
      "Epoch 50/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 7.9692e-07 - acc: 1.0000\n",
      "Epoch 51/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 6.8385e-07 - acc: 1.0000\n",
      "Epoch 52/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 5.8999e-07 - acc: 1.0000\n",
      "Epoch 53/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 5.1103e-07 - acc: 1.0000\n",
      "Epoch 54/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 4.4580e-07 - acc: 1.0000\n",
      "Epoch 55/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.9107e-07 - acc: 1.0000\n",
      "Epoch 56/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.4543e-07 - acc: 1.0000\n",
      "Epoch 57/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.0730e-07 - acc: 1.0000\n",
      "Epoch 58/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.7532e-07 - acc: 1.0000\n",
      "Epoch 59/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.4854e-07 - acc: 1.0000\n",
      "Epoch 60/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.2619e-07 - acc: 1.0000\n",
      "Epoch 61/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.0733e-07 - acc: 1.0000\n",
      "Epoch 62/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.9153e-07 - acc: 1.0000\n",
      "Epoch 63/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.7835e-07 - acc: 1.0000\n",
      "Epoch 64/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.6708e-07 - acc: 1.0000\n",
      "Epoch 65/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.5768e-07 - acc: 1.0000\n",
      "Epoch 66/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.4971e-07 - acc: 1.0000\n",
      "Epoch 67/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.4296e-07 - acc: 1.0000\n",
      "Epoch 68/200\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 1.3726e-07 - acc: 1.0000\n",
      "Epoch 69/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.3242e-07 - acc: 1.0000\n",
      "Epoch 70/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.2837e-07 - acc: 1.0000\n",
      "Epoch 71/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.2486e-07 - acc: 1.0000\n",
      "Epoch 72/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.2192e-07 - acc: 1.0000\n",
      "Epoch 73/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.1938e-07 - acc: 1.0000\n",
      "Epoch 74/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.1717e-07 - acc: 1.0000\n",
      "Epoch 75/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.1528e-07 - acc: 1.0000\n",
      "Epoch 76/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.1367e-07 - acc: 1.0000\n",
      "Epoch 77/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.1229e-07 - acc: 1.0000\n",
      "Epoch 78/200\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 1.1110e-07 - acc: 1.0000\n",
      "Epoch 79/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.1002e-07 - acc: 1.0000\n",
      "Epoch 80/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0915e-07 - acc: 1.0000\n",
      "Epoch 81/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0832e-07 - acc: 1.0000\n",
      "Epoch 82/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0761e-07 - acc: 1.0000\n",
      "Epoch 83/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0700e-07 - acc: 1.0000\n",
      "Epoch 84/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0646e-07 - acc: 1.0000\n",
      "Epoch 85/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0597e-07 - acc: 1.0000\n",
      "Epoch 86/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0552e-07 - acc: 1.0000\n",
      "Epoch 87/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.0514e-07 - acc: 1.0000\n",
      "Epoch 88/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.0483e-07 - acc: 1.0000\n",
      "Epoch 89/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0452e-07 - acc: 1.0000\n",
      "Epoch 90/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0427e-07 - acc: 1.0000\n",
      "Epoch 91/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0401e-07 - acc: 1.0000\n",
      "Epoch 92/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0378e-07 - acc: 1.0000\n",
      "Epoch 93/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0358e-07 - acc: 1.0000\n",
      "Epoch 94/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0341e-07 - acc: 1.0000\n",
      "Epoch 95/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0325e-07 - acc: 1.0000\n",
      "Epoch 96/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0310e-07 - acc: 1.0000\n",
      "Epoch 97/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0296e-07 - acc: 1.0000\n",
      "Epoch 98/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0284e-07 - acc: 1.0000\n",
      "Epoch 99/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0272e-07 - acc: 1.0000\n",
      "Epoch 100/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0261e-07 - acc: 1.0000\n",
      "Epoch 101/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0252e-07 - acc: 1.0000\n",
      "Epoch 102/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0242e-07 - acc: 1.0000\n",
      "Epoch 103/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0233e-07 - acc: 1.0000\n",
      "Epoch 104/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0225e-07 - acc: 1.0000\n",
      "Epoch 105/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0217e-07 - acc: 1.0000\n",
      "Epoch 106/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0212e-07 - acc: 1.0000\n",
      "Epoch 107/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0204e-07 - acc: 1.0000\n",
      "Epoch 108/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0198e-07 - acc: 1.0000\n",
      "Epoch 109/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0193e-07 - acc: 1.0000\n",
      "Epoch 110/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0188e-07 - acc: 1.0000\n",
      "Epoch 111/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0182e-07 - acc: 1.0000\n",
      "Epoch 112/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0179e-07 - acc: 1.0000\n",
      "Epoch 113/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0175e-07 - acc: 1.0000\n",
      "Epoch 114/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.0171e-07 - acc: 1.0000\n",
      "Epoch 115/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0166e-07 - acc: 1.0000\n",
      "Epoch 116/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0164e-07 - acc: 1.0000\n",
      "Epoch 117/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0160e-07 - acc: 1.0000\n",
      "Epoch 118/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0157e-07 - acc: 1.0000\n",
      "Epoch 119/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0154e-07 - acc: 1.0000\n",
      "Epoch 120/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0150e-07 - acc: 1.0000\n",
      "Epoch 121/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0150e-07 - acc: 1.0000\n",
      "Epoch 122/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0147e-07 - acc: 1.0000\n",
      "Epoch 123/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0145e-07 - acc: 1.0000\n",
      "Epoch 124/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0141e-07 - acc: 1.0000\n",
      "Epoch 125/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0140e-07 - acc: 1.0000\n",
      "Epoch 126/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0137e-07 - acc: 1.0000\n",
      "Epoch 127/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0136e-07 - acc: 1.0000\n",
      "Epoch 128/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0134e-07 - acc: 1.0000\n",
      "Epoch 129/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0132e-07 - acc: 1.0000\n",
      "Epoch 130/200\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 1.0130e-07 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0128e-07 - acc: 1.0000\n",
      "Epoch 132/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0126e-07 - acc: 1.0000\n",
      "Epoch 133/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0125e-07 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0124e-07 - acc: 1.0000\n",
      "Epoch 135/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0121e-07 - acc: 1.0000\n",
      "Epoch 136/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0120e-07 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0119e-07 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0117e-07 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0117e-07 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0116e-07 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0113e-07 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0112e-07 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0113e-07 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0112e-07 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0110e-07 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0110e-07 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0108e-07 - acc: 1.0000\n",
      "Epoch 148/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0108e-07 - acc: 1.0000\n",
      "Epoch 149/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.0108e-07 - acc: 1.0000\n",
      "Epoch 150/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0108e-07 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0106e-07 - acc: 1.0000\n",
      "Epoch 152/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0105e-07 - acc: 1.0000\n",
      "Epoch 153/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0104e-07 - acc: 1.0000\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0104e-07 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0103e-07 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0103e-07 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0102e-07 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0102e-07 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0101e-07 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.0100e-07 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0100e-07 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0099e-07 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0098e-07 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0098e-07 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0098e-07 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0097e-07 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0096e-07 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0097e-07 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0095e-07 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0095e-07 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0095e-07 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0094e-07 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0094e-07 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0094e-07 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0094e-07 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0093e-07 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0093e-07 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0092e-07 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0092e-07 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0092e-07 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0089e-07 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0089e-07 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0089e-07 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0089e-07 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0088e-07 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0088e-07 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0088e-07 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.0088e-07 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0087e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb33e8a898>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 99us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0087433304306614e-07, 1.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = data_genelization()\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction_list, label_list = predict_results_only_2(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.count(True)/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 69us/step - loss: 0.2913 - binary_accuracy: 0.9186\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1489 - binary_accuracy: 0.9615\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1244 - binary_accuracy: 0.9616\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0989 - binary_accuracy: 0.9651\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0800 - binary_accuracy: 0.9735\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0691 - binary_accuracy: 0.9799\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.0629 - binary_accuracy: 0.9834\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0590 - binary_accuracy: 0.9854\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0562 - binary_accuracy: 0.9870\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0542 - binary_accuracy: 0.9878\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.0526 - binary_accuracy: 0.9886\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.0513 - binary_accuracy: 0.9892\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 0.0502 - binary_accuracy: 0.9897\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0493 - binary_accuracy: 0.9901\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0484 - binary_accuracy: 0.9905\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0477 - binary_accuracy: 0.9908\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0471 - binary_accuracy: 0.9911\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0466 - binary_accuracy: 0.9914\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0461 - binary_accuracy: 0.9916\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0456 - binary_accuracy: 0.9917\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0452 - binary_accuracy: 0.9918\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0448 - binary_accuracy: 0.9920\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0445 - binary_accuracy: 0.9921\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0442 - binary_accuracy: 0.9922\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0438 - binary_accuracy: 0.9922\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0436 - binary_accuracy: 0.9923\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0434 - binary_accuracy: 0.9923\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0432 - binary_accuracy: 0.9923\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.0430 - binary_accuracy: 0.9924\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0427 - binary_accuracy: 0.9924\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0426 - binary_accuracy: 0.9924\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0425 - binary_accuracy: 0.9924\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0423 - binary_accuracy: 0.9924\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0422 - binary_accuracy: 0.9924\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.0421 - binary_accuracy: 0.9924\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0419 - binary_accuracy: 0.9924\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0418 - binary_accuracy: 0.9924\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0418 - binary_accuracy: 0.9924\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.0417 - binary_accuracy: 0.9924\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0416 - binary_accuracy: 0.9924\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0415 - binary_accuracy: 0.9924\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0414 - binary_accuracy: 0.9924\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.0413 - binary_accuracy: 0.9924\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0412 - binary_accuracy: 0.9925\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0412 - binary_accuracy: 0.9925\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0411 - binary_accuracy: 0.9924\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.0411 - binary_accuracy: 0.9924\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0410 - binary_accuracy: 0.9925\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0409 - binary_accuracy: 0.9925\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0409 - binary_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2ca8c0b8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = misslabeled_data_genelization(loops=10000, prob=0.1)\n",
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model.fit(x_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 139us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.010614696949720382, 0.9998076915740967]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = data_genelization()\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction_list, label_list = predict_results_only_2(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.count(True)/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 65us/step - loss: 0.2886 - acc: 0.9219\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1595 - acc: 0.9615\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1543 - acc: 0.9615\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1480 - acc: 0.9615\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1427 - acc: 0.9615\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1390 - acc: 0.9616\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1362 - acc: 0.9616\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1342 - acc: 0.9617\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1325 - acc: 0.9618\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1311 - acc: 0.9619\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1301 - acc: 0.9621\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1293 - acc: 0.9622\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1287 - acc: 0.9623\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1282 - acc: 0.9623\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1278 - acc: 0.9624\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1273 - acc: 0.9624\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1270 - acc: 0.9625\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1266 - acc: 0.9626\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1263 - acc: 0.9627\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1260 - acc: 0.9627\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1257 - acc: 0.9629\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1255 - acc: 0.9628\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1253 - acc: 0.9627\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1251 - acc: 0.9629\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1249 - acc: 0.9629\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1247 - acc: 0.9629\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1246 - acc: 0.9630\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1244 - acc: 0.9629\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1242 - acc: 0.9631\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1240 - acc: 0.9632\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1240 - acc: 0.9631\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1238 - acc: 0.9631\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1236 - acc: 0.9633\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1235 - acc: 0.9632\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1234 - acc: 0.9631\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1233 - acc: 0.9632\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1231 - acc: 0.9632\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1230 - acc: 0.9634\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1230 - acc: 0.9634\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1228 - acc: 0.9634\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1227 - acc: 0.9635\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1227 - acc: 0.9635\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1226 - acc: 0.9633\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1225 - acc: 0.9634\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1225 - acc: 0.9635\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1224 - acc: 0.9635\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1223 - acc: 0.9634\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1223 - acc: 0.9635\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1222 - acc: 0.9634\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1222 - acc: 0.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb350bccc0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = misslabeled_data_genelization(loops=10000,prob=0.5)\n",
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model.fit(x_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05628207671642303, 0.9727115383148194]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = data_genelization()\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction_list, label_list = predict_results_only_2(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.count(True)/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 0.2798 - binary_accuracy: 0.9334\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1636 - binary_accuracy: 0.9615\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1634 - binary_accuracy: 0.9615\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1633 - binary_accuracy: 0.9615\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1632 - binary_accuracy: 0.9615\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1632 - binary_accuracy: 0.9615\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1631 - binary_accuracy: 0.9615\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1630 - binary_accuracy: 0.9615\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1630 - binary_accuracy: 0.9615\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1629 - binary_accuracy: 0.9615\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1629 - binary_accuracy: 0.9615\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1628 - binary_accuracy: 0.9615\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1628 - binary_accuracy: 0.9615\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1627 - binary_accuracy: 0.9615\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.1627 - binary_accuracy: 0.9615\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.1626 - binary_accuracy: 0.9615\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.1626 - binary_accuracy: 0.9615\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.1625 - binary_accuracy: 0.9615\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1625 - binary_accuracy: 0.9615\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1624 - binary_accuracy: 0.9615\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1624 - binary_accuracy: 0.9615\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1624 - binary_accuracy: 0.9615\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1623 - binary_accuracy: 0.9615\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 0.1623 - binary_accuracy: 0.9615\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1623 - binary_accuracy: 0.9615\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1622 - binary_accuracy: 0.9615\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.1622 - binary_accuracy: 0.9615\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1622 - binary_accuracy: 0.9615\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1621 - binary_accuracy: 0.9615\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1621 - binary_accuracy: 0.9615\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.1621 - binary_accuracy: 0.9615\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1620 - binary_accuracy: 0.9615\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1620 - binary_accuracy: 0.9615\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.1620 - binary_accuracy: 0.9615\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.1620 - binary_accuracy: 0.9615\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.1619 - binary_accuracy: 0.9615\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1620 - binary_accuracy: 0.9615\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1619 - binary_accuracy: 0.9615\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 0.1619 - binary_accuracy: 0.9615\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.1619 - binary_accuracy: 0.9615\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.1618 - binary_accuracy: 0.9615\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.1618 - binary_accuracy: 0.9615\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.1618 - binary_accuracy: 0.9615\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.1618 - binary_accuracy: 0.9615\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1617 - binary_accuracy: 0.9615\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.1617 - binary_accuracy: 0.9615\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1617 - binary_accuracy: 0.9615\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.1617 - binary_accuracy: 0.9615\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1617 - binary_accuracy: 0.9615\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 0.1616 - binary_accuracy: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2e719128>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = misslabeled_data_genelization(loops=10000,prob=1)\n",
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model.fit(x_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 165us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1622277238368988, 0.9615384340286255]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = data_genelization()\n",
    "model.evaluate(x_train, y_train)\n",
    "# accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05782998, 0.04312533, 0.02446508, 0.04520819, 0.03111434,\n",
       "       0.02661541, 0.06205994, 0.04283503, 0.02940458, 0.02315688,\n",
       "       0.05089739, 0.04925868, 0.03103292, 0.02741677, 0.03175721,\n",
       "       0.03121656, 0.0260765 , 0.03302103, 0.03087243, 0.05739969,\n",
       "       0.03313187, 0.04012492, 0.03958389, 0.04621243, 0.02950165,\n",
       "       0.03897682, 0.0458104 , 0.04001316, 0.05719036, 0.04335079,\n",
       "       0.03130934, 0.03770629, 0.02816728, 0.02217126, 0.05322996,\n",
       "       0.02566212, 0.02198333, 0.03381696, 0.04690459, 0.05378154,\n",
       "       0.02867231, 0.04377073, 0.03626743, 0.03402472, 0.04069489,\n",
       "       0.03261653, 0.04009095, 0.02743965, 0.04895318, 0.03384253,\n",
       "       0.03311864, 0.03658763], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction_list, label_list = predict_results_only_2(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.count(True)/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes hours to get the curves, the python file is in documents/curves1(234).py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubostibility of deep learning with large size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "with open('./data/noise_size_500.pickle', 'rb') as f:\n",
    "    info500 = pickle.load(f)\n",
    "with open('./data/noise_size_1000.pickle', 'rb') as f:\n",
    "    info1000 = pickle.load(f)\n",
    "with open('./data/noise_size_10000.pickle', 'rb') as f:\n",
    "    info10000 = pickle.load(f)\n",
    "with open('./data/noise_size_20000.pickle', 'rb') as f:\n",
    "    info20000 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Write some analyse about the rubostiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.legend((l2, l3, l4, l5), ('500', '1000', '10000', '20000'))\n",
    "l2, = plt.plot(np.arange(0, 1, .01), info500, label='data size 500')\n",
    "l3, = plt.plot(np.arange(0, 1, .01), info1000, label='data size 1000')\n",
    "l4, = plt.plot(np.arange(0, 1, .01), info10000, label='data size 10000')\n",
    "l5, = plt.plot(np.arange(0, 1, .01), info20000, label='data size 20000')\n",
    "plt.xlabel('Error rate in encryption')\n",
    "plt.ylabel('Accuracy of model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL algorithms are quite robust to random errors in the training set especially when the data size is big enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For systematic errors, we can imagine that it cannot generate a good result as the model will predict in the wrong way, which made the system losting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
