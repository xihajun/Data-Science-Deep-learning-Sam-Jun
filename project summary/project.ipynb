{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning structure 1: One input vs one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for one two one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are going to train it in our model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(26, input_dim=1, name=\"test1\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, init='uniform', name = 'test1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(26, name = 'test2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test4'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test5'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, name = 'test6'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Activation('linear')) #relu seems better\n",
    "#model.add(Dense(2, input_dim=1,activation='relu'))\n",
    "# change sigomiod to softmax made acc increasing 100%\n",
    "#model.add(Dense(1, activation='softmax'))\n",
    "# change loss from possion to binary it works well :P\n",
    "#tensorboard = TensorBoard(log_dir = \"graphs/1to1\")\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "#model.compile(loss='mse', optimizer='sgd', metrics=['mse', 'mae', 'mape', 'cosine', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",x_as_vector = False, y_as_vector = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 210.5014 - acc: 0.0385\n",
      "Epoch 2/250\n",
      "26/26 [==============================] - 0s 208us/step - loss: 208.4807 - acc: 0.0385\n",
      "Epoch 3/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 200.0516 - acc: 0.0385\n",
      "Epoch 4/250\n",
      "26/26 [==============================] - 0s 192us/step - loss: 187.1421 - acc: 0.0385\n",
      "Epoch 5/250\n",
      "26/26 [==============================] - 0s 280us/step - loss: 169.8583 - acc: 0.0385\n",
      "Epoch 6/250\n",
      "26/26 [==============================] - 0s 254us/step - loss: 128.3512 - acc: 0.0385\n",
      "Epoch 7/250\n",
      "26/26 [==============================] - 0s 241us/step - loss: 105.8038 - acc: 0.0385\n",
      "Epoch 8/250\n",
      "26/26 [==============================] - 0s 246us/step - loss: 88.6425 - acc: 0.0385\n",
      "Epoch 9/250\n",
      "26/26 [==============================] - 0s 301us/step - loss: 77.8178 - acc: 0.0385\n",
      "Epoch 10/250\n",
      "26/26 [==============================] - 0s 222us/step - loss: 73.2377 - acc: 0.0385\n",
      "Epoch 11/250\n",
      "26/26 [==============================] - 0s 238us/step - loss: 71.3204 - acc: 0.2308\n",
      "Epoch 12/250\n",
      "26/26 [==============================] - 0s 283us/step - loss: 71.9695 - acc: 0.0769\n",
      "Epoch 13/250\n",
      "26/26 [==============================] - 0s 271us/step - loss: 71.0896 - acc: 0.2308\n",
      "Epoch 14/250\n",
      "26/26 [==============================] - 0s 256us/step - loss: 71.5707 - acc: 0.0769\n",
      "Epoch 15/250\n",
      "26/26 [==============================] - 0s 343us/step - loss: 67.5228 - acc: 0.2692\n",
      "Epoch 16/250\n",
      "26/26 [==============================] - 0s 242us/step - loss: 67.0190 - acc: 0.4615\n",
      "Epoch 17/250\n",
      "26/26 [==============================] - 0s 245us/step - loss: 66.8330 - acc: 0.5769\n",
      "Epoch 18/250\n",
      "26/26 [==============================] - 0s 191us/step - loss: 66.7359 - acc: 0.6923\n",
      "Epoch 19/250\n",
      "26/26 [==============================] - 0s 190us/step - loss: 66.6772 - acc: 0.6923\n",
      "Epoch 20/250\n",
      "26/26 [==============================] - 0s 232us/step - loss: 66.6305 - acc: 0.7692\n",
      "Epoch 21/250\n",
      "26/26 [==============================] - 0s 216us/step - loss: 66.6062 - acc: 0.8077\n",
      "Epoch 22/250\n",
      "26/26 [==============================] - 0s 273us/step - loss: 66.5925 - acc: 0.8077\n",
      "Epoch 23/250\n",
      "26/26 [==============================] - 0s 222us/step - loss: 66.5840 - acc: 0.8462\n",
      "Epoch 24/250\n",
      "26/26 [==============================] - 0s 211us/step - loss: 66.5780 - acc: 0.8462\n",
      "Epoch 25/250\n",
      "26/26 [==============================] - 0s 244us/step - loss: 66.5734 - acc: 0.8462\n",
      "Epoch 26/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5698 - acc: 0.8462\n",
      "Epoch 27/250\n",
      "26/26 [==============================] - 0s 323us/step - loss: 66.5669 - acc: 0.8846\n",
      "Epoch 28/250\n",
      "26/26 [==============================] - 0s 263us/step - loss: 66.5645 - acc: 0.8846\n",
      "Epoch 29/250\n",
      "26/26 [==============================] - 0s 271us/step - loss: 66.5623 - acc: 0.8846\n",
      "Epoch 30/250\n",
      "26/26 [==============================] - 0s 244us/step - loss: 66.5604 - acc: 0.8846\n",
      "Epoch 31/250\n",
      "26/26 [==============================] - 0s 252us/step - loss: 66.5588 - acc: 0.8846\n",
      "Epoch 32/250\n",
      "26/26 [==============================] - 0s 258us/step - loss: 66.5574 - acc: 0.8846\n",
      "Epoch 33/250\n",
      "26/26 [==============================] - 0s 271us/step - loss: 66.5562 - acc: 0.8846\n",
      "Epoch 34/250\n",
      "26/26 [==============================] - 0s 221us/step - loss: 66.5550 - acc: 0.8846\n",
      "Epoch 35/250\n",
      "26/26 [==============================] - 0s 243us/step - loss: 66.5541 - acc: 0.8846\n",
      "Epoch 36/250\n",
      "26/26 [==============================] - 0s 271us/step - loss: 66.5532 - acc: 0.8846\n",
      "Epoch 37/250\n",
      "26/26 [==============================] - 0s 228us/step - loss: 66.5524 - acc: 0.8846\n",
      "Epoch 38/250\n",
      "26/26 [==============================] - 0s 239us/step - loss: 66.5517 - acc: 0.8846\n",
      "Epoch 39/250\n",
      "26/26 [==============================] - 0s 313us/step - loss: 66.5510 - acc: 0.8846\n",
      "Epoch 40/250\n",
      "26/26 [==============================] - 0s 314us/step - loss: 66.5504 - acc: 0.8846\n",
      "Epoch 41/250\n",
      "26/26 [==============================] - 0s 240us/step - loss: 66.5498 - acc: 0.8846\n",
      "Epoch 42/250\n",
      "26/26 [==============================] - 0s 241us/step - loss: 66.5493 - acc: 0.8846\n",
      "Epoch 43/250\n",
      "26/26 [==============================] - 0s 321us/step - loss: 66.5488 - acc: 0.8846\n",
      "Epoch 44/250\n",
      "26/26 [==============================] - 0s 230us/step - loss: 66.5483 - acc: 0.8846\n",
      "Epoch 45/250\n",
      "26/26 [==============================] - 0s 261us/step - loss: 66.5479 - acc: 0.8846\n",
      "Epoch 46/250\n",
      "26/26 [==============================] - 0s 338us/step - loss: 66.5475 - acc: 0.8846\n",
      "Epoch 47/250\n",
      "26/26 [==============================] - 0s 218us/step - loss: 66.5471 - acc: 0.8846\n",
      "Epoch 48/250\n",
      "26/26 [==============================] - 0s 262us/step - loss: 66.5468 - acc: 0.8846\n",
      "Epoch 49/250\n",
      "26/26 [==============================] - 0s 324us/step - loss: 66.5465 - acc: 0.8846\n",
      "Epoch 50/250\n",
      "26/26 [==============================] - 0s 272us/step - loss: 66.5462 - acc: 0.8846\n",
      "Epoch 51/250\n",
      "26/26 [==============================] - 0s 330us/step - loss: 66.5459 - acc: 0.8846\n",
      "Epoch 52/250\n",
      "26/26 [==============================] - 0s 257us/step - loss: 66.5456 - acc: 0.8846\n",
      "Epoch 53/250\n",
      "26/26 [==============================] - 0s 299us/step - loss: 66.5453 - acc: 0.8846\n",
      "Epoch 54/250\n",
      "26/26 [==============================] - 0s 294us/step - loss: 66.5451 - acc: 0.8846\n",
      "Epoch 55/250\n",
      "26/26 [==============================] - 0s 253us/step - loss: 66.5448 - acc: 0.8846\n",
      "Epoch 56/250\n",
      "26/26 [==============================] - 0s 366us/step - loss: 66.5446 - acc: 0.8846\n",
      "Epoch 57/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5444 - acc: 0.8846\n",
      "Epoch 58/250\n",
      "26/26 [==============================] - 0s 282us/step - loss: 66.5442 - acc: 0.8846\n",
      "Epoch 59/250\n",
      "26/26 [==============================] - 0s 394us/step - loss: 66.5440 - acc: 0.8846\n",
      "Epoch 60/250\n",
      "26/26 [==============================] - 0s 269us/step - loss: 66.5438 - acc: 0.8846\n",
      "Epoch 61/250\n",
      "26/26 [==============================] - 0s 215us/step - loss: 66.5436 - acc: 0.8846\n",
      "Epoch 62/250\n",
      "26/26 [==============================] - 0s 283us/step - loss: 66.5434 - acc: 0.8846\n",
      "Epoch 63/250\n",
      "26/26 [==============================] - 0s 265us/step - loss: 66.5433 - acc: 0.8846\n",
      "Epoch 64/250\n",
      "26/26 [==============================] - 0s 294us/step - loss: 66.5431 - acc: 0.8846\n",
      "Epoch 65/250\n",
      "26/26 [==============================] - 0s 227us/step - loss: 66.5430 - acc: 0.8846\n",
      "Epoch 66/250\n",
      "26/26 [==============================] - 0s 271us/step - loss: 66.5428 - acc: 0.8846\n",
      "Epoch 67/250\n",
      "26/26 [==============================] - 0s 217us/step - loss: 66.5427 - acc: 0.8846\n",
      "Epoch 68/250\n",
      "26/26 [==============================] - 0s 271us/step - loss: 66.5425 - acc: 0.8846\n",
      "Epoch 69/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5424 - acc: 0.8846\n",
      "Epoch 70/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5423 - acc: 0.8846\n",
      "Epoch 71/250\n",
      "26/26 [==============================] - 0s 342us/step - loss: 66.5422 - acc: 0.8846\n",
      "Epoch 72/250\n",
      "26/26 [==============================] - 0s 274us/step - loss: 66.5420 - acc: 0.8846\n",
      "Epoch 73/250\n",
      "26/26 [==============================] - 0s 293us/step - loss: 66.5419 - acc: 0.8846\n",
      "Epoch 74/250\n",
      "26/26 [==============================] - 0s 250us/step - loss: 66.5418 - acc: 0.8846\n",
      "Epoch 75/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 66.5417 - acc: 0.8846\n",
      "Epoch 76/250\n",
      "26/26 [==============================] - 0s 197us/step - loss: 66.5416 - acc: 0.8846\n",
      "Epoch 77/250\n",
      "26/26 [==============================] - 0s 263us/step - loss: 66.5415 - acc: 0.8846\n",
      "Epoch 78/250\n",
      "26/26 [==============================] - 0s 246us/step - loss: 66.5414 - acc: 0.8846\n",
      "Epoch 79/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5414 - acc: 0.8846\n",
      "Epoch 80/250\n",
      "26/26 [==============================] - 0s 219us/step - loss: 66.5413 - acc: 0.8846\n",
      "Epoch 81/250\n",
      "26/26 [==============================] - 0s 214us/step - loss: 66.5412 - acc: 0.8846\n",
      "Epoch 82/250\n",
      "26/26 [==============================] - 0s 208us/step - loss: 66.5412 - acc: 0.8846\n",
      "Epoch 83/250\n",
      "26/26 [==============================] - 0s 185us/step - loss: 66.5411 - acc: 0.8846\n",
      "Epoch 84/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5410 - acc: 0.8846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/250\n",
      "26/26 [==============================] - 0s 239us/step - loss: 66.5410 - acc: 0.8846\n",
      "Epoch 86/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 66.5409 - acc: 0.8846\n",
      "Epoch 87/250\n",
      "26/26 [==============================] - 0s 219us/step - loss: 66.5409 - acc: 0.8846\n",
      "Epoch 88/250\n",
      "26/26 [==============================] - 0s 217us/step - loss: 66.5408 - acc: 0.8846\n",
      "Epoch 89/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5407 - acc: 0.8846\n",
      "Epoch 90/250\n",
      "26/26 [==============================] - 0s 218us/step - loss: 66.5407 - acc: 0.8846\n",
      "Epoch 91/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 66.5406 - acc: 0.8846\n",
      "Epoch 92/250\n",
      "26/26 [==============================] - 0s 213us/step - loss: 66.5406 - acc: 0.8846\n",
      "Epoch 93/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5405 - acc: 0.8846\n",
      "Epoch 94/250\n",
      "26/26 [==============================] - 0s 222us/step - loss: 66.5405 - acc: 0.8846\n",
      "Epoch 95/250\n",
      "26/26 [==============================] - 0s 261us/step - loss: 66.5405 - acc: 0.8846\n",
      "Epoch 96/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5404 - acc: 0.8846\n",
      "Epoch 97/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 66.5404 - acc: 0.8846\n",
      "Epoch 98/250\n",
      "26/26 [==============================] - 0s 192us/step - loss: 66.5403 - acc: 0.8846\n",
      "Epoch 99/250\n",
      "26/26 [==============================] - 0s 198us/step - loss: 66.5403 - acc: 0.8846\n",
      "Epoch 100/250\n",
      "26/26 [==============================] - 0s 197us/step - loss: 66.5402 - acc: 0.8846\n",
      "Epoch 101/250\n",
      "26/26 [==============================] - 0s 193us/step - loss: 66.5402 - acc: 0.8846\n",
      "Epoch 102/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 66.5402 - acc: 0.8846\n",
      "Epoch 103/250\n",
      "26/26 [==============================] - 0s 198us/step - loss: 66.5401 - acc: 0.8846\n",
      "Epoch 104/250\n",
      "26/26 [==============================] - 0s 195us/step - loss: 66.5401 - acc: 0.8846\n",
      "Epoch 105/250\n",
      "26/26 [==============================] - 0s 220us/step - loss: 66.5400 - acc: 0.8846\n",
      "Epoch 106/250\n",
      "26/26 [==============================] - 0s 198us/step - loss: 66.5400 - acc: 0.8846\n",
      "Epoch 107/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5400 - acc: 0.8846\n",
      "Epoch 108/250\n",
      "26/26 [==============================] - 0s 208us/step - loss: 66.5399 - acc: 0.8846\n",
      "Epoch 109/250\n",
      "26/26 [==============================] - 0s 282us/step - loss: 66.5399 - acc: 0.8846\n",
      "Epoch 110/250\n",
      "26/26 [==============================] - 0s 259us/step - loss: 66.5399 - acc: 0.8846\n",
      "Epoch 111/250\n",
      "26/26 [==============================] - 0s 269us/step - loss: 66.5398 - acc: 0.8846\n",
      "Epoch 112/250\n",
      "26/26 [==============================] - 0s 275us/step - loss: 66.5398 - acc: 0.8846\n",
      "Epoch 113/250\n",
      "26/26 [==============================] - 0s 248us/step - loss: 66.5398 - acc: 0.8846\n",
      "Epoch 114/250\n",
      "26/26 [==============================] - 0s 263us/step - loss: 66.5397 - acc: 0.8846\n",
      "Epoch 115/250\n",
      "26/26 [==============================] - 0s 209us/step - loss: 66.5397 - acc: 0.8846\n",
      "Epoch 116/250\n",
      "26/26 [==============================] - 0s 231us/step - loss: 66.5397 - acc: 0.8846\n",
      "Epoch 117/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5396 - acc: 0.8846\n",
      "Epoch 118/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5396 - acc: 0.8846\n",
      "Epoch 119/250\n",
      "26/26 [==============================] - 0s 209us/step - loss: 66.5396 - acc: 0.8846\n",
      "Epoch 120/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5396 - acc: 0.8846\n",
      "Epoch 121/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5395 - acc: 0.8846\n",
      "Epoch 122/250\n",
      "26/26 [==============================] - 0s 212us/step - loss: 66.5395 - acc: 0.8846\n",
      "Epoch 123/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5395 - acc: 0.8846\n",
      "Epoch 124/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5395 - acc: 0.8846\n",
      "Epoch 125/250\n",
      "26/26 [==============================] - 0s 214us/step - loss: 66.5394 - acc: 0.8846\n",
      "Epoch 126/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5394 - acc: 0.8846\n",
      "Epoch 127/250\n",
      "26/26 [==============================] - 0s 217us/step - loss: 66.5394 - acc: 0.8846\n",
      "Epoch 128/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5394 - acc: 0.8846\n",
      "Epoch 129/250\n",
      "26/26 [==============================] - 0s 219us/step - loss: 66.5394 - acc: 0.8846\n",
      "Epoch 130/250\n",
      "26/26 [==============================] - 0s 228us/step - loss: 66.5393 - acc: 0.8846\n",
      "Epoch 131/250\n",
      "26/26 [==============================] - 0s 217us/step - loss: 66.5393 - acc: 0.8846\n",
      "Epoch 132/250\n",
      "26/26 [==============================] - 0s 219us/step - loss: 66.5393 - acc: 0.8846\n",
      "Epoch 133/250\n",
      "26/26 [==============================] - 0s 216us/step - loss: 66.5393 - acc: 0.8846\n",
      "Epoch 134/250\n",
      "26/26 [==============================] - 0s 215us/step - loss: 66.5393 - acc: 0.8846\n",
      "Epoch 135/250\n",
      "26/26 [==============================] - 0s 218us/step - loss: 66.5393 - acc: 0.8846\n",
      "Epoch 136/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5392 - acc: 0.8846\n",
      "Epoch 137/250\n",
      "26/26 [==============================] - 0s 233us/step - loss: 66.5392 - acc: 0.8846\n",
      "Epoch 138/250\n",
      "26/26 [==============================] - 0s 227us/step - loss: 66.5392 - acc: 0.8846\n",
      "Epoch 139/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5392 - acc: 0.8846\n",
      "Epoch 140/250\n",
      "26/26 [==============================] - 0s 212us/step - loss: 66.5392 - acc: 0.8846\n",
      "Epoch 141/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5392 - acc: 0.8846\n",
      "Epoch 142/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5391 - acc: 0.8846\n",
      "Epoch 143/250\n",
      "26/26 [==============================] - 0s 215us/step - loss: 66.5391 - acc: 0.8846\n",
      "Epoch 144/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5391 - acc: 0.8846\n",
      "Epoch 145/250\n",
      "26/26 [==============================] - 0s 216us/step - loss: 66.5391 - acc: 0.8846\n",
      "Epoch 146/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5391 - acc: 0.8846\n",
      "Epoch 147/250\n",
      "26/26 [==============================] - 0s 213us/step - loss: 66.5391 - acc: 0.8846\n",
      "Epoch 148/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5390 - acc: 0.8846\n",
      "Epoch 149/250\n",
      "26/26 [==============================] - 0s 225us/step - loss: 66.5390 - acc: 0.8846\n",
      "Epoch 150/250\n",
      "26/26 [==============================] - 0s 216us/step - loss: 66.5390 - acc: 0.8846\n",
      "Epoch 151/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5390 - acc: 0.8846\n",
      "Epoch 152/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 66.5390 - acc: 0.8846\n",
      "Epoch 153/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5390 - acc: 0.8846\n",
      "Epoch 154/250\n",
      "26/26 [==============================] - 0s 213us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 155/250\n",
      "26/26 [==============================] - 0s 211us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 156/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 157/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 158/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 159/250\n",
      "26/26 [==============================] - 0s 195us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 160/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 161/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 162/250\n",
      "26/26 [==============================] - 0s 201us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 163/250\n",
      "26/26 [==============================] - 0s 199us/step - loss: 66.5389 - acc: 0.8846\n",
      "Epoch 164/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 165/250\n",
      "26/26 [==============================] - 0s 195us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 166/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 167/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5388 - acc: 0.8846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 169/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 170/250\n",
      "26/26 [==============================] - 0s 208us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 171/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 172/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 173/250\n",
      "26/26 [==============================] - 0s 199us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 174/250\n",
      "26/26 [==============================] - 0s 211us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 175/250\n",
      "26/26 [==============================] - 0s 212us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 176/250\n",
      "26/26 [==============================] - 0s 201us/step - loss: 66.5388 - acc: 0.8846\n",
      "Epoch 177/250\n",
      "26/26 [==============================] - 0s 208us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 178/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 179/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 180/250\n",
      "26/26 [==============================] - 0s 195us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 181/250\n",
      "26/26 [==============================] - 0s 213us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 182/250\n",
      "26/26 [==============================] - 0s 212us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 183/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 184/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 185/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 186/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 187/250\n",
      "26/26 [==============================] - 0s 216us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 188/250\n",
      "26/26 [==============================] - 0s 198us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 189/250\n",
      "26/26 [==============================] - 0s 215us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 190/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 191/250\n",
      "26/26 [==============================] - 0s 199us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 192/250\n",
      "26/26 [==============================] - 0s 215us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 193/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 194/250\n",
      "26/26 [==============================] - 0s 212us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 195/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 196/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 197/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 198/250\n",
      "26/26 [==============================] - 0s 215us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 199/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 200/250\n",
      "26/26 [==============================] - 0s 212us/step - loss: 66.5387 - acc: 0.8846\n",
      "Epoch 201/250\n",
      "26/26 [==============================] - 0s 198us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 202/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 203/250\n",
      "26/26 [==============================] - 0s 220us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 204/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 205/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 206/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 207/250\n",
      "26/26 [==============================] - 0s 197us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 208/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 209/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 210/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 211/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 212/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 213/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 214/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 215/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 216/250\n",
      "26/26 [==============================] - 0s 197us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 217/250\n",
      "26/26 [==============================] - 0s 193us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 218/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 219/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 220/250\n",
      "26/26 [==============================] - 0s 195us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 221/250\n",
      "26/26 [==============================] - 0s 209us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 222/250\n",
      "26/26 [==============================] - 0s 214us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 223/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 224/250\n",
      "26/26 [==============================] - 0s 213us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 225/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 226/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 227/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 228/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 229/250\n",
      "26/26 [==============================] - 0s 201us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 230/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 231/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 232/250\n",
      "26/26 [==============================] - 0s 197us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 233/250\n",
      "26/26 [==============================] - 0s 195us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 234/250\n",
      "26/26 [==============================] - 0s 213us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 235/250\n",
      "26/26 [==============================] - 0s 215us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 236/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 237/250\n",
      "26/26 [==============================] - 0s 199us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 238/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 239/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 240/250\n",
      "26/26 [==============================] - 0s 208us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 241/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 242/250\n",
      "26/26 [==============================] - 0s 199us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 243/250\n",
      "26/26 [==============================] - 0s 211us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 244/250\n",
      "26/26 [==============================] - 0s 197us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 245/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 246/250\n",
      "26/26 [==============================] - 0s 288us/step - loss: 66.5386 - acc: 0.8846\n",
      "Epoch 247/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 66.5385 - acc: 0.8846\n",
      "Epoch 248/250\n",
      "26/26 [==============================] - 0s 193us/step - loss: 66.5385 - acc: 0.8846\n",
      "Epoch 249/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 66.5385 - acc: 0.8846\n",
      "Epoch 250/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 66.5385 - acc: 0.8846\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(x_train)/25, np.array(y_train), epochs = 250);#, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the result seems weird that for the same data, the training result shows that we got 100% accuracy but the prediction is different!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: try to find out why it happens like that? How to calculate the accuracy inside the keras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0911873],\n",
       "       [ 1.3614738],\n",
       "       [ 2.2711205],\n",
       "       [ 3.1149487],\n",
       "       [ 3.9516196],\n",
       "       [ 4.971271 ],\n",
       "       [ 5.912551 ],\n",
       "       [ 6.9199853],\n",
       "       [ 7.7896094],\n",
       "       [ 8.786919 ],\n",
       "       [ 9.735275 ],\n",
       "       [10.58296  ],\n",
       "       [11.464203 ],\n",
       "       [12.281906 ],\n",
       "       [13.131165 ],\n",
       "       [14.088701 ],\n",
       "       [14.9621105],\n",
       "       [15.910618 ],\n",
       "       [16.820295 ],\n",
       "       [17.722948 ],\n",
       "       [18.625608 ],\n",
       "       [19.561155 ],\n",
       "       [20.528915 ],\n",
       "       [ 0.       ],\n",
       "       [ 0.       ],\n",
       "       [ 0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(x_train)/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "26/26 [==============================] - 2s 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[67.09132385253906, 0.4615384638309479]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array(x_train)/25, np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",x_as_vector = False, y_as_vector = False)\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c654baf28>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# let change the prediction into int, see the confusion matrix\n",
    "array = confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25)))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preformance for the last 3 shift is super terrible, that is to say, the model doesn't learn the shift at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "# Set one layer as output we can get every layers' information given the input\n",
    "\n",
    "dense1_layer_model = Model(inputs=model.input,outputs=model.get_layer('test1').output)\n",
    "dense2_layer_model = Model(inputs=model.input,outputs=model.get_layer('test2').output)\n",
    "dense3_layer_model = Model(inputs=model.input,outputs=model.get_layer('test3').output)\n",
    "dense4_layer_model = Model(inputs=model.input,outputs=model.get_layer('test4').output)\n",
    "dense5_layer_model = Model(inputs=model.input,outputs=model.get_layer('test5').output)\n",
    "dense6_layer_model = Model(inputs=model.input,outputs=model.get_layer('test6').output)\n",
    "\n",
    "dense1_output = dense1_layer_model.predict(x_train)\n",
    "dense2_output = dense2_layer_model.predict(x_train)\n",
    "dense3_output = dense3_layer_model.predict(x_train)\n",
    "dense4_output = dense4_layer_model.predict(x_train)\n",
    "dense5_output = dense5_layer_model.predict(x_train)\n",
    "dense6_output = dense6_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are outputs for every layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  6.,  6.,  6., 11., 13., 24., 27., 27., 37., 59., 74., 95.,\n",
       "        82., 55., 35., 25., 20., 18., 15.,  9.,  8.,  4.,  4.,  3.,  1.,\n",
       "         2.,  1.,  2.,  1.,  2.]),\n",
       " array([-25.837606  , -23.881598  , -21.925589  , -19.969578  ,\n",
       "        -18.013569  , -16.05756   , -14.10155   , -12.145541  ,\n",
       "        -10.189531  ,  -8.233522  ,  -6.277513  ,  -4.3215036 ,\n",
       "         -2.3654943 ,  -0.40948498,   1.5465244 ,   3.5025337 ,\n",
       "          5.458543  ,   7.414552  ,   9.370562  ,  11.326571  ,\n",
       "         13.28258   ,  15.238589  ,  17.1946    ,  19.150608  ,\n",
       "         21.106617  ,  23.062628  ,  25.018637  ,  26.974646  ,\n",
       "         28.930655  ,  30.886665  ,  32.842674  ,  34.798683  ],\n",
       "       dtype=float32),\n",
       " <a list of 31 Patch objects>)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense1_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense1_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.53202176,   4.8975964 ,  -8.040409  ,  -0.08820163,\n",
       "         1.685654  ,  -5.682117  ,   3.691348  ,   4.6625967 ,\n",
       "        -8.567575  ,  -1.7011356 ,  20.772137  ,   8.2918    ,\n",
       "       -43.913387  ,   3.1354609 ,   4.141806  ,  -2.9192665 ,\n",
       "        -7.2887836 ,  11.166663  , -10.864956  ,  19.62452   ,\n",
       "       -10.583656  ,   9.630901  ,  -0.18748859,   4.618703  ,\n",
       "       -15.725863  ,  14.408938  ], dtype=float32)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense2_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense2_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.3702971 ,  -7.509313  ,   8.504009  , -16.592175  ,\n",
       "         8.2181015 ,  -9.388616  ,  -1.7214049 ,  13.26726   ,\n",
       "        12.221661  ,   6.3840766 ,   4.6750755 ,   6.351042  ,\n",
       "        -0.84754705,  -3.075376  ,  -8.200859  ,   3.8729634 ,\n",
       "        -4.6415696 ,   6.8114676 ,  -8.273968  , -10.568449  ,\n",
       "        -5.606188  ,   2.6931336 ,   6.465182  ,  11.909492  ,\n",
       "         8.681584  ,  -3.5256786 ], dtype=float32)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense3_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense3_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.7611098 ,  -0.45224255,  10.329805  ,   2.5343046 ,\n",
       "        -0.3699739 ,  -2.6897104 ,  -1.4771736 ,  -5.604663  ,\n",
       "        10.327579  ,  -8.052563  ,   7.0529065 ,  14.645329  ,\n",
       "         3.2256944 ,  -2.0225425 ,  -0.31267118,  -4.75432   ,\n",
       "        10.297465  ,  -2.5396543 ,   9.253574  ,   6.1650696 ,\n",
       "        -0.5407438 ,  -4.79996   ,  -4.8368573 ,  14.085703  ,\n",
       "        11.816038  , -17.709518  ], dtype=float32)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense4_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense4_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.913244  ,  -4.5295653 ,  14.824623  ,   2.0132833 ,\n",
       "         7.4564877 ,   3.450368  ,   3.0163221 ,  -9.199384  ,\n",
       "       -15.348791  , -10.074503  ,   1.378602  ,   8.780954  ,\n",
       "         3.5297174 , -16.130342  ,   8.673261  , -11.035252  ,\n",
       "        10.57411   ,  22.402895  ,  -0.50996447,  10.788156  ,\n",
       "         3.6928134 ,  -5.6229944 ,   6.817444  ,  -1.1548746 ,\n",
       "         3.08654   ,   9.723611  ], dtype=float32)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense5_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense5_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5., 4., 4., 4., 4., 5.]),\n",
       " array([ -0.8044691,  95.29532  , 191.39511  , 287.4949   , 383.59467  ,\n",
       "        479.69446  , 575.79425  ], dtype=float32),\n",
       " <a list of 6 Patch objects>)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense6_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you noticed that we used batch normalisation in the above model, how about the results without BatchNormalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(26, input_dim=1, name=\"test1\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, init='uniform', name = 'test1'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test2'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test3'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test4'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test5'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, name = 'test6'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 2/250\n",
      "26/26 [==============================] - 0s 130us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 3/250\n",
      "26/26 [==============================] - 0s 120us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 4/250\n",
      "26/26 [==============================] - 0s 136us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 5/250\n",
      "26/26 [==============================] - 0s 125us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 6/250\n",
      "26/26 [==============================] - 0s 103us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 7/250\n",
      "26/26 [==============================] - 0s 156us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 8/250\n",
      "26/26 [==============================] - 0s 185us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 9/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 10/250\n",
      "26/26 [==============================] - 0s 135us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 11/250\n",
      "26/26 [==============================] - 0s 141us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 12/250\n",
      "26/26 [==============================] - 0s 168us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 13/250\n",
      "26/26 [==============================] - 0s 152us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 14/250\n",
      "26/26 [==============================] - 0s 162us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 15/250\n",
      "26/26 [==============================] - 0s 227us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 16/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 17/250\n",
      "26/26 [==============================] - 0s 167us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 18/250\n",
      "26/26 [==============================] - 0s 171us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 19/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 20/250\n",
      "26/26 [==============================] - 0s 160us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 21/250\n",
      "26/26 [==============================] - 0s 246us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 22/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 23/250\n",
      "26/26 [==============================] - 0s 220us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 24/250\n",
      "26/26 [==============================] - 0s 137us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 25/250\n",
      "26/26 [==============================] - 0s 167us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 26/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 27/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 28/250\n",
      "26/26 [==============================] - 0s 217us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 29/250\n",
      "26/26 [==============================] - 0s 317us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 30/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 31/250\n",
      "26/26 [==============================] - 0s 163us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 32/250\n",
      "26/26 [==============================] - 0s 320us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 33/250\n",
      "26/26 [==============================] - 0s 160us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 34/250\n",
      "26/26 [==============================] - 0s 436us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 35/250\n",
      "26/26 [==============================] - 0s 205us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 36/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 37/250\n",
      "26/26 [==============================] - 0s 217us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 38/250\n",
      "26/26 [==============================] - 0s 330us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 39/250\n",
      "26/26 [==============================] - 0s 245us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 40/250\n",
      "26/26 [==============================] - 0s 496us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 41/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 42/250\n",
      "26/26 [==============================] - 0s 271us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 43/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 44/250\n",
      "26/26 [==============================] - 0s 155us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 45/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 46/250\n",
      "26/26 [==============================] - 0s 276us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 47/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 48/250\n",
      "26/26 [==============================] - 0s 166us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 49/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 50/250\n",
      "26/26 [==============================] - 0s 136us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 51/250\n",
      "26/26 [==============================] - 0s 124us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 52/250\n",
      "26/26 [==============================] - 0s 125us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 53/250\n",
      "26/26 [==============================] - 0s 208us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 54/250\n",
      "26/26 [==============================] - 0s 135us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 55/250\n",
      "26/26 [==============================] - 0s 131us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 56/250\n",
      "26/26 [==============================] - 0s 163us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 57/250\n",
      "26/26 [==============================] - 0s 180us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 58/250\n",
      "26/26 [==============================] - 0s 131us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 59/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 60/250\n",
      "26/26 [==============================] - 0s 253us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 61/250\n",
      "26/26 [==============================] - 0s 135us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 62/250\n",
      "26/26 [==============================] - 0s 178us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 63/250\n",
      "26/26 [==============================] - 0s 222us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 64/250\n",
      "26/26 [==============================] - 0s 131us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 65/250\n",
      "26/26 [==============================] - 0s 194us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 66/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 67/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 68/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 69/250\n",
      "26/26 [==============================] - 0s 172us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 70/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 71/250\n",
      "26/26 [==============================] - 0s 220us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 72/250\n",
      "26/26 [==============================] - 0s 179us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 73/250\n",
      "26/26 [==============================] - 0s 192us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 74/250\n",
      "26/26 [==============================] - 0s 179us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 75/250\n",
      "26/26 [==============================] - 0s 132us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 76/250\n",
      "26/26 [==============================] - 0s 126us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 77/250\n",
      "26/26 [==============================] - 0s 245us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 78/250\n",
      "26/26 [==============================] - 0s 139us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 79/250\n",
      "26/26 [==============================] - 0s 186us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 80/250\n",
      "26/26 [==============================] - 0s 172us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 81/250\n",
      "26/26 [==============================] - 0s 190us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 82/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 83/250\n",
      "26/26 [==============================] - 0s 198us/step - loss: 212.5000 - acc: 0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/250\n",
      "26/26 [==============================] - 0s 207us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 85/250\n",
      "26/26 [==============================] - 0s 150us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 86/250\n",
      "26/26 [==============================] - 0s 235us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 87/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 88/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 89/250\n",
      "26/26 [==============================] - 0s 235us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 90/250\n",
      "26/26 [==============================] - 0s 183us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 91/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 92/250\n",
      "26/26 [==============================] - 0s 208us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 93/250\n",
      "26/26 [==============================] - 0s 156us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 94/250\n",
      "26/26 [==============================] - 0s 136us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 95/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 96/250\n",
      "26/26 [==============================] - 0s 141us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 97/250\n",
      "26/26 [==============================] - 0s 338us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 98/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 99/250\n",
      "26/26 [==============================] - 0s 161us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 100/250\n",
      "26/26 [==============================] - 0s 188us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 101/250\n",
      "26/26 [==============================] - 0s 216us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 102/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 103/250\n",
      "26/26 [==============================] - 0s 235us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 104/250\n",
      "26/26 [==============================] - 0s 165us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 105/250\n",
      "26/26 [==============================] - 0s 182us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 106/250\n",
      "26/26 [==============================] - 0s 198us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 107/250\n",
      "26/26 [==============================] - 0s 222us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 108/250\n",
      "26/26 [==============================] - 0s 223us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 109/250\n",
      "26/26 [==============================] - 0s 200us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 110/250\n",
      "26/26 [==============================] - 0s 196us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 111/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 112/250\n",
      "26/26 [==============================] - 0s 193us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 113/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 114/250\n",
      "26/26 [==============================] - 0s 199us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 115/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 116/250\n",
      "26/26 [==============================] - 0s 171us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 117/250\n",
      "26/26 [==============================] - 0s 256us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 118/250\n",
      "26/26 [==============================] - 0s 182us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 119/250\n",
      "26/26 [==============================] - 0s 136us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 120/250\n",
      "26/26 [==============================] - 0s 162us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 121/250\n",
      "26/26 [==============================] - 0s 133us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 122/250\n",
      "26/26 [==============================] - 0s 201us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 123/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 124/250\n",
      "26/26 [==============================] - 0s 171us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 125/250\n",
      "26/26 [==============================] - 0s 191us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 126/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 127/250\n",
      "26/26 [==============================] - 0s 131us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 128/250\n",
      "26/26 [==============================] - 0s 250us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 129/250\n",
      "26/26 [==============================] - 0s 187us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 130/250\n",
      "26/26 [==============================] - 0s 163us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 131/250\n",
      "26/26 [==============================] - 0s 199us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 132/250\n",
      "26/26 [==============================] - 0s 148us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 133/250\n",
      "26/26 [==============================] - 0s 138us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 134/250\n",
      "26/26 [==============================] - 0s 204us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 135/250\n",
      "26/26 [==============================] - 0s 238us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 136/250\n",
      "26/26 [==============================] - 0s 173us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 137/250\n",
      "26/26 [==============================] - 0s 181us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 138/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 139/250\n",
      "26/26 [==============================] - 0s 135us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 140/250\n",
      "26/26 [==============================] - 0s 134us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 141/250\n",
      "26/26 [==============================] - 0s 250us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 142/250\n",
      "26/26 [==============================] - 0s 165us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 143/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 144/250\n",
      "26/26 [==============================] - 0s 188us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 145/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 146/250\n",
      "26/26 [==============================] - 0s 171us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 147/250\n",
      "26/26 [==============================] - 0s 224us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 148/250\n",
      "26/26 [==============================] - 0s 169us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 149/250\n",
      "26/26 [==============================] - 0s 177us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 150/250\n",
      "26/26 [==============================] - 0s 169us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 151/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 152/250\n",
      "26/26 [==============================] - 0s 127us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 153/250\n",
      "26/26 [==============================] - 0s 248us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 154/250\n",
      "26/26 [==============================] - 0s 158us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 155/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 156/250\n",
      "26/26 [==============================] - 0s 202us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 157/250\n",
      "26/26 [==============================] - 0s 136us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 158/250\n",
      "26/26 [==============================] - 0s 127us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 159/250\n",
      "26/26 [==============================] - 0s 221us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 160/250\n",
      "26/26 [==============================] - 0s 179us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 161/250\n",
      "26/26 [==============================] - 0s 178us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 162/250\n",
      "26/26 [==============================] - 0s 184us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 163/250\n",
      "26/26 [==============================] - 0s 210us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 164/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 165/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 212.5000 - acc: 0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/250\n",
      "26/26 [==============================] - 0s 201us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 167/250\n",
      "26/26 [==============================] - 0s 168us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 168/250\n",
      "26/26 [==============================] - 0s 175us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 169/250\n",
      "26/26 [==============================] - 0s 199us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 170/250\n",
      "26/26 [==============================] - 0s 147us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 171/250\n",
      "26/26 [==============================] - 0s 168us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 172/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 173/250\n",
      "26/26 [==============================] - 0s 169us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 174/250\n",
      "26/26 [==============================] - 0s 137us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 175/250\n",
      "26/26 [==============================] - 0s 137us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 176/250\n",
      "26/26 [==============================] - 0s 140us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 177/250\n",
      "26/26 [==============================] - 0s 144us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 178/250\n",
      "26/26 [==============================] - 0s 129us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 179/250\n",
      "26/26 [==============================] - 0s 143us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 180/250\n",
      "26/26 [==============================] - 0s 149us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 181/250\n",
      "26/26 [==============================] - 0s 155us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 182/250\n",
      "26/26 [==============================] - 0s 134us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 183/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 184/250\n",
      "26/26 [==============================] - 0s 137us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 185/250\n",
      "26/26 [==============================] - 0s 134us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 186/250\n",
      "26/26 [==============================] - 0s 283us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 187/250\n",
      "26/26 [==============================] - 0s 171us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 188/250\n",
      "26/26 [==============================] - 0s 160us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 189/250\n",
      "26/26 [==============================] - 0s 165us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 190/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 191/250\n",
      "26/26 [==============================] - 0s 164us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 192/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 193/250\n",
      "26/26 [==============================] - 0s 189us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 194/250\n",
      "26/26 [==============================] - 0s 190us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 195/250\n",
      "26/26 [==============================] - 0s 196us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 196/250\n",
      "26/26 [==============================] - 0s 168us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 197/250\n",
      "26/26 [==============================] - 0s 270us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 198/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 199/250\n",
      "26/26 [==============================] - 0s 164us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 200/250\n",
      "26/26 [==============================] - 0s 206us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 201/250\n",
      "26/26 [==============================] - 0s 143us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 202/250\n",
      "26/26 [==============================] - 0s 154us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 203/250\n",
      "26/26 [==============================] - 0s 212us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 204/250\n",
      "26/26 [==============================] - 0s 166us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 205/250\n",
      "26/26 [==============================] - 0s 178us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 206/250\n",
      "26/26 [==============================] - 0s 213us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 207/250\n",
      "26/26 [==============================] - 0s 139us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 208/250\n",
      "26/26 [==============================] - 0s 260us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 209/250\n",
      "26/26 [==============================] - 0s 161us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 210/250\n",
      "26/26 [==============================] - 0s 170us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 211/250\n",
      "26/26 [==============================] - 0s 203us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 212/250\n",
      "26/26 [==============================] - 0s 138us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 213/250\n",
      "26/26 [==============================] - 0s 171us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 214/250\n",
      "26/26 [==============================] - 0s 151us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 215/250\n",
      "26/26 [==============================] - 0s 166us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 216/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 217/250\n",
      "26/26 [==============================] - 0s 180us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 218/250\n",
      "26/26 [==============================] - 0s 159us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 219/250\n",
      "26/26 [==============================] - 0s 179us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 220/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 221/250\n",
      "26/26 [==============================] - 0s 138us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 222/250\n",
      "26/26 [==============================] - 0s 172us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 223/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 224/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 225/250\n",
      "26/26 [==============================] - 0s 162us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 226/250\n",
      "26/26 [==============================] - 0s 128us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 227/250\n",
      "26/26 [==============================] - 0s 157us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 228/250\n",
      "26/26 [==============================] - 0s 129us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 229/250\n",
      "26/26 [==============================] - 0s 138us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 230/250\n",
      "26/26 [==============================] - 0s 119us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 231/250\n",
      "26/26 [==============================] - 0s 139us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 232/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 233/250\n",
      "26/26 [==============================] - 0s 142us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 234/250\n",
      "26/26 [==============================] - 0s 137us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 235/250\n",
      "26/26 [==============================] - 0s 135us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 236/250\n",
      "26/26 [==============================] - 0s 126us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 237/250\n",
      "26/26 [==============================] - 0s 131us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 238/250\n",
      "26/26 [==============================] - 0s 141us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 239/250\n",
      "26/26 [==============================] - 0s 146us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 240/250\n",
      "26/26 [==============================] - 0s 160us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 241/250\n",
      "26/26 [==============================] - 0s 131us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 242/250\n",
      "26/26 [==============================] - 0s 138us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 243/250\n",
      "26/26 [==============================] - 0s 176us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 244/250\n",
      "26/26 [==============================] - 0s 129us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 245/250\n",
      "26/26 [==============================] - 0s 126us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 246/250\n",
      "26/26 [==============================] - 0s 136us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 247/250\n",
      "26/26 [==============================] - 0s 133us/step - loss: 212.5000 - acc: 0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/250\n",
      "26/26 [==============================] - 0s 129us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 249/250\n",
      "26/26 [==============================] - 0s 127us/step - loss: 212.5000 - acc: 0.0385\n",
      "Epoch 250/250\n",
      "26/26 [==============================] - 0s 139us/step - loss: 212.5000 - acc: 0.0385\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(x_train), np.array(y_train), epochs = 250);#, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(x_train)/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",x_as_vector = False, y_as_vector = False)\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a5aa0cc50>"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# let change the prediction into int, see the confusion matrix\n",
    "array = confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25)))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1_layer_model = Model(inputs=model.input,outputs=model.get_layer('test1').output)\n",
    "dense2_layer_model = Model(inputs=model.input,outputs=model.get_layer('test2').output)\n",
    "dense3_layer_model = Model(inputs=model.input,outputs=model.get_layer('test3').output)\n",
    "dense4_layer_model = Model(inputs=model.input,outputs=model.get_layer('test4').output)\n",
    "dense5_layer_model = Model(inputs=model.input,outputs=model.get_layer('test5').output)\n",
    "dense6_layer_model = Model(inputs=model.input,outputs=model.get_layer('test6').output)\n",
    "\n",
    "\n",
    "dense1_output = dense1_layer_model.predict(x_train)\n",
    "dense2_output = dense2_layer_model.predict(x_train)\n",
    "dense3_output = dense3_layer_model.predict(x_train)\n",
    "dense4_output = dense4_layer_model.predict(x_train)\n",
    "dense5_output = dense5_layer_model.predict(x_train)\n",
    "dense6_output = dense6_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12962213,  0.00239396,  0.13372184,  0.11873104, -0.0405076 ,\n",
       "        0.11765052, -0.07359366,  0.15232082,  0.04087219, -0.10766783,\n",
       "        0.06550656, -0.1584858 ,  0.0911222 ,  0.13256313,  0.12079649,\n",
       "       -0.02061744, -0.1390882 , -0.16752219,  0.15554051, -0.15082936,\n",
       "       -0.1148798 ,  0.01012278, -0.04709062,  0.05714168,  0.10203476,\n",
       "       -0.09205513], dtype=float32)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense1_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20209996,  0.00508077,  0.03560118, -0.00646364, -0.0655774 ,\n",
       "       -0.15138274,  0.05606088, -0.03491664,  0.04021179,  0.01088696,\n",
       "        0.05839626, -0.01288312, -0.12592092, -0.02556491,  0.07688269,\n",
       "        0.0475435 ,  0.05018999, -0.0234301 , -0.02369701, -0.08938733,\n",
       "       -0.00575437,  0.01245589, -0.09540208, -0.00302075, -0.03713066,\n",
       "       -0.03716866], dtype=float32)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense2_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9116541e-02, -8.2723703e-03, -1.1419123e-02, -1.1327737e-01,\n",
       "       -6.5194346e-02,  4.8418857e-02, -3.9538316e-02, -1.6164562e-02,\n",
       "       -4.4511978e-02,  7.4561641e-02, -5.8861740e-02, -9.5505053e-03,\n",
       "        2.0113796e-02, -6.1410822e-02, -6.5478124e-02, -4.0245024e-03,\n",
       "        2.3716087e-02, -5.0526451e-02, -1.2454178e-01, -8.0824932e-05,\n",
       "       -1.0469779e-01,  1.2737224e-02, -1.7199157e-02,  2.2517337e-02,\n",
       "        3.4629973e-03, -1.5731044e-02], dtype=float32)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADGRJREFUeJzt3GuMXHUZx/Hfj24BuSiFDrVSykIkJo2JEDdEgi9KJdzFRE1so4Qoui+MCYiJaUNMRDABogY1RtggXiIXRSRWQGoVG8QouMVCWtrS2tRQIHaRqG2MmsLjizk1k2Wmc6Zzzsw+k+8n2exc/jt9/sz2y/TsmXVECACQxxHDHgAA0BvCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgmbE6HnThwoUxPj5ex0MDwEjauHHjKxHRKLO2lnCPj49renq6jocGgJFk+y9l13KoBACSIdwAkAzhBoBkCDcAJEO4ASCZUmeV2N4taZ+k1yQdiIiJOocCAHTWy+mA50fEK7VNAgAohUMlAJBM2XCHpF/a3mh7ss6BAACHVvZQyXkR8ZLtkyWtt70tIh5vXVAEfVKSli5detgDja9++LC/dq7ZffNlwx4BmPP4O9+7Uq+4I+Kl4vNeSQ9KOqfNmqmImIiIiUaj1NvtAQCHoWu4bR9r+/iDlyVdKGlz3YMBANorc6hkkaQHbR9cf09EPFrrVACAjrqGOyJ2SXrXAGYBAJTA6YAAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIpHW7b82z/yfZDdQ4EADi0Xl5xXyNpa12DAADKKRVu20skXSbpznrHAQB0U/YV922SPi/p9RpnAQCUMNZtge3LJe2NiI22lx9i3aSkSUlaunRpZQNmNr764WGPAGAElXnFfZ6kK2zvlnSfpBW2fzh7UURMRcREREw0Go2KxwQAHNQ13BGxJiKWRMS4pJWSHouIj9U+GQCgLc7jBoBkuh7jbhURGyRtqGUSAEApvOIGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZLqG2/bRtp+y/YztLbZvGMRgAID2xkqs+Y+kFRGx3/Z8SU/Y/kVE/KHm2QAAbXQNd0SEpP3F1fnFR9Q5FACgs1LHuG3Ps71J0l5J6yPiyXrHAgB0UircEfFaRJwlaYmkc2y/c/Ya25O2p21Pz8zMVD0nAKDQ01klEfF3SRskXdzmvqmImIiIiUajUdF4AIDZypxV0rB9QnH5TZIukLSt7sEAAO2VOatksaTv256nZuh/HBEP1TsWAKCTMmeVPCvp7AHMAgAogXdOAkAyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIpmu4bZ9q+ze2t9reYvuaQQwGAGhvrMSaA5I+FxFP2z5e0kbb6yPiuZpnAwC00fUVd0S8HBFPF5f3Sdoq6ZS6BwMAtNfTMW7b45LOlvRkHcMAALorHW7bx0l6QNK1EfHPNvdP2p62PT0zM1PljACAFqXCbXu+mtG+OyJ+2m5NRExFxERETDQajSpnBAC0KHNWiSV9R9LWiPha/SMBAA6lzCvu8yRdKWmF7U3Fx6U1zwUA6KDr6YAR8YQkD2AWAEAJvHMSAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkukabtt32d5re/MgBgIAHFqZV9zfk3RxzXMAAErqGu6IeFzSqwOYBQBQQmXHuG1P2p62PT0zM1PVwwIAZqks3BExFRETETHRaDSqelgAwCycVQIAyRBuAEimzOmA90r6vaR32N5j++r6xwIAdDLWbUFErBrEIACAcjhUAgDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgmVLhtn2x7e22d9peXfdQAIDOuobb9jxJ35J0iaRlklbZXlb3YACA9sq84j5H0s6I2BUR/5V0n6QP1DsWAKCTMuE+RdILLdf3FLcBAIZgrMQat7kt3rDInpQ0WVzdb3v7rCULJb3S23hz2qjtRxq9PbGfuW+k9uRb+trPaWUXlgn3HkmntlxfIuml2YsiYkrSVKcHsT0dERNlB5vrRm0/0ujtif3MfaO2p0Htp8yhkj9KOtP26baPlLRS0tp6xwIAdNL1FXdEHLD9GUnrJM2TdFdEbKl9MgBAW2UOlSgiHpH0SJ9/VsfDKEmN2n6k0dsT+5n7Rm1PA9mPI97wc0YAwBzGW94BIJlKw237RNvrbe8oPi/osO6qYs0O21e13H6k7Snbz9veZvtDVc7Xqwr2s6H4VQGbio+TBzd92zn72k/L/Wttb65/4u4qeI4etf2M7S22by/eKTw0/ezH9jG2Hy7+7myxffNgp2+vgufoy7ZfsL1/cFO3ne+Qv/rD9lG2f1Tc/6Tt8Zb71hS3b7d9Ud/DRERlH5JulbS6uLxa0i1t1pwoaVfxeUFxeUFx3w2SbiouHyFpYZXzDWE/GyRNDHMPVe6nuP+Dku6RtHnY+6noOXpz8dmSHpC0Mut+JB0j6fxizZGSfivpkhF4jt4jabGk/UPcwzxJf5Z0RvHf9hlJy2at+bSk24vLKyX9qLi8rFh/lKTTi8eZ19c8FW9uu6TFxeXFkra3WbNK0h0t1++QtKq4/IKkY4f9jVbhfuZauPvdz3GSnii+EedKuPvaU8tt8yX9XNJHRmE/xe1fl/SpEXqOhhnucyWta7m+RtKaWWvWSTq3uDym5htxPHtt67rD/aj6GPeiiHhZkorP7Q4NtH0Lve0Tius32n7a9v22F1U8X68Oez8t179bHCb5gu1270IdpH73c6Okr0r6V51D9qjv58j2Okl7Je2T9JP6Ri2liu85FX+f3i/p1zXN2YtK9jRkZeb7/5qIOCDpH5JOKvm1PSl1OmAr27+S9NY2d11f9iHa3BbFLEsk/S4irrN9naSvSLqy1xl7UeN+JOmjEfGi7ePV/Gf4lZJ+0PuU5dW1H9tnSXp7RHy29djdINT8HCkiLrJ9tKS7Ja2QtL7nIXtQ935sj0m6V9I3ImJX7xP2ru49zQFl5uu0pvK99RzuiLig0322/2p7cUS8bHuxmq9iZtsjaXnL9SVqHlL4m5qv5B4sbr9f0tW9zterGvejiHix+LzP9j1q/qbFWsNd437OlfRu27vV/L452faGiFiumtX5HLX8Gf+2vVbN33xZa7gHsJ8pSTsi4rYKxi1lEM/RkJX51R8H1+wp/uf5FkmvlvzanlR9qGStpIM/Db5K0s/arFkn6ULbC4qfLl+o5rGjUPMY4/Ji3fskPVfxfL067P3YHrO9UJJsz5d0uaRhn4nRz/Pz7Yh4W0SMS3qvpOcHEe0S+nmOjitCcvBV6qWStg1g5kM57P1Iku2b1AzGtQOYtay+9jRHlPnVH637/LCkx4qurZW0sjjr5HRJZ0p6qq9pKj6Af5Kax9R2FJ9PLG6fkHRny7pPSNpZfHy85fbTJD0u6dni65cO64cR/e5H0rGSNhZ72aLmD4r6+knysJ+flvvHNXd+ONnPc7RIzb+QB5+jb0oaS7yfJWr+E3yrpE3FxyczP0fF7beq+ar19eLzF4e0j0slPa/mWSHXF7d9SdIVxeWj1TxSsFPNMJ/R8rXXF1+3XRWc6cM7JwEgGd45CQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgmf8BTZXLy0CiqkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense3_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00756586, -0.02501711,  0.0099206 , -0.01653922, -0.00498954,\n",
       "       -0.02412132,  0.01906661,  0.01431654, -0.02750618,  0.00811449,\n",
       "        0.00446448, -0.01168522,  0.0049389 , -0.00479022, -0.00707201,\n",
       "       -0.00961357,  0.02616026, -0.00593084, -0.02092301,  0.02076958,\n",
       "       -0.03055543,  0.02764627, -0.00403613, -0.00593389, -0.02290643,\n",
       "       -0.01369932], dtype=float32)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense4_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00376486, -0.00684315, -0.01224959, -0.01735649,  0.00282918,\n",
       "        0.00966029, -0.00057398,  0.0065892 ,  0.00791861, -0.00477751,\n",
       "       -0.01065411, -0.00087457, -0.00948363, -0.00772376, -0.00306472,\n",
       "        0.00406543,  0.0013066 ,  0.00924314, -0.00038361,  0.00988583,\n",
       "       -0.01568382,  0.01192703, -0.0080044 ,  0.00257939,  0.00652821,\n",
       "       -0.0205815 ], dtype=float32)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADGRJREFUeJzt3GuMXHUZx/Hfj24BuSiFDrVSykIkJo2JEDdEgi9KJdzFRE1so4Qoui+MCYiJaUNMRDABogY1RtggXiIXRSRWQGoVG8QouMVCWtrS2tRQIHaRqG2MmsLjizk1k2Wmc6Zzzsw+k+8n2exc/jt9/sz2y/TsmXVECACQxxHDHgAA0BvCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgmbE6HnThwoUxPj5ex0MDwEjauHHjKxHRKLO2lnCPj49renq6jocGgJFk+y9l13KoBACSIdwAkAzhBoBkCDcAJEO4ASCZUmeV2N4taZ+k1yQdiIiJOocCAHTWy+mA50fEK7VNAgAohUMlAJBM2XCHpF/a3mh7ss6BAACHVvZQyXkR8ZLtkyWtt70tIh5vXVAEfVKSli5detgDja9++LC/dq7ZffNlwx4BmPP4O9+7Uq+4I+Kl4vNeSQ9KOqfNmqmImIiIiUaj1NvtAQCHoWu4bR9r+/iDlyVdKGlz3YMBANorc6hkkaQHbR9cf09EPFrrVACAjrqGOyJ2SXrXAGYBAJTA6YAAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIpHW7b82z/yfZDdQ4EADi0Xl5xXyNpa12DAADKKRVu20skXSbpznrHAQB0U/YV922SPi/p9RpnAQCUMNZtge3LJe2NiI22lx9i3aSkSUlaunRpZQNmNr764WGPAGAElXnFfZ6kK2zvlnSfpBW2fzh7UURMRcREREw0Go2KxwQAHNQ13BGxJiKWRMS4pJWSHouIj9U+GQCgLc7jBoBkuh7jbhURGyRtqGUSAEApvOIGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZLqG2/bRtp+y/YztLbZvGMRgAID2xkqs+Y+kFRGx3/Z8SU/Y/kVE/KHm2QAAbXQNd0SEpP3F1fnFR9Q5FACgs1LHuG3Ps71J0l5J6yPiyXrHAgB0UircEfFaRJwlaYmkc2y/c/Ya25O2p21Pz8zMVD0nAKDQ01klEfF3SRskXdzmvqmImIiIiUajUdF4AIDZypxV0rB9QnH5TZIukLSt7sEAAO2VOatksaTv256nZuh/HBEP1TsWAKCTMmeVPCvp7AHMAgAogXdOAkAyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIpmu4bZ9q+ze2t9reYvuaQQwGAGhvrMSaA5I+FxFP2z5e0kbb6yPiuZpnAwC00fUVd0S8HBFPF5f3Sdoq6ZS6BwMAtNfTMW7b45LOlvRkHcMAALorHW7bx0l6QNK1EfHPNvdP2p62PT0zM1PljACAFqXCbXu+mtG+OyJ+2m5NRExFxERETDQajSpnBAC0KHNWiSV9R9LWiPha/SMBAA6lzCvu8yRdKWmF7U3Fx6U1zwUA6KDr6YAR8YQkD2AWAEAJvHMSAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkukabtt32d5re/MgBgIAHFqZV9zfk3RxzXMAAErqGu6IeFzSqwOYBQBQQmXHuG1P2p62PT0zM1PVwwIAZqks3BExFRETETHRaDSqelgAwCycVQIAyRBuAEimzOmA90r6vaR32N5j++r6xwIAdDLWbUFErBrEIACAcjhUAgDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgGcINAMkQbgBIhnADQDKEGwCSIdwAkAzhBoBkCDcAJEO4ASAZwg0AyRBuAEiGcANAMoQbAJIh3ACQDOEGgGQINwAkQ7gBIBnCDQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgmVLhtn2x7e22d9peXfdQAIDOuobb9jxJ35J0iaRlklbZXlb3YACA9sq84j5H0s6I2BUR/5V0n6QP1DsWAKCTMuE+RdILLdf3FLcBAIZgrMQat7kt3rDInpQ0WVzdb3v7rCULJb3S23hz2qjtRxq9PbGfuW+k9uRb+trPaWUXlgn3HkmntlxfIuml2YsiYkrSVKcHsT0dERNlB5vrRm0/0ujtif3MfaO2p0Htp8yhkj9KOtP26baPlLRS0tp6xwIAdNL1FXdEHLD9GUnrJM2TdFdEbKl9MgBAW2UOlSgiHpH0SJ9/VsfDKEmN2n6k0dsT+5n7Rm1PA9mPI97wc0YAwBzGW94BIJlKw237RNvrbe8oPi/osO6qYs0O21e13H6k7Snbz9veZvtDVc7Xqwr2s6H4VQGbio+TBzd92zn72k/L/Wttb65/4u4qeI4etf2M7S22by/eKTw0/ezH9jG2Hy7+7myxffNgp2+vgufoy7ZfsL1/cFO3ne+Qv/rD9lG2f1Tc/6Tt8Zb71hS3b7d9Ud/DRERlH5JulbS6uLxa0i1t1pwoaVfxeUFxeUFx3w2SbiouHyFpYZXzDWE/GyRNDHMPVe6nuP+Dku6RtHnY+6noOXpz8dmSHpC0Mut+JB0j6fxizZGSfivpkhF4jt4jabGk/UPcwzxJf5Z0RvHf9hlJy2at+bSk24vLKyX9qLi8rFh/lKTTi8eZ19c8FW9uu6TFxeXFkra3WbNK0h0t1++QtKq4/IKkY4f9jVbhfuZauPvdz3GSnii+EedKuPvaU8tt8yX9XNJHRmE/xe1fl/SpEXqOhhnucyWta7m+RtKaWWvWSTq3uDym5htxPHtt67rD/aj6GPeiiHhZkorP7Q4NtH0Lve0Tius32n7a9v22F1U8X68Oez8t179bHCb5gu1270IdpH73c6Okr0r6V51D9qjv58j2Okl7Je2T9JP6Ri2liu85FX+f3i/p1zXN2YtK9jRkZeb7/5qIOCDpH5JOKvm1PSl1OmAr27+S9NY2d11f9iHa3BbFLEsk/S4irrN9naSvSLqy1xl7UeN+JOmjEfGi7ePV/Gf4lZJ+0PuU5dW1H9tnSXp7RHy29djdINT8HCkiLrJ9tKS7Ja2QtL7nIXtQ935sj0m6V9I3ImJX7xP2ru49zQFl5uu0pvK99RzuiLig0322/2p7cUS8bHuxmq9iZtsjaXnL9SVqHlL4m5qv5B4sbr9f0tW9zterGvejiHix+LzP9j1q/qbFWsNd437OlfRu27vV/L452faGiFiumtX5HLX8Gf+2vVbN33xZa7gHsJ8pSTsi4rYKxi1lEM/RkJX51R8H1+wp/uf5FkmvlvzanlR9qGStpIM/Db5K0s/arFkn6ULbC4qfLl+o5rGjUPMY4/Ji3fskPVfxfL067P3YHrO9UJJsz5d0uaRhn4nRz/Pz7Yh4W0SMS3qvpOcHEe0S+nmOjitCcvBV6qWStg1g5kM57P1Iku2b1AzGtQOYtay+9jRHlPnVH637/LCkx4qurZW0sjjr5HRJZ0p6qq9pKj6Af5Kax9R2FJ9PLG6fkHRny7pPSNpZfHy85fbTJD0u6dni65cO64cR/e5H0rGSNhZ72aLmD4r6+knysJ+flvvHNXd+ONnPc7RIzb+QB5+jb0oaS7yfJWr+E3yrpE3FxyczP0fF7beq+ar19eLzF4e0j0slPa/mWSHXF7d9SdIVxeWj1TxSsFPNMJ/R8rXXF1+3XRWc6cM7JwEgGd45CQDJEG4ASIZwA0AyhBsAkiHcAJAM4QaAZAg3ACRDuAEgmf8BTZXLy0CiqkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense5_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00929426], dtype=float32)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense6_output[i] for i in range(26)])\n",
    "plt.hist(a, bins='auto') \n",
    "dense6_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions converge to a small namber without batch normalisation which shows that batch normalisation can make the data has a wider distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some non-linear activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(26, input_dim=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, init='uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(26))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "model.add(Dense(26))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 200.6960 - acc: 0.0385\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 117us/step - loss: 145.4241 - acc: 0.0385\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 123us/step - loss: 115.4484 - acc: 0.0385\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 129us/step - loss: 87.7187 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 136us/step - loss: 74.5877 - acc: 0.0385\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 135us/step - loss: 70.4799 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 134us/step - loss: 96.2158 - acc: 0.0385\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 51.9465 - acc: 0.0385\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 153us/step - loss: 40.8296 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 136us/step - loss: 50.1674 - acc: 0.2308\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 166.1336 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 150us/step - loss: 88.7009 - acc: 0.0769\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 68.0996 - acc: 0.0385\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 141us/step - loss: 50.6899 - acc: 0.0769\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 41.2325 - acc: 0.0385\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 141us/step - loss: 35.4768 - acc: 0.0769\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 152us/step - loss: 32.0972 - acc: 0.0769\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 148us/step - loss: 28.4547 - acc: 0.1154\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 24.9296 - acc: 0.1154\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 140us/step - loss: 26.3248 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 136us/step - loss: 34.0591 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 132us/step - loss: 48.9648 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 40.4114 - acc: 0.0385\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 25.1448 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 138us/step - loss: 20.9737 - acc: 0.1538\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 141us/step - loss: 19.6246 - acc: 0.2692\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 150us/step - loss: 18.4064 - acc: 0.1154\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 137us/step - loss: 16.7896 - acc: 0.1154\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 137us/step - loss: 16.1269 - acc: 0.2308\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 140us/step - loss: 16.3724 - acc: 0.1154\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 153us/step - loss: 17.3178 - acc: 0.1538\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 135us/step - loss: 19.4162 - acc: 0.1923\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 148us/step - loss: 20.4365 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 145us/step - loss: 20.0779 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 19.5924 - acc: 0.0385\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 153us/step - loss: 17.8568 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 17.3693 - acc: 0.1154\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 136us/step - loss: 16.3900 - acc: 0.0385\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 16.0900 - acc: 0.1538\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 138us/step - loss: 14.1677 - acc: 0.1154\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 136us/step - loss: 14.1548 - acc: 0.1923\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 14.7834 - acc: 0.1538\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 139us/step - loss: 15.9898 - acc: 0.3077\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 15.9859 - acc: 0.0769\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 128us/step - loss: 15.2066 - acc: 0.2308\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 14.4222 - acc: 0.1538\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 140us/step - loss: 13.4115 - acc: 0.3462\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 141us/step - loss: 13.0436 - acc: 0.1923\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 12.5361 - acc: 0.3077\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 12.2809 - acc: 0.3846\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 150us/step - loss: 12.0611 - acc: 0.3077\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 11.9509 - acc: 0.3846\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 141us/step - loss: 11.9372 - acc: 0.3462\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 151us/step - loss: 12.0988 - acc: 0.3846\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 11.9039 - acc: 0.2692\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 168us/step - loss: 11.7817 - acc: 0.4231\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 147us/step - loss: 11.6910 - acc: 0.3077\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 150us/step - loss: 11.6402 - acc: 0.4231\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 138us/step - loss: 11.6543 - acc: 0.3462\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 137us/step - loss: 11.8752 - acc: 0.3846\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 138us/step - loss: 11.7290 - acc: 0.2692\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 145us/step - loss: 11.6491 - acc: 0.4231\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 150us/step - loss: 11.5839 - acc: 0.3077\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 11.5900 - acc: 0.4231\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 155us/step - loss: 11.6365 - acc: 0.3462\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 12.0134 - acc: 0.3462\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 11.8106 - acc: 0.2308\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 131us/step - loss: 11.7237 - acc: 0.3846\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 164us/step - loss: 11.6247 - acc: 0.2308\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 11.6232 - acc: 0.3846\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 11.5874 - acc: 0.2308\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 160us/step - loss: 11.7151 - acc: 0.1923\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 11.7448 - acc: 0.2308\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 138us/step - loss: 12.2567 - acc: 0.0769\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 11.8898 - acc: 0.1538\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 160us/step - loss: 11.7508 - acc: 0.2308\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 143us/step - loss: 11.5532 - acc: 0.2692\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 153us/step - loss: 11.5085 - acc: 0.3077\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 11.4055 - acc: 0.3077\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 147us/step - loss: 11.4652 - acc: 0.2692\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 147us/step - loss: 11.2454 - acc: 0.2692\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 147us/step - loss: 10.1911 - acc: 0.1154\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 147us/step - loss: 11.1280 - acc: 0.2308\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 150us/step - loss: 13.8077 - acc: 0.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 137us/step - loss: 16.1891 - acc: 0.0769\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 141us/step - loss: 11.6888 - acc: 0.0769\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 147us/step - loss: 16.8317 - acc: 0.0385\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 132us/step - loss: 10.6501 - acc: 0.0385\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 149us/step - loss: 10.1640 - acc: 0.0769\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 142us/step - loss: 10.2557 - acc: 0.1154\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 156us/step - loss: 10.0532 - acc: 0.3462\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 153us/step - loss: 9.6977 - acc: 0.0769\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 150us/step - loss: 9.5878 - acc: 0.4615\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 9.2443 - acc: 0.1538\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 149us/step - loss: 9.1750 - acc: 0.3846\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 8.9817 - acc: 0.3846\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 137us/step - loss: 8.9704 - acc: 0.3846\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 144us/step - loss: 8.8867 - acc: 0.3846\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 155us/step - loss: 8.8953 - acc: 0.4231\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 146us/step - loss: 8.8467 - acc: 0.3846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a44d25550>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x_train), np.array(y_train), epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",x_as_vector = False, y_as_vector = False)\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a45c1e358>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# let change the prediction into int, see the confusion matrix\n",
    "array = confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25)))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not amazing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: delete it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning structure 2: One input vs 26 output (as a classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\", x_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 0, 1, 2] y_train: 26\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train:\",x_train,\"y_train:\",y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(26, activation='relu'))\n",
    "\n",
    "# change sigomiod to softmax made acc increasing 100%\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 0.7251 - acc: 0.5710\n",
      "Epoch 2/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6907 - acc: 0.5814\n",
      "Epoch 3/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.6766 - acc: 0.6146\n",
      "Epoch 4/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.6677 - acc: 0.6331\n",
      "Epoch 5/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.6600 - acc: 0.6649\n",
      "Epoch 6/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.6529 - acc: 0.6849\n",
      "Epoch 7/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.6458 - acc: 0.6864\n",
      "Epoch 8/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.6381 - acc: 0.6916\n",
      "Epoch 9/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.6298 - acc: 0.7189\n",
      "Epoch 10/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.6213 - acc: 0.7189\n",
      "Epoch 11/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.6126 - acc: 0.7189\n",
      "Epoch 12/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.6040 - acc: 0.7189\n",
      "Epoch 13/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.5946 - acc: 0.7189\n",
      "Epoch 14/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.5843 - acc: 0.7189\n",
      "Epoch 15/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.5725 - acc: 0.7175\n",
      "Epoch 16/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.5599 - acc: 0.7175\n",
      "Epoch 17/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.5460 - acc: 0.7175\n",
      "Epoch 18/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.5309 - acc: 0.7189\n",
      "Epoch 19/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.5156 - acc: 0.7175\n",
      "Epoch 20/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4990 - acc: 0.7189\n",
      "Epoch 21/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.4820 - acc: 0.7714\n",
      "Epoch 22/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.4637 - acc: 0.7885\n",
      "Epoch 23/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.4464 - acc: 0.7885\n",
      "Epoch 24/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.4287 - acc: 0.7899\n",
      "Epoch 25/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.4114 - acc: 0.8025\n",
      "Epoch 26/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.3946 - acc: 0.8787\n",
      "Epoch 27/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.3783 - acc: 0.8935\n",
      "Epoch 28/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.3630 - acc: 0.8950\n",
      "Epoch 29/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.3482 - acc: 0.8950\n",
      "Epoch 30/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.3337 - acc: 0.9179\n",
      "Epoch 31/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.3120 - acc: 0.9312\n",
      "Epoch 32/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.2898 - acc: 0.9504\n",
      "Epoch 33/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.2780 - acc: 0.9615\n",
      "Epoch 34/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.2709 - acc: 0.9615\n",
      "Epoch 35/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.2636 - acc: 0.9615\n",
      "Epoch 36/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.2563 - acc: 0.9615\n",
      "Epoch 37/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.2496 - acc: 0.9615\n",
      "Epoch 38/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.2443 - acc: 0.9615\n",
      "Epoch 39/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.2399 - acc: 0.9615\n",
      "Epoch 40/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.2345 - acc: 0.9615\n",
      "Epoch 41/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.2291 - acc: 0.9615\n",
      "Epoch 42/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.2245 - acc: 0.9615\n",
      "Epoch 43/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.2204 - acc: 0.9615\n",
      "Epoch 44/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.2158 - acc: 0.9615\n",
      "Epoch 45/300\n",
      "52/52 [==============================] - 0s 150us/step - loss: 0.2120 - acc: 0.9615\n",
      "Epoch 46/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.2083 - acc: 0.9615\n",
      "Epoch 47/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.2051 - acc: 0.9615\n",
      "Epoch 48/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.2015 - acc: 0.9615\n",
      "Epoch 49/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1979 - acc: 0.9615\n",
      "Epoch 50/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1943 - acc: 0.9615\n",
      "Epoch 51/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1908 - acc: 0.9615\n",
      "Epoch 52/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1876 - acc: 0.9615\n",
      "Epoch 53/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1841 - acc: 0.9615\n",
      "Epoch 54/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1814 - acc: 0.9615\n",
      "Epoch 55/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1784 - acc: 0.9615\n",
      "Epoch 56/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1763 - acc: 0.9615\n",
      "Epoch 57/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1740 - acc: 0.9615\n",
      "Epoch 58/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1717 - acc: 0.9615\n",
      "Epoch 59/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1701 - acc: 0.9615\n",
      "Epoch 60/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1690 - acc: 0.9615\n",
      "Epoch 61/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1677 - acc: 0.9615\n",
      "Epoch 62/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1663 - acc: 0.9615\n",
      "Epoch 63/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1659 - acc: 0.9615\n",
      "Epoch 64/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1650 - acc: 0.9615\n",
      "Epoch 65/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1644 - acc: 0.9615\n",
      "Epoch 66/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1629 - acc: 0.9615\n",
      "Epoch 67/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1612 - acc: 0.9615\n",
      "Epoch 68/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1611 - acc: 0.9615\n",
      "Epoch 69/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1601 - acc: 0.9615\n",
      "Epoch 70/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1593 - acc: 0.9615\n",
      "Epoch 71/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1584 - acc: 0.9615\n",
      "Epoch 72/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1575 - acc: 0.9615\n",
      "Epoch 73/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1569 - acc: 0.9615\n",
      "Epoch 74/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1558 - acc: 0.9615\n",
      "Epoch 75/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1551 - acc: 0.9615\n",
      "Epoch 76/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1544 - acc: 0.9615\n",
      "Epoch 77/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1539 - acc: 0.9615\n",
      "Epoch 78/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1530 - acc: 0.9615\n",
      "Epoch 79/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1525 - acc: 0.9615\n",
      "Epoch 80/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1519 - acc: 0.9615\n",
      "Epoch 81/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1513 - acc: 0.9615\n",
      "Epoch 82/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1507 - acc: 0.9615\n",
      "Epoch 83/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1500 - acc: 0.9615\n",
      "Epoch 84/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1494 - acc: 0.9615\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 137us/step - loss: 0.1490 - acc: 0.9615\n",
      "Epoch 86/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1487 - acc: 0.9615\n",
      "Epoch 87/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1479 - acc: 0.9615\n",
      "Epoch 88/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.1473 - acc: 0.9615\n",
      "Epoch 89/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1472 - acc: 0.9615\n",
      "Epoch 90/300\n",
      "52/52 [==============================] - 0s 148us/step - loss: 0.1463 - acc: 0.9615\n",
      "Epoch 91/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1458 - acc: 0.9615\n",
      "Epoch 92/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1456 - acc: 0.9615\n",
      "Epoch 93/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1450 - acc: 0.9615\n",
      "Epoch 94/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1443 - acc: 0.9615\n",
      "Epoch 95/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1444 - acc: 0.9615\n",
      "Epoch 96/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1435 - acc: 0.9615\n",
      "Epoch 97/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1431 - acc: 0.9615\n",
      "Epoch 98/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1426 - acc: 0.9615\n",
      "Epoch 99/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1417 - acc: 0.9615\n",
      "Epoch 100/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1414 - acc: 0.9615\n",
      "Epoch 101/300\n",
      "52/52 [==============================] - 0s 150us/step - loss: 0.1409 - acc: 0.9615\n",
      "Epoch 102/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1405 - acc: 0.9615\n",
      "Epoch 103/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1398 - acc: 0.9615\n",
      "Epoch 104/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1401 - acc: 0.9615\n",
      "Epoch 105/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1395 - acc: 0.9615\n",
      "Epoch 106/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1385 - acc: 0.9615\n",
      "Epoch 107/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.1385 - acc: 0.9615\n",
      "Epoch 108/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1389 - acc: 0.9615\n",
      "Epoch 109/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1376 - acc: 0.9615\n",
      "Epoch 110/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1383 - acc: 0.9615\n",
      "Epoch 111/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1376 - acc: 0.9615\n",
      "Epoch 112/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1363 - acc: 0.9615\n",
      "Epoch 113/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1369 - acc: 0.9615\n",
      "Epoch 114/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1361 - acc: 0.9615\n",
      "Epoch 115/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1355 - acc: 0.9615\n",
      "Epoch 116/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1357 - acc: 0.9615\n",
      "Epoch 117/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1342 - acc: 0.9615\n",
      "Epoch 118/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1345 - acc: 0.9615\n",
      "Epoch 119/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1338 - acc: 0.9615\n",
      "Epoch 120/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1334 - acc: 0.9615\n",
      "Epoch 121/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1331 - acc: 0.9615\n",
      "Epoch 122/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1325 - acc: 0.9615\n",
      "Epoch 123/300\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.1321 - acc: 0.9615\n",
      "Epoch 124/300\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.1321 - acc: 0.9615\n",
      "Epoch 125/300\n",
      "52/52 [==============================] - 0s 193us/step - loss: 0.1313 - acc: 0.9615\n",
      "Epoch 126/300\n",
      "52/52 [==============================] - 0s 193us/step - loss: 0.1309 - acc: 0.9615\n",
      "Epoch 127/300\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.1305 - acc: 0.9615\n",
      "Epoch 128/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1303 - acc: 0.9615\n",
      "Epoch 129/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1300 - acc: 0.9615\n",
      "Epoch 130/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1295 - acc: 0.9615\n",
      "Epoch 131/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1296 - acc: 0.9615\n",
      "Epoch 132/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1289 - acc: 0.9615\n",
      "Epoch 133/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1286 - acc: 0.9615\n",
      "Epoch 134/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1282 - acc: 0.9615\n",
      "Epoch 135/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1277 - acc: 0.9615\n",
      "Epoch 136/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1273 - acc: 0.9615\n",
      "Epoch 137/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1270 - acc: 0.9615\n",
      "Epoch 138/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1268 - acc: 0.9615\n",
      "Epoch 139/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1270 - acc: 0.9615\n",
      "Epoch 140/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 141/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 142/300\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.1254 - acc: 0.9615\n",
      "Epoch 143/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1250 - acc: 0.9615\n",
      "Epoch 144/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1246 - acc: 0.9615\n",
      "Epoch 145/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1243 - acc: 0.9615\n",
      "Epoch 146/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1240 - acc: 0.9615\n",
      "Epoch 147/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1235 - acc: 0.9615\n",
      "Epoch 148/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1234 - acc: 0.9615\n",
      "Epoch 149/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1228 - acc: 0.9615\n",
      "Epoch 150/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1224 - acc: 0.9615\n",
      "Epoch 151/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1223 - acc: 0.9615\n",
      "Epoch 152/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1216 - acc: 0.9615\n",
      "Epoch 153/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1215 - acc: 0.9615\n",
      "Epoch 154/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1210 - acc: 0.9615\n",
      "Epoch 155/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1208 - acc: 0.9615\n",
      "Epoch 156/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1208 - acc: 0.9615\n",
      "Epoch 157/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1201 - acc: 0.9615\n",
      "Epoch 158/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1200 - acc: 0.9615\n",
      "Epoch 159/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1195 - acc: 0.9615\n",
      "Epoch 160/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1189 - acc: 0.9615\n",
      "Epoch 161/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1185 - acc: 0.9615\n",
      "Epoch 162/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1187 - acc: 0.9615\n",
      "Epoch 163/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1189 - acc: 0.9615\n",
      "Epoch 164/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1178 - acc: 0.9615\n",
      "Epoch 165/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1174 - acc: 0.9615\n",
      "Epoch 166/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1170 - acc: 0.9615\n",
      "Epoch 167/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1167 - acc: 0.9615\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 133us/step - loss: 0.1170 - acc: 0.9615\n",
      "Epoch 169/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1159 - acc: 0.9615\n",
      "Epoch 170/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1155 - acc: 0.9615\n",
      "Epoch 171/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1157 - acc: 0.9615\n",
      "Epoch 172/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1162 - acc: 0.9615\n",
      "Epoch 173/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1155 - acc: 0.9615\n",
      "Epoch 174/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1141 - acc: 0.9615\n",
      "Epoch 175/300\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.1142 - acc: 0.9615\n",
      "Epoch 176/300\n",
      "52/52 [==============================] - 0s 146us/step - loss: 0.1136 - acc: 0.9615\n",
      "Epoch 177/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1128 - acc: 0.9615\n",
      "Epoch 178/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1132 - acc: 0.9615\n",
      "Epoch 179/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1134 - acc: 0.9615\n",
      "Epoch 180/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1126 - acc: 0.9615\n",
      "Epoch 181/300\n",
      "52/52 [==============================] - 0s 150us/step - loss: 0.1116 - acc: 0.9615\n",
      "Epoch 182/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1109 - acc: 0.9615\n",
      "Epoch 183/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1120 - acc: 0.9615\n",
      "Epoch 184/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.1124 - acc: 0.9615\n",
      "Epoch 185/300\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.1108 - acc: 0.9615\n",
      "Epoch 186/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1108 - acc: 0.9615\n",
      "Epoch 187/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1100 - acc: 0.9615\n",
      "Epoch 188/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1094 - acc: 0.9615\n",
      "Epoch 189/300\n",
      "52/52 [==============================] - 0s 155us/step - loss: 0.1091 - acc: 0.9615\n",
      "Epoch 190/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1090 - acc: 0.9615\n",
      "Epoch 191/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1090 - acc: 0.9615\n",
      "Epoch 192/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1074 - acc: 0.9615\n",
      "Epoch 193/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1075 - acc: 0.9615\n",
      "Epoch 194/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1080 - acc: 0.9615\n",
      "Epoch 195/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1088 - acc: 0.9615\n",
      "Epoch 196/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1106 - acc: 0.9615\n",
      "Epoch 197/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1080 - acc: 0.9615\n",
      "Epoch 198/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1122 - acc: 0.9615\n",
      "Epoch 199/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1106 - acc: 0.9615\n",
      "Epoch 200/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1061 - acc: 0.9615\n",
      "Epoch 201/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1069 - acc: 0.9615\n",
      "Epoch 202/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1076 - acc: 0.9615\n",
      "Epoch 203/300\n",
      "52/52 [==============================] - 0s 146us/step - loss: 0.1045 - acc: 0.9615\n",
      "Epoch 204/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1046 - acc: 0.9615\n",
      "Epoch 205/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1045 - acc: 0.9623\n",
      "Epoch 206/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.1032 - acc: 0.9630\n",
      "Epoch 207/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1031 - acc: 0.9630\n",
      "Epoch 208/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1029 - acc: 0.9630\n",
      "Epoch 209/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1018 - acc: 0.9630\n",
      "Epoch 210/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1014 - acc: 0.9630\n",
      "Epoch 211/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1014 - acc: 0.9630\n",
      "Epoch 212/300\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.1002 - acc: 0.9630\n",
      "Epoch 213/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1003 - acc: 0.9630\n",
      "Epoch 214/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1008 - acc: 0.9630\n",
      "Epoch 215/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.0994 - acc: 0.9630\n",
      "Epoch 216/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.0994 - acc: 0.9630\n",
      "Epoch 217/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.0993 - acc: 0.9630\n",
      "Epoch 218/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.0983 - acc: 0.9630\n",
      "Epoch 219/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.0981 - acc: 0.9630\n",
      "Epoch 220/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.0976 - acc: 0.9630\n",
      "Epoch 221/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.0978 - acc: 0.9630\n",
      "Epoch 222/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.0969 - acc: 0.9630\n",
      "Epoch 223/300\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.0965 - acc: 0.9630\n",
      "Epoch 224/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.0965 - acc: 0.9630\n",
      "Epoch 225/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0962 - acc: 0.9630\n",
      "Epoch 226/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.0954 - acc: 0.9630\n",
      "Epoch 227/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.0954 - acc: 0.9630\n",
      "Epoch 228/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.0946 - acc: 0.9630\n",
      "Epoch 229/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.0952 - acc: 0.9630\n",
      "Epoch 230/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.0940 - acc: 0.9630\n",
      "Epoch 231/300\n",
      "52/52 [==============================] - 0s 148us/step - loss: 0.0937 - acc: 0.9630\n",
      "Epoch 232/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.0941 - acc: 0.9630\n",
      "Epoch 233/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.0938 - acc: 0.9630\n",
      "Epoch 234/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.0942 - acc: 0.9630\n",
      "Epoch 235/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.0945 - acc: 0.9630\n",
      "Epoch 236/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.0948 - acc: 0.9630\n",
      "Epoch 237/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0928 - acc: 0.9630\n",
      "Epoch 238/300\n",
      "52/52 [==============================] - 0s 146us/step - loss: 0.0921 - acc: 0.9630\n",
      "Epoch 239/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.0921 - acc: 0.9630\n",
      "Epoch 240/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.0921 - acc: 0.9638\n",
      "Epoch 241/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0912 - acc: 0.9645\n",
      "Epoch 242/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.0905 - acc: 0.9645\n",
      "Epoch 243/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.0906 - acc: 0.9630\n",
      "Epoch 244/300\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.0903 - acc: 0.9630\n",
      "Epoch 245/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.0899 - acc: 0.9630\n",
      "Epoch 246/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.0895 - acc: 0.9638\n",
      "Epoch 247/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.0887 - acc: 0.9645\n",
      "Epoch 248/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.0898 - acc: 0.9630\n",
      "Epoch 249/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.0889 - acc: 0.9630\n",
      "Epoch 250/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.0892 - acc: 0.9645\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 143us/step - loss: 0.0891 - acc: 0.9638\n",
      "Epoch 252/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.0907 - acc: 0.9645\n",
      "Epoch 253/300\n",
      "52/52 [==============================] - 0s 148us/step - loss: 0.0903 - acc: 0.9630\n",
      "Epoch 254/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.0879 - acc: 0.9660\n",
      "Epoch 255/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.0894 - acc: 0.9645\n",
      "Epoch 256/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.0919 - acc: 0.9645\n",
      "Epoch 257/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.0886 - acc: 0.9652\n",
      "Epoch 258/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.0858 - acc: 0.9645\n",
      "Epoch 259/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.0854 - acc: 0.9638\n",
      "Epoch 260/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.0863 - acc: 0.9630\n",
      "Epoch 261/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.0864 - acc: 0.9645\n",
      "Epoch 262/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.0859 - acc: 0.9645\n",
      "Epoch 263/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0858 - acc: 0.9638\n",
      "Epoch 264/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0842 - acc: 0.9645\n",
      "Epoch 265/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.0870 - acc: 0.9652\n",
      "Epoch 266/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0859 - acc: 0.9645\n",
      "Epoch 267/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.0849 - acc: 0.9652\n",
      "Epoch 268/300\n",
      "52/52 [==============================] - 0s 151us/step - loss: 0.0840 - acc: 0.9660\n",
      "Epoch 269/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.0827 - acc: 0.9660\n",
      "Epoch 270/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.0837 - acc: 0.9645\n",
      "Epoch 271/300\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.0829 - acc: 0.9630\n",
      "Epoch 272/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.0834 - acc: 0.9660\n",
      "Epoch 273/300\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.0830 - acc: 0.9689\n",
      "Epoch 274/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0823 - acc: 0.9660\n",
      "Epoch 275/300\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.0822 - acc: 0.9645\n",
      "Epoch 276/300\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.0825 - acc: 0.9645\n",
      "Epoch 277/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.0813 - acc: 0.9645\n",
      "Epoch 278/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.0811 - acc: 0.9667\n",
      "Epoch 279/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.0804 - acc: 0.9675\n",
      "Epoch 280/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0801 - acc: 0.9645\n",
      "Epoch 281/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.0793 - acc: 0.9645\n",
      "Epoch 282/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.0794 - acc: 0.9645\n",
      "Epoch 283/300\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.0792 - acc: 0.9682\n",
      "Epoch 284/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.0790 - acc: 0.9675\n",
      "Epoch 285/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.0781 - acc: 0.9675\n",
      "Epoch 286/300\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.0780 - acc: 0.9660\n",
      "Epoch 287/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.0776 - acc: 0.9645\n",
      "Epoch 288/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.0772 - acc: 0.9645\n",
      "Epoch 289/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.0767 - acc: 0.9660\n",
      "Epoch 290/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.0767 - acc: 0.9660\n",
      "Epoch 291/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.0765 - acc: 0.9667\n",
      "Epoch 292/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.0759 - acc: 0.9675\n",
      "Epoch 293/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.0761 - acc: 0.9689\n",
      "Epoch 294/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.0754 - acc: 0.9675\n",
      "Epoch 295/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.0774 - acc: 0.9682\n",
      "Epoch 296/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.0767 - acc: 0.9667\n",
      "Epoch 297/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.0776 - acc: 0.9704\n",
      "Epoch 298/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.0784 - acc: 0.9682\n",
      "Epoch 299/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.0769 - acc: 0.9660\n",
      "Epoch 300/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.0763 - acc: 0.9675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a48590e48>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return (I2L[index])\n",
    "\n",
    "def predict_results(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index = np.argmax(predictions, axis=1)\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index))\n",
    "\n",
    "    return (prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = 'IAMREALLYGOOD'\n",
    "text, x_train, y_train = caeserde(mystr,x_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: IAMREALLYGOOD\n",
      "Cipertext: LDPUHDOOBJRRG\n",
      "Prediction: IZMTEZLLYGPPC\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\",mystr)\n",
    "print(\"Cipertext:\",text)\n",
    "print(\"Prediction:\",\"\".join(predict_results(model, x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde('ABCDEFGHIJKLMNOPQRSTUVWXYZ', x_as_vector=False, y_as_vector=False)\n",
    "\n",
    "predictions = model.predict_classes(x_train)\n",
    "\n",
    "#print(confusion_matrix(y_train, predictions.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4b391e48>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_train, predictions.astype(int))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 26 outputs, the results seems better than 1 output by using the binary cross entropy which are able get the 100% accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\", x_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(26, activation='relu'))\n",
    "\n",
    "# change sigomiod to softmax made acc increasing 100%\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "52/52 [==============================] - 4s 78ms/step - loss: 3.3385 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 3.2939 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 3.2696 - categorical_accuracy: 0.0385\n",
      "Epoch 4/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 3.2541 - categorical_accuracy: 0.0385\n",
      "Epoch 5/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 3.2476 - categorical_accuracy: 0.0385\n",
      "Epoch 6/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 3.2388 - categorical_accuracy: 0.0385\n",
      "Epoch 7/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 3.2328 - categorical_accuracy: 0.0385\n",
      "Epoch 8/600\n",
      "52/52 [==============================] - 0s 150us/step - loss: 3.2293 - categorical_accuracy: 0.0385\n",
      "Epoch 9/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 3.2264 - categorical_accuracy: 0.0385\n",
      "Epoch 10/600\n",
      "52/52 [==============================] - 0s 143us/step - loss: 3.2236 - categorical_accuracy: 0.0385\n",
      "Epoch 11/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 3.2201 - categorical_accuracy: 0.0385\n",
      "Epoch 12/600\n",
      "52/52 [==============================] - 0s 140us/step - loss: 3.2160 - categorical_accuracy: 0.0385\n",
      "Epoch 13/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 3.2123 - categorical_accuracy: 0.0385\n",
      "Epoch 14/600\n",
      "52/52 [==============================] - 0s 148us/step - loss: 3.2090 - categorical_accuracy: 0.0385\n",
      "Epoch 15/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 3.2047 - categorical_accuracy: 0.0385\n",
      "Epoch 16/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 3.2011 - categorical_accuracy: 0.1154\n",
      "Epoch 17/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 3.1968 - categorical_accuracy: 0.0769\n",
      "Epoch 18/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 3.1920 - categorical_accuracy: 0.0769\n",
      "Epoch 19/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 3.1869 - categorical_accuracy: 0.0769\n",
      "Epoch 20/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 3.1819 - categorical_accuracy: 0.0769\n",
      "Epoch 21/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 3.1759 - categorical_accuracy: 0.0769\n",
      "Epoch 22/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 3.1698 - categorical_accuracy: 0.0769\n",
      "Epoch 23/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 3.1646 - categorical_accuracy: 0.0769\n",
      "Epoch 24/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 3.1574 - categorical_accuracy: 0.0769\n",
      "Epoch 25/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 3.1519 - categorical_accuracy: 0.0769\n",
      "Epoch 26/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 3.1426 - categorical_accuracy: 0.0769\n",
      "Epoch 27/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 3.1341 - categorical_accuracy: 0.0769\n",
      "Epoch 28/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 3.1240 - categorical_accuracy: 0.0769\n",
      "Epoch 29/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 3.1140 - categorical_accuracy: 0.0769\n",
      "Epoch 30/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 3.1038 - categorical_accuracy: 0.0769\n",
      "Epoch 31/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 3.0916 - categorical_accuracy: 0.0769\n",
      "Epoch 32/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 3.0777 - categorical_accuracy: 0.0769\n",
      "Epoch 33/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 3.0643 - categorical_accuracy: 0.1154\n",
      "Epoch 34/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 3.0491 - categorical_accuracy: 0.1154\n",
      "Epoch 35/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 3.0335 - categorical_accuracy: 0.1154\n",
      "Epoch 36/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 3.0144 - categorical_accuracy: 0.1154\n",
      "Epoch 37/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 2.9970 - categorical_accuracy: 0.1154\n",
      "Epoch 38/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 2.9752 - categorical_accuracy: 0.1154\n",
      "Epoch 39/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 2.9555 - categorical_accuracy: 0.1154\n",
      "Epoch 40/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 2.9337 - categorical_accuracy: 0.1154\n",
      "Epoch 41/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 2.9102 - categorical_accuracy: 0.1154\n",
      "Epoch 42/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 2.8858 - categorical_accuracy: 0.1154\n",
      "Epoch 43/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 2.8555 - categorical_accuracy: 0.1154\n",
      "Epoch 44/600\n",
      "52/52 [==============================] - 0s 153us/step - loss: 2.8267 - categorical_accuracy: 0.1923\n",
      "Epoch 45/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 2.7964 - categorical_accuracy: 0.1923\n",
      "Epoch 46/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 2.7656 - categorical_accuracy: 0.1923\n",
      "Epoch 47/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 2.7328 - categorical_accuracy: 0.2115\n",
      "Epoch 48/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 2.7018 - categorical_accuracy: 0.2308\n",
      "Epoch 49/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 2.6713 - categorical_accuracy: 0.1923\n",
      "Epoch 50/600\n",
      "52/52 [==============================] - 0s 150us/step - loss: 2.6411 - categorical_accuracy: 0.1731\n",
      "Epoch 51/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 2.6095 - categorical_accuracy: 0.1923\n",
      "Epoch 52/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 2.5798 - categorical_accuracy: 0.2308\n",
      "Epoch 53/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 2.5546 - categorical_accuracy: 0.2308\n",
      "Epoch 54/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 2.5183 - categorical_accuracy: 0.2115\n",
      "Epoch 55/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 2.4914 - categorical_accuracy: 0.2692\n",
      "Epoch 56/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 2.4597 - categorical_accuracy: 0.2885\n",
      "Epoch 57/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 2.4305 - categorical_accuracy: 0.2308\n",
      "Epoch 58/600\n",
      "52/52 [==============================] - 0s 150us/step - loss: 2.4046 - categorical_accuracy: 0.1923\n",
      "Epoch 59/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 2.3790 - categorical_accuracy: 0.1923\n",
      "Epoch 60/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 2.3512 - categorical_accuracy: 0.2308\n",
      "Epoch 61/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 2.3248 - categorical_accuracy: 0.2885\n",
      "Epoch 62/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 2.3039 - categorical_accuracy: 0.3077\n",
      "Epoch 63/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 2.2745 - categorical_accuracy: 0.3269\n",
      "Epoch 64/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 2.2539 - categorical_accuracy: 0.4231\n",
      "Epoch 65/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 2.2265 - categorical_accuracy: 0.3846\n",
      "Epoch 66/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 2.2029 - categorical_accuracy: 0.4231\n",
      "Epoch 67/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 2.1810 - categorical_accuracy: 0.4615\n",
      "Epoch 68/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 2.1579 - categorical_accuracy: 0.4231\n",
      "Epoch 69/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 2.1342 - categorical_accuracy: 0.4423\n",
      "Epoch 70/600\n",
      "52/52 [==============================] - 0s 146us/step - loss: 2.1077 - categorical_accuracy: 0.4423\n",
      "Epoch 71/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.0845 - categorical_accuracy: 0.5000\n",
      "Epoch 72/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 158us/step - loss: 2.0606 - categorical_accuracy: 0.4615\n",
      "Epoch 73/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 2.0394 - categorical_accuracy: 0.4615\n",
      "Epoch 74/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 2.0182 - categorical_accuracy: 0.4615\n",
      "Epoch 75/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 1.9976 - categorical_accuracy: 0.4231\n",
      "Epoch 76/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 1.9736 - categorical_accuracy: 0.4615\n",
      "Epoch 77/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 1.9524 - categorical_accuracy: 0.5000\n",
      "Epoch 78/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 1.9348 - categorical_accuracy: 0.4423\n",
      "Epoch 79/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 1.9161 - categorical_accuracy: 0.5385\n",
      "Epoch 80/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 1.8923 - categorical_accuracy: 0.5000\n",
      "Epoch 81/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 1.8852 - categorical_accuracy: 0.4038\n",
      "Epoch 82/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 1.8606 - categorical_accuracy: 0.5385\n",
      "Epoch 83/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.8363 - categorical_accuracy: 0.4808\n",
      "Epoch 84/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 1.8206 - categorical_accuracy: 0.4615\n",
      "Epoch 85/600\n",
      "52/52 [==============================] - 0s 153us/step - loss: 1.8038 - categorical_accuracy: 0.4615\n",
      "Epoch 86/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 1.7886 - categorical_accuracy: 0.4615\n",
      "Epoch 87/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 1.7687 - categorical_accuracy: 0.4231\n",
      "Epoch 88/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 1.7547 - categorical_accuracy: 0.4231\n",
      "Epoch 89/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 1.7328 - categorical_accuracy: 0.5000\n",
      "Epoch 90/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 1.7237 - categorical_accuracy: 0.4615\n",
      "Epoch 91/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 1.7089 - categorical_accuracy: 0.6154\n",
      "Epoch 92/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 1.7024 - categorical_accuracy: 0.4808\n",
      "Epoch 93/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 1.6868 - categorical_accuracy: 0.5192\n",
      "Epoch 94/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 1.6681 - categorical_accuracy: 0.5962\n",
      "Epoch 95/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 1.6567 - categorical_accuracy: 0.6538\n",
      "Epoch 96/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 1.6339 - categorical_accuracy: 0.5385\n",
      "Epoch 97/600\n",
      "52/52 [==============================] - 0s 149us/step - loss: 1.6188 - categorical_accuracy: 0.5577\n",
      "Epoch 98/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 1.6063 - categorical_accuracy: 0.5385\n",
      "Epoch 99/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 1.5927 - categorical_accuracy: 0.5385\n",
      "Epoch 100/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 1.5801 - categorical_accuracy: 0.5385\n",
      "Epoch 101/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 1.5707 - categorical_accuracy: 0.5577\n",
      "Epoch 102/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 1.5562 - categorical_accuracy: 0.6154\n",
      "Epoch 103/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 1.5411 - categorical_accuracy: 0.6154\n",
      "Epoch 104/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 1.5294 - categorical_accuracy: 0.6154\n",
      "Epoch 105/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.5197 - categorical_accuracy: 0.6923\n",
      "Epoch 106/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 1.5087 - categorical_accuracy: 0.6154\n",
      "Epoch 107/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.4987 - categorical_accuracy: 0.6923\n",
      "Epoch 108/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 1.4925 - categorical_accuracy: 0.7115\n",
      "Epoch 109/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 1.4866 - categorical_accuracy: 0.6731\n",
      "Epoch 110/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 1.4850 - categorical_accuracy: 0.5962\n",
      "Epoch 111/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 1.4755 - categorical_accuracy: 0.5962\n",
      "Epoch 112/600\n",
      "52/52 [==============================] - 0s 153us/step - loss: 1.4530 - categorical_accuracy: 0.6154\n",
      "Epoch 113/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.4555 - categorical_accuracy: 0.6154\n",
      "Epoch 114/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 1.4347 - categorical_accuracy: 0.6923\n",
      "Epoch 115/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 1.4316 - categorical_accuracy: 0.6346\n",
      "Epoch 116/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 1.4382 - categorical_accuracy: 0.6346\n",
      "Epoch 117/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 1.4204 - categorical_accuracy: 0.6346\n",
      "Epoch 118/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 1.3901 - categorical_accuracy: 0.6538\n",
      "Epoch 119/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 1.4154 - categorical_accuracy: 0.5962\n",
      "Epoch 120/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 1.3955 - categorical_accuracy: 0.5577\n",
      "Epoch 121/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 1.3671 - categorical_accuracy: 0.6346\n",
      "Epoch 122/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 1.3566 - categorical_accuracy: 0.6154\n",
      "Epoch 123/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 1.3603 - categorical_accuracy: 0.7115\n",
      "Epoch 124/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 1.3487 - categorical_accuracy: 0.5962\n",
      "Epoch 125/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 1.3285 - categorical_accuracy: 0.7308\n",
      "Epoch 126/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 1.3252 - categorical_accuracy: 0.7115\n",
      "Epoch 127/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 1.3220 - categorical_accuracy: 0.7308\n",
      "Epoch 128/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.3121 - categorical_accuracy: 0.7308\n",
      "Epoch 129/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 1.2994 - categorical_accuracy: 0.7115\n",
      "Epoch 130/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 1.2917 - categorical_accuracy: 0.7115\n",
      "Epoch 131/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 1.2895 - categorical_accuracy: 0.7500\n",
      "Epoch 132/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 1.2817 - categorical_accuracy: 0.7692\n",
      "Epoch 133/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 1.2666 - categorical_accuracy: 0.7692\n",
      "Epoch 134/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 1.2625 - categorical_accuracy: 0.7308\n",
      "Epoch 135/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 1.2531 - categorical_accuracy: 0.7308\n",
      "Epoch 136/600\n",
      "52/52 [==============================] - 0s 149us/step - loss: 1.2458 - categorical_accuracy: 0.7115\n",
      "Epoch 137/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 1.2395 - categorical_accuracy: 0.6923\n",
      "Epoch 138/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 1.2318 - categorical_accuracy: 0.6538\n",
      "Epoch 139/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 1.2253 - categorical_accuracy: 0.6923\n",
      "Epoch 140/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 1.2243 - categorical_accuracy: 0.6538\n",
      "Epoch 141/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 1.2365 - categorical_accuracy: 0.7115\n",
      "Epoch 142/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 1.2072 - categorical_accuracy: 0.6923\n",
      "Epoch 143/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 155us/step - loss: 1.1978 - categorical_accuracy: 0.7692\n",
      "Epoch 144/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 1.1924 - categorical_accuracy: 0.7308\n",
      "Epoch 145/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 1.1848 - categorical_accuracy: 0.8077\n",
      "Epoch 146/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 1.1785 - categorical_accuracy: 0.7308\n",
      "Epoch 147/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 1.1725 - categorical_accuracy: 0.7115\n",
      "Epoch 148/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 1.1711 - categorical_accuracy: 0.7692\n",
      "Epoch 149/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 1.1643 - categorical_accuracy: 0.8077\n",
      "Epoch 150/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 1.1564 - categorical_accuracy: 0.7308\n",
      "Epoch 151/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 1.1519 - categorical_accuracy: 0.8462\n",
      "Epoch 152/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 1.1411 - categorical_accuracy: 0.8269\n",
      "Epoch 153/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 1.1337 - categorical_accuracy: 0.8462\n",
      "Epoch 154/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 1.1320 - categorical_accuracy: 0.8462\n",
      "Epoch 155/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 1.1271 - categorical_accuracy: 0.8269\n",
      "Epoch 156/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 1.1189 - categorical_accuracy: 0.8462\n",
      "Epoch 157/600\n",
      "52/52 [==============================] - ETA: 0s - loss: 1.0809 - categorical_accuracy: 0.81 - 0s 162us/step - loss: 1.1139 - categorical_accuracy: 0.8269\n",
      "Epoch 158/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 1.1168 - categorical_accuracy: 0.8077\n",
      "Epoch 159/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.1163 - categorical_accuracy: 0.7500\n",
      "Epoch 160/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 1.1106 - categorical_accuracy: 0.7115\n",
      "Epoch 161/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 1.1086 - categorical_accuracy: 0.7885\n",
      "Epoch 162/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 1.1147 - categorical_accuracy: 0.7308\n",
      "Epoch 163/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 1.1179 - categorical_accuracy: 0.5962\n",
      "Epoch 164/600\n",
      "52/52 [==============================] - 0s 185us/step - loss: 1.1086 - categorical_accuracy: 0.6923\n",
      "Epoch 165/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 1.0988 - categorical_accuracy: 0.7308\n",
      "Epoch 166/600\n",
      "52/52 [==============================] - 0s 182us/step - loss: 1.0880 - categorical_accuracy: 0.7308\n",
      "Epoch 167/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 1.0848 - categorical_accuracy: 0.7692\n",
      "Epoch 168/600\n",
      "52/52 [==============================] - 0s 187us/step - loss: 1.0780 - categorical_accuracy: 0.7308\n",
      "Epoch 169/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 1.0954 - categorical_accuracy: 0.6538\n",
      "Epoch 170/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 1.1090 - categorical_accuracy: 0.5769\n",
      "Epoch 171/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 1.0974 - categorical_accuracy: 0.5577\n",
      "Epoch 172/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 1.0562 - categorical_accuracy: 0.7692\n",
      "Epoch 173/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.0482 - categorical_accuracy: 0.8654\n",
      "Epoch 174/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 1.0456 - categorical_accuracy: 0.7885\n",
      "Epoch 175/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 1.0495 - categorical_accuracy: 0.7692\n",
      "Epoch 176/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 1.0396 - categorical_accuracy: 0.7885\n",
      "Epoch 177/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.0291 - categorical_accuracy: 0.7308\n",
      "Epoch 178/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.0216 - categorical_accuracy: 0.8269\n",
      "Epoch 179/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 1.0140 - categorical_accuracy: 0.8077\n",
      "Epoch 180/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 1.0134 - categorical_accuracy: 0.7885\n",
      "Epoch 181/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 1.0146 - categorical_accuracy: 0.7692\n",
      "Epoch 182/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 1.0041 - categorical_accuracy: 0.7500\n",
      "Epoch 183/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 1.0018 - categorical_accuracy: 0.8462\n",
      "Epoch 184/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 0.9938 - categorical_accuracy: 0.7308\n",
      "Epoch 185/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.9837 - categorical_accuracy: 0.8269\n",
      "Epoch 186/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.9826 - categorical_accuracy: 0.8269\n",
      "Epoch 187/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.9749 - categorical_accuracy: 0.7692\n",
      "Epoch 188/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 0.9679 - categorical_accuracy: 0.7885\n",
      "Epoch 189/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.9654 - categorical_accuracy: 0.7885\n",
      "Epoch 190/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.9662 - categorical_accuracy: 0.7500\n",
      "Epoch 191/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.9681 - categorical_accuracy: 0.7308\n",
      "Epoch 192/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.9537 - categorical_accuracy: 0.8077\n",
      "Epoch 193/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.9470 - categorical_accuracy: 0.8269\n",
      "Epoch 194/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.9529 - categorical_accuracy: 0.8269\n",
      "Epoch 195/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.9373 - categorical_accuracy: 0.8077\n",
      "Epoch 196/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.9351 - categorical_accuracy: 0.8462\n",
      "Epoch 197/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.9292 - categorical_accuracy: 0.8077\n",
      "Epoch 198/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.9243 - categorical_accuracy: 0.8269\n",
      "Epoch 199/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.9209 - categorical_accuracy: 0.8077\n",
      "Epoch 200/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.9147 - categorical_accuracy: 0.8462\n",
      "Epoch 201/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.9175 - categorical_accuracy: 0.8269\n",
      "Epoch 202/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.9099 - categorical_accuracy: 0.8654\n",
      "Epoch 203/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.9214 - categorical_accuracy: 0.7500\n",
      "Epoch 204/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.9219 - categorical_accuracy: 0.8077\n",
      "Epoch 205/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.9017 - categorical_accuracy: 0.7308\n",
      "Epoch 206/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.9076 - categorical_accuracy: 0.7692\n",
      "Epoch 207/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.9039 - categorical_accuracy: 0.8269\n",
      "Epoch 208/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.9012 - categorical_accuracy: 0.8462\n",
      "Epoch 209/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.8896 - categorical_accuracy: 0.8462\n",
      "Epoch 210/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.8817 - categorical_accuracy: 0.9038\n",
      "Epoch 211/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.8782 - categorical_accuracy: 0.9231\n",
      "Epoch 212/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.8785 - categorical_accuracy: 0.8654\n",
      "Epoch 213/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 163us/step - loss: 0.8732 - categorical_accuracy: 0.8654\n",
      "Epoch 214/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.8838 - categorical_accuracy: 0.8654\n",
      "Epoch 215/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.8784 - categorical_accuracy: 0.8077\n",
      "Epoch 216/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.8648 - categorical_accuracy: 0.8462\n",
      "Epoch 217/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.8566 - categorical_accuracy: 0.8846\n",
      "Epoch 218/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.8493 - categorical_accuracy: 0.8846\n",
      "Epoch 219/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.8508 - categorical_accuracy: 0.8654\n",
      "Epoch 220/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 0.8439 - categorical_accuracy: 0.9038\n",
      "Epoch 221/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.8430 - categorical_accuracy: 0.8846\n",
      "Epoch 222/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.8438 - categorical_accuracy: 0.8077\n",
      "Epoch 223/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.8390 - categorical_accuracy: 0.8846\n",
      "Epoch 224/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.8327 - categorical_accuracy: 0.8462\n",
      "Epoch 225/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.8387 - categorical_accuracy: 0.9038\n",
      "Epoch 226/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.8257 - categorical_accuracy: 0.8846\n",
      "Epoch 227/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.8253 - categorical_accuracy: 0.8846\n",
      "Epoch 228/600\n",
      "52/52 [==============================] - 0s 187us/step - loss: 0.8261 - categorical_accuracy: 0.9038\n",
      "Epoch 229/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.8215 - categorical_accuracy: 0.8846\n",
      "Epoch 230/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.8120 - categorical_accuracy: 0.9231\n",
      "Epoch 231/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.8119 - categorical_accuracy: 0.8846\n",
      "Epoch 232/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.8120 - categorical_accuracy: 0.8654\n",
      "Epoch 233/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.8088 - categorical_accuracy: 0.9038\n",
      "Epoch 234/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.7959 - categorical_accuracy: 0.9423\n",
      "Epoch 235/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.7992 - categorical_accuracy: 0.8846\n",
      "Epoch 236/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.7927 - categorical_accuracy: 0.9615\n",
      "Epoch 237/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.7965 - categorical_accuracy: 0.8462\n",
      "Epoch 238/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.7983 - categorical_accuracy: 0.9038\n",
      "Epoch 239/600\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7916 - categorical_accuracy: 0.8846\n",
      "Epoch 240/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 0.7968 - categorical_accuracy: 0.8462\n",
      "Epoch 241/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.7974 - categorical_accuracy: 0.8077\n",
      "Epoch 242/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.7973 - categorical_accuracy: 0.8462\n",
      "Epoch 243/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.8060 - categorical_accuracy: 0.7692\n",
      "Epoch 244/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.7885 - categorical_accuracy: 0.8846\n",
      "Epoch 245/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.7655 - categorical_accuracy: 0.8846\n",
      "Epoch 246/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.7693 - categorical_accuracy: 0.8846\n",
      "Epoch 247/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.7656 - categorical_accuracy: 0.9615\n",
      "Epoch 248/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.7624 - categorical_accuracy: 0.9038\n",
      "Epoch 249/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.7620 - categorical_accuracy: 0.9231\n",
      "Epoch 250/600\n",
      "52/52 [==============================] - 0s 185us/step - loss: 0.7655 - categorical_accuracy: 0.8462\n",
      "Epoch 251/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.7616 - categorical_accuracy: 0.8846\n",
      "Epoch 252/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.7548 - categorical_accuracy: 0.9231\n",
      "Epoch 253/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.7557 - categorical_accuracy: 0.8462\n",
      "Epoch 254/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.7613 - categorical_accuracy: 0.9038\n",
      "Epoch 255/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.7550 - categorical_accuracy: 0.8077\n",
      "Epoch 256/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.7463 - categorical_accuracy: 0.9231\n",
      "Epoch 257/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.7325 - categorical_accuracy: 0.8846\n",
      "Epoch 258/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.7322 - categorical_accuracy: 0.9615\n",
      "Epoch 259/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.7349 - categorical_accuracy: 0.9038\n",
      "Epoch 260/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.7308 - categorical_accuracy: 0.8846\n",
      "Epoch 261/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.7291 - categorical_accuracy: 0.9038\n",
      "Epoch 262/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.7258 - categorical_accuracy: 0.8654\n",
      "Epoch 263/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.7218 - categorical_accuracy: 0.9231\n",
      "Epoch 264/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.7239 - categorical_accuracy: 0.9423\n",
      "Epoch 265/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.7154 - categorical_accuracy: 0.9038\n",
      "Epoch 266/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.7180 - categorical_accuracy: 0.8846\n",
      "Epoch 267/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.7174 - categorical_accuracy: 0.8269\n",
      "Epoch 268/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.7101 - categorical_accuracy: 0.8846\n",
      "Epoch 269/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.7047 - categorical_accuracy: 0.9038\n",
      "Epoch 270/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.7004 - categorical_accuracy: 0.9615\n",
      "Epoch 271/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.7062 - categorical_accuracy: 0.9038\n",
      "Epoch 272/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.7132 - categorical_accuracy: 0.8269\n",
      "Epoch 273/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.7134 - categorical_accuracy: 0.8846\n",
      "Epoch 274/600\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.7061 - categorical_accuracy: 0.8462\n",
      "Epoch 275/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.6977 - categorical_accuracy: 0.8846\n",
      "Epoch 276/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.6986 - categorical_accuracy: 0.8846\n",
      "Epoch 277/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.6977 - categorical_accuracy: 0.8462\n",
      "Epoch 278/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 0.6920 - categorical_accuracy: 0.8462\n",
      "Epoch 279/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.6919 - categorical_accuracy: 0.8846\n",
      "Epoch 280/600\n",
      "52/52 [==============================] - 0s 181us/step - loss: 0.6961 - categorical_accuracy: 0.9231\n",
      "Epoch 281/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 0.6913 - categorical_accuracy: 0.8846\n",
      "Epoch 282/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.7028 - categorical_accuracy: 0.8654\n",
      "Epoch 283/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.6986 - categorical_accuracy: 0.8462\n",
      "Epoch 284/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 160us/step - loss: 0.7099 - categorical_accuracy: 0.8462\n",
      "Epoch 285/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.7019 - categorical_accuracy: 0.8654\n",
      "Epoch 286/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.6974 - categorical_accuracy: 0.8077\n",
      "Epoch 287/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.6889 - categorical_accuracy: 0.8654\n",
      "Epoch 288/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.6622 - categorical_accuracy: 0.8654\n",
      "Epoch 289/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.6711 - categorical_accuracy: 0.9231\n",
      "Epoch 290/600\n",
      "52/52 [==============================] - 0s 200us/step - loss: 0.6878 - categorical_accuracy: 0.8462\n",
      "Epoch 291/600\n",
      "52/52 [==============================] - 0s 180us/step - loss: 0.6680 - categorical_accuracy: 0.8846\n",
      "Epoch 292/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.6941 - categorical_accuracy: 0.8077\n",
      "Epoch 293/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.7000 - categorical_accuracy: 0.8077\n",
      "Epoch 294/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.7036 - categorical_accuracy: 0.7692\n",
      "Epoch 295/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.7026 - categorical_accuracy: 0.8462\n",
      "Epoch 296/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.7343 - categorical_accuracy: 0.6346\n",
      "Epoch 297/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.6695 - categorical_accuracy: 0.8846\n",
      "Epoch 298/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.7040 - categorical_accuracy: 0.8462\n",
      "Epoch 299/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.6682 - categorical_accuracy: 0.8269\n",
      "Epoch 300/600\n",
      "52/52 [==============================] - 0s 180us/step - loss: 0.6584 - categorical_accuracy: 0.9231\n",
      "Epoch 301/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.6486 - categorical_accuracy: 0.8846\n",
      "Epoch 302/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.6629 - categorical_accuracy: 0.9038\n",
      "Epoch 303/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.6562 - categorical_accuracy: 0.8269\n",
      "Epoch 304/600\n",
      "52/52 [==============================] - 0s 155us/step - loss: 0.6755 - categorical_accuracy: 0.9038\n",
      "Epoch 305/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.6690 - categorical_accuracy: 0.8269\n",
      "Epoch 306/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.6682 - categorical_accuracy: 0.8462\n",
      "Epoch 307/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.6838 - categorical_accuracy: 0.7500\n",
      "Epoch 308/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.6777 - categorical_accuracy: 0.8077\n",
      "Epoch 309/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.6405 - categorical_accuracy: 0.8846\n",
      "Epoch 310/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.6352 - categorical_accuracy: 0.8654\n",
      "Epoch 311/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.6320 - categorical_accuracy: 0.9615\n",
      "Epoch 312/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.6228 - categorical_accuracy: 0.9423\n",
      "Epoch 313/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.6602 - categorical_accuracy: 0.9231\n",
      "Epoch 314/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.6313 - categorical_accuracy: 0.9423\n",
      "Epoch 315/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.6415 - categorical_accuracy: 0.9038\n",
      "Epoch 316/600\n",
      "52/52 [==============================] - 0s 183us/step - loss: 0.6278 - categorical_accuracy: 0.9038\n",
      "Epoch 317/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.6291 - categorical_accuracy: 0.9038\n",
      "Epoch 318/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.6134 - categorical_accuracy: 0.9231\n",
      "Epoch 319/600\n",
      "52/52 [==============================] - 0s 184us/step - loss: 0.6121 - categorical_accuracy: 0.8846\n",
      "Epoch 320/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.6172 - categorical_accuracy: 0.8462\n",
      "Epoch 321/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.6172 - categorical_accuracy: 0.8846\n",
      "Epoch 322/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.6077 - categorical_accuracy: 0.8654\n",
      "Epoch 323/600\n",
      "52/52 [==============================] - 0s 207us/step - loss: 0.6001 - categorical_accuracy: 0.9615\n",
      "Epoch 324/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.6009 - categorical_accuracy: 0.9231\n",
      "Epoch 325/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.5949 - categorical_accuracy: 0.9808\n",
      "Epoch 326/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.6036 - categorical_accuracy: 0.9038\n",
      "Epoch 327/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.5982 - categorical_accuracy: 0.9231\n",
      "Epoch 328/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.5919 - categorical_accuracy: 0.9038\n",
      "Epoch 329/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.5834 - categorical_accuracy: 0.9231\n",
      "Epoch 330/600\n",
      "52/52 [==============================] - 0s 184us/step - loss: 0.5765 - categorical_accuracy: 0.9615\n",
      "Epoch 331/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.5846 - categorical_accuracy: 0.9423\n",
      "Epoch 332/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.5767 - categorical_accuracy: 1.0000\n",
      "Epoch 333/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.5777 - categorical_accuracy: 0.9231\n",
      "Epoch 334/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.5851 - categorical_accuracy: 0.9808\n",
      "Epoch 335/600\n",
      "52/52 [==============================] - 0s 196us/step - loss: 0.5694 - categorical_accuracy: 0.9615\n",
      "Epoch 336/600\n",
      "52/52 [==============================] - 0s 181us/step - loss: 0.5692 - categorical_accuracy: 1.0000\n",
      "Epoch 337/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.5690 - categorical_accuracy: 0.9808\n",
      "Epoch 338/600\n",
      "52/52 [==============================] - 0s 184us/step - loss: 0.5689 - categorical_accuracy: 0.9423\n",
      "Epoch 339/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.5638 - categorical_accuracy: 0.9615\n",
      "Epoch 340/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 0.5790 - categorical_accuracy: 0.9231\n",
      "Epoch 341/600\n",
      "52/52 [==============================] - 0s 178us/step - loss: 0.5817 - categorical_accuracy: 0.9423\n",
      "Epoch 342/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.5648 - categorical_accuracy: 0.9615\n",
      "Epoch 343/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.5699 - categorical_accuracy: 0.9615\n",
      "Epoch 344/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.5737 - categorical_accuracy: 0.9423\n",
      "Epoch 345/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.5675 - categorical_accuracy: 0.9615\n",
      "Epoch 346/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.5533 - categorical_accuracy: 0.9615\n",
      "Epoch 347/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.5605 - categorical_accuracy: 0.9615\n",
      "Epoch 348/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.5593 - categorical_accuracy: 1.0000\n",
      "Epoch 349/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.5535 - categorical_accuracy: 1.0000\n",
      "Epoch 350/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.5442 - categorical_accuracy: 1.0000\n",
      "Epoch 351/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.5411 - categorical_accuracy: 1.0000\n",
      "Epoch 352/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.5429 - categorical_accuracy: 1.0000\n",
      "Epoch 353/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.5371 - categorical_accuracy: 1.0000\n",
      "Epoch 354/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.5410 - categorical_accuracy: 1.0000\n",
      "Epoch 355/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 208us/step - loss: 0.5339 - categorical_accuracy: 1.0000\n",
      "Epoch 356/600\n",
      "52/52 [==============================] - 0s 280us/step - loss: 0.5357 - categorical_accuracy: 1.0000\n",
      "Epoch 357/600\n",
      "52/52 [==============================] - 0s 198us/step - loss: 0.5349 - categorical_accuracy: 0.9615\n",
      "Epoch 358/600\n",
      "52/52 [==============================] - 0s 182us/step - loss: 0.5315 - categorical_accuracy: 1.0000\n",
      "Epoch 359/600\n",
      "52/52 [==============================] - 0s 190us/step - loss: 0.5306 - categorical_accuracy: 1.0000\n",
      "Epoch 360/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.5247 - categorical_accuracy: 1.0000\n",
      "Epoch 361/600\n",
      "52/52 [==============================] - 0s 184us/step - loss: 0.5260 - categorical_accuracy: 1.0000\n",
      "Epoch 362/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.5285 - categorical_accuracy: 0.9808\n",
      "Epoch 363/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.5236 - categorical_accuracy: 1.0000\n",
      "Epoch 364/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.5251 - categorical_accuracy: 0.9423\n",
      "Epoch 365/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.5196 - categorical_accuracy: 0.9231\n",
      "Epoch 366/600\n",
      "52/52 [==============================] - 0s 178us/step - loss: 0.5233 - categorical_accuracy: 0.9808\n",
      "Epoch 367/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.5178 - categorical_accuracy: 1.0000\n",
      "Epoch 368/600\n",
      "52/52 [==============================] - 0s 183us/step - loss: 0.5196 - categorical_accuracy: 1.0000\n",
      "Epoch 369/600\n",
      "52/52 [==============================] - 0s 178us/step - loss: 0.5120 - categorical_accuracy: 1.0000\n",
      "Epoch 370/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.5145 - categorical_accuracy: 1.0000\n",
      "Epoch 371/600\n",
      "52/52 [==============================] - 0s 187us/step - loss: 0.5174 - categorical_accuracy: 1.0000\n",
      "Epoch 372/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.5186 - categorical_accuracy: 0.9808\n",
      "Epoch 373/600\n",
      "52/52 [==============================] - 0s 189us/step - loss: 0.5195 - categorical_accuracy: 1.0000\n",
      "Epoch 374/600\n",
      "52/52 [==============================] - 0s 196us/step - loss: 0.5418 - categorical_accuracy: 0.9231\n",
      "Epoch 375/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.5230 - categorical_accuracy: 0.9615\n",
      "Epoch 376/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.5155 - categorical_accuracy: 0.9615\n",
      "Epoch 377/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.5217 - categorical_accuracy: 0.9423\n",
      "Epoch 378/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.5077 - categorical_accuracy: 0.9615\n",
      "Epoch 379/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.5101 - categorical_accuracy: 0.9423\n",
      "Epoch 380/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.5189 - categorical_accuracy: 0.8654\n",
      "Epoch 381/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.5279 - categorical_accuracy: 0.9038\n",
      "Epoch 382/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.5451 - categorical_accuracy: 0.8269\n",
      "Epoch 383/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.5234 - categorical_accuracy: 0.8462\n",
      "Epoch 384/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.5087 - categorical_accuracy: 0.9423\n",
      "Epoch 385/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.5056 - categorical_accuracy: 0.9423\n",
      "Epoch 386/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.5100 - categorical_accuracy: 0.9615\n",
      "Epoch 387/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.5058 - categorical_accuracy: 0.9231\n",
      "Epoch 388/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.5068 - categorical_accuracy: 0.9615\n",
      "Epoch 389/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.4999 - categorical_accuracy: 0.9423\n",
      "Epoch 390/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.5072 - categorical_accuracy: 1.0000\n",
      "Epoch 391/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.4995 - categorical_accuracy: 1.0000\n",
      "Epoch 392/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.5031 - categorical_accuracy: 0.9615\n",
      "Epoch 393/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.4910 - categorical_accuracy: 0.9808\n",
      "Epoch 394/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.4864 - categorical_accuracy: 0.9231\n",
      "Epoch 395/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.4905 - categorical_accuracy: 0.9615\n",
      "Epoch 396/600\n",
      "52/52 [==============================] - 0s 185us/step - loss: 0.4877 - categorical_accuracy: 0.9615\n",
      "Epoch 397/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 0.4933 - categorical_accuracy: 0.9231\n",
      "Epoch 398/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.4866 - categorical_accuracy: 0.9615\n",
      "Epoch 399/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.4918 - categorical_accuracy: 0.9808\n",
      "Epoch 400/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.4809 - categorical_accuracy: 0.9808\n",
      "Epoch 401/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.4764 - categorical_accuracy: 0.9615\n",
      "Epoch 402/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.4743 - categorical_accuracy: 1.0000\n",
      "Epoch 403/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.4711 - categorical_accuracy: 1.0000\n",
      "Epoch 404/600\n",
      "52/52 [==============================] - 0s 180us/step - loss: 0.4870 - categorical_accuracy: 0.9423\n",
      "Epoch 405/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.4855 - categorical_accuracy: 0.8846\n",
      "Epoch 406/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.4670 - categorical_accuracy: 0.9615\n",
      "Epoch 407/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.4757 - categorical_accuracy: 0.9423\n",
      "Epoch 408/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.4676 - categorical_accuracy: 0.9808\n",
      "Epoch 409/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.4715 - categorical_accuracy: 0.9615\n",
      "Epoch 410/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.4612 - categorical_accuracy: 0.9423\n",
      "Epoch 411/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.4617 - categorical_accuracy: 0.9615\n",
      "Epoch 412/600\n",
      "52/52 [==============================] - 0s 153us/step - loss: 0.4634 - categorical_accuracy: 0.9423\n",
      "Epoch 413/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.4688 - categorical_accuracy: 1.0000\n",
      "Epoch 414/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.4479 - categorical_accuracy: 1.0000\n",
      "Epoch 415/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.4461 - categorical_accuracy: 1.0000\n",
      "Epoch 416/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.4497 - categorical_accuracy: 1.0000\n",
      "Epoch 417/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.4537 - categorical_accuracy: 0.9423\n",
      "Epoch 418/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.4570 - categorical_accuracy: 0.9808\n",
      "Epoch 419/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.4542 - categorical_accuracy: 0.9615\n",
      "Epoch 420/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.4434 - categorical_accuracy: 0.9423\n",
      "Epoch 421/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.4416 - categorical_accuracy: 1.0000\n",
      "Epoch 422/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.4452 - categorical_accuracy: 1.0000\n",
      "Epoch 423/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.4449 - categorical_accuracy: 1.0000\n",
      "Epoch 424/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.4400 - categorical_accuracy: 0.9615\n",
      "Epoch 425/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.4377 - categorical_accuracy: 0.9615\n",
      "Epoch 426/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 156us/step - loss: 0.4430 - categorical_accuracy: 0.9231\n",
      "Epoch 427/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.4512 - categorical_accuracy: 0.9423\n",
      "Epoch 428/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.4412 - categorical_accuracy: 0.9615\n",
      "Epoch 429/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.4361 - categorical_accuracy: 0.9808\n",
      "Epoch 430/600\n",
      "52/52 [==============================] - 0s 151us/step - loss: 0.4407 - categorical_accuracy: 1.0000\n",
      "Epoch 431/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.4454 - categorical_accuracy: 0.9423\n",
      "Epoch 432/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.4501 - categorical_accuracy: 0.9615\n",
      "Epoch 433/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.4442 - categorical_accuracy: 0.9615\n",
      "Epoch 434/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.4457 - categorical_accuracy: 0.9615\n",
      "Epoch 435/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.4371 - categorical_accuracy: 1.0000\n",
      "Epoch 436/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.4361 - categorical_accuracy: 0.9808\n",
      "Epoch 437/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.4326 - categorical_accuracy: 1.0000\n",
      "Epoch 438/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 0.4487 - categorical_accuracy: 0.9038\n",
      "Epoch 439/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.4401 - categorical_accuracy: 0.9615\n",
      "Epoch 440/600\n",
      "52/52 [==============================] - 0s 186us/step - loss: 0.4307 - categorical_accuracy: 0.9615\n",
      "Epoch 441/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.4166 - categorical_accuracy: 1.0000\n",
      "Epoch 442/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.4293 - categorical_accuracy: 0.9615\n",
      "Epoch 443/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.4325 - categorical_accuracy: 0.9231\n",
      "Epoch 444/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.4582 - categorical_accuracy: 0.8846\n",
      "Epoch 445/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.4543 - categorical_accuracy: 0.9423\n",
      "Epoch 446/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.4240 - categorical_accuracy: 0.9808\n",
      "Epoch 447/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.4100 - categorical_accuracy: 1.0000\n",
      "Epoch 448/600\n",
      "52/52 [==============================] - 0s 183us/step - loss: 0.4155 - categorical_accuracy: 1.0000\n",
      "Epoch 449/600\n",
      "52/52 [==============================] - 0s 213us/step - loss: 0.4151 - categorical_accuracy: 1.0000\n",
      "Epoch 450/600\n",
      "52/52 [==============================] - 0s 287us/step - loss: 0.4215 - categorical_accuracy: 0.9615\n",
      "Epoch 451/600\n",
      "52/52 [==============================] - 0s 242us/step - loss: 0.4257 - categorical_accuracy: 0.9615\n",
      "Epoch 452/600\n",
      "52/52 [==============================] - 0s 187us/step - loss: 0.4071 - categorical_accuracy: 1.0000\n",
      "Epoch 453/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.4017 - categorical_accuracy: 1.0000\n",
      "Epoch 454/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.4108 - categorical_accuracy: 1.0000\n",
      "Epoch 455/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.4097 - categorical_accuracy: 0.9615\n",
      "Epoch 456/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.4050 - categorical_accuracy: 1.0000\n",
      "Epoch 457/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.4031 - categorical_accuracy: 1.0000\n",
      "Epoch 458/600\n",
      "52/52 [==============================] - 0s 184us/step - loss: 0.4030 - categorical_accuracy: 1.0000\n",
      "Epoch 459/600\n",
      "52/52 [==============================] - 0s 230us/step - loss: 0.4003 - categorical_accuracy: 1.0000\n",
      "Epoch 460/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.3995 - categorical_accuracy: 1.0000\n",
      "Epoch 461/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.3988 - categorical_accuracy: 1.0000\n",
      "Epoch 462/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.4175 - categorical_accuracy: 0.9231\n",
      "Epoch 463/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.3970 - categorical_accuracy: 1.0000\n",
      "Epoch 464/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.3961 - categorical_accuracy: 1.0000\n",
      "Epoch 465/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.3988 - categorical_accuracy: 0.9615\n",
      "Epoch 466/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.4184 - categorical_accuracy: 0.9808\n",
      "Epoch 467/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.4085 - categorical_accuracy: 0.9615\n",
      "Epoch 468/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.3905 - categorical_accuracy: 1.0000\n",
      "Epoch 469/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.3980 - categorical_accuracy: 1.0000\n",
      "Epoch 470/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.3934 - categorical_accuracy: 1.0000\n",
      "Epoch 471/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.4066 - categorical_accuracy: 0.9808\n",
      "Epoch 472/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.3988 - categorical_accuracy: 1.0000\n",
      "Epoch 473/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 0.4164 - categorical_accuracy: 0.9615\n",
      "Epoch 474/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.4641 - categorical_accuracy: 0.8654\n",
      "Epoch 475/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.4268 - categorical_accuracy: 0.9038\n",
      "Epoch 476/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.3861 - categorical_accuracy: 1.0000\n",
      "Epoch 477/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.3906 - categorical_accuracy: 1.0000\n",
      "Epoch 478/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.3941 - categorical_accuracy: 1.0000\n",
      "Epoch 479/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.3946 - categorical_accuracy: 1.0000\n",
      "Epoch 480/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.3904 - categorical_accuracy: 0.9808\n",
      "Epoch 481/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.3777 - categorical_accuracy: 0.9615\n",
      "Epoch 482/600\n",
      "52/52 [==============================] - 0s 158us/step - loss: 0.3749 - categorical_accuracy: 1.0000\n",
      "Epoch 483/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.3739 - categorical_accuracy: 1.0000\n",
      "Epoch 484/600\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.3785 - categorical_accuracy: 1.0000\n",
      "Epoch 485/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.3789 - categorical_accuracy: 1.0000\n",
      "Epoch 486/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.3755 - categorical_accuracy: 1.0000\n",
      "Epoch 487/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.3725 - categorical_accuracy: 1.0000\n",
      "Epoch 488/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.3861 - categorical_accuracy: 1.0000\n",
      "Epoch 489/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.3759 - categorical_accuracy: 1.0000\n",
      "Epoch 490/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.3724 - categorical_accuracy: 0.9615\n",
      "Epoch 491/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.3704 - categorical_accuracy: 1.0000\n",
      "Epoch 492/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.3691 - categorical_accuracy: 1.0000\n",
      "Epoch 493/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.3593 - categorical_accuracy: 1.0000\n",
      "Epoch 494/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.3606 - categorical_accuracy: 1.0000\n",
      "Epoch 495/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.3677 - categorical_accuracy: 1.0000\n",
      "Epoch 496/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.3665 - categorical_accuracy: 0.9808\n",
      "Epoch 497/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 159us/step - loss: 0.3635 - categorical_accuracy: 1.0000\n",
      "Epoch 498/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.3790 - categorical_accuracy: 0.9808\n",
      "Epoch 499/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.4096 - categorical_accuracy: 0.8654\n",
      "Epoch 500/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.4094 - categorical_accuracy: 0.9038\n",
      "Epoch 501/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.3893 - categorical_accuracy: 0.9231\n",
      "Epoch 502/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.3833 - categorical_accuracy: 0.9423\n",
      "Epoch 503/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.4154 - categorical_accuracy: 0.9231\n",
      "Epoch 504/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.4094 - categorical_accuracy: 0.8269\n",
      "Epoch 505/600\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.3846 - categorical_accuracy: 0.93 - 0s 169us/step - loss: 0.4566 - categorical_accuracy: 0.8269\n",
      "Epoch 506/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.3825 - categorical_accuracy: 0.9615\n",
      "Epoch 507/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.4282 - categorical_accuracy: 0.8269\n",
      "Epoch 508/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.3924 - categorical_accuracy: 0.9231\n",
      "Epoch 509/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.3866 - categorical_accuracy: 0.9423\n",
      "Epoch 510/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.3726 - categorical_accuracy: 1.0000\n",
      "Epoch 511/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.3705 - categorical_accuracy: 0.9231\n",
      "Epoch 512/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.3684 - categorical_accuracy: 1.0000\n",
      "Epoch 513/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 0.3463 - categorical_accuracy: 1.0000\n",
      "Epoch 514/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.3622 - categorical_accuracy: 1.0000\n",
      "Epoch 515/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.3464 - categorical_accuracy: 1.0000\n",
      "Epoch 516/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.3614 - categorical_accuracy: 0.9808\n",
      "Epoch 517/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.3479 - categorical_accuracy: 0.9808\n",
      "Epoch 518/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.3602 - categorical_accuracy: 0.9615\n",
      "Epoch 519/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.3500 - categorical_accuracy: 0.9808\n",
      "Epoch 520/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.3513 - categorical_accuracy: 0.9808\n",
      "Epoch 521/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.3536 - categorical_accuracy: 1.0000\n",
      "Epoch 522/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.3966 - categorical_accuracy: 0.9231\n",
      "Epoch 523/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.4963 - categorical_accuracy: 0.6923\n",
      "Epoch 524/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.4809 - categorical_accuracy: 0.7500\n",
      "Epoch 525/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.5639 - categorical_accuracy: 0.6731\n",
      "Epoch 526/600\n",
      "52/52 [==============================] - 0s 180us/step - loss: 0.6684 - categorical_accuracy: 0.5769\n",
      "Epoch 527/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.6431 - categorical_accuracy: 0.6731\n",
      "Epoch 528/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.5854 - categorical_accuracy: 0.6154\n",
      "Epoch 529/600\n",
      "52/52 [==============================] - 0s 157us/step - loss: 0.7018 - categorical_accuracy: 0.5385\n",
      "Epoch 530/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 1.2386 - categorical_accuracy: 0.4231\n",
      "Epoch 531/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.9142 - categorical_accuracy: 0.6731\n",
      "Epoch 532/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.6579 - categorical_accuracy: 0.7692\n",
      "Epoch 533/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.6381 - categorical_accuracy: 0.6154\n",
      "Epoch 534/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.7011 - categorical_accuracy: 0.6154\n",
      "Epoch 535/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.5941 - categorical_accuracy: 0.7308\n",
      "Epoch 536/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.4118 - categorical_accuracy: 0.8846\n",
      "Epoch 537/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.4318 - categorical_accuracy: 0.9038\n",
      "Epoch 538/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.4387 - categorical_accuracy: 0.8654\n",
      "Epoch 539/600\n",
      "52/52 [==============================] - 0s 174us/step - loss: 0.4204 - categorical_accuracy: 0.8654\n",
      "Epoch 540/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.3855 - categorical_accuracy: 0.9231\n",
      "Epoch 541/600\n",
      "52/52 [==============================] - 0s 161us/step - loss: 0.3847 - categorical_accuracy: 0.9615\n",
      "Epoch 542/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.3984 - categorical_accuracy: 0.8462\n",
      "Epoch 543/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.4053 - categorical_accuracy: 0.8462\n",
      "Epoch 544/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.3680 - categorical_accuracy: 0.9615\n",
      "Epoch 545/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.3572 - categorical_accuracy: 0.9808\n",
      "Epoch 546/600\n",
      "52/52 [==============================] - 0s 163us/step - loss: 0.3492 - categorical_accuracy: 0.9808\n",
      "Epoch 547/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.3506 - categorical_accuracy: 1.0000\n",
      "Epoch 548/600\n",
      "52/52 [==============================] - 0s 159us/step - loss: 0.3481 - categorical_accuracy: 1.0000\n",
      "Epoch 549/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.3478 - categorical_accuracy: 1.0000\n",
      "Epoch 550/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.3338 - categorical_accuracy: 1.0000\n",
      "Epoch 551/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.3491 - categorical_accuracy: 0.9615\n",
      "Epoch 552/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.3414 - categorical_accuracy: 1.0000\n",
      "Epoch 553/600\n",
      "52/52 [==============================] - 0s 149us/step - loss: 0.3307 - categorical_accuracy: 1.0000\n",
      "Epoch 554/600\n",
      "52/52 [==============================] - 0s 170us/step - loss: 0.3281 - categorical_accuracy: 1.0000\n",
      "Epoch 555/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.3329 - categorical_accuracy: 1.0000\n",
      "Epoch 556/600\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.3318 - categorical_accuracy: 1.0000\n",
      "Epoch 557/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.3291 - categorical_accuracy: 1.0000\n",
      "Epoch 558/600\n",
      "52/52 [==============================] - 0s 156us/step - loss: 0.3294 - categorical_accuracy: 1.0000\n",
      "Epoch 559/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.3313 - categorical_accuracy: 1.0000\n",
      "Epoch 560/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.3270 - categorical_accuracy: 1.0000\n",
      "Epoch 561/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.3241 - categorical_accuracy: 1.0000\n",
      "Epoch 562/600\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.3237 - categorical_accuracy: 1.0000\n",
      "Epoch 563/600\n",
      "52/52 [==============================] - 0s 199us/step - loss: 0.3216 - categorical_accuracy: 1.0000\n",
      "Epoch 564/600\n",
      "52/52 [==============================] - 0s 243us/step - loss: 0.3195 - categorical_accuracy: 1.0000\n",
      "Epoch 565/600\n",
      "52/52 [==============================] - 0s 213us/step - loss: 0.3235 - categorical_accuracy: 1.0000\n",
      "Epoch 566/600\n",
      "52/52 [==============================] - 0s 201us/step - loss: 0.3245 - categorical_accuracy: 1.0000\n",
      "Epoch 567/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 186us/step - loss: 0.3186 - categorical_accuracy: 1.0000\n",
      "Epoch 568/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.3177 - categorical_accuracy: 1.0000\n",
      "Epoch 569/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.3195 - categorical_accuracy: 1.0000\n",
      "Epoch 570/600\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.3235 - categorical_accuracy: 1.0000\n",
      "Epoch 571/600\n",
      "52/52 [==============================] - 0s 176us/step - loss: 0.3183 - categorical_accuracy: 1.0000\n",
      "Epoch 572/600\n",
      "52/52 [==============================] - 0s 180us/step - loss: 0.3131 - categorical_accuracy: 1.0000\n",
      "Epoch 573/600\n",
      "52/52 [==============================] - 0s 172us/step - loss: 0.3096 - categorical_accuracy: 1.0000\n",
      "Epoch 574/600\n",
      "52/52 [==============================] - 0s 178us/step - loss: 0.3126 - categorical_accuracy: 1.0000\n",
      "Epoch 575/600\n",
      "52/52 [==============================] - 0s 166us/step - loss: 0.3120 - categorical_accuracy: 1.0000\n",
      "Epoch 576/600\n",
      "52/52 [==============================] - 0s 182us/step - loss: 0.3112 - categorical_accuracy: 1.0000\n",
      "Epoch 577/600\n",
      "52/52 [==============================] - 0s 185us/step - loss: 0.3107 - categorical_accuracy: 1.0000\n",
      "Epoch 578/600\n",
      "52/52 [==============================] - 0s 177us/step - loss: 0.3144 - categorical_accuracy: 1.0000\n",
      "Epoch 579/600\n",
      "52/52 [==============================] - 0s 183us/step - loss: 0.3202 - categorical_accuracy: 1.0000\n",
      "Epoch 580/600\n",
      "52/52 [==============================] - 0s 175us/step - loss: 0.3152 - categorical_accuracy: 1.0000\n",
      "Epoch 581/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.3204 - categorical_accuracy: 1.0000\n",
      "Epoch 582/600\n",
      "52/52 [==============================] - 0s 183us/step - loss: 0.3096 - categorical_accuracy: 1.0000\n",
      "Epoch 583/600\n",
      "52/52 [==============================] - 0s 178us/step - loss: 0.3062 - categorical_accuracy: 1.0000\n",
      "Epoch 584/600\n",
      "52/52 [==============================] - 0s 204us/step - loss: 0.3075 - categorical_accuracy: 1.0000\n",
      "Epoch 585/600\n",
      "52/52 [==============================] - 0s 207us/step - loss: 0.3094 - categorical_accuracy: 0.9615\n",
      "Epoch 586/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.3078 - categorical_accuracy: 1.0000\n",
      "Epoch 587/600\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.3027 - categorical_accuracy: 1.0000\n",
      "Epoch 588/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.3011 - categorical_accuracy: 1.0000\n",
      "Epoch 589/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.2988 - categorical_accuracy: 1.0000\n",
      "Epoch 590/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.3031 - categorical_accuracy: 1.0000\n",
      "Epoch 591/600\n",
      "52/52 [==============================] - 0s 178us/step - loss: 0.3010 - categorical_accuracy: 1.0000\n",
      "Epoch 592/600\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.3027 - categorical_accuracy: 1.0000\n",
      "Epoch 593/600\n",
      "52/52 [==============================] - 0s 167us/step - loss: 0.3043 - categorical_accuracy: 1.0000\n",
      "Epoch 594/600\n",
      "52/52 [==============================] - 0s 183us/step - loss: 0.3132 - categorical_accuracy: 1.0000\n",
      "Epoch 595/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.2976 - categorical_accuracy: 1.0000\n",
      "Epoch 596/600\n",
      "52/52 [==============================] - 0s 169us/step - loss: 0.2963 - categorical_accuracy: 1.0000\n",
      "Epoch 597/600\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.2943 - categorical_accuracy: 1.0000\n",
      "Epoch 598/600\n",
      "52/52 [==============================] - 0s 162us/step - loss: 0.2939 - categorical_accuracy: 1.0000\n",
      "Epoch 599/600\n",
      "52/52 [==============================] - 0s 168us/step - loss: 0.2952 - categorical_accuracy: 1.0000\n",
      "Epoch 600/600\n",
      "52/52 [==============================] - 0s 164us/step - loss: 0.2941 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a613caf60>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = 'IAMREALLYGOOD'\n",
    "text, x_train, y_train = caeserde(mystr, x_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: IAMREALLYGOOD\n",
      "Cipertext: LDPUHDOOBJRRG\n",
      "Prediction: IAMREALLYGOOD\n"
     ]
    }
   ],
   "source": [
    "#from keras.utils import to_categorical\n",
    "#categorical_labels = to_categorical(y_train, num_classes=None)\n",
    "\n",
    "print(\"Original:\",mystr)\n",
    "print(\"Cipertext:\",text)\n",
    "print(\"Prediction:\",\"\".join(predict_results(model, x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "text, x_train, y_train = caeserde('ABCDEFGHIJKLMNOPQRSTUVWXYZ', x_as_vector=False, y_as_vector=False)\n",
    "\n",
    "predictions = model.predict_classes(x_train)\n",
    "\n",
    "#print(confusion_matrix(y_train, predictions.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a6270fc18>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGfCAYAAACNytIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXucXWV5tq8nkcMEkyhqPQAaD1AFqUGDirR4SK3RqIyNaNAJtUbHGKlFP9NPYz6ipMXUhqgVNUaqolHwHGlFtBWxakEzmjThJCKiBKgoGINoFZjn+2Pvwc3M7PO79nrWm/vyt37O3rPXte61d8h+854ec3eEEEIIIcpiRtkBhBBCCLFvo8aIEEIIIUpFjREhhBBClIoaI0IIIYQoFTVGhBBCCFEqaowIIYQQolTUGBFCCCFEx5jZh83sFjO7vMnvzcz+2cyuNbOdZvbEdk41RoQQQgjRDR8FFrX4/XOBw+vHKPCBdkI1RoQQQgjRMe7+n8BtLV5yIvAxr3EZcD8ze2gr531SBpyOO39xXd9bvA497M9SRBFCCCEGwl2/v9EGeb0U37UT7P+gR7+GWo/GBJvdfXMXikOAGxoe764/d3OzEwpvjAghhBCiOtQbHt00PiYzXUOsZWNJjREhhBCi6ozfXXaCRnYDhzU8PhS4qdUJmjMihBBCiJRcAJxSX1XzVOBX7t50iAZKboysOXMjJyxeyvDIip4dz/mLZ3DF5f/J1Vd+i79b9bpSPXKkd0TKIkfcLDk5ImWRozhPcnw83dEGMzsPuBT4YzPbbWbLzWyFmU18mV8IXAdcC3wIWNnW6d7dnBczOx54mbt39Cm0mlQztmMXs4aGWL1uA1u3bGrqaDaBdcaMGVx1xTdZ9LyT2b37Zi679EJGlq3kqqt+2Em0pB450jsiZZEjbpacHJGyyNGfZ+ATWG++KtkE1v0e+riBZocOe0bMbL6ZvdPMrgf+Hrg6xcUXzD+auXNm93z+k489hh/96Hp+/OOfcuedd/LpT3+RF77gOaV45EjviJRFjrhZcnJEyiJHcR4xlaaNETM7wsxON7OrgLOpLdMxd3+mu793YAlb8LBDHsINu/8wJ2b3jTfzsIc9pBSPHOkdkbLIETdLTo5IWeQozlME7uPJjjJo1TNyNbAQeIG7/2m9AdLRdF0zGzWzMTMbO+dj56XI2ew6U57rdtgplUeO9I5IWeSImyUnR6QschTnKYTx8XRHCbRa2rsEWAp83cwuAs5n+rXDU2hco5xyI5bJ3Lj7Zg479GH3PD70kIdy880/K8UjR3pHpCxyxM2SkyNSFjmK84ipNO0ZcfcvuPtLgccClwBvAB5sZh8ws78YUL6WbBvbwWMe80jmzTuM/fbbj5e85ET+9d++WopHjvSOSFnkiJslJ0ekLHIU5ymEAa6mKYK2m565+x3AJ4BPmNnBwEnAm4G+P4FVa9ezbftO9uzZy8LhEVYuX8aSLiYD3X333fztaWu48EufZOaMGXz03E9x5ZXXdJ0jhUeO9I5IWeSImyUnR6QschTnKYRYm551TddLe7tFtWmEEELsawx6ae/vf/L9dLVpHvHEgS/t1XbwQgghRNUpaXglFYU3RlL0avz2pm+GyCGEEEKEpKRVMKlQbRohhBBClIqGaYQQQoiKU9ZmZalQY0QIIYSoOhqm6Z0U1Q9TVP5NlUWO9I5IWeSImyUnR6QschTnEfem8KW999n/kGkv0E31w1YTWPut/NttFjkG54iURY64WXJyRMoiR3+eQS/t/d0130r2ZX7AEX8as2pvEaSqfthv5d9UWeRI74iURY64WXJyRMoiR3GeQhi/O91RAl03RszsgTZdtaAuiVT9MEpVSDniZpEjbpacHJGyyFGcR0ylZWPEzJ5qZpeY2efN7Bgzuxy4HPiZmS1qcd49VXvHx+9o9popz5VV/TBKVUg54maRI26WnByRsshRnKcQMq9NczawGpgLXAw8190vM7PHAucBF013UmPV3mZzRiJVP4xSFVKOuFnkiJslJ0ekLHIU5ymEzFfT3Mfdv+runwH+x90vA3D3q/u9cKTqh1GqQsoRN4sccbPk5IiURY7iPGIq7XpGGptav530u776plJVP+y38m+qLHKkd0TKIkfcLDk5ImWRozhPIVR807OWS3vN7G7gDsCAIeA3E78CDnT3/dpdoNkwTTeoNo0QQogqMfClvTu/km5p7588J1bVXnefOaggQgghhNg30XbwQgghRMVxL2d/kFRUojGSYohFQz1CCCGypeJzRkqtTSOEEEIIUYmeESGEEEK0oOL7jKgxIoQQQlQdDdP0TpSy0GvO3MgJi5cyPLKip/NTZpEjbhY54mbJyREpixzFeZJT8UJ5LfcZSUGzfUYGXRa61QTWsR27mDU0xOp1G9i6ZVPT17WawBqlzHVOjkhZ5IibJSdHpCxy9OcZ9D4j/7vtc8m+zA88dsnA9xlpVyjvMWZ2/DTP/5mZPbqfC0cqC71g/tHMnTO76/NSZ5EjbhY54mbJyREpixzFeQqh4oXy2g3TvBu4fZrnf1v/Xc9EKgudgij3k5MjUhY54mbJyREpixzFeQphfDzdUQLtGiPz3H3n5CfdfQyY1+wkMxs1szEzGxsfv6PZa6Y8V1ZZ6BREuZ+cHJGyyBE3S06OSFnkKM4jptJuNc2BLX431OwX7r4Z2AzN54xEKgudgij3k5MjUhY54mbJyREpixzFeQoh89U028zs1ZOfNLPlwPf6uXCkstApiHI/OTkiZZEjbpacHJGyyFGcpxAqPkzTrmfkNOALZvZy/tD4WADsD7yonwtHKgu9au16tm3fyZ49e1k4PMLK5ctY0uWkpCj3k5MjUhY54mbJyREpixzFecRUOlraa2bPBB5ff3iFu1/c6QWaDdMMGtWmEUIIMSgGvrT3mx9Pt7T3z5YNfGlvRzuwuvvXga8XnEUIIYQQPVD1qr0qlCeEEEKIUtlnatOkGGLRUI8QQoiQqFCeEEIIIUol86W9QgghhBCFoqq9iTyq/FuMI1IWOeJmyckRKYscxXmSU/F9RvaZqr0pPKr8G/ezkUOfTQ6OSFnk6M8z6KW9v/2PTcm+zIf+fEWsqr1FklslRlX+Te+IlEWOuFlyckTKIkdxHjGVjhsjZvYgM3tQqgurEmMxOXJyRMoiR9wsOTkiZZGjOE8hVHyYpmVjxGq8zcx+AVwNXGNmPzez0/u9sCoxFpMjJ0ekLHLEzZKTI1IWOYrzFIKPpztKoF3PyGnA8cCx7v4Ad78/8BTgeDN7Q7OTzGzUzMbMbGx8/I5pX6NKjMXkyMkRKYsccbPk5IiURY7iPGIq7RojpwAnu/uPJ55w9+uAkfrvpsXdN7v7AndfMGPGQdO+RpUYi8mRkyNSFjniZsnJESmLHMV5CqHiwzTtNj3bz91/MflJd/+5me3Xz4Vzq8Soyr/pHZGyyBE3S06OSFnkKM5TCBXfgbXl0l4z+767P7Hb3zUSpWpvCrQdvBBCiE4Y+NLeL7073dLexaeFq9r7BDPbO83zBhxYQB4hhBBCdEvFt4Nv2Rhx95mDCiKEEEKIHqn4MI0K5XVBlMq/oOEeIYQQ+aDGiBBCCFF1ch6mEUIIIUQFqPgwTalVe4UQQgghSm2M5FYWul/HmjM3csLipQyPrOjp+qlyRHJEyiJH3Cw5OSJlkaM4T3Iqvh18y31GUtBsn5GqloXu19FqAuvYjl3MGhpi9boNbN2yqeX1mk1gjfK+VvGzkUOfTdmOSFnk6M8z8H1GPvv36fYZefGage8zUlrPSG5loVM4Fsw/mrlzZnd1ThE5ojgiZZEjbpacHJGyyFGcR0ylXdXev2v4+aRJvzuznwvnVhY6SmnpKPeS22cjR9wsOTkiZZGjOE8hVLw2TbuekaUNP79l0u8WNTupk6q9uZWFjlJaOsq95PbZyBE3S06OSFnkKM5TCO7pjhJo1xixJj9P9/geOqnam1tZ6CilpaPcS26fjRxxs+TkiJRFjuI8YirtGiPe5OfpHndFbmWho5SWjnIvuX02csTNkpMjUhY5ivMUQsWHaTotlGfAUEPRvL4L5eVWFjqFY9Xa9WzbvpM9e/aycHiElcuXsaTLyVFR7iW3z0aOuFlyckTKIkdxnkKo+KZnpS3t3VdRbRohhMifgS/t/cT/S7e09+XrBr60V9vBCyGEEFVHtWmEEEIIUSoVH6ZRY2TApBpeSTHco6EeIYQQ3WJmi4D3ADOBc9x9/aTfPxw4F7hf/TVvdvcLWzlVKE8IIYSoOgPaZ8TMZgLvA54LHAmcbGZHTnrZGuDT7n4Mtf3K3t8uvnpGhBBCiKozuGGaJwPXuvt1AGZ2PnAicGXDaxyYU/95LnATbVDPiBBCCCHuoXEX9fox2vDrQ4AbGh7vrj/XyNuAETPbDVwI/E27a5baGMmtLHQUx5ozN3LC4qUMj6zo6fxUOfTZ5O2IlCUnR6QschTnSU7CTc8ad1GvH5sbrjTdst/JYzsnAx9190OB5wEfN7PWtfDK2mekqmWhozhaTWAd27GLWUNDrF63ga1bNjV9XbMJrFHej0hZ5IibJSdHpCxy9OcZ+D4j57wx3T4jr9rYNLuZHQe8zd2fU3/8FgB3f0fDa64AFrn7DfXH1wFPdfdbmnnbVe19eFd30AW5lYWO4gBYMP9o5s6Z3fV5KXPos8nbESlLTo5IWeQozlNxtgGHm9kjzWx/ahNUL5j0mp8CCwHM7HHUdmz/eStpu2GarRM/mNnnuk3citzKQkdxpCDSvUTJIkfcLDk5ImWRozhPEfi4JztaXsf9LuBU4CvAVdRWzVxhZmeY2QvrL/s/wKvN7L+B84BXeJthmHaraRq7ah7V5rV/OKk22WUUwGbOZbrKvbmVhY7iSEGke4mSRY64WXJyRMoiR3GeQhjgpmf1PUMunPTc6Q0/Xwkc342zn6q9zU9qmPwyXUME8isLHcWRgkj3EiWLHHGz5OSIlEWO4jxiKu0aI08ws71mdjvwJ/Wf95rZ7Q0VfHsit7LQURwpiHQvUbLIETdLTo5IWeQozlMIPp7uKIGWwzTuPrOoC+dWFjqKA2DV2vVs276TPXv2snB4hJXLl7Gki0lWke4lShY54mbJyREpixzFeQqhzVyP6JS2tFf0h2rTCCFEXAa9tPc37zs12XftrNedPdDsoO3ghRBCiOqjqr1CCCGEKBU1RkQZpBhi0VCPEEJkQpQlxj2iQnlCCCGEKBX1jAghhBBVp+LDNKraGyxLFEeUyr+pPHKkd0TKkpMjUhY5ivMkZ9zTHSWgqr2BsqjybzEeOdI7ImXJyREpixz9eQa+tHfDq9It7X3TOQNf2ltaz0hulRhzckCMyr+pPHKkd0TKkpMjUhY5ivMUQsV3YG3ZGDGzE83sdQ2Pv2Nm19WPF/dz4dwqMebkSIE+m7wdkbLk5IiURY7iPIVQ8WGadj0jfwdc0PD4AOBY4BnAa5udZGajZjZmZmPj43c0e82U56pciTEnRwr02eTtiJQlJ0ekLHIU5xFTabeaZn93v6Hh8bfc/VbgVjObvhwvtaq9wGZoPmckt0qMOTlSoM8mb0ekLDk5ImWRozhPEXjmq2nu3/jA3U9tePigfi6cWyXGnBwp0GeTtyNSlpwckbLIUZynECo+TNOuZ+Q7ZvZqd/9Q45Nm9hrgu/1cOLdKjDk5IEbl31QeOdI7ImXJyREpixzFecRUWi7tNbM/ArYCvwO+X3/6SdTmjgy7e9v+KVXtjYu2gxdCiGIY9NLeO/5+JNl37UFrtsSq2uvutwBPM7NnAUfVn/6Su19ceDIhhBBCdEZJwyup6Gg7+HrjQw0QIYQQQiRHtWn2YVT5VwghMqHiq2nUGBFCCCGqTsWHaUotlCeEEEIIoZ4RIYQQouqUVFMmFaX2jORWFlqOe7PmzI2csHgpwyMrejo/ZRY50jsiZcnJESmLHMV5klPxTc9a7jOSgmb7jFS1LLQc96bVBNaxHbuYNTTE6nUb2LplU9PXtZrAWsX3ZF9wRMqSkyNSFjn68wx8n5G3npRun5F/+MzA9xkprWckt7LQckxlwfyjmTtndtfnpc4iR3pHpCw5OSJlkaM4TxH4+HiyowxaNkbM7L1m9s/Njn4unFtZaDmKIcr9yBE3S06OSFnkKM5TCBUfpmk3gXWs4ee3A2s7kZrZKDAKYDPnMmPG1AK/uZWFlqMYotyPHHGz5OSIlEWO4jxiKu22gz934mczO63xcZvzNgObofmckdzKQstRDFHuR464WXJyRMoiR3GeQtiH9hlJeqe5lYWWoxii3I8ccbPk5IiURY7iPIXg4+mOEihtn5HcykLLMZVVa9ezbftO9uzZy8LhEVYuX8aSLid7RbkfOeJmyckRKYscxXnEVFou7TWz2/lDj8gs4DcTvwLc3ee0u0CzYRqRB6pNI4QQUxn00t5fv/GFyb5r77vxgoEv7W03Z6S/dZlCCCGEKBzfh+aMCCGEEEIkR7VpRF+kGGLRUI8QQvRJxXtG1BgRQgghqk5JO6emQsM0QgghhCgV9YwIIYQQVafiwzSl9ozkVhZajvSONWdu5ITFSxkeWdHT+SmzyBE3S06OSFnkKM6TnIrXpmm5z0gKmu0zUtWy0HKkd7SawDq2YxezhoZYvW4DW7dsavq6VhNYq/ieRHdEypKTI1IWOfrzDHqfkdtXLEr2ZT5700UD32ektJ6R3MpCy5HeAbBg/tHMndPfdjdR7icnR6QsOTkiZZGjOE8RuHuyowxaNkbM7HYz2zvNcbuZ7e3nwrmVhZYjvSMVUe4nJ0ekLDk5ImWRozhPIVR8mKaQHVjNbBQYBbCZc5kx46DpXjPd9bq9Tt+OSFnkKIYo95OTI1KWnByRsshRnEdMpZDVNO6+GdgMzeeM5FYWWo70jlREuZ+cHJGy5OSIlEWO4jyFoNU0vZFbWWg50jtSEeV+cnJEypKTI1IWOYrzFIGPe7KjDErbZyS3stBypHcArFq7nm3bd7Jnz14WDo+wcvkylnQ5YSzK/eTkiJQlJ0ekLHIU5xFTKW1prxATqDaNECI3Br2091d/tTDZd+3cc7828KW92oFVCCGEqDrVLk2j2jRCCCGEKBf1jIjSSTHEoqEeIcS+TFkTT1OhxogQQghRdSreGNEwjRBCCCFKRVV7g2WRI71HlX+LcUTKkpMjUhY5ivMkZzzhUQKq2hsoixy9e1T5N+5nI4fe1xwc3XoGvbT3lyc9I9mX+f0/c0mcqr0tiuTtNbOfm9llZraw1wvnVolRjvSOVB5V/k3viJQlJ0ekLHIU5xFTadoYcffZ7j5nugN4CPAa4D29Xji3SoxypHek9PRLlPckiiNSlpwckbLIUZynECo+TNPTahp3vxv4bzN773S/V9VeOSJ9NimI8p5EcUTKkpMjUhY5ivMUQdWX9vY1gdXdP9jk+c3uvsDdF0zXEIH8KjHKkd6R0tMvUd6TKI5IWXJyRMoiR3EeMRVV7Q2URY7iPP0S5T2J4oiUJSdHpCxyFOcphH1xmCYFuVVilCO9I5VHlX/TOyJlyckRKYscxXmKwCtem0ZVe0UWaDt4IUQkBr2099bFT0/2XfuAL30jztJeIYQQQohBoNo0QgghRMWp+jCNGiMiC6JU/gUN9wghSqDijREN0wghhBCiVNQzIoQQQlScqg/TqGdECCGEqDg+nu5oh5ktMrMfmNm1ZvbmJq95iZldaWZXmNkn2zlLbYzkVhZajvSOKFnWnLmRExYvZXhkRU/XT5UjkiNSlpwckbLIUZynqpjZTOB9wHOBI4GTzezISa85HHgLcLy7HwWc1tZb1j4jVS0LLcfgHIPO0moC69iOXcwaGmL1ug1s3bKp5fWaTWCN8r5W8bPZVxyRssjRn2fQ+4z87Jnp9hl58Neb7zNiZscBb3P359QfvwXA3d/R8Jp3Ate4+zmdXrNlz4iZHdridy/o9CLTkVtZaDnSOyJlWTD/aObOmd3VOUXkiOKIlCUnR6QschTnKQS3ZIeZjZrZWMMx2nClQ4AbGh7vrj/XyBHAEWb2bTO7zMwWtYvfbpjma2Y2b/KTZvZK4N3t5K3IrSy0HOkd0bL0S5R7ye2zyckRKYscxXmi01jstn5sbvj1dL0mk3tl7gMcDjwDOBk4x8zu1+qa7RojbwD+vT7+U0tR65J5A/D0Zic1tqrGx+9o9popz1W5LLQc6R3RsvRLlHvJ7bPJyREpixzFeYpggBNYdwOHNTw+FLhpmtd80d3vdPcfAz+g1jhpSsulve5+oZn9DviymQ0DrwKOBU5w91+2OG8zsBmazxnJrSy0HOkd0bL0S5R7ye2zyckRKYscxXmKwMcHNkVlG3C4mT0SuBFYCrxs0mu2UusR+aiZPZDasM11raRtV9O4+9eAVwCXAI8CFrZqiHRKbmWh5UjviJalX6LcS26fTU6OSFnkKM5TZdz9LuBU4CvAVcCn3f0KMzvDzF5Yf9lXgFvN7Erg68Aqd7+1lbdlz4iZ3U5tLMiAA4CFwC1W66tyd5/T6w3lVhZajvSOSFlWrV3Ptu072bNnLwuHR1i5fBlLupy4FuVecvtscnJEyiJHcZ4iGOSmZ+5+IXDhpOdOb/jZgTfWj44obWmvENFQbRohRCoGvbT3xuOeley79pBLLx5odtAOrEIIIYQoGdWmEUIIISpO1WvTqDEiRJ1Uwysphns01COE6IYBrqYpBA3TCCGEEKJU1DMihBBCVJwge6/1jBojQgghRMXRME0f5FYWWo70jkhZUjjWnLmRExYvZXhkRU/np8qhzyauI1IWOYrziHtT2j4jVS0LLcfgHJGydONoNYF1bMcuZg0NsXrdBrZu2dT0dc0msEZ5PyJlyckRKYsc/XkGvc/I9fOfnezLfN6Of6/OPiNmdlo/F86tLLQc6R2RsqS6nwXzj2bunNldn5cyhz6buI5IWeQozlME7umOMuhnmKbjbV6nI7ey0HKkd0TKEqV0eKR7iZIlJ0ekLHIU5xFT6WcCa9NuHDMbBUYBbOZcZsw4aLrXTHmuymWh5UjviJQlSunwSPcSJUtOjkhZ5CjOUwRVn8DaT2Ok6Sfg7puBzdB8zkhuZaHlSO+IlCVK6fBI9xIlS06OSFnkKM5TBO7Vboy0HKYxs9vNbO80x+3Aw1qd247cykLLkd4RKUuU0uGR7iVKlpwckbLIUZxHTKVlz4i79z7Trg25lYWWI70jUpZU97Nq7Xq2bd/Jnj17WTg8wsrly1jSxQS4SPcSJUtOjkhZ5CjOUwRVr01T2tJeIXJFtWmEEINe2nvN4xYl+6494qqLqrO0VwghhBAiBdoOXojEpOjVUO+KEKIbqj6BVY0RIYQQouJUfWmvhmmEEEIIUSrqGRFCCCEqTpC913pGVXuDZZEjbpYojiiVf1N55IibRY7iPKnxcUt2lIGq9gbKIkfcLKr8W4xHjrhZ5OjPM+ilvVc+enGyL/Mjf/SlfWdpb26VGOVI74iUJYoDYlT+TeWRI24WOYrzFMG4W7KjDEprjORWiVGO9I5IWaI4UqDPJq4jUhY5ivMUgbslO8qg5QRWM7ug1e/d/YVNzlPVXjn6dkTKEsWRAn02cR2RsshRnEdMpd1qmuOAG4DzgO8AHTWZVLVXDn02xThSoM8mriNSFjmK8xRB1dtE7YZpHgKsBh4PvAd4NvALd/+Gu3+jnwvnVolRjvSOSFmiOFKgzyauI1IWOYrzFEHV54y0q9p7N3ARcJGZHQCcDFxiZme4+3v7uXBulRjlSO+IlCWKA2JU/k3lkSNuFjmK84iptF3aW2+ELKbWEJkHXAB82N1v7OQCqtorRPeoNo0Q1WbQS3u3P/zEZN+1x/z0iwPvHmk3gfVcakM0Xwbe7u6XDySVEEIIITqm6nNG2k1gXQbcARwBvL5hJrEB7u5zCswmhBBCiH2AdnNGVEhPiBJIMcSioR4h9h3KmniaChXKE0IIISpOWZuVpUI9H0IIIYQoFfWMCCGEEBWn6sM0pfaM5FYWWo70jkhZcnKsOXMjJyxeyvDIip7OT5lFjrhZ5CjOkxpPeJRB231G+qXZPiNVLQstx+AckbJU0dFqAuvYjl3MGhpi9boNbN2yqenrWk1greJ7Et0RKYsc/XkGvc/Ifz10SbIv86fd/LmBd7OU1jOSW1loOdI7ImXJyQGwYP7RzJ0zu+vzUmeRI24WOYrziKm0bIyY2ektjv/Xz4VzKwstR3pHpCw5OVIR5X5yckTKIkdxniJwt2RHGbSbwHrHNM/NAl4FPABYN91JZjYKjALYzLnMmHHQdK+Z8lyVy0LLkd4RKUtOjlREuZ+cHJGyyFGcpwjGyw7QJ+02PTtr4mczmw38LfBK4HzgrBbnbQY2Q/M5I7mVhZYjvSNSlpwcqYhyPzk5ImWRoziPmErbOSNmdrCZ/T2wk1rj5Ynu/n/d/ZZ+LpxbWWg50jsiZcnJkYoo95OTI1IWOYrzFIFjyY4yaFco75+Av6TWy3G0u/861YVzKwstR3pHpCw5OQBWrV3Ptu072bNnLwuHR1i5fBlLupyIF+V+cnJEyiJHcZ4iGI8xWtQzLZf2mtk48DvgLu69/LjjQnnNhmmEEMWi2jRClMegl/Ze8uCTkn3XPuNnnxl494gK5QkhhBAVZ7yk4ZVUaDt4IYQQouKUNdcjFWqMCJEpKYZYNNQjhBgEaowIIYQQFSfrfUaEEEIIEZ+qD9Ooam+wLHLEzSLHvVHl32IckbLIUZxH3BtV7Q2URY64WfZVhyr/6s+8HL15Br2096IHL032Zb7oZ+fHrNprZgea2ePN7CgzOzDFhXOrxChHekekLHJMRZV/0zsiZZGjOE8RjCc8yqBd1d77mNk7gd3AucAW4AYze6eZ7dfPhXOrxChHekekLHIUQ5T7ieKIlEWO4jxiKu16Rv4JOBh4pLs/yd2PAR4N3A/Y0OwkMxs1szEzGxsfn67wb36VGOVI74iURY5iiHI/URyRsshRnKcIsq5NAzwfOMIb3m1332tmrwWuplbFdwqq2iuHPpu8HamIcj9RHJGyyFGcpwjGq72Ypm3PiPs0zT53v5t716rpmtwqMcqR3hEpixzFEOV+ojgiZZGjOI+YSruekSvN7BRsA1gwAAAgAElEQVR3/1jjk2Y2Qq1npGdyq8QoR3pHpCxyTEWVf9M7ImWRozhPEVS9Nk27qr2HAJ8Hfgt8j1pvyLHAEPAid7+x3QVUtVeI6qLt4IXojUEv7d36kJcl+64d/p9PhqvaeyPwFDN7FnAUYMCX3f1rgwgnhBBCiPzpaDt4d78YuLjgLEIIIYToAdWmEUJkiyr/ClENxqdZdlwlSq1NI4QQQgihnhEhhBCi4lR9pYgaI0IIIUTFqfqckVKHaXIrCy1HekekLHKk96w5cyMnLF7K8MiKnjOkyBHJESmLHMV5xL1puc9ICprtM1LVstByDM4RKYscvXtaTWAd27GLWUNDrF63ga1bNjV9XasJrFHeE/2Zz9vRrWfQ+4yc97CXJ/syP/mmTwx8NmxpPSO5lYWWI70jUhY5ivEsmH80c+fM7vraqXNEcUTKIkdxniIYx5IdZdCyMWJmB5rZaWZ2tpm9xsySzTHJrSy0HOkdkbLIUZynX6K8J5HeVznSO1J6qo6ZLTKzH5jZtWb25have7GZuZktaOds1zNyLrAA2AU8Fzirw6CjZjZmZmPj43c0e82U56pcFlqO9I5IWeQoztMvUd6TSO+rHOkdKT1F4AmPVpjZTOB91NoERwInm9mR07xuNvB64Dud5G/X03Gkux9dF/8L8N1OpO6+GdgMzeeM5FYWWo70jkhZ5CjO0y9R3pNI76sc6R0pPUUwPrjRlScD17r7dQBmdj5wInDlpNetA94JvKkTabuekTsnfnD3uzqO2gG5lYWWI70jUhY5ivP0S5T3JNL7Kkd6R0pPdBpHN+rHaMOvDwFuaHi8u/5c4/nHAIe5+791es12PSNPMLO9E35gqP7YAHf3OZ1eaDK5lYWWI70jUhY5ivGsWruebdt3smfPXhYOj7By+TKWdDkhMMp7Eul9lSO9I6WnCFLuM9I4ujEN0/XB3DMCYmYzgHcBr+jmmqUt7RVC7BuoNo3YFxn00t6PHDKS7Lv2r2/c0jS7mR0HvM3dn1N//BYAd39H/fFc4EfAr+unPAS4DXihu48186o2jRBCCCE6ZRtwuJk90sz2B5YCF0z80t1/5e4PdPd57j4PuIw2DRHQdvBCCCFE5RnUBFZ3v8vMTgW+AswEPuzuV5jZGcCYu1/Q2jA9aowIIQolxRBLiqEe0HCPyJdB1qZx9wuBCyc9d3qT1z6jE6eGaYQQQghRKuoZEUIIISpO1av2qjEihBBCVBwvp6RMMkodpsmtLLQc6R2RssgRM8uaMzdywuKlDI+s6On6qXKkckTKIkdxHnFvOtpnxMxmAY+pP/yBu/+u0ws022ekqmWh5RicI1IWOcrN0moC69iOXcwaGmL1ug1s3bKp5fWaTWDdV99XOYr7bAa9z8j7D0u3z8jKG5rvM1IU7ar27mdm76a23etHqBXOu26iSl99y9eeyK0stBzpHZGyyBE3y4L5RzN3zuyuzikiR27vqxzFeYpgPOFRBu2Gac4C7gs8wt2f5O7HAI8DHmVmHwA+3+uFcysLLUd6R6QscsTO0i+R7iVKFjmK84iptJvA+jzgcG8Yy3H3vWb2WuAX1EoIT6FeVGcUwGbOZcaMg6Z7zZTnqlwWWo70jkhZ5IidpV8i3UuULHIU5ymCGCl6p11jZNyneafd/W4z+7m7XzbdSY1FdprNGcmtLLQc6R2RssgRO0u/RLqXKFnkKM5TBIPagbUo2g3TXGlmp0x+0sxGgKv6uXBuZaHlSO+IlEWO2Fn6JdK9RMkiR3EeMZV2PSOvAz5vZq8EvketJ+hYYAh4UT8Xzq0stBzpHZGyyBE3y6q169m2fSd79uxl4fAIK5cvY0mXkwqj3EukLHIU5ymCqm961unS3mcBRwEGXOHuX+v0As2GaYQQolNUm0ZUjUEv7T3r4emW9v6fnw5+aW9HO7C6+8XAxQVnEUIIIcQ+iLaDF0IIISpO1Ycg1BgRQoQn1fBKiuEeDfWIiFR9NY0aI0IIIUTFqfoE1lIL5QkhhBBCqGpvsCxyxM0iR9wsKRwpqv/qfc3bkdKTGk94lEFHS3v7QVV75dBnk58jUpZuHCmq/xZZ+TeVR470jm49g17a+w+PeHmyL/O3/uQTsar2FklulRjlSO+IlEWOuFlS3U+/1X/1vubtSOkRU+mpMWJmM83s5f1cOLdKjHKkd0TKIkfcLFEqqep9zduR0lME4wmPMmjZGDGzOWb2FjM728z+wmr8DXAd8JIW542a2ZiZjY2P39HsNVOeq3IlRjnSOyJlkSNuliiVVPW+5u1I6SmCqs8Zabe09+PAL4FLgVcBq4D9gRPdfUezk1S1Vw59Nnk7ImWJUklV72vejpQeMZV2wzSPcvdXuPsHgZOBBcDzWzVEOiW3SoxypHdEyiJH3CxRKqnqfc3bkdJTBFUfpmnXM3LnxA/ufreZ/djdb09x4dwqMcqR3hEpixxxs6S6n36r/+p9zduR0lMEVd+BteXSXjO7G5iY9GHAEPCb+s/u7nPaXUBVe4UQUdB28GJQDHpp7+nz0i3tPeP6wS/tbdkz4u4zBxVECCGEEL0xXvFSeapNI4QQQlScajdF1BgRQuxDpBhi0VCPEOlRY0QIIYSoOFWv2qvGiBBCCFFxqj5npNSqvUIIIYQQpTZGcisLLUd6R6QscsTNEsWx5syNnLB4KcMjK3o6P2UWOdI7UnpSU/Xt4FvuM5KCZvuMVLUstByDc0TKIkfcLIN2tJrAOrZjF7OGhli9bgNbt2xq+rpWE1ir+J7sC45uPYPeZ+RN805O9mW+4frzBr7PSLtCecea2UMaHp9iZl80s382s4P7uXBuZaHlSO+IlEWOuFmiOAAWzD+auXNmd31e6ixypHek9IiptBum+SDwewAzOwFYD3wM+BX1Qni9kltZaDnSOyJlkSNuliiOVES5HzmK8xTBOJ7sKIN2q2lmuvtt9Z9fCmx2988BnzOzpsXyzGwUGAWwmXOZMeOg6V4z5bkql4WWI70jUhY54maJ4khFlPuRozhPEcRI0TvtekZmmtlEg2UhcHHD75o2ZNx9s7svcPcF0zVEIL+y0HKkd0TKIkfcLFEcqYhyP3IU5xFTadcYOQ/4hpl9Efgt8E0AM3sMtaGansmtLLQc6R2RssgRN0sURyqi3I8cxXmKYDzhUQbtCuX9g5l9DXgo8FX/Q3/UDOBv+rlwbmWh5UjviJRFjrhZojgAVq1dz7btO9mzZy8Lh0dYuXwZS7qc4BjlfuQozlMEXvGBmtKW9gohRBVRbRrRCYNe2vv6eS9N9l37z9d/auBLe7UdvBBCCFFxVJtGCCGEEKVS9do0aowIIUQXpBhi0VCPEPdGjREhhBCi4lS7X0SNESGEEKLyVH2YptSqvUIIIYQQTRsjDTuvFkZuZaHlSO+IlEWOuFlycqw5cyMnLF7K8MiKns5PmUWO4jypqfqmZ033GTGz77v7E/u9QLN9RqpaFlqOwTkiZZEjbpYqOlpNYB3bsYtZQ0OsXreBrVs2NX1dqwmsVXxPoju69Qx6n5FXzXtxsnGac67/7MD3GWk1TFNomNzKQsuR3hEpixxxs+TkAFgw/2jmzpnd9Xmps8hRnEdMpVVj5EFm9sZmR78Xzq0stBzpHZGyyBE3S06OVES5n5wcKT1FUPVhmlbzQmYC96WHHhIzGwVGAWzmXKar3JtbWWg50jsiZZEjbpacHKmIcj85OVJ6iqDqtWlaNUZudvczepG6+2ZgMzSfM5JbWWg50jsiZZEjbpacHKmIcj85OVJ6xFRKmzOSW1loOdI7ImWRI26WnBypiHI/OTlSeoog52GahUVeOLey0HKkd0TKIkfcLDk5AFatXc+27TvZs2cvC4dHWLl8GUu6nCQZ5X5ycqT0FMF4kOGiXmm6tDcVzYZphBBiX0W1afJn0Et7lz3iL5N91378J58f+NJebQcvhBBCVJyq/6tfjREhhBgwUSr/gnpYckG1aYQQQlQSNUREFNQzIoQQQlScnPcZEUIIIUQFKGtJbipKHabJrRKjHOkdkbLIETdLTo4UHlX+LcaR0iPuTWlLe6taiVGOwTkiZZEjbpacHN14VPk37mcDg1/ae9IjTkz2Zf6Zn3wxVNXeQsmtEqMc6R2RssgRN0tOjlQeVf5N70jpKQJP+L8yaNkYmaZa7xvMbJmZPbLfC+dWiVGO9I5IWeSImyUnR0pPv0R5T6I4UnrEVNr1jMyedMwBFgBfNrOlzU4ys1EzGzOzsfHxO5q9ZspzVa7EKEd6R6QscsTNkpMjpadforwnURwpPUWQc20a3P3t0z1vZgcD/wGc3+Q8Ve2VQ59Nxo5IWXJypPT0S5T3JIojpacIojSKeqWnOSPufht9VvXNrRKjHOkdkbLIETdLTo6Unn6J8p5EcaT0VB0zW2RmPzCza83szdP8/o1mdqWZ7TSzr5nZI9o5e9pnxMyeBfyyl3MnyK0SoxzpHZGyyBE3S06OVB5V/k3vSOkpgkFtB29mM4H3Ac8GdgPbzOwCd7+y4WXbgQXu/hszey3wTuClLb2tunbMbBdT6+8cDNwEnOLuV7cLrqq9QgiRHlX+jc2gl/a+4OHPT/Zd+68//bem2c3sOOBt7v6c+uO3ALj7O5q8/hjgbHc/vtU12/WMPH/SYwdudffpZ6UKIYQQYuCkXJJrZqPAaMNTm+tzQQEOAW5o+N1u4CktdMuBL7e7ZrsJrD9pJxBCCCFEPjQuQpmG6XpNpm0JmdkItRW4T293TdWmEUKICpJiiEVDPfkwqDkj1HpCDmt4fCi1qRv3wsz+HHgr8HR3/107qRojQgghRMUZ4NLebcDh9c1PbwSWAi9rfEF9nsgHgUXufksn0lIL5QkhhBCiOrj7XcCpwFeAq4BPu/sVZnaGmb2w/rJ/Au4LfMbMdpjZBe286hkRQgghKs4gd0519wuBCyc9d3rDz3/erbPUnpHcykLLkd4RKYsccbPk5IiSZc2ZGzlh8VKGR1b0dP1UOSI5UnpSU/VCeS33GUlBs31GqloWWo7BOSJlkSNulpwcg87SagLr2I5dzBoaYvW6DWzdsqnp61pNYI3yvpbx2Qx6n5G/OGxRsi/zr95w0UCzQ4ueETM728yeVtSFcysLLUd6R6QscsTNkpMjUpYF849m7pzZXZ1TRI4ojpSeIhjHkx1l0GqY5ofAWWZ2vZn9o5nNT3nh3MpCy5HeESmLHHGz5OSIlqVfotxLpM+mKNw92VEGTRsj7v4edz+O2mYltwEfMbOrzOx0MzuildTMRs1szMzGxsen36w1t7LQcqR3RMoiR9wsOTmiZemXKPcS6bMR09N2Aqu7/8Td/9Hdj6G2lvhF1JbztDpns7svcPcFM2YcNO1rcisLLUd6R6QscsTNkpMjWpZ+iXIvkT6bosh5mAYAM9vPzF5gZp+gtr/8NcCSfi+cW1loOdI7ImWRI26WnBzRsvRLlHuJ9NkURdVX0zTdZ8TMng2cDCwGvgucD4ymKpKXW1loOdI7ImWRI26WnByRsqxau55t23eyZ89eFg6PsHL5MpZ0OVkzyr1E+mzE9DRd2mtmXwc+CXzO3W/r9QLNlvYKIYQoF9WmKY5BL+094ZCFyb5r//PGrw18aW/TnhF3f+YggwghhBCiN6r+r37VphFCCCFEqag2jRBC7KOkGGJJMdQDGu7pl7JWwaRCjREhhBCi4lS9MaJhGiGEEEKUiqr2BssiR9wscsTNkpMjUhZV/i3Ok5qqbwevqr2BssgRN4sccbPk5IiUZZCVf6H5nJEo70e3nkEv7X3yw56e7Mv8uzd9I07VXgAzO83MjjWz5HNLcqvEKEd6R6QscsTNkpMjUhZV/i3OI6bSbpjmUOA9wC1mdomZnWlmi83s4H4vnFslRjnSOyJlkSNulpwckbJEqVAb6V6ivCfTke128ADu/iYAM9sfWAA8DXgl8CEz2+PuR/Z64dwqMcqR3hEpixxxs+TkiJQlSoXaSPcS5T2Zjig5eqXTCaxDwBxgbv24CfhOsxeb2aiZjZnZ2Pj49KVscqvEKEd6R6QscsTNkpMjUpYoFWoj3UuU9yRH2s0Z2Wxm3wY+BRwH/BdwkrsvcPe/bnaeu2+uv2bBjBkHTfua3CoxypHeESmLHHGz5OSIlCVKhdpI9xLlPZmOcTzZUQbtJqY+HDgA+CFwI7Ab2JPiwrlVYpQjvSNSFjniZsnJESmLKv8W5ymCqg/TtF3aa7VBsqOozRd5GvB44DbgUndf2+4CqtorhBD5ou3gp2fQS3uPecjxyb5rt//Pt+NU7Z3Aa62Vy81sD/Cr+vF84MlA28aIEEIIIYql6tvBt2yMmNnrqfWGHA/cCXwbuBT4MLCr8HRCCCGEaEtZS3JT0a5nZB7wWeAN7n5z8XGEEEJUiVTDKymGe3Ib6tmXaLfPyBsHFUQIIYQQvTFe8Qmsybd5F0IIIcRgqfowTalVe4UQQgghSm2M5FYWWo70jkhZ5IibJSdHpCxRHGvO3MgJi5cyPLKip/NT5UjpSc24e7KjDNruM9IvzfYZqWpZaDkG54iURY64WXJyRMoyaEerCaxjO3Yxa2iI1es2sHXLpqavazaBtYzPZtD7jDz2j45N9mV+9S3bBr7PSNOeETM7rMXv+p6ynFtZaDnSOyJlkSNulpwckbJEcQAsmH80c+fM7vq81DlSecRUWg3TfMPM/s7M7pnkamYPNrMtwMZ+L5xbWWg50jsiZZEjbpacHJGyRHGkINJnUxRVH6Zp1Rh5EvBoYLuZPcvM/hb4LrVNz57SStpJ1d7cykLLkd4RKYsccbPk5IiUJYojBZE+m6LwhP8rg6ZLe939l8Br6o2Q/wBuAp7q7rvbSd19M7AZms8Zya0stBzpHZGyyBE3S06OSFmiOFIQ6bMR09Nqzsj9zOyDwF8Di6jtxPplM3tWigvnVhZajvSOSFnkiJslJ0ekLFEcKYj02RRF1YdpWm169n3g/cDr3P0u4KtmNh94v5n9xN1P7ufCuZWFliO9I1IWOeJmyckRKUsUB8CqtevZtn0ne/bsZeHwCCuXL2NJFxNHI302RVH1Tc+aLu01s0ObDcmY2avd/UOdXKDZMI0QQggxQW61aQa9tPdRDzwm2Xftdb/YPvClva3mjDSdG9JpQ0QIIYQQxeM+XnaEvlBtGiGEEKLijFd8mEaNESGEEKWTYoglt6GefQk1RoQQQoiKE2W/k15RY0QIIYSoOFUfpim1aq8QQgghRKmNkSjlqSNlkSNuFjniZsnJESlLTo41Z27khMVLGR5Z0dP5KbMUgbsnO8qg1T4jFwIr3f36fi7QbJ+RKCWuI2WRI24WOeJmyckRKUsVHa0msI7t2MWsoSFWr9vA1i2bmr6u1QTWbrIMep+Rh97vyGStiJv3XDnwfUZa9Yx8lNquq281s/1SXzhSeeooWeSIm0WOuFlyckTKkpMDYMH8o5k7Z3bX5xWRRUylaWPE3T8NHAPMAcbM7E1m9saJo98LRypPHSWLHHGzyBE3S06OSFlycqQiUpbJZFu1t86dwB3AAcBsoKMt3sxsFBgFsJlzmTHjoOleM+U5leyWI2oWOeJmyckRKUtOjlREyjKZKDl6pWljxMwWARuBC4AnuvtvOpW6+2ZgMzSfMxKpPHWULHLEzSJH3Cw5OSJlycmRikhZJpPz0t63Aie5+5u7aYh0SqTy1FGyyBE3ixxxs+TkiJQlJ0cqImXJjVaF8grdEzdSeeooWeSIm0WOuFlyckTKkpMDYNXa9WzbvpM9e/aycHiElcuXsaTLyaepshRB1Ydpmi7tTUWzYRohhBAiJZFq0wx6ae/Bsw9P9l172+0/DLW0VwghhBCicFSbRgghhKg4VR+mUWNECCFEFqQYYkkx1FMGOa+mEUIIIYQoHPWMCCGEEBWn6sM0qtobLIsccbPIETdLTo5IWeS4N6kq/xbBuHuyowxKW9obpSJkpCxyxM0iR9wsOTkiZdlXHSkq/wLs98BHDXR57H1nPTLZl/mvf/PjWEt7zazpjjBmdlI/F45UzTFKFjniZpEjbpacHJGyyDGVFJV/i6LqhfLaDdNcaGZfN7NDpvndW/q5cKRqjlGyyBE3ixxxs+TkiJRFjmpR9WGado2RncAngcum6Qlp2o1jZqNmNmZmY+PjdzR7zZTnVCVTjqhZ5IibJSdHpCxyiEHSrjHi7v4hYCHwd2b2ETObNfG7FidtdvcF7r5gxoyDpn1NpGqOUbLIETeLHHGz5OSIlEWOauHuyY4y6Gg1jbtfAxwH/AzYbmZP6ffCkao5RskiR9wscsTNkpMjUhY5qkXV54y022fknr4td78LeLOZXQScBzyonwtHquYYJYsccbPIETdLTo5IWeSYSorKv2J6Wi7tNbNhd986zfP3B17j7uvbXUBVe4UQQlSFVNvBD3pp7/4HHJrsu/b3v9sda2nvdA2R+vO/7KQhIoQQQojiGeScETNbZGY/MLNrzezN0/z+ADP7VP333zGzee2cqk0jhBBCiI4ws5nA+4DnAkcCJ5vZkZNethz4pbs/BngX8I/tvGqMCCGEEBXHEx5teDJwrbtf5+6/B84HTpz0mhOBc+s/fxZYaNOtr77XDSTs2umjS2hUjrSOSFnkiJtFjrhZcnJEyhLFEfkARoGxhmO04XcvBs5peLwMOHvS+ZcDhzY8/hHwwFbXjNIzMipHckcqjxzpHak8cqR3pPLIUYwnJ0dYvGGvsPqxueHX0/VwTO5Q6eQ19yJKY0QIIYQQ8dkNHNbw+FDgpmavMbP7AHOB21pJ1RgRQgghRKdsAw43s0ea2f7AUuCCSa+5APir+s8vBi72+nhNM9ptejYoNrd/iRwleeRI70jlkSO9I5VHjmI8OTkqibvfZWanAl8BZgIfdvcrzOwMYMzdLwD+Bfi4mV1LrUdkaTtvy03PhBBCCCGKRsM0QgghhCgVNUaEEEIIUSqlNkbM7EVm5mb22D4cd5vZDjP7bzP7vpk9rQfHQ8zsfDP7kZldaWYXmtkRPWS4op7jjWbW9Xvb4Jk4pmyz26NnXpfnP9jMPmlm15nZ98zsUjN7UZeOX096/AozO7sbRyvfoB2N55rZ88zsh2b28EFmqJ/vZvbxhsf3MbOfm9m/dek4q+Hxm8zsbT1kOdTMvlh/L35kZu+pT2jrxjHxZ/VyM/uMmc3qM8d1Zna2mR3QR45/NbP7dZuj7nlr/e+BnXVfVxXOzewBDf/d/o+Z3djwuKP31szmmdnlk557m5m9qYscl5jZcyY9d5qZvb/D899lZqc1PP6KmZ3T8PgsM3tjh67DzOzHZnZw/fH9648f0dndgNX4lpk9t+G5l1it8GunjhdN+nt1h5mNNzpF75TdM3Iy8C06mNzSgt+6+3x3fwLwFuAd3ZxsZgZ8AbjE3R/t7kcCq4EH95DhKODZwPOAtd3kmOSZOHqt/zPZc32nJ9bfj63Af7r7o9z9SdQ+n0N7zJIVZrYQeC+wyN1/WkKEO4DHm9lQ/fGzgRu7dPwO+Esze2CvIep/Tj4PbHX3w4EjgPsC/9ClauLP6uOB3wMr+sxxODAEvLOPHLcBr+vyfMzsOOD5wBPd/U+APwdu6Mbh7rdO/HcLbALe1fDf8e+7zdQH5zH17+Wl9ec74b+ApwHU/2H2QOCoht8/Dfh2JyJ3vwH4ADDx9+F6YLO7/6TDLNRXcqwANprZgWZ2ELU/qx1/zu7+hca/V4H3A9+kNpFT9ElpjREzuy9wPLU97PtpjDQyB/hll+c8E7jT3TdNPOHuO9y9p9KN7n4LtQ1xTq3/RVk1ngX8ftL78RN3f2+JmUJgZn8GfAhY7O4/KjHKl4HF9Z9PpvMviAnuorYa4A19ZHgW8L/u/hEAd7+77ntlL70bdb4JPCZRjlPqf8f0wqXAIT2c91DgF+7+u3qWX7j75P0XqsJngedP9DDVe1cfRu0fj53wbeqNEWqNkMuB2+u9GgcAjwO2d5HnXcBT670tfwqc1eb1U3D3y4F/Bf4vtX8sfqzX/46t1nN+OrDM3cd7cYh7U2bPyDBwkbtfA9xmZk/s0TNU7y67GjgHWNfl+Y8HvtfjtafF3a+j9t7+UZenTtzLxPHSHiM0er7Q5blHAd/v8brNMuwAzkjgLJMDgC8Cw+5+dclZzgeWmtmBwJ8A3+nB8T7g5WY2t8cMRzHpvxt33wv8lO4bFBMbIz0X2JUox/U95pgJLGTqvgmd8FXgMDO7xszeb2ZP78ERAne/FfgusKj+1FLgU+32img4/ybgrvpQ5tOoNfC+AxwHLAB2dtPT4+53AquoNUpO66OX6O3Ay6j9Weu29wwAM9sP+CTwppJ6R7OkzMbIydT+UqX+/yf36JnoXn0stf9wPhakR6KXDJOHVz7V47UbPV3N9ZiMmb3PavNgtvWRYT61f0VUmTupdT0vLzuIu+8E5lH7b+bCHh17gY8Br+8xhjH99s7Nnm/GUL2xOkatIfMvCXN0w0SOW4GDgX/v8nzc/dfAk6j1jP4c+JSZvaJbTwKavf/d7uPQOFTTzRDNBBO9IxONkUsbHv9Xly6oNSBupvYPyJ5w9zuATwEfn+jB6oF1wBXufn7bV4qOKaUxYmYPoNa9eo6ZXU+txfvSfhsR7n4ptbHJB3Vx2hXU/gJJhpk9CrgbuCWld0BcAdzTS+Xur6P2L8Vu3tMcGQdeAhxrZqvLDkPtX+4b6P4LopF3U2tcHdTDuVdQ+xfuPZjZHGpbQHfT9d3YaP2bHv7F2yzHg4EfdJsDeASwPz3MGYHaMJG7X+Lua4FTgSW9ePrkVuD+k547GPhFl56t1KqtPhEYcvdue0wn5o0cTW2Y5jJqPSMdzxeZwMzmU5sf9VTgDWb20C6zNDJeP7rGzJ5B7TM9tY/ri2koq2fkxdTG6x7h7vPc/TDgx9TGAnvGaqtyZlL7j7FTLgYOMLNXN3iO7bWL1cweRG3i2dmddmkG4w2cGaEAAAILSURBVGLgQDN7bcNzvc4ByAp3/w21CYovN7Oye0g+DJzh7t0Oa9yDu98GfJreenu+Bswys1PgnuGNs4CP1t+nQdEsx9nu/ttuZe7+K2q9RW+qd8d3jJn9sZkd3vDUfKDjSZapqPfQ3FyfbE19FcoiOp/v0ei5hNqftV4avd+m9t/LbfVG2m3A/ag1SC7tVFL/R+oHqA3P/BT4J2oN8YFiZvcHPgKc4u63D/r6uVNWY+RkaitYGvkctbG8brlnbgK17re/qk9i64h6g+FFwLOttjzxCuBtTC3800mGK4D/oDZ2/PYuzp/smTh6XU3TM/X3Yxh4en353HeBc6lN+qos9TkJvXbL3kP9L9RFwBozO7EHxSwz291wdLS8cZocu939Pb2cO4mzqPUmdnv9if9uTjKzHwLXAP9LbSXawGjI8eJ6jluBcXfvdlVPo3M78N90P7H+vsC5VtseYCdwJLW/S8rgFGp/RndQ+wfG23ucrHke8AT+MKTeDbuo/dm6bNJzv3L3bnppXg381N0nhs7eDzy2hDk5K6jNA/xAorl9ogFtBy/2CczsCcCH3P3JZWcRxWG1fYbOA/7S3ZNOTBdCFIcaIyJ7zGwFta7309z9q2XnEUIIcW/UGBFCCCFEqZS9A6sQQggh9nHUGBFCCCFEqagxIoQQQohSUWNECCGEEKWixogQQgghSuX/AzAQ315hjFBvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_train, predictions.astype(int))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning structure 3: 26 inputs vs one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",y_as_vector=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "# change sigomiod to softmax made acc increasing 100%\n",
    "model.add(Dense(1, activation='relu'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 3s 96ms/step - loss: 210.1361 - acc: 0.0385\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 204.9134 - acc: 0.0385\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 194.4588 - acc: 0.0769\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 182.6714 - acc: 0.0385\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 169.7396 - acc: 0.0385\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 154.0535 - acc: 0.0385\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 116us/step - loss: 135.6995 - acc: 0.0385\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 115.9403 - acc: 0.0769\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 96.2145 - acc: 0.0385\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 78.7653 - acc: 0.0385\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 65.5266 - acc: 0.0385\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 56.9366 - acc: 0.0769\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 52.0538 - acc: 0.0385\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 49.4107 - acc: 0.0385\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 47.8398 - acc: 0.0385\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 46.7012 - acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 45.7182 - acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 44.7870 - acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 43.8718 - acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 42.9618 - acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 42.0530 - acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 41.1440 - acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 76us/step - loss: 40.2333 - acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 39.3207 - acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 111us/step - loss: 38.4064 - acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 130us/step - loss: 37.4893 - acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 36.5696 - acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 35.6514 - acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 34.7310 - acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 33.8088 - acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 32.8857 - acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 31.9606 - acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 31.0348 - acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 30.1078 - acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 29.1809 - acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 28.2541 - acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 105us/step - loss: 27.3289 - acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 26.4055 - acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 25.4875 - acc: 0.0385\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 24.5812 - acc: 0.0385\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 23.6796 - acc: 0.0385\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 22.7839 - acc: 0.0385\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 21.8985 - acc: 0.0385\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 21.0192 - acc: 0.0385\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 20.1489 - acc: 0.0385\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 19.2903 - acc: 0.0385\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 111us/step - loss: 18.4450 - acc: 0.0385\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 105us/step - loss: 17.6125 - acc: 0.0385\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 16.7916 - acc: 0.0385\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 15.9886 - acc: 0.0385\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 15.2061 - acc: 0.0385\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 14.4410 - acc: 0.0385\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 13.7024 - acc: 0.0385\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 12.9874 - acc: 0.0385\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 111us/step - loss: 12.2932 - acc: 0.0385\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 11.6115 - acc: 0.0385\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 112us/step - loss: 10.9620 - acc: 0.0385\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 10.3389 - acc: 0.0385\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 79us/step - loss: 9.7322 - acc: 0.0385\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 9.1522 - acc: 0.0385\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 8.5924 - acc: 0.0385\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 8.0556 - acc: 0.0385\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 7.5484 - acc: 0.0385\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 7.0601 - acc: 0.0385\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 6.6008 - acc: 0.0385\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 6.1562 - acc: 0.0769\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 5.7395 - acc: 0.0769\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 5.3441 - acc: 0.1154\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 4.9668 - acc: 0.1154\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 4.6144 - acc: 0.1154\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 4.2774 - acc: 0.1154\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 3.9630 - acc: 0.1154\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 3.6698 - acc: 0.1538\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 108us/step - loss: 3.3911 - acc: 0.1538\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 3.1336 - acc: 0.1538\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 120us/step - loss: 2.8946 - acc: 0.1538\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 2.6764 - acc: 0.1538\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 2.4743 - acc: 0.1538\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 125us/step - loss: 2.2914 - acc: 0.1923\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 2.1231 - acc: 0.2308\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 108us/step - loss: 1.9669 - acc: 0.2308\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 1.8262 - acc: 0.2692\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 1.6979 - acc: 0.2692\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 1.5776 - acc: 0.2692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 1.4663 - acc: 0.2692\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 1.3619 - acc: 0.2692\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 1.2644 - acc: 0.2692\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 1.1738 - acc: 0.2692\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 1.0894 - acc: 0.3077\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 1.0112 - acc: 0.3077\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.9383 - acc: 0.3077\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 80us/step - loss: 0.8703 - acc: 0.3077\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.8081 - acc: 0.3077\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.7517 - acc: 0.3462\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 107us/step - loss: 0.6993 - acc: 0.3846\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 0.6508 - acc: 0.4231\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.6066 - acc: 0.4615\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.5655 - acc: 0.4615\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 0.5271 - acc: 0.5000\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.4923 - acc: 0.5000\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 105us/step - loss: 0.4615 - acc: 0.5000\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.4330 - acc: 0.5000\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 107us/step - loss: 0.4068 - acc: 0.5385\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 151us/step - loss: 0.3824 - acc: 0.5769\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.3602 - acc: 0.6538\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 0.3392 - acc: 0.6923\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.3195 - acc: 0.6923\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.3014 - acc: 0.6923\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.2842 - acc: 0.6923\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 0.2690 - acc: 0.7308\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.2548 - acc: 0.7308\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.2410 - acc: 0.7692\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.2283 - acc: 0.7692\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.2166 - acc: 0.7692\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 136us/step - loss: 0.2056 - acc: 0.7692\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 0.1955 - acc: 0.8077\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.1863 - acc: 0.8462\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 115us/step - loss: 0.1773 - acc: 0.8462\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 0.1689 - acc: 0.8462\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 112us/step - loss: 0.1612 - acc: 0.8462\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 0.1538 - acc: 0.8462\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 0.1468 - acc: 0.8846\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 0.1402 - acc: 0.8846\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 0.1341 - acc: 0.9231\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.1282 - acc: 0.9231\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 0.1226 - acc: 0.9231\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.1174 - acc: 0.9231\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.1125 - acc: 0.9231\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 120us/step - loss: 0.1079 - acc: 0.9231\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 162us/step - loss: 0.1034 - acc: 0.9231\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 111us/step - loss: 0.0994 - acc: 0.9231\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 108us/step - loss: 0.0956 - acc: 0.9231\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 0.0918 - acc: 0.9231\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0883 - acc: 0.9231\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 0.0852 - acc: 0.9231\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 0.0823 - acc: 0.9231\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.0795 - acc: 0.9231\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 151us/step - loss: 0.0768 - acc: 0.9231\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.0743 - acc: 0.9231\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0720 - acc: 0.9231\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.0698 - acc: 0.9231\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 0.0675 - acc: 0.9231\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0654 - acc: 0.9231\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0633 - acc: 0.9231\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.0614 - acc: 0.9231\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0595 - acc: 0.9231\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.0577 - acc: 0.9231\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0560 - acc: 0.9231\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 83us/step - loss: 0.0544 - acc: 0.9231\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 131us/step - loss: 0.0528 - acc: 0.9231\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 0.0514 - acc: 0.9231\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 0.0501 - acc: 0.9231\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0486 - acc: 0.9231\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 0.0472 - acc: 0.9231\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 116us/step - loss: 0.0459 - acc: 0.9615\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 108us/step - loss: 0.0446 - acc: 0.9615\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 0.0434 - acc: 0.9615\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 0.0423 - acc: 0.9615\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.0411 - acc: 0.9615\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 0.0401 - acc: 0.9615\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.0391 - acc: 0.9615\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.0381 - acc: 0.9615\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.0371 - acc: 0.9615\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0362 - acc: 0.9615\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0352 - acc: 0.9615\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 108us/step - loss: 0.0343 - acc: 0.9615\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0334 - acc: 0.9615\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.0326 - acc: 0.9615\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 115us/step - loss: 0.0319 - acc: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 0.0311 - acc: 0.9615\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 0.0303 - acc: 0.9615\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 0.0295 - acc: 0.9615\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0288 - acc: 0.9615\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 0.0281 - acc: 0.9615\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0275 - acc: 0.9615\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 111us/step - loss: 0.0268 - acc: 0.9615\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0263 - acc: 0.9615\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 125us/step - loss: 0.0256 - acc: 0.9615\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 107us/step - loss: 0.0250 - acc: 0.9615\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.0244 - acc: 0.9615\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0238 - acc: 0.9615\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 0.0233 - acc: 0.9615\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0227 - acc: 0.9615\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.0222 - acc: 0.9615\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 111us/step - loss: 0.0217 - acc: 0.9615\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 111us/step - loss: 0.0212 - acc: 0.9615\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.0208 - acc: 0.9615\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 149us/step - loss: 0.0203 - acc: 0.9615\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0198 - acc: 0.9615\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0193 - acc: 0.9615\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0189 - acc: 0.9615\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0185 - acc: 0.9615\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0181 - acc: 0.9615\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.0176 - acc: 0.9615\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 111us/step - loss: 0.0173 - acc: 0.9615\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 0.0169 - acc: 0.9615\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 0.0165 - acc: 0.9615\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0161 - acc: 0.9615\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 101us/step - loss: 0.0158 - acc: 0.9615\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.0154 - acc: 0.9615\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0151 - acc: 0.9615\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0148 - acc: 0.9615\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0145 - acc: 0.9615\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0141 - acc: 0.9615\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 0.0138 - acc: 0.9615\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 0.0135 - acc: 0.9615\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.0132 - acc: 0.9615\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 0.0129 - acc: 0.9615\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 0.0126 - acc: 0.9615\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9615\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0121 - acc: 0.9615\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.0119 - acc: 0.9615\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.0116 - acc: 0.9615\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 116us/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 112us/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 118us/step - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 98us/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 84us/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 126us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 115us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 122us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 88us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 90us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 91us/step - loss: 0.0049 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 118us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 119us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 114us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 104us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 110us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 121us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 117us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 95us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 124us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 99us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 218us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 134us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 163us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 175us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 179us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 137us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 145us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 109us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 103us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 120us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 116us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 113us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 94us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 82us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 96us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 86us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 81us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 87us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 72us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 92us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 89us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 115us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 106us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 97us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 100us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 93us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 85us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 102us/step - loss: 0.0020 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a48450128>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return (I2L[index])\n",
    "\n",
    "def predict_results(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index = np.argmax(predictions, axis=1)\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index))\n",
    "\n",
    "    return (prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21897495],\n",
       "       [ 1.0498525 ],\n",
       "       [ 2.0024214 ],\n",
       "       [ 3.0137682 ],\n",
       "       [ 3.9934096 ],\n",
       "       [ 4.9947343 ],\n",
       "       [ 5.996136  ],\n",
       "       [ 6.997001  ],\n",
       "       [ 8.000188  ],\n",
       "       [ 8.992074  ],\n",
       "       [ 9.997525  ],\n",
       "       [10.992929  ],\n",
       "       [11.991884  ],\n",
       "       [12.996147  ],\n",
       "       [13.997149  ],\n",
       "       [14.993398  ],\n",
       "       [15.994487  ],\n",
       "       [16.99484   ],\n",
       "       [17.99553   ],\n",
       "       [18.995718  ],\n",
       "       [19.99908   ],\n",
       "       [21.001575  ],\n",
       "       [21.998983  ],\n",
       "       [23.002846  ],\n",
       "       [23.999924  ],\n",
       "       [25.007292  ]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the prediction is quite good compared with the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: find out why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4cc84d68>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_train, np.rint(model.predict(x_train)))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_153 (Dense)            (None, 20)                540       \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the model just has 2 layers, we can still get good prediction results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning structure 4: 26 inputs vs 26 outputs (as a classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 26 y_train: 26\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train:\",x_train.shape[1],\"y_train:\",y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], input_dim=x_train.shape[1], activation='softmax'))\n",
    "\n",
    "# change sigomiod to softmax made acc increasing 100%\n",
    "#model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 0.1606 - acc: 0.9615\n",
      "Epoch 2/300\n",
      "52/52 [==============================] - 0s 87us/step - loss: 0.1605 - acc: 0.9615\n",
      "Epoch 3/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1603 - acc: 0.9615\n",
      "Epoch 4/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1602 - acc: 0.9615\n",
      "Epoch 5/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1601 - acc: 0.9615\n",
      "Epoch 6/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1599 - acc: 0.9615\n",
      "Epoch 7/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1598 - acc: 0.9615\n",
      "Epoch 8/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1597 - acc: 0.9615\n",
      "Epoch 9/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1596 - acc: 0.9615\n",
      "Epoch 10/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1595 - acc: 0.9615\n",
      "Epoch 11/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1593 - acc: 0.9615\n",
      "Epoch 12/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1592 - acc: 0.9615\n",
      "Epoch 13/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1591 - acc: 0.9615\n",
      "Epoch 14/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1590 - acc: 0.9615\n",
      "Epoch 15/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1588 - acc: 0.9615\n",
      "Epoch 16/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1587 - acc: 0.9615\n",
      "Epoch 17/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1586 - acc: 0.9615\n",
      "Epoch 18/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1585 - acc: 0.9615\n",
      "Epoch 19/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1583 - acc: 0.9615\n",
      "Epoch 20/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1582 - acc: 0.9615\n",
      "Epoch 21/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1581 - acc: 0.9615\n",
      "Epoch 22/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1580 - acc: 0.9615\n",
      "Epoch 23/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1578 - acc: 0.9615\n",
      "Epoch 24/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1577 - acc: 0.9615\n",
      "Epoch 25/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1576 - acc: 0.9615\n",
      "Epoch 26/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1575 - acc: 0.9615\n",
      "Epoch 27/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1573 - acc: 0.9615\n",
      "Epoch 28/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1572 - acc: 0.9615\n",
      "Epoch 29/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1571 - acc: 0.9615\n",
      "Epoch 30/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1570 - acc: 0.9615\n",
      "Epoch 31/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1568 - acc: 0.9615\n",
      "Epoch 32/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1567 - acc: 0.9615\n",
      "Epoch 33/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1566 - acc: 0.9615\n",
      "Epoch 34/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1565 - acc: 0.9615\n",
      "Epoch 35/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1564 - acc: 0.9615\n",
      "Epoch 36/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1562 - acc: 0.9615\n",
      "Epoch 37/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1561 - acc: 0.9615\n",
      "Epoch 38/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1560 - acc: 0.9615\n",
      "Epoch 39/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1559 - acc: 0.9615\n",
      "Epoch 40/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1557 - acc: 0.9615\n",
      "Epoch 41/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1556 - acc: 0.9615\n",
      "Epoch 42/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1555 - acc: 0.9615\n",
      "Epoch 43/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1554 - acc: 0.9615\n",
      "Epoch 44/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1552 - acc: 0.9615\n",
      "Epoch 45/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1551 - acc: 0.9615\n",
      "Epoch 46/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 47/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1549 - acc: 0.9615\n",
      "Epoch 48/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1547 - acc: 0.9615\n",
      "Epoch 49/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1546 - acc: 0.9615\n",
      "Epoch 50/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1545 - acc: 0.9615\n",
      "Epoch 51/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1544 - acc: 0.9615\n",
      "Epoch 52/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1542 - acc: 0.9615\n",
      "Epoch 53/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1541 - acc: 0.9615\n",
      "Epoch 54/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1540 - acc: 0.9615\n",
      "Epoch 55/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1539 - acc: 0.9615\n",
      "Epoch 56/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1538 - acc: 0.9615\n",
      "Epoch 57/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1536 - acc: 0.9615\n",
      "Epoch 58/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1535 - acc: 0.9615\n",
      "Epoch 59/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1534 - acc: 0.9615\n",
      "Epoch 60/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1533 - acc: 0.9615\n",
      "Epoch 61/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1531 - acc: 0.9615\n",
      "Epoch 62/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1530 - acc: 0.9615\n",
      "Epoch 63/300\n",
      "52/52 [==============================] - 0s 98us/step - loss: 0.1529 - acc: 0.9615\n",
      "Epoch 64/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1528 - acc: 0.9615\n",
      "Epoch 65/300\n",
      "52/52 [==============================] - 0s 149us/step - loss: 0.1526 - acc: 0.9615\n",
      "Epoch 66/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1525 - acc: 0.9615\n",
      "Epoch 67/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1524 - acc: 0.9615\n",
      "Epoch 68/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1523 - acc: 0.9615\n",
      "Epoch 69/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1522 - acc: 0.9615\n",
      "Epoch 70/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1520 - acc: 0.9615\n",
      "Epoch 71/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1519 - acc: 0.9615\n",
      "Epoch 72/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1518 - acc: 0.9615\n",
      "Epoch 73/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1517 - acc: 0.9615\n",
      "Epoch 74/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1515 - acc: 0.9615\n",
      "Epoch 75/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1514 - acc: 0.9615\n",
      "Epoch 76/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1513 - acc: 0.9615\n",
      "Epoch 77/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1512 - acc: 0.9615\n",
      "Epoch 78/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1510 - acc: 0.9615\n",
      "Epoch 79/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1509 - acc: 0.9615\n",
      "Epoch 80/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1508 - acc: 0.9615\n",
      "Epoch 81/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1507 - acc: 0.9615\n",
      "Epoch 82/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1505 - acc: 0.9615\n",
      "Epoch 83/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1504 - acc: 0.9615\n",
      "Epoch 84/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1503 - acc: 0.9615\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 105us/step - loss: 0.1502 - acc: 0.9615\n",
      "Epoch 86/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1501 - acc: 0.9615\n",
      "Epoch 87/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1499 - acc: 0.9615\n",
      "Epoch 88/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1498 - acc: 0.9615\n",
      "Epoch 89/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1497 - acc: 0.9615\n",
      "Epoch 90/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1496 - acc: 0.9615\n",
      "Epoch 91/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1494 - acc: 0.9615\n",
      "Epoch 92/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1493 - acc: 0.9615\n",
      "Epoch 93/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1492 - acc: 0.9615\n",
      "Epoch 94/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1491 - acc: 0.9615\n",
      "Epoch 95/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1489 - acc: 0.9615\n",
      "Epoch 96/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1488 - acc: 0.9615\n",
      "Epoch 97/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1487 - acc: 0.9615\n",
      "Epoch 98/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1486 - acc: 0.9615\n",
      "Epoch 99/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1484 - acc: 0.9615\n",
      "Epoch 100/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1483 - acc: 0.9615\n",
      "Epoch 101/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1482 - acc: 0.9615\n",
      "Epoch 102/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1481 - acc: 0.9615\n",
      "Epoch 103/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1480 - acc: 0.9615\n",
      "Epoch 104/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1478 - acc: 0.9615\n",
      "Epoch 105/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1477 - acc: 0.9615\n",
      "Epoch 106/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1476 - acc: 0.9615\n",
      "Epoch 107/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1475 - acc: 0.9615\n",
      "Epoch 108/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1473 - acc: 0.9615\n",
      "Epoch 109/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1472 - acc: 0.9615\n",
      "Epoch 110/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1471 - acc: 0.9615\n",
      "Epoch 111/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1470 - acc: 0.9615\n",
      "Epoch 112/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1468 - acc: 0.9615\n",
      "Epoch 113/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1467 - acc: 0.9615\n",
      "Epoch 114/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1466 - acc: 0.9615\n",
      "Epoch 115/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1465 - acc: 0.9615\n",
      "Epoch 116/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1463 - acc: 0.9615\n",
      "Epoch 117/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1462 - acc: 0.9615\n",
      "Epoch 118/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1461 - acc: 0.9615\n",
      "Epoch 119/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1460 - acc: 0.9615\n",
      "Epoch 120/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1458 - acc: 0.9615\n",
      "Epoch 121/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1457 - acc: 0.9615\n",
      "Epoch 122/300\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1455 - acc: 0.961 - 0s 115us/step - loss: 0.1456 - acc: 0.9615\n",
      "Epoch 123/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1455 - acc: 0.9615\n",
      "Epoch 124/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1454 - acc: 0.9615\n",
      "Epoch 125/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1452 - acc: 0.9615\n",
      "Epoch 126/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1451 - acc: 0.9615\n",
      "Epoch 127/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1450 - acc: 0.9615\n",
      "Epoch 128/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1449 - acc: 0.9615\n",
      "Epoch 129/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1447 - acc: 0.9615\n",
      "Epoch 130/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1446 - acc: 0.9615\n",
      "Epoch 131/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1445 - acc: 0.9615\n",
      "Epoch 132/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1444 - acc: 0.9615\n",
      "Epoch 133/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1442 - acc: 0.9615\n",
      "Epoch 134/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1441 - acc: 0.9615\n",
      "Epoch 135/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1440 - acc: 0.9615\n",
      "Epoch 136/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1439 - acc: 0.9615\n",
      "Epoch 137/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1437 - acc: 0.9615\n",
      "Epoch 138/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1436 - acc: 0.9615\n",
      "Epoch 139/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1435 - acc: 0.9615\n",
      "Epoch 140/300\n",
      "52/52 [==============================] - 0s 101us/step - loss: 0.1434 - acc: 0.9615\n",
      "Epoch 141/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1433 - acc: 0.9615\n",
      "Epoch 142/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1431 - acc: 0.9615\n",
      "Epoch 143/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1430 - acc: 0.9615\n",
      "Epoch 144/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1429 - acc: 0.9615\n",
      "Epoch 145/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1428 - acc: 0.9615\n",
      "Epoch 146/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1426 - acc: 0.9615\n",
      "Epoch 147/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1425 - acc: 0.9615\n",
      "Epoch 148/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1424 - acc: 0.9615\n",
      "Epoch 149/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1423 - acc: 0.9615\n",
      "Epoch 150/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1421 - acc: 0.9615\n",
      "Epoch 151/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1420 - acc: 0.9615\n",
      "Epoch 152/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1419 - acc: 0.9615\n",
      "Epoch 153/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1418 - acc: 0.9615\n",
      "Epoch 154/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1417 - acc: 0.9615\n",
      "Epoch 155/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1415 - acc: 0.9615\n",
      "Epoch 156/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1414 - acc: 0.9615\n",
      "Epoch 157/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1413 - acc: 0.9615\n",
      "Epoch 158/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1412 - acc: 0.9615\n",
      "Epoch 159/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1410 - acc: 0.9615\n",
      "Epoch 160/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1409 - acc: 0.9615\n",
      "Epoch 161/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1408 - acc: 0.9615\n",
      "Epoch 162/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1407 - acc: 0.9615\n",
      "Epoch 163/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1405 - acc: 0.9615\n",
      "Epoch 164/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1404 - acc: 0.9615\n",
      "Epoch 165/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1403 - acc: 0.9615\n",
      "Epoch 166/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1402 - acc: 0.9615\n",
      "Epoch 167/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1401 - acc: 0.9615\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 123us/step - loss: 0.1399 - acc: 0.9615\n",
      "Epoch 169/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1398 - acc: 0.9615\n",
      "Epoch 170/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1397 - acc: 0.9615\n",
      "Epoch 171/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1396 - acc: 0.9615\n",
      "Epoch 172/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1394 - acc: 0.9615\n",
      "Epoch 173/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1393 - acc: 0.9615\n",
      "Epoch 174/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1392 - acc: 0.9615\n",
      "Epoch 175/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1391 - acc: 0.9615\n",
      "Epoch 176/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1389 - acc: 0.9615\n",
      "Epoch 177/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1388 - acc: 0.9615\n",
      "Epoch 178/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1387 - acc: 0.9615\n",
      "Epoch 179/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1386 - acc: 0.9615\n",
      "Epoch 180/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1385 - acc: 0.9615\n",
      "Epoch 181/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1383 - acc: 0.9615\n",
      "Epoch 182/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1382 - acc: 0.9615\n",
      "Epoch 183/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1381 - acc: 0.9615\n",
      "Epoch 184/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1380 - acc: 0.9615\n",
      "Epoch 185/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1378 - acc: 0.9615\n",
      "Epoch 186/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1377 - acc: 0.9615\n",
      "Epoch 187/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1376 - acc: 0.9615\n",
      "Epoch 188/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1375 - acc: 0.9615\n",
      "Epoch 189/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1373 - acc: 0.9615\n",
      "Epoch 190/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1372 - acc: 0.9615\n",
      "Epoch 191/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1371 - acc: 0.9615\n",
      "Epoch 192/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1370 - acc: 0.9615\n",
      "Epoch 193/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1369 - acc: 0.9615\n",
      "Epoch 194/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1367 - acc: 0.9615\n",
      "Epoch 195/300\n",
      "52/52 [==============================] - 0s 105us/step - loss: 0.1366 - acc: 0.9615\n",
      "Epoch 196/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1365 - acc: 0.9615\n",
      "Epoch 197/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1364 - acc: 0.9615\n",
      "Epoch 198/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1362 - acc: 0.9615\n",
      "Epoch 199/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1361 - acc: 0.9615\n",
      "Epoch 200/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1360 - acc: 0.9615\n",
      "Epoch 201/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1359 - acc: 0.9615\n",
      "Epoch 202/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1357 - acc: 0.9615\n",
      "Epoch 203/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1356 - acc: 0.9615\n",
      "Epoch 204/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1355 - acc: 0.9615\n",
      "Epoch 205/300\n",
      "52/52 [==============================] - 0s 150us/step - loss: 0.1354 - acc: 0.9615\n",
      "Epoch 206/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1353 - acc: 0.9615\n",
      "Epoch 207/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1351 - acc: 0.9615\n",
      "Epoch 208/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1350 - acc: 0.9615\n",
      "Epoch 209/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1349 - acc: 0.9615\n",
      "Epoch 210/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1348 - acc: 0.9615\n",
      "Epoch 211/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1346 - acc: 0.9615\n",
      "Epoch 212/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1345 - acc: 0.9615\n",
      "Epoch 213/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1344 - acc: 0.9615\n",
      "Epoch 214/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1343 - acc: 0.9615\n",
      "Epoch 215/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1341 - acc: 0.9615\n",
      "Epoch 216/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1340 - acc: 0.9615\n",
      "Epoch 217/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1339 - acc: 0.9615\n",
      "Epoch 218/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1338 - acc: 0.9615\n",
      "Epoch 219/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1337 - acc: 0.9615\n",
      "Epoch 220/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1335 - acc: 0.9615\n",
      "Epoch 221/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1334 - acc: 0.9615\n",
      "Epoch 222/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1333 - acc: 0.9615\n",
      "Epoch 223/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1332 - acc: 0.9615\n",
      "Epoch 224/300\n",
      "52/52 [==============================] - 0s 104us/step - loss: 0.1330 - acc: 0.9615\n",
      "Epoch 225/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1329 - acc: 0.9615\n",
      "Epoch 226/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1328 - acc: 0.9615\n",
      "Epoch 227/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1327 - acc: 0.9615\n",
      "Epoch 228/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1325 - acc: 0.9615\n",
      "Epoch 229/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1324 - acc: 0.9615\n",
      "Epoch 230/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1323 - acc: 0.9615\n",
      "Epoch 231/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1322 - acc: 0.9615\n",
      "Epoch 232/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1321 - acc: 0.9615\n",
      "Epoch 233/300\n",
      "52/52 [==============================] - 0s 99us/step - loss: 0.1319 - acc: 0.9615\n",
      "Epoch 234/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1318 - acc: 0.9615\n",
      "Epoch 235/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1317 - acc: 0.9615\n",
      "Epoch 236/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1316 - acc: 0.9615\n",
      "Epoch 237/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1314 - acc: 0.9615\n",
      "Epoch 238/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1313 - acc: 0.9615\n",
      "Epoch 239/300\n",
      "52/52 [==============================] - 0s 103us/step - loss: 0.1312 - acc: 0.9615\n",
      "Epoch 240/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1311 - acc: 0.9615\n",
      "Epoch 241/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1309 - acc: 0.9615\n",
      "Epoch 242/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1308 - acc: 0.9615\n",
      "Epoch 243/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1307 - acc: 0.9615\n",
      "Epoch 244/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1306 - acc: 0.9615\n",
      "Epoch 245/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1305 - acc: 0.9615\n",
      "Epoch 246/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1303 - acc: 0.9615\n",
      "Epoch 247/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1302 - acc: 0.9615\n",
      "Epoch 248/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1301 - acc: 0.9615\n",
      "Epoch 249/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1300 - acc: 0.9615\n",
      "Epoch 250/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.1298 - acc: 0.9615\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 104us/step - loss: 0.1297 - acc: 0.9615\n",
      "Epoch 252/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1296 - acc: 0.9615\n",
      "Epoch 253/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1295 - acc: 0.9615\n",
      "Epoch 254/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1293 - acc: 0.9615\n",
      "Epoch 255/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1292 - acc: 0.9615\n",
      "Epoch 256/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1291 - acc: 0.9615\n",
      "Epoch 257/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1290 - acc: 0.9615\n",
      "Epoch 258/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1289 - acc: 0.9615\n",
      "Epoch 259/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1287 - acc: 0.9615\n",
      "Epoch 260/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1286 - acc: 0.9615\n",
      "Epoch 261/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1285 - acc: 0.9615\n",
      "Epoch 262/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1284 - acc: 0.9615\n",
      "Epoch 263/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1282 - acc: 0.9615\n",
      "Epoch 264/300\n",
      "52/52 [==============================] - 0s 171us/step - loss: 0.1281 - acc: 0.9615\n",
      "Epoch 265/300\n",
      "52/52 [==============================] - 0s 199us/step - loss: 0.1280 - acc: 0.9615\n",
      "Epoch 266/300\n",
      "52/52 [==============================] - 0s 205us/step - loss: 0.1279 - acc: 0.9615\n",
      "Epoch 267/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1278 - acc: 0.9615\n",
      "Epoch 268/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1276 - acc: 0.9615\n",
      "Epoch 269/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.1275 - acc: 0.9615\n",
      "Epoch 270/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1274 - acc: 0.9615\n",
      "Epoch 271/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1273 - acc: 0.9615\n",
      "Epoch 272/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1271 - acc: 0.9615\n",
      "Epoch 273/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1270 - acc: 0.9615\n",
      "Epoch 274/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1269 - acc: 0.9615\n",
      "Epoch 275/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1268 - acc: 0.9615\n",
      "Epoch 276/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1267 - acc: 0.9615\n",
      "Epoch 277/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1265 - acc: 0.9615\n",
      "Epoch 278/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1264 - acc: 0.9615\n",
      "Epoch 279/300\n",
      "52/52 [==============================] - 0s 90us/step - loss: 0.1263 - acc: 0.9615\n",
      "Epoch 280/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 281/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1260 - acc: 0.9615\n",
      "Epoch 282/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1259 - acc: 0.9615\n",
      "Epoch 283/300\n",
      "52/52 [==============================] - 0s 92us/step - loss: 0.1258 - acc: 0.9615\n",
      "Epoch 284/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1257 - acc: 0.9615\n",
      "Epoch 285/300\n",
      "52/52 [==============================] - 0s 100us/step - loss: 0.1255 - acc: 0.9615\n",
      "Epoch 286/300\n",
      "52/52 [==============================] - 0s 91us/step - loss: 0.1254 - acc: 0.9615\n",
      "Epoch 287/300\n",
      "52/52 [==============================] - 0s 84us/step - loss: 0.1253 - acc: 0.9615\n",
      "Epoch 288/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1252 - acc: 0.9615\n",
      "Epoch 289/300\n",
      "52/52 [==============================] - 0s 106us/step - loss: 0.1251 - acc: 0.9615\n",
      "Epoch 290/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1249 - acc: 0.9615\n",
      "Epoch 291/300\n",
      "52/52 [==============================] - 0s 96us/step - loss: 0.1248 - acc: 0.9615\n",
      "Epoch 292/300\n",
      "52/52 [==============================] - 0s 95us/step - loss: 0.1247 - acc: 0.9615\n",
      "Epoch 293/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1246 - acc: 0.9615\n",
      "Epoch 294/300\n",
      "52/52 [==============================] - 0s 102us/step - loss: 0.1244 - acc: 0.9615\n",
      "Epoch 295/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1243 - acc: 0.9615\n",
      "Epoch 296/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.1242 - acc: 0.9615\n",
      "Epoch 297/300\n",
      "52/52 [==============================] - 0s 109us/step - loss: 0.1241 - acc: 0.9615\n",
      "Epoch 298/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1240 - acc: 0.9615\n",
      "Epoch 299/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1238 - acc: 0.9615\n",
      "Epoch 300/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1237 - acc: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5065ac18>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return (I2L[index])\n",
    "\n",
    "def predict_results(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index = np.argmax(predictions, axis=1)\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index))\n",
    "\n",
    "    return (prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = 'IAMREALLYGOOD'\n",
    "text, x_train, y_train = caeserde(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: IAMREALLYGOOD\n",
      "Cipertext: LDPUHDOOBJRRG\n",
      "Prediction: IAMREALLYGOOD\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\",mystr)\n",
    "print(\"Cipertext:\",text)\n",
    "print(\"Prediction:\",\"\".join(predict_results(model, x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a530a8438>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\", y_as_vector= False)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_train, model.predict_classes(x_train))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26 to 26 model has a best preformance for caeser decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_161 (Dense)            (None, 26)                702       \n",
      "=================================================================\n",
      "Total params: 702\n",
      "Trainable params: 702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Try to reduce it complixicity. (But it doesn't work, it will work for the position matrix input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a middle layer with different number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, x_train, y_train = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnum = 25\n",
    "model = Sequential()\n",
    "model.add(Dense(neuralnum, input_dim=x_train.shape[1], activation='relu'))\n",
    "# change sigomiod to softmax made acc increasing 100%\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "52/52 [==============================] - 3s 57ms/step - loss: 0.6930 - acc: 0.5288\n",
      "Epoch 2/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.6893 - acc: 0.5518\n",
      "Epoch 3/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.6857 - acc: 0.5725\n",
      "Epoch 4/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.6821 - acc: 0.5947\n",
      "Epoch 5/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.6785 - acc: 0.6139\n",
      "Epoch 6/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.6749 - acc: 0.6361\n",
      "Epoch 7/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.6713 - acc: 0.6568\n",
      "Epoch 8/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.6677 - acc: 0.6812\n",
      "Epoch 9/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.6641 - acc: 0.7004\n",
      "Epoch 10/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.6604 - acc: 0.7101\n",
      "Epoch 11/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.6568 - acc: 0.7293\n",
      "Epoch 12/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.6531 - acc: 0.7441\n",
      "Epoch 13/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.6493 - acc: 0.7574\n",
      "Epoch 14/300\n",
      "52/52 [==============================] - 0s 107us/step - loss: 0.6456 - acc: 0.7633\n",
      "Epoch 15/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.6418 - acc: 0.7737\n",
      "Epoch 16/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.6378 - acc: 0.7899\n",
      "Epoch 17/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.6339 - acc: 0.7996\n",
      "Epoch 18/300\n",
      "52/52 [==============================] - 0s 108us/step - loss: 0.6300 - acc: 0.8129\n",
      "Epoch 19/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.6259 - acc: 0.8217\n",
      "Epoch 20/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.6218 - acc: 0.8321\n",
      "Epoch 21/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.6176 - acc: 0.8425\n",
      "Epoch 22/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.6133 - acc: 0.8491\n",
      "Epoch 23/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.6091 - acc: 0.8609\n",
      "Epoch 24/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.6047 - acc: 0.8750\n",
      "Epoch 25/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.6002 - acc: 0.8846\n",
      "Epoch 26/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.5957 - acc: 0.8898\n",
      "Epoch 27/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.5911 - acc: 0.8979\n",
      "Epoch 28/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.5863 - acc: 0.8994\n",
      "Epoch 29/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.5816 - acc: 0.9046\n",
      "Epoch 30/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.5767 - acc: 0.9105\n",
      "Epoch 31/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.5717 - acc: 0.9149\n",
      "Epoch 32/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.5667 - acc: 0.9186\n",
      "Epoch 33/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.5615 - acc: 0.9223\n",
      "Epoch 34/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.5563 - acc: 0.9275\n",
      "Epoch 35/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.5509 - acc: 0.9320\n",
      "Epoch 36/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.5455 - acc: 0.9364\n",
      "Epoch 37/300\n",
      "52/52 [==============================] - 0s 195us/step - loss: 0.5400 - acc: 0.9364\n",
      "Epoch 38/300\n",
      "52/52 [==============================] - 0s 216us/step - loss: 0.5344 - acc: 0.9393\n",
      "Epoch 39/300\n",
      "52/52 [==============================] - 0s 179us/step - loss: 0.5288 - acc: 0.9438\n",
      "Epoch 40/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.5231 - acc: 0.9438\n",
      "Epoch 41/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.5173 - acc: 0.9527\n",
      "Epoch 42/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.5115 - acc: 0.9527\n",
      "Epoch 43/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.5055 - acc: 0.9519\n",
      "Epoch 44/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.4995 - acc: 0.9512\n",
      "Epoch 45/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.4936 - acc: 0.9549\n",
      "Epoch 46/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4875 - acc: 0.9556\n",
      "Epoch 47/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.4814 - acc: 0.9556\n",
      "Epoch 48/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.4753 - acc: 0.9571\n",
      "Epoch 49/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.4691 - acc: 0.9571\n",
      "Epoch 50/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4629 - acc: 0.9571\n",
      "Epoch 51/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.4566 - acc: 0.9586\n",
      "Epoch 52/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.4503 - acc: 0.9586\n",
      "Epoch 53/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.4440 - acc: 0.9586\n",
      "Epoch 54/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.4377 - acc: 0.9593\n",
      "Epoch 55/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.4314 - acc: 0.9601\n",
      "Epoch 56/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.4251 - acc: 0.9601\n",
      "Epoch 57/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.4187 - acc: 0.9615\n",
      "Epoch 58/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.4124 - acc: 0.9615\n",
      "Epoch 59/300\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.4061 - acc: 0.9615\n",
      "Epoch 60/300\n",
      "52/52 [==============================] - 0s 183us/step - loss: 0.3997 - acc: 0.9615\n",
      "Epoch 61/300\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.3934 - acc: 0.9615\n",
      "Epoch 62/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.3870 - acc: 0.9615\n",
      "Epoch 63/300\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.3808 - acc: 0.9615\n",
      "Epoch 64/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.3745 - acc: 0.9615\n",
      "Epoch 65/300\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.3683 - acc: 0.9615\n",
      "Epoch 66/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.3622 - acc: 0.9615\n",
      "Epoch 67/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.3561 - acc: 0.9615\n",
      "Epoch 68/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.3501 - acc: 0.9615\n",
      "Epoch 69/300\n",
      "52/52 [==============================] - 0s 147us/step - loss: 0.3441 - acc: 0.9615\n",
      "Epoch 70/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.3383 - acc: 0.9615\n",
      "Epoch 71/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.3325 - acc: 0.9615\n",
      "Epoch 72/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.3269 - acc: 0.9615\n",
      "Epoch 73/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.3213 - acc: 0.9615\n",
      "Epoch 74/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.3158 - acc: 0.9615\n",
      "Epoch 75/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.3104 - acc: 0.9615\n",
      "Epoch 76/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.3052 - acc: 0.9615\n",
      "Epoch 77/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.3000 - acc: 0.9615\n",
      "Epoch 78/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.2949 - acc: 0.9615\n",
      "Epoch 79/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.2899 - acc: 0.9615\n",
      "Epoch 80/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.2851 - acc: 0.9615\n",
      "Epoch 81/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.2803 - acc: 0.9615\n",
      "Epoch 82/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.2757 - acc: 0.9615\n",
      "Epoch 83/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.2712 - acc: 0.9615\n",
      "Epoch 84/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.2668 - acc: 0.9615\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 132us/step - loss: 0.2625 - acc: 0.9615\n",
      "Epoch 86/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.2584 - acc: 0.9615\n",
      "Epoch 87/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.2544 - acc: 0.9615\n",
      "Epoch 88/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.2505 - acc: 0.9615\n",
      "Epoch 89/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.2467 - acc: 0.9615\n",
      "Epoch 90/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.2431 - acc: 0.9615\n",
      "Epoch 91/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.2395 - acc: 0.9615\n",
      "Epoch 92/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.2361 - acc: 0.9615\n",
      "Epoch 93/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.2328 - acc: 0.9615\n",
      "Epoch 94/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.2297 - acc: 0.9615\n",
      "Epoch 95/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.2266 - acc: 0.9615\n",
      "Epoch 96/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.2236 - acc: 0.9615\n",
      "Epoch 97/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.2208 - acc: 0.9615\n",
      "Epoch 98/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.2180 - acc: 0.9615\n",
      "Epoch 99/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.2154 - acc: 0.9615\n",
      "Epoch 100/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.2129 - acc: 0.9615\n",
      "Epoch 101/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.2104 - acc: 0.9615\n",
      "Epoch 102/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.2081 - acc: 0.9615\n",
      "Epoch 103/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.2058 - acc: 0.9615\n",
      "Epoch 104/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.2037 - acc: 0.9615\n",
      "Epoch 105/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.2016 - acc: 0.9615\n",
      "Epoch 106/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1996 - acc: 0.9615\n",
      "Epoch 107/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1977 - acc: 0.9615\n",
      "Epoch 108/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1958 - acc: 0.9615\n",
      "Epoch 109/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1940 - acc: 0.9615\n",
      "Epoch 110/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1923 - acc: 0.9615\n",
      "Epoch 111/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1907 - acc: 0.9615\n",
      "Epoch 112/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1891 - acc: 0.9615\n",
      "Epoch 113/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1876 - acc: 0.9615\n",
      "Epoch 114/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1862 - acc: 0.9615\n",
      "Epoch 115/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1848 - acc: 0.9615\n",
      "Epoch 116/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1835 - acc: 0.9615\n",
      "Epoch 117/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1822 - acc: 0.9615\n",
      "Epoch 118/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1810 - acc: 0.9615\n",
      "Epoch 119/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1798 - acc: 0.9615\n",
      "Epoch 120/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1787 - acc: 0.9615\n",
      "Epoch 121/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1776 - acc: 0.9615\n",
      "Epoch 122/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1766 - acc: 0.9615\n",
      "Epoch 123/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1756 - acc: 0.9615\n",
      "Epoch 124/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1746 - acc: 0.9615\n",
      "Epoch 125/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1737 - acc: 0.9615\n",
      "Epoch 126/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1728 - acc: 0.9615\n",
      "Epoch 127/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1719 - acc: 0.9615\n",
      "Epoch 128/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1711 - acc: 0.9615\n",
      "Epoch 129/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1703 - acc: 0.9615\n",
      "Epoch 130/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1695 - acc: 0.9615\n",
      "Epoch 131/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1688 - acc: 0.9615\n",
      "Epoch 132/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1681 - acc: 0.9615\n",
      "Epoch 133/300\n",
      "52/52 [==============================] - 0s 151us/step - loss: 0.1674 - acc: 0.9615\n",
      "Epoch 134/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1667 - acc: 0.9615\n",
      "Epoch 135/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1661 - acc: 0.9615\n",
      "Epoch 136/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1654 - acc: 0.9615\n",
      "Epoch 137/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1648 - acc: 0.9615\n",
      "Epoch 138/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1642 - acc: 0.9615\n",
      "Epoch 139/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1636 - acc: 0.9615\n",
      "Epoch 140/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1630 - acc: 0.9615\n",
      "Epoch 141/300\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.1625 - acc: 0.9615\n",
      "Epoch 142/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1620 - acc: 0.9615\n",
      "Epoch 143/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1614 - acc: 0.9615\n",
      "Epoch 144/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.1609 - acc: 0.9615\n",
      "Epoch 145/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1604 - acc: 0.9615\n",
      "Epoch 146/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1600 - acc: 0.9615\n",
      "Epoch 147/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1595 - acc: 0.9615\n",
      "Epoch 148/300\n",
      "52/52 [==============================] - 0s 134us/step - loss: 0.1590 - acc: 0.9615\n",
      "Epoch 149/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1586 - acc: 0.9615\n",
      "Epoch 150/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1581 - acc: 0.9615\n",
      "Epoch 151/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1577 - acc: 0.9615\n",
      "Epoch 152/300\n",
      "52/52 [==============================] - 0s 142us/step - loss: 0.1573 - acc: 0.9615\n",
      "Epoch 153/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1569 - acc: 0.9615\n",
      "Epoch 154/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1565 - acc: 0.9615\n",
      "Epoch 155/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1561 - acc: 0.9615\n",
      "Epoch 156/300\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.1557 - acc: 0.9615\n",
      "Epoch 157/300\n",
      "52/52 [==============================] - 0s 152us/step - loss: 0.1553 - acc: 0.9615\n",
      "Epoch 158/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 159/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1546 - acc: 0.9615\n",
      "Epoch 160/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1542 - acc: 0.9615\n",
      "Epoch 161/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1539 - acc: 0.9615\n",
      "Epoch 162/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1535 - acc: 0.9615\n",
      "Epoch 163/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.1532 - acc: 0.9615\n",
      "Epoch 164/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1529 - acc: 0.9615\n",
      "Epoch 165/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1525 - acc: 0.9615\n",
      "Epoch 166/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1522 - acc: 0.9615\n",
      "Epoch 167/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1519 - acc: 0.9615\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 130us/step - loss: 0.1516 - acc: 0.9615\n",
      "Epoch 169/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1513 - acc: 0.9615\n",
      "Epoch 170/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1509 - acc: 0.9615\n",
      "Epoch 171/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1506 - acc: 0.9615\n",
      "Epoch 172/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1503 - acc: 0.9615\n",
      "Epoch 173/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1500 - acc: 0.9615\n",
      "Epoch 174/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1497 - acc: 0.9615\n",
      "Epoch 175/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1495 - acc: 0.9615\n",
      "Epoch 176/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1492 - acc: 0.9615\n",
      "Epoch 177/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1489 - acc: 0.9615\n",
      "Epoch 178/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1486 - acc: 0.9615\n",
      "Epoch 179/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1483 - acc: 0.9615\n",
      "Epoch 180/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1480 - acc: 0.9615\n",
      "Epoch 181/300\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.1477 - acc: 0.9615\n",
      "Epoch 182/300\n",
      "52/52 [==============================] - 0s 148us/step - loss: 0.1474 - acc: 0.9615\n",
      "Epoch 183/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1472 - acc: 0.9615\n",
      "Epoch 184/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1469 - acc: 0.9615\n",
      "Epoch 185/300\n",
      "52/52 [==============================] - 0s 139us/step - loss: 0.1466 - acc: 0.9615\n",
      "Epoch 186/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1463 - acc: 0.9615\n",
      "Epoch 187/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1461 - acc: 0.9615\n",
      "Epoch 188/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1458 - acc: 0.9615\n",
      "Epoch 189/300\n",
      "52/52 [==============================] - 0s 149us/step - loss: 0.1455 - acc: 0.9615\n",
      "Epoch 190/300\n",
      "52/52 [==============================] - 0s 165us/step - loss: 0.1453 - acc: 0.9615\n",
      "Epoch 191/300\n",
      "52/52 [==============================] - 0s 153us/step - loss: 0.1450 - acc: 0.9615\n",
      "Epoch 192/300\n",
      "52/52 [==============================] - 0s 160us/step - loss: 0.1447 - acc: 0.9615\n",
      "Epoch 193/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1445 - acc: 0.9615\n",
      "Epoch 194/300\n",
      "52/52 [==============================] - 0s 141us/step - loss: 0.1442 - acc: 0.9615\n",
      "Epoch 195/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1439 - acc: 0.9615\n",
      "Epoch 196/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1437 - acc: 0.9615\n",
      "Epoch 197/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1434 - acc: 0.9615\n",
      "Epoch 198/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1432 - acc: 0.9615\n",
      "Epoch 199/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1429 - acc: 0.9615\n",
      "Epoch 200/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1426 - acc: 0.9615\n",
      "Epoch 201/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1424 - acc: 0.9615\n",
      "Epoch 202/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1421 - acc: 0.9615\n",
      "Epoch 203/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1419 - acc: 0.9615\n",
      "Epoch 204/300\n",
      "52/52 [==============================] - 0s 111us/step - loss: 0.1416 - acc: 0.9615\n",
      "Epoch 205/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1413 - acc: 0.9615\n",
      "Epoch 206/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1411 - acc: 0.9615\n",
      "Epoch 207/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1408 - acc: 0.9615\n",
      "Epoch 208/300\n",
      "52/52 [==============================] - 0s 153us/step - loss: 0.1406 - acc: 0.9615\n",
      "Epoch 209/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1403 - acc: 0.9615\n",
      "Epoch 210/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1401 - acc: 0.9615\n",
      "Epoch 211/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1398 - acc: 0.9615\n",
      "Epoch 212/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1395 - acc: 0.9615\n",
      "Epoch 213/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1393 - acc: 0.9615\n",
      "Epoch 214/300\n",
      "52/52 [==============================] - 0s 131us/step - loss: 0.1390 - acc: 0.9615\n",
      "Epoch 215/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1388 - acc: 0.9615\n",
      "Epoch 216/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1385 - acc: 0.9615\n",
      "Epoch 217/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1383 - acc: 0.9615\n",
      "Epoch 218/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1380 - acc: 0.9615\n",
      "Epoch 219/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1377 - acc: 0.9615\n",
      "Epoch 220/300\n",
      "52/52 [==============================] - 0s 110us/step - loss: 0.1375 - acc: 0.9615\n",
      "Epoch 221/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1372 - acc: 0.9615\n",
      "Epoch 222/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1370 - acc: 0.9615\n",
      "Epoch 223/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1367 - acc: 0.9615\n",
      "Epoch 224/300\n",
      "52/52 [==============================] - 0s 145us/step - loss: 0.1365 - acc: 0.9615\n",
      "Epoch 225/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1362 - acc: 0.9615\n",
      "Epoch 226/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1359 - acc: 0.9615\n",
      "Epoch 227/300\n",
      "52/52 [==============================] - 0s 128us/step - loss: 0.1357 - acc: 0.9615\n",
      "Epoch 228/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1354 - acc: 0.9615\n",
      "Epoch 229/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1352 - acc: 0.9615\n",
      "Epoch 230/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1349 - acc: 0.9615\n",
      "Epoch 231/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1347 - acc: 0.9615\n",
      "Epoch 232/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1344 - acc: 0.9615\n",
      "Epoch 233/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1341 - acc: 0.9615\n",
      "Epoch 234/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1339 - acc: 0.9615\n",
      "Epoch 235/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1336 - acc: 0.9615\n",
      "Epoch 236/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1334 - acc: 0.9615\n",
      "Epoch 237/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1331 - acc: 0.9615\n",
      "Epoch 238/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1328 - acc: 0.9615\n",
      "Epoch 239/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1326 - acc: 0.9615\n",
      "Epoch 240/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1323 - acc: 0.9615\n",
      "Epoch 241/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1321 - acc: 0.9615\n",
      "Epoch 242/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1318 - acc: 0.9615\n",
      "Epoch 243/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1315 - acc: 0.9615\n",
      "Epoch 244/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1313 - acc: 0.9615\n",
      "Epoch 245/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1310 - acc: 0.9615\n",
      "Epoch 246/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1308 - acc: 0.9615\n",
      "Epoch 247/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1305 - acc: 0.9615\n",
      "Epoch 248/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1302 - acc: 0.9615\n",
      "Epoch 249/300\n",
      "52/52 [==============================] - 0s 137us/step - loss: 0.1300 - acc: 0.9615\n",
      "Epoch 250/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1297 - acc: 0.9615\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 136us/step - loss: 0.1294 - acc: 0.9615\n",
      "Epoch 252/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1292 - acc: 0.9615\n",
      "Epoch 253/300\n",
      "52/52 [==============================] - 0s 132us/step - loss: 0.1289 - acc: 0.9615\n",
      "Epoch 254/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1286 - acc: 0.9615\n",
      "Epoch 255/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1284 - acc: 0.9615\n",
      "Epoch 256/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1281 - acc: 0.9615\n",
      "Epoch 257/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1278 - acc: 0.9615\n",
      "Epoch 258/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1276 - acc: 0.9615\n",
      "Epoch 259/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1273 - acc: 0.9615\n",
      "Epoch 260/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1270 - acc: 0.9615\n",
      "Epoch 261/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1267 - acc: 0.9615\n",
      "Epoch 262/300\n",
      "52/52 [==============================] - 0s 126us/step - loss: 0.1265 - acc: 0.9615\n",
      "Epoch 263/300\n",
      "52/52 [==============================] - 0s 117us/step - loss: 0.1262 - acc: 0.9615\n",
      "Epoch 264/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1259 - acc: 0.9615\n",
      "Epoch 265/300\n",
      "52/52 [==============================] - 0s 140us/step - loss: 0.1256 - acc: 0.9615\n",
      "Epoch 266/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1254 - acc: 0.9615\n",
      "Epoch 267/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1251 - acc: 0.9615\n",
      "Epoch 268/300\n",
      "52/52 [==============================] - 0s 114us/step - loss: 0.1248 - acc: 0.9615\n",
      "Epoch 269/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1245 - acc: 0.9615\n",
      "Epoch 270/300\n",
      "52/52 [==============================] - 0s 129us/step - loss: 0.1243 - acc: 0.9615\n",
      "Epoch 271/300\n",
      "52/52 [==============================] - 0s 118us/step - loss: 0.1240 - acc: 0.9615\n",
      "Epoch 272/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1237 - acc: 0.9615\n",
      "Epoch 273/300\n",
      "52/52 [==============================] - 0s 143us/step - loss: 0.1234 - acc: 0.9615\n",
      "Epoch 274/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1231 - acc: 0.9615\n",
      "Epoch 275/300\n",
      "52/52 [==============================] - 0s 144us/step - loss: 0.1228 - acc: 0.9615\n",
      "Epoch 276/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1226 - acc: 0.9615\n",
      "Epoch 277/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1223 - acc: 0.9615\n",
      "Epoch 278/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1220 - acc: 0.9615\n",
      "Epoch 279/300\n",
      "52/52 [==============================] - 0s 127us/step - loss: 0.1217 - acc: 0.9615\n",
      "Epoch 280/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1214 - acc: 0.9615\n",
      "Epoch 281/300\n",
      "52/52 [==============================] - 0s 122us/step - loss: 0.1211 - acc: 0.9615\n",
      "Epoch 282/300\n",
      "52/52 [==============================] - 0s 133us/step - loss: 0.1208 - acc: 0.9615\n",
      "Epoch 283/300\n",
      "52/52 [==============================] - 0s 123us/step - loss: 0.1206 - acc: 0.9615\n",
      "Epoch 284/300\n",
      "52/52 [==============================] - 0s 120us/step - loss: 0.1203 - acc: 0.9615\n",
      "Epoch 285/300\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.1201 - acc: 0.961 - 0s 129us/step - loss: 0.1200 - acc: 0.9615\n",
      "Epoch 286/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1197 - acc: 0.9615\n",
      "Epoch 287/300\n",
      "52/52 [==============================] - 0s 135us/step - loss: 0.1194 - acc: 0.9615\n",
      "Epoch 288/300\n",
      "52/52 [==============================] - 0s 138us/step - loss: 0.1191 - acc: 0.9615\n",
      "Epoch 289/300\n",
      "52/52 [==============================] - 0s 113us/step - loss: 0.1188 - acc: 0.9615\n",
      "Epoch 290/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1185 - acc: 0.9615\n",
      "Epoch 291/300\n",
      "52/52 [==============================] - 0s 125us/step - loss: 0.1182 - acc: 0.9615\n",
      "Epoch 292/300\n",
      "52/52 [==============================] - 0s 124us/step - loss: 0.1179 - acc: 0.9615\n",
      "Epoch 293/300\n",
      "52/52 [==============================] - 0s 136us/step - loss: 0.1176 - acc: 0.9615\n",
      "Epoch 294/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1173 - acc: 0.9615\n",
      "Epoch 295/300\n",
      "52/52 [==============================] - 0s 119us/step - loss: 0.1170 - acc: 0.9615\n",
      "Epoch 296/300\n",
      "52/52 [==============================] - 0s 115us/step - loss: 0.1167 - acc: 0.9615\n",
      "Epoch 297/300\n",
      "52/52 [==============================] - 0s 116us/step - loss: 0.1165 - acc: 0.9615\n",
      "Epoch 298/300\n",
      "52/52 [==============================] - 0s 112us/step - loss: 0.1162 - acc: 0.9615\n",
      "Epoch 299/300\n",
      "52/52 [==============================] - 0s 121us/step - loss: 0.1158 - acc: 0.9615\n",
      "Epoch 300/300\n",
      "52/52 [==============================] - 0s 130us/step - loss: 0.1156 - acc: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a553439b0>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a55783748>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text, x_test, y_test = caeserde(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", y_as_vector= False)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print(confusion_matrix(y_train, np.rint(model.predict(np.array(x_train)/25))))\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_test, model.predict_classes(x_test))\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the output has 26 dimension, the accuracy is not the real accuracy for the systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial caeser function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to build a architechture for our deep learning model, we tried to use sigmoid function to build one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caeser funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, Caeser encryption function is $(n+3) mod 26$. key = 3 in this situation, but generally we can chose key as any integer number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit it by using sigmoid function, we can see in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return(1/(1 + math.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_caeser_function(x):\n",
    "    s1 = sigmoid(-30*(x-22.5))\n",
    "    s2 = sigmoid(30*(x-22.5))\n",
    "    y = (x+3)*s1+(x-23)*s2\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.953457900066243e-06"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_caeser_function(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ai_caeser_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fb0e461d9c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_caeser_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_caeser_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ai_caeser_function' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,26,.01), list(map(ai_caeser_function,np.arange(0,26,.01))),'-')\n",
    "plt.plot(np.arange(0,26,1), list(map(ai_caeser_function,np.arange(0,26,1))), 'g.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = (x-3)sigmoid(-30(x-22.5))+(x-23)sigmoid(30(x-22.5))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: try to build a similar structure for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use this function data to train the neural networks, let's see the if the prediction for one input one output model will be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihajun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2000, input_dim=1, name=\"test1\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_dim=1, init='uniform', name = 'test1'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(26, name = 'test2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test3'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test4'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(26, name = 'test5'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, name = 'test6'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.  , 3.01, 3.02, ..., 2.97, 2.98, 2.99])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(ai_caeser_function, np.arange(0,26,.01))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2600/2600 [==============================] - 3s 1ms/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "2600/2600 [==============================] - 0s 68us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "2600/2600 [==============================] - 0s 77us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "2600/2600 [==============================] - 0s 85us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "2600/2600 [==============================] - 0s 81us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "2600/2600 [==============================] - 0s 82us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "2600/2600 [==============================] - 0s 85us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "2600/2600 [==============================] - 0s 86us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "2600/2600 [==============================] - 0s 81us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "2600/2600 [==============================] - 0s 77us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "2600/2600 [==============================] - 0s 78us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "2600/2600 [==============================] - 0s 91us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "2600/2600 [==============================] - 0s 79us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "2600/2600 [==============================] - 0s 85us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "2600/2600 [==============================] - 0s 81us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "2600/2600 [==============================] - 0s 92us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "2600/2600 [==============================] - 0s 87us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "2600/2600 [==============================] - 0s 73us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "2600/2600 [==============================] - 0s 83us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "2600/2600 [==============================] - 0s 77us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "2600/2600 [==============================] - 0s 78us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "2600/2600 [==============================] - 0s 77us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "2600/2600 [==============================] - 0s 94us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "2600/2600 [==============================] - 0s 88us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "2600/2600 [==============================] - 0s 79us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "2600/2600 [==============================] - 0s 84us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "2600/2600 [==============================] - 0s 87us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "2600/2600 [==============================] - 0s 87us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "2600/2600 [==============================] - 0s 78us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "2600/2600 [==============================] - 0s 83us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "2600/2600 [==============================] - 0s 82us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "2600/2600 [==============================] - 0s 65us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "2600/2600 [==============================] - 0s 69us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "2600/2600 [==============================] - 0s 73us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "2600/2600 [==============================] - 0s 82us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "2600/2600 [==============================] - 0s 73us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "2600/2600 [==============================] - 0s 83us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "2600/2600 [==============================] - 0s 64us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "2600/2600 [==============================] - 0s 61us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "2600/2600 [==============================] - 0s 75us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "2600/2600 [==============================] - 0s 73us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "2600/2600 [==============================] - 0s 76us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "2600/2600 [==============================] - 0s 71us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "2600/2600 [==============================] - 0s 70us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "2600/2600 [==============================] - 0s 63us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "2600/2600 [==============================] - 0s 60us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "2600/2600 [==============================] - 0s 69us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "2600/2600 [==============================] - 0s 72us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "2600/2600 [==============================] - 0s 89us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "2600/2600 [==============================] - 0s 86us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "2600/2600 [==============================] - 0s 78us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "2600/2600 [==============================] - 0s 74us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "2600/2600 [==============================] - 0s 80us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "2600/2600 [==============================] - 0s 104us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "2600/2600 [==============================] - 0s 115us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "2600/2600 [==============================] - 0s 118us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "2600/2600 [==============================] - 0s 123us/step - loss: 211.7203 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "2600/2600 [==============================] - 0s 92us/step - loss: 211.7203 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a481ac2e8>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.arange(0,26,.01)/25, np.array(list(map(ai_caeser_function, np.arange(0,26,.01)))), epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it doesn't work amazing even we get enough data. If we have enough time, we will try to find a better structure for our networks to fit this function appropriately (roughly ideas is to set the sigmoid as an activation function for a layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will **take a long time** to run. We recommond to download the results/ folder in the main page, and if you open tensorboard by `tensorboard --logdir=results/`, you can see how the function change and how the loss reducing. Bacially, the loss will stay at 9, as the last 3 shifts are too hard to fit. If we trained 5000 times, the loss will decrease to 6, and start to learn something new as the pictures show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/xihajun/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Training our universal approximator\n",
      "batch: 100, loss: 43.954262\n",
      "batch: 200, loss: 19.234653\n",
      "batch: 300, loss: 10.666520\n",
      "batch: 400, loss: 9.649702\n",
      "batch: 500, loss: 9.367650\n",
      "batch: 600, loss: 9.268389\n",
      "batch: 700, loss: 9.143136\n",
      "batch: 800, loss: 9.262796\n",
      "batch: 900, loss: 9.267904\n",
      "batch: 1000, loss: 9.429953\n",
      "Plotting graphs\n"
     ]
    }
   ],
   "source": [
    "# this code is just for 1000 epochs\n",
    "# By modify the code from here: https://blog.metaflow.fr/tensorflow-howto-a-universal-approximator-inside-a-neural-net-bb034430b71e#.cves3pv8h\n",
    "%run neurons.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100: (the one above is the \"caeser\" function, another one is the prediction function)\n",
    "<img src=\"./images/100.png\" width=\"400\" height=\"300\">\n",
    "\n",
    "1000: (the one above is the \"caeser\" function, another one is the prediction function)\n",
    "<img src=\"./images/1000.png\" width=\"400\" height=\"300\">\n",
    "\n",
    "5000: (the one above is the \"caeser\" function, another one is the prediction function)\n",
    "<img src=\"./images/5000.png\" width=\"400\" height=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more, we tried use neurals more than 500 but it doesn't help anymore no matter for the loss reducing or function fitting effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 2 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function data_genelization in module myfun:\n",
      "\n",
      "data_genelization(sample_size=2, loops=1000, size=26, key=3, x_as_vector=False, y_as_vector=False)\n",
      "    data_genelization(sample_size = 2,loops = 1000, size = 26, key = 3, x_as_vector = False, y_as_vector = False):\n",
      "    return x_train, label with equual size, labels with 1 dimension\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_genelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling 1000 random sequences with length 2\n",
    "x_train, y_train, y_train_small = data_genelization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6609 - binary_accuracy: 0.7355\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.5519 - binary_accuracy: 0.9135\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.3407 - binary_accuracy: 0.9601\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.1922 - binary_accuracy: 0.9615\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.1680 - binary_accuracy: 0.9615\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.1644 - binary_accuracy: 0.9615\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.1621 - binary_accuracy: 0.9615\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.1603 - binary_accuracy: 0.9615\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.1588 - binary_accuracy: 0.9615\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.1573 - binary_accuracy: 0.9615\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.1557 - binary_accuracy: 0.9615\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.1540 - binary_accuracy: 0.9615\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.1523 - binary_accuracy: 0.9615\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1503 - binary_accuracy: 0.9615\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1482 - binary_accuracy: 0.9615\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1458 - binary_accuracy: 0.9615\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1433 - binary_accuracy: 0.9615\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1405 - binary_accuracy: 0.9615\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.1376 - binary_accuracy: 0.9615\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.1344 - binary_accuracy: 0.9615\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1310 - binary_accuracy: 0.9616\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1275 - binary_accuracy: 0.9617\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1239 - binary_accuracy: 0.9617\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1201 - binary_accuracy: 0.9618\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1162 - binary_accuracy: 0.9621\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1123 - binary_accuracy: 0.9622\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1083 - binary_accuracy: 0.9626\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.1042 - binary_accuracy: 0.9631\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.1002 - binary_accuracy: 0.9638\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0963 - binary_accuracy: 0.9644\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0924 - binary_accuracy: 0.9652\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0886 - binary_accuracy: 0.9662\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0847 - binary_accuracy: 0.967 - 0s 66us/step - loss: 0.0849 - binary_accuracy: 0.9673\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0814 - binary_accuracy: 0.9686\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0779 - binary_accuracy: 0.9702\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0747 - binary_accuracy: 0.9712\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0715 - binary_accuracy: 0.9732\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0685 - binary_accuracy: 0.9744\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0655 - binary_accuracy: 0.9759\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0628 - binary_accuracy: 0.9769\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0600 - binary_accuracy: 0.9782\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0575 - binary_accuracy: 0.9794\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0549 - binary_accuracy: 0.9812\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0524 - binary_accuracy: 0.9822\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0501 - binary_accuracy: 0.9835\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0478 - binary_accuracy: 0.9846\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0457 - binary_accuracy: 0.9852\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0436 - binary_accuracy: 0.9862\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0416 - binary_accuracy: 0.9867\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0396 - binary_accuracy: 0.9873\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0379 - binary_accuracy: 0.9885\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0361 - binary_accuracy: 0.9896\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0344 - binary_accuracy: 0.9900\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0329 - binary_accuracy: 0.9907\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0314 - binary_accuracy: 0.9914\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0300 - binary_accuracy: 0.9916\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0286 - binary_accuracy: 0.9922\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0273 - binary_accuracy: 0.9927\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0261 - binary_accuracy: 0.9930\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0250 - binary_accuracy: 0.9934\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0239 - binary_accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0229 - binary_accuracy: 0.9941\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0219 - binary_accuracy: 0.9944\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0210 - binary_accuracy: 0.9946\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0201 - binary_accuracy: 0.9950\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0192 - binary_accuracy: 0.9952\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.0185 - binary_accuracy: 0.9953\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0177 - binary_accuracy: 0.9957\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.0169 - binary_accuracy: 0.9958\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0162 - binary_accuracy: 0.9961\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0156 - binary_accuracy: 0.9961\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.0149 - binary_accuracy: 0.9963\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.0143 - binary_accuracy: 0.9965\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0137 - binary_accuracy: 0.9968\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0131 - binary_accuracy: 0.9970\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0126 - binary_accuracy: 0.9971\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0121 - binary_accuracy: 0.9973\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0116 - binary_accuracy: 0.9974\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0111 - binary_accuracy: 0.9975\n",
      "Epoch 80/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0106 - binary_accuracy: 0.9977\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0102 - binary_accuracy: 0.9979\n",
      "Epoch 82/200\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0098 - binary_accuracy: 0.9981\n",
      "Epoch 83/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0094 - binary_accuracy: 0.9981\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0090 - binary_accuracy: 0.9983\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0087 - binary_accuracy: 0.9983\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0083 - binary_accuracy: 0.9984\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.0080 - binary_accuracy: 0.9985\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.0077 - binary_accuracy: 0.9985\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0074 - binary_accuracy: 0.9986\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0071 - binary_accuracy: 0.9987\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0068 - binary_accuracy: 0.9988\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0065 - binary_accuracy: 0.9989\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0063 - binary_accuracy: 0.9989\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0060 - binary_accuracy: 0.9990\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0058 - binary_accuracy: 0.9990\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0056 - binary_accuracy: 0.9991\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0054 - binary_accuracy: 0.9992\n",
      "Epoch 98/200\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0051 - binary_accuracy: 0.9992\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0049 - binary_accuracy: 0.9992\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0048 - binary_accuracy: 0.9992\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0046 - binary_accuracy: 0.9993\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0044 - binary_accuracy: 0.9995\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0042 - binary_accuracy: 0.9994\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0041 - binary_accuracy: 0.9995\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0039 - binary_accuracy: 0.9995\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0038 - binary_accuracy: 0.9995\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0036 - binary_accuracy: 0.9996\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0035 - binary_accuracy: 0.9995\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0034 - binary_accuracy: 0.9996\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0033 - binary_accuracy: 0.9997\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0032 - binary_accuracy: 0.9997\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0030 - binary_accuracy: 0.9998\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0029 - binary_accuracy: 0.9998\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0028 - binary_accuracy: 0.9998\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0027 - binary_accuracy: 0.9998\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0026 - binary_accuracy: 0.9998\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0025 - binary_accuracy: 0.9998\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0024 - binary_accuracy: 0.9999\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0023 - binary_accuracy: 0.9999\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0023 - binary_accuracy: 0.9999\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0022 - binary_accuracy: 0.9999\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0021 - binary_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0020 - binary_accuracy: 0.9999\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0010 - binary_accuracy: 1.0000\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0010 - binary_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 9.7466e-04 - binary_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 9.4375e-04 - binary_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 9.1543e-04 - binary_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 8.8831e-04 - binary_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 8.6660e-04 - binary_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 8.3751e-04 - binary_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 8.1315e-04 - binary_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 7.9372e-04 - binary_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 7.6942e-04 - binary_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 7.4801e-04 - binary_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 7.2518e-04 - binary_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 7.0446e-04 - binary_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 6.9158e-04 - binary_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 6.6578e-04 - binary_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 6.4470e-04 - binary_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 6.2957e-04 - binary_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 6.1202e-04 - binary_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 5.9723e-04 - binary_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 5.7943e-04 - binary_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 5.6149e-04 - binary_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 5.4661e-04 - binary_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 5.3276e-04 - binary_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 5.1935e-04 - binary_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 5.0489e-04 - binary_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 4.9267e-04 - binary_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 4.7820e-04 - binary_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 4.6636e-04 - binary_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 4.5307e-04 - binary_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 4.4312e-04 - binary_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 4.3030e-04 - binary_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 4.1932e-04 - binary_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 4.0941e-04 - binary_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 3.9836e-04 - binary_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 3.8856e-04 - binary_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 3.7722e-04 - binary_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 3.6798e-04 - binary_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 3.5879e-04 - binary_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 3.4966e-04 - binary_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 3.4302e-04 - binary_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 3.3155e-04 - binary_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 3.2308e-04 - binary_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 3.1475e-04 - binary_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 3.0792e-04 - binary_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 3.0027e-04 - binary_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 2.9206e-04 - binary_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 2.8587e-04 - binary_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 2.7924e-04 - binary_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.7101e-04 - binary_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 2.6510e-04 - binary_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 2.5922e-04 - binary_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 2.5196e-04 - binary_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.4593e-04 - binary_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 2.4061e-04 - binary_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 2.3543e-04 - binary_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.2856e-04 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a576472b0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index1, index2, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return ([I2L[index1], I2L[index2]])\n",
    "\n",
    "\n",
    "def predict_results_only_2(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index1 = np.argmax(predictions[:, 0:26], axis=1)\n",
    "    index2 = np.argmax(predictions[:, 26:52], axis=1)\n",
    "    label1 = np.argmax(y_train[:, 0:26], axis=1)\n",
    "    label2 = np.argmax(y_train[:, 26:52], axis=1)\n",
    "\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index1, index2))\n",
    "    label_list = list(map(num2str, label1, label2))\n",
    "\n",
    "    return (prediction_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(list1, list2):   \n",
    "    if \"\".join(list1) != \"\".join(list2):\n",
    "        return(\"\".join(list1), \"\".join(list2))\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "\n",
      "binary_accuracy: 99.82%\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test, y_test_small = data_genelization()\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "prediction_list, label_list = predict_results_only_2(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZI ZI\n",
      "VN VN\n",
      "XR XR\n",
      "TO TO\n",
      "IK IK\n",
      "QB QB\n",
      "ZA ZA\n",
      "SM SM\n",
      "XC XC\n",
      "MJ MJ\n",
      "PM PM\n",
      "KP KP\n",
      "TR TR\n",
      "XW XW\n",
      "JF JF\n",
      "ZX ZX\n",
      "OJ OJ\n",
      "AH AH\n",
      "EJ EJ\n",
      "UA UA\n",
      "XP XP\n",
      "KV KV\n",
      "DZ DZ\n",
      "LY LY\n",
      "BO BO\n",
      "TS TS\n",
      "TP TP\n",
      "PJ PJ\n",
      "RE RE\n",
      "XN XN\n",
      "RM RM\n",
      "MG MG\n",
      "PP PP\n",
      "YK YK\n",
      "NU NU\n",
      "LK LK\n",
      "EG EG\n",
      "KS KS\n",
      "HM HM\n",
      "WR WR\n",
      "VB VB\n",
      "SG SG\n",
      "HS HS\n",
      "TZ TZ\n",
      "MH MH\n",
      "JK JK\n",
      "BE BE\n",
      "SX SX\n",
      "NJ NJ\n",
      "CE CE\n",
      "AF AF\n",
      "OB OB\n",
      "EP EP\n",
      "OW OW\n",
      "HW HW\n",
      "PL PL\n",
      "MV MV\n",
      "FO FO\n",
      "OW OW\n",
      "VI VI\n",
      "OQ OQ\n",
      "ET ET\n",
      "FD FD\n",
      "VA VA\n",
      "WE WE\n",
      "RG RG\n",
      "YA YA\n",
      "KZ KZ\n",
      "EN EN\n",
      "IF IF\n",
      "HL HL\n",
      "PN PN\n",
      "JL JL\n",
      "KK KK\n",
      "TT TT\n",
      "IP IP\n",
      "OP OP\n",
      "LT LT\n",
      "VM VM\n",
      "KY KY\n",
      "SE SE\n",
      "ET ET\n",
      "LG LG\n",
      "SK SK\n",
      "IM IM\n",
      "QW QW\n",
      "TT TT\n",
      "MO MO\n",
      "WF WF\n",
      "DX DX\n",
      "WY WY\n",
      "OZ OZ\n",
      "EA EA\n",
      "WF WF\n",
      "XN XN\n",
      "WL WL\n",
      "IX IX\n",
      "XM XM\n",
      "NZ NZ\n",
      "SS SS\n",
      "EX EX\n",
      "CE CE\n",
      "GL GL\n",
      "YF YF\n",
      "FH FH\n",
      "YA YA\n",
      "EX EX\n",
      "VK VK\n",
      "YT YT\n",
      "CD CD\n",
      "SG SG\n",
      "OA OA\n",
      "NO NO\n",
      "OQ OQ\n",
      "OQ OQ\n",
      "EH EH\n",
      "KN KN\n",
      "DR DR\n",
      "PB PF\n",
      "LU LU\n",
      "HW HW\n",
      "SS SS\n",
      "PD PD\n",
      "RM RM\n",
      "WU WM\n",
      "TC TC\n",
      "JR JR\n",
      "LF LF\n",
      "GR HE\n",
      "CF CF\n",
      "RQ RQ\n",
      "QE QE\n",
      "WW WW\n",
      "AM AM\n",
      "XM XM\n",
      "TI TI\n",
      "WD WD\n",
      "YB YB\n",
      "MY MY\n",
      "RR RR\n",
      "SG SG\n",
      "ID ID\n",
      "EI EI\n",
      "HC HC\n",
      "KM KM\n",
      "AK AK\n",
      "ET ET\n",
      "TQ TQ\n",
      "FI FI\n",
      "IA IA\n",
      "IC IC\n",
      "YZ YZ\n",
      "DO DO\n",
      "JQ JQ\n",
      "NJ NJ\n",
      "FR FR\n",
      "YF YF\n",
      "VN VN\n",
      "ZF ZF\n",
      "DD DD\n",
      "QT QT\n",
      "UZ UZ\n",
      "OH OH\n",
      "LN LN\n",
      "SB SB\n",
      "ZW ZW\n",
      "YK YK\n",
      "MY MY\n",
      "CT CT\n",
      "XV XV\n",
      "DT DT\n",
      "XK XK\n",
      "PT PT\n",
      "MQ MQ\n",
      "TV TV\n",
      "IG IG\n",
      "SI SI\n",
      "MM MM\n",
      "AP AP\n",
      "MW MW\n",
      "NS NS\n",
      "RL RL\n",
      "LN LN\n",
      "AP AP\n",
      "PI PI\n",
      "AC AC\n",
      "LW LW\n",
      "RL RL\n",
      "SS SS\n",
      "SJ SJ\n",
      "VG VG\n",
      "UL UL\n",
      "QL QL\n",
      "XC XC\n",
      "HZ HZ\n",
      "OG OG\n",
      "LC LC\n",
      "QG QG\n",
      "YW YW\n",
      "YT YT\n",
      "MO MO\n",
      "ZH ZH\n",
      "OL OL\n",
      "GL GL\n",
      "SH SH\n",
      "KL KL\n",
      "SN SN\n",
      "ER ER\n",
      "JN JN\n",
      "HX HX\n",
      "LT LT\n",
      "LB LB\n",
      "DU DU\n",
      "UG UG\n",
      "GP GP\n",
      "MJ MJ\n",
      "NH NH\n",
      "AE AE\n",
      "FJ FJ\n",
      "XJ XJ\n",
      "SV SV\n",
      "KX KX\n",
      "EW EW\n",
      "AO AO\n",
      "MU MU\n",
      "KG KG\n",
      "LA LA\n",
      "AF AF\n",
      "NZ NZ\n",
      "WW JW\n",
      "EE EE\n",
      "MF MF\n",
      "XJ XJ\n",
      "NQ NQ\n",
      "XF XF\n",
      "QQ QQ\n",
      "DC DC\n",
      "YV YV\n",
      "FZ FZ\n",
      "TV TV\n",
      "ND ND\n",
      "XH XH\n",
      "PC PC\n",
      "FB FB\n",
      "OO OO\n",
      "ML ML\n",
      "UL UL\n",
      "EY EY\n",
      "YV YV\n",
      "YG YG\n",
      "AY AY\n",
      "SU SU\n",
      "RZ RZ\n",
      "RM RM\n",
      "OF OF\n",
      "GY GY\n",
      "XL XL\n",
      "TV TV\n",
      "WF WF\n",
      "CD CD\n",
      "PQ PQ\n",
      "CQ CQ\n",
      "XB XB\n",
      "XQ XQ\n",
      "IZ IZ\n",
      "TW TW\n",
      "LW LW\n",
      "WB WB\n",
      "HD HD\n",
      "TJ TJ\n",
      "NS NS\n",
      "GS GS\n",
      "FA FA\n",
      "ME ME\n",
      "SD SD\n",
      "SE SE\n",
      "QK QK\n",
      "XL XL\n",
      "FK FK\n",
      "RE RE\n",
      "NM NM\n",
      "YB YB\n",
      "VH VH\n",
      "OX OX\n",
      "ZJ ZJ\n",
      "DJ DJ\n",
      "YI YI\n",
      "UB UB\n",
      "VR VR\n",
      "EA EA\n",
      "DQ DQ\n",
      "NC NC\n",
      "VM VM\n",
      "QX QX\n",
      "GQ GQ\n",
      "ZG ZG\n",
      "DG DG\n",
      "WK WK\n",
      "QK QK\n",
      "ZG ZG\n",
      "KG KG\n",
      "UF UF\n",
      "JF JF\n",
      "CE CE\n",
      "UN UN\n",
      "WO WO\n",
      "HU HU\n",
      "VH VH\n",
      "QU QU\n",
      "SG SG\n",
      "KR KR\n",
      "CU CU\n",
      "RO RO\n",
      "CA CA\n",
      "DJ DJ\n",
      "ZP ZP\n",
      "BU BU\n",
      "PE PE\n",
      "PM PM\n",
      "WL WL\n",
      "YN YN\n",
      "DQ DQ\n",
      "VR VR\n",
      "IL IL\n",
      "QN QN\n",
      "MT MT\n",
      "DR DR\n",
      "PB PB\n",
      "OV OV\n",
      "EC EC\n",
      "WK WK\n",
      "SR SR\n",
      "NS NS\n",
      "OY OY\n",
      "VJ VJ\n",
      "BP BP\n",
      "OI OI\n",
      "VV VV\n",
      "QO QO\n",
      "AJ AJ\n",
      "HR HR\n",
      "XD XD\n",
      "HB HB\n",
      "WU WM\n",
      "GS GS\n",
      "FE FE\n",
      "OO OO\n",
      "CJ CJ\n",
      "VI VI\n",
      "XI XI\n",
      "SJ SJ\n",
      "CI CI\n",
      "IH IH\n",
      "QO QO\n",
      "BU BU\n",
      "PV PV\n",
      "XM XM\n",
      "MO MO\n",
      "CB CB\n",
      "OQ OQ\n",
      "KA KA\n",
      "TQ TQ\n",
      "WF WF\n",
      "BU BU\n",
      "OJ OJ\n",
      "RY RY\n",
      "GJ GJ\n",
      "YC YC\n",
      "NO NO\n",
      "ZJ ZJ\n",
      "RR XY\n",
      "UQ UQ\n",
      "GJ GJ\n",
      "BW BW\n",
      "IJ IJ\n",
      "QA QA\n",
      "VG VG\n",
      "VL VL\n",
      "CP CP\n",
      "BN BN\n",
      "YW YW\n",
      "HR HR\n",
      "IZ IZ\n",
      "VS VS\n",
      "DV DV\n",
      "VI VI\n",
      "EA EA\n",
      "LR LR\n",
      "TG TG\n",
      "BM BM\n",
      "XH XH\n",
      "GU GU\n",
      "VP VP\n",
      "FY FY\n",
      "JG JG\n",
      "RI RI\n",
      "WL WL\n",
      "BV BV\n",
      "EE EE\n",
      "IS IS\n",
      "VG VG\n",
      "OS OS\n",
      "WW WW\n",
      "AS AS\n",
      "HY HY\n",
      "HY HY\n",
      "YV YV\n",
      "AA AA\n",
      "LD LD\n",
      "PE PE\n",
      "YT YT\n",
      "RG RG\n",
      "HT HT\n",
      "GO GO\n",
      "WQ WQ\n",
      "YG YG\n",
      "FY FY\n",
      "XM XM\n",
      "HH HH\n",
      "AC AC\n",
      "XC XC\n",
      "DU DU\n",
      "RX RX\n",
      "RR XY\n",
      "DC DC\n",
      "OU OU\n",
      "GU GU\n",
      "KG KG\n",
      "MG MG\n",
      "YZ YZ\n",
      "NH NH\n",
      "HX HX\n",
      "JV JV\n",
      "IL IL\n",
      "SM SM\n",
      "XG XG\n",
      "BQ BQ\n",
      "BO BO\n",
      "FI FI\n",
      "EU EU\n",
      "NS NS\n",
      "VP VP\n",
      "XR XR\n",
      "KT KT\n",
      "KA KA\n",
      "GR GR\n",
      "YE YE\n",
      "AH AH\n",
      "JV JV\n",
      "FU FU\n",
      "GI GI\n",
      "KP KP\n",
      "ZO ZO\n",
      "XQ XQ\n",
      "AX AX\n",
      "TD TD\n",
      "LV LV\n",
      "FC FC\n",
      "GU GU\n",
      "JF JF\n",
      "FB FB\n",
      "QJ QJ\n",
      "NY NY\n",
      "IY IY\n",
      "LS LS\n",
      "TX TX\n",
      "QG QG\n",
      "AR AR\n",
      "DU DU\n",
      "NB NB\n",
      "GW GW\n",
      "MI MI\n",
      "PW PW\n",
      "WJ WJ\n",
      "JQ JQ\n",
      "XI XI\n",
      "YP YP\n",
      "YL YL\n",
      "RD RD\n",
      "DJ DJ\n",
      "TM TM\n",
      "EZ EZ\n",
      "PV PV\n",
      "BJ BJ\n",
      "MF MF\n",
      "FI FI\n",
      "OU OU\n",
      "NG NG\n",
      "OP OP\n",
      "CQ CQ\n",
      "CZ CZ\n",
      "LH LH\n",
      "GZ GZ\n",
      "EQ EQ\n",
      "KZ KZ\n",
      "ST ST\n",
      "VQ VQ\n",
      "GN GN\n",
      "OQ OQ\n",
      "VS VS\n",
      "EI EI\n",
      "SM VU\n",
      "YK YK\n",
      "TW TW\n",
      "KW KW\n",
      "QH QH\n",
      "BH BH\n",
      "TJ TJ\n",
      "PK PK\n",
      "MI MI\n",
      "TQ TQ\n",
      "TL TL\n",
      "PN PN\n",
      "EQ EQ\n",
      "ON ON\n",
      "TV TV\n",
      "PU PU\n",
      "PI PI\n",
      "RX RX\n",
      "LB LB\n",
      "DK DK\n",
      "FS FS\n",
      "KW KW\n",
      "JF JF\n",
      "SQ SQ\n",
      "VE VE\n",
      "MS MS\n",
      "NV NV\n",
      "WU WU\n",
      "ED ED\n",
      "BC BC\n",
      "IH IH\n",
      "TU TU\n",
      "JG JG\n",
      "JJ JJ\n",
      "HN HN\n",
      "VJ VJ\n",
      "FR FR\n",
      "DR DR\n",
      "KP KP\n",
      "XW XW\n",
      "CO CO\n",
      "TM TM\n",
      "QF QF\n",
      "GL GL\n",
      "TJ TJ\n",
      "JP JP\n",
      "QY QY\n",
      "ML ML\n",
      "RM RM\n",
      "BN BN\n",
      "FQ FQ\n",
      "BM BM\n",
      "BV BV\n",
      "KB KB\n",
      "QI QI\n",
      "CU CU\n",
      "LQ LQ\n",
      "JY JY\n",
      "BO BO\n",
      "KO KO\n",
      "SA SA\n",
      "ME ME\n",
      "SG SG\n",
      "ZO ZO\n",
      "WZ WZ\n",
      "AW AW\n",
      "JC JC\n",
      "JT JT\n",
      "CJ CJ\n",
      "VC VC\n",
      "QW CW\n",
      "TE TE\n",
      "IG IG\n",
      "NK NK\n",
      "HS HS\n",
      "OY OY\n",
      "CS CS\n",
      "TS TS\n",
      "IJ IJ\n",
      "YE YE\n",
      "JM JM\n",
      "DK DK\n",
      "TG TG\n",
      "DI DI\n",
      "BG BG\n",
      "LO LO\n",
      "IX IX\n",
      "DP DP\n",
      "LK LK\n",
      "BL BL\n",
      "ZT ZT\n",
      "DZ DZ\n",
      "YC YC\n",
      "UG UG\n",
      "KV KV\n",
      "QN QN\n",
      "VC VC\n",
      "FB FB\n",
      "TX TX\n",
      "JX JX\n",
      "QO QO\n",
      "JY JY\n",
      "HN HN\n",
      "DG DG\n",
      "XF XF\n",
      "WS WS\n",
      "WD WD\n",
      "KJ KJ\n",
      "AS AS\n",
      "MG MG\n",
      "JL JL\n",
      "LA LA\n",
      "NK NK\n",
      "TT TT\n",
      "AW AW\n",
      "DT DT\n",
      "VN VN\n",
      "ED ED\n",
      "HX HX\n",
      "YD YD\n",
      "NF NF\n",
      "TJ TJ\n",
      "BQ BQ\n",
      "FQ FQ\n",
      "ZC ZC\n",
      "WQ WQ\n",
      "EP EP\n",
      "VP VP\n",
      "VT VT\n",
      "DO DO\n",
      "BW BW\n",
      "RA RA\n",
      "ET ET\n",
      "AW AW\n",
      "CV CV\n",
      "MN MN\n",
      "QO QO\n",
      "CB CB\n",
      "TZ TZ\n",
      "QB QB\n",
      "PX PX\n",
      "JJ JJ\n",
      "BD BD\n",
      "XN XN\n",
      "TC TC\n",
      "BR BR\n",
      "DK DK\n",
      "FM FM\n",
      "KY KY\n",
      "KP KP\n",
      "CA CA\n",
      "JL JL\n",
      "GI GI\n",
      "BD BD\n",
      "PU PU\n",
      "WC WC\n",
      "OI OI\n",
      "OX OX\n",
      "SM SM\n",
      "TX TX\n",
      "KD KD\n",
      "JZ JZ\n",
      "CT CT\n",
      "AH AH\n",
      "US US\n",
      "JZ JZ\n",
      "EA EA\n",
      "DN DN\n",
      "SV SV\n",
      "TZ TZ\n",
      "LV LV\n",
      "EZ EZ\n",
      "JP JP\n",
      "GH GH\n",
      "OQ OQ\n",
      "PK PK\n",
      "JR JR\n",
      "YO YO\n",
      "WR WR\n",
      "SS SS\n",
      "JN JN\n",
      "XV XV\n",
      "UT UT\n",
      "PD PD\n",
      "OE OE\n",
      "CB CB\n",
      "EI EI\n",
      "KQ KQ\n",
      "FK FK\n",
      "LI LI\n",
      "ZF ZF\n",
      "RS RS\n",
      "HF HF\n",
      "QP QP\n",
      "VO VO\n",
      "TA TA\n",
      "KR KR\n",
      "EQ EQ\n",
      "VN VX\n",
      "KW KW\n",
      "WI WI\n",
      "YE YE\n",
      "TZ TZ\n",
      "LT LT\n",
      "SU SU\n",
      "YI YI\n",
      "VI VI\n",
      "YP YP\n",
      "JA JA\n",
      "JY JY\n",
      "BG BG\n",
      "ZL ZL\n",
      "IL IL\n",
      "IK IK\n",
      "QJ QJ\n",
      "AK AK\n",
      "WU WU\n",
      "QG QG\n",
      "TK TK\n",
      "YX YX\n",
      "FV FV\n",
      "OI OI\n",
      "HV HV\n",
      "ZF ZF\n",
      "YA YA\n",
      "EO EO\n",
      "IU IU\n",
      "AC AC\n",
      "UA UA\n",
      "SF SF\n",
      "IU IU\n",
      "JG JG\n",
      "NN NN\n",
      "RF RF\n",
      "YS YS\n",
      "WD WD\n",
      "ZU ZU\n",
      "LF LF\n",
      "DU DU\n",
      "JY JY\n",
      "QJ QJ\n",
      "PI PI\n",
      "HZ HZ\n",
      "NH NH\n",
      "HB HB\n",
      "MB MB\n",
      "KX KX\n",
      "CT CT\n",
      "VM VM\n",
      "CQ CQ\n",
      "WX WX\n",
      "OA OA\n",
      "GU GU\n",
      "WQ WQ\n",
      "EW EW\n",
      "VA VA\n",
      "IP IP\n",
      "WF WF\n",
      "ZS ZS\n",
      "ZL ZL\n",
      "CR CR\n",
      "GK GK\n",
      "PI PI\n",
      "TU TU\n",
      "GR HE\n",
      "UJ UJ\n",
      "QT QT\n",
      "UH UH\n",
      "SM SM\n",
      "GS GS\n",
      "GW GW\n",
      "GD GD\n",
      "XH XH\n",
      "IU IU\n",
      "TR TR\n",
      "ET ET\n",
      "DE DE\n",
      "XB XB\n",
      "BO BO\n",
      "XV XV\n",
      "BY BY\n",
      "LQ LQ\n",
      "VM VM\n",
      "BW BW\n",
      "LB LB\n",
      "TB TB\n",
      "QP QP\n",
      "VL VL\n",
      "FG FG\n",
      "CF CF\n",
      "DA DA\n",
      "TH TH\n",
      "VY VY\n",
      "CZ CZ\n",
      "RX RX\n",
      "WD WD\n",
      "HA HA\n",
      "XO XO\n",
      "UE UE\n",
      "YF YF\n",
      "YM YM\n",
      "GK GK\n",
      "SH SH\n",
      "IQ IQ\n",
      "JG JG\n",
      "IR IR\n",
      "FV FV\n",
      "MH MH\n",
      "ZH ZH\n",
      "MS MS\n",
      "NQ NQ\n",
      "HL HL\n",
      "TK TK\n",
      "GG GG\n",
      "RZ RZ\n",
      "EL EL\n",
      "KP KP\n",
      "LH LH\n",
      "NR NR\n",
      "RR XY\n",
      "YJ YJ\n",
      "CO CO\n",
      "YK YK\n",
      "RR XY\n",
      "DX DX\n",
      "UY UY\n",
      "SH SH\n",
      "WP WP\n",
      "QA QA\n",
      "AM AM\n",
      "SJ SJ\n",
      "AW AW\n",
      "JA JA\n",
      "BM BM\n",
      "EX EX\n",
      "QG QG\n",
      "DC DC\n",
      "PA PA\n",
      "OP OP\n",
      "ZM ZM\n",
      "AF AF\n",
      "MV MV\n",
      "MW MW\n",
      "JR JR\n",
      "FS FS\n",
      "GR HE\n",
      "VI VI\n",
      "LT LT\n",
      "AX AX\n",
      "DO DO\n",
      "AE AE\n",
      "XQ XQ\n",
      "UK UK\n",
      "HA HA\n",
      "VP VP\n",
      "FA FA\n",
      "KX KX\n",
      "WX WX\n",
      "JS JS\n",
      "RV RV\n",
      "DM DM\n",
      "XT XT\n",
      "XO XO\n",
      "JY JY\n",
      "JD JD\n",
      "RR RR\n",
      "WY WY\n",
      "DH DH\n",
      "AL AL\n",
      "PG PG\n",
      "US US\n",
      "BT BT\n",
      "TR TR\n",
      "YR YR\n",
      "LQ LQ\n",
      "GM GM\n",
      "MF MF\n",
      "ZK ZK\n",
      "SW SW\n",
      "QN QN\n",
      "BS BS\n",
      "JG JG\n",
      "IJ IJ\n",
      "GT GT\n",
      "SM VU\n",
      "OZ OZ\n",
      "BX BX\n",
      "YU YU\n",
      "OF OF\n",
      "PZ PZ\n",
      "FV FV\n",
      "ZC ZC\n",
      "BV BV\n",
      "KZ KZ\n",
      "IC IC\n",
      "KK KK\n",
      "GE GE\n",
      "CS CS\n",
      "RV RV\n",
      "CR CR\n",
      "YM YM\n",
      "FL FL\n",
      "MM MM\n",
      "YM YM\n",
      "JT JT\n",
      "DK DK\n",
      "RN RN\n",
      "QK QK\n",
      "WX WX\n",
      "QZ QZ\n",
      "DL DL\n",
      "CP CP\n",
      "PX PX\n",
      "MR MR\n",
      "ZG ZG\n",
      "SP SP\n",
      "DL DL\n",
      "LM LM\n",
      "IG IG\n",
      "MR MR\n",
      "HQ HQ\n",
      "DU DU\n",
      "SD SD\n",
      "KI KI\n",
      "SI SI\n",
      "HD HD\n",
      "UM UM\n",
      "PB PB\n",
      "MQ MQ\n",
      "YC YC\n",
      "NO NO\n",
      "JX JX\n",
      "GV GV\n",
      "DE DE\n",
      "OS OS\n",
      "CN CN\n",
      "YE YE\n",
      "MF MF\n",
      "MU MU\n",
      "DH DH\n",
      "IY IY\n",
      "AX AX\n",
      "GR GR\n",
      "WQ WQ\n",
      "DX DX\n",
      "XA XA\n",
      "ZW ZW\n",
      "BF BF\n",
      "OC OC\n",
      "XQ XQ\n",
      "ZA ZA\n",
      "VE VE\n",
      "HC HC\n",
      "ZX ZX\n",
      "IC IC\n",
      "HU HU\n",
      "YD YD\n",
      "NF NF\n",
      "KZ KZ\n",
      "JH JH\n",
      "VD VD\n",
      "FA FA\n",
      "SS SS\n",
      "VW VW\n",
      "GK GK\n",
      "UZ UZ\n",
      "AZ AZ\n",
      "VY VY\n",
      "PY PY\n",
      "YF YF\n",
      "LP LP\n",
      "CI CI\n",
      "QI QI\n",
      "GX GX\n",
      "AZ AZ\n",
      "GB GB\n",
      "LM LM\n",
      "SS SS\n",
      "UO UO\n",
      "OG OG\n",
      "SZ SZ\n",
      "MR MR\n",
      "DA DA\n",
      "WZ WZ\n",
      "QA QA\n",
      "MZ MZ\n",
      "FJ FJ\n",
      "OM OM\n",
      "LH LH\n",
      "XD XD\n",
      "GS GS\n",
      "RR RR\n",
      "SQ SQ\n",
      "HC HC\n",
      "PH PH\n",
      "VZ VZ\n",
      "YD YD\n",
      "IJ IJ\n",
      "UU UU\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prediction_list)):\n",
    "    print(\"\".join(prediction_list[i]), \"\".join(label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PB', 'PF'),\n",
       " ('WU', 'WM'),\n",
       " ('GR', 'HE'),\n",
       " ('WW', 'JW'),\n",
       " ('RR', 'XY'),\n",
       " ('SM', 'VU'),\n",
       " ('QW', 'CW'),\n",
       " ('VN', 'VX')]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))\n",
    "output = []\n",
    "for x in diff:\n",
    "    if x not in output:\n",
    "        output.append(x)\n",
    "print(\"Errors:\")\n",
    "output.remove(True)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick an error see if the model can predict it well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [\"VN\"]\n",
    "for i in range(1000):\n",
    "    temp.append(\"SA\")\n",
    "x_test, y_test, y_test_small = data_test(temp)\n",
    "prediction_list, label_list = predict_results_only_2(model, x_test, y_test)\n",
    "diff = list(map(find_diff, prediction_list, label_list))\n",
    "output = []\n",
    "for x in diff:\n",
    "    if x not in output:\n",
    "        output.append(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 3 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 3 letters have 17576 different combinations, we set the for loop times to 20000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "x_train, y_train, y_train_small = data_genelization(sample_size = 3, loops = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 5s 235us/step - loss: 0.2133 - binary_accuracy: 0.9480\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.1229 - binary_accuracy: 0.9623\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.0816 - binary_accuracy: 0.9714\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 76us/step - loss: 0.0571 - binary_accuracy: 0.9810\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 1s 73us/step - loss: 0.0433 - binary_accuracy: 0.9863\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 1s 74us/step - loss: 0.0351 - binary_accuracy: 0.9894\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.0296 - binary_accuracy: 0.9914\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.0249 - binary_accuracy: 0.9930\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 1s 69us/step - loss: 0.0203 - binary_accuracy: 0.9944\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.0158 - binary_accuracy: 0.9957\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.0119 - binary_accuracy: 0.9969\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.0085 - binary_accuracy: 0.9980\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.0057 - binary_accuracy: 0.9988\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.0037 - binary_accuracy: 0.9994\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.0023 - binary_accuracy: 0.9997\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 1s 57us/step - loss: 0.0014 - binary_accuracy: 0.9999\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 9.2103e-04 - binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 1s 69us/step - loss: 5.9408e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 3.9398e-04 - binary_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 2.6408e-04 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a583c40f0>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index1, index2, index3, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return ([I2L[index1], I2L[index2], I2L[index3]])\n",
    "\n",
    "\n",
    "def predict_results_only_3(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index1 = np.argmax(predictions[:, 0:26], axis=1)\n",
    "    index2 = np.argmax(predictions[:, 26:52], axis=1)\n",
    "    index3 = np.argmax(predictions[:, 52:-1], axis=1)\n",
    "    label1 = np.argmax(y_train[:, 0:26], axis=1)\n",
    "    label2 = np.argmax(y_train[:, 26:52], axis=1)\n",
    "    label3 = np.argmax(y_train[:, 52:-1], axis=1)\n",
    "\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index1, index2, index3))\n",
    "    label_list = list(map(num2str, label1, label2, label3))\n",
    "\n",
    "    return (prediction_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(list1, list2):   \n",
    "    if \"\".join(list1) != \"\".join(list2):\n",
    "        return(\"\".join(list1), \"\".join(list2))\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test, y_test_small = data_genelization(sample_size = 3)\n",
    "prediction_list, label_list = predict_results_only_3(model, x_test, y_test)\n",
    "#prediction_list, label_list = predict_results_only_3(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 predictions:\n",
      "PSP PSP\n",
      "VAG VAG\n",
      "SQW SQW\n",
      "CLI CLI\n",
      "SPT SPT\n",
      "REE REE\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 6 predictions:\")\n",
    "for i in range(6):\n",
    "    print(\"\".join(prediction_list[i]), \"\".join(label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show some errors:\n",
      "('QFK', 'QFA')\n",
      "('LYK', 'LYA')\n",
      "('HUG', 'HUA')\n",
      "('WNK', 'WNA')\n",
      "('OJD', 'OJA')\n",
      "('FNK', 'FNA')\n",
      "The num of total errors: 33\n",
      "The accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))\n",
    "output = []\n",
    "for x in diff:\n",
    "    if x not in output:\n",
    "        output.append(x)\n",
    "print(\"Show some errors:\")\n",
    "output.remove(True)\n",
    "for i in range(6):\n",
    "    print(output[i])\n",
    "print(\"The num of total errors:\", len(output))\n",
    "print(\"The accuracy:\", 1-len(output)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 4 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6743 - binary_accuracy: 0.6908\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.5730 - binary_accuracy: 0.9254\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.3244 - binary_accuracy: 0.9588\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1773 - binary_accuracy: 0.9615\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1664 - binary_accuracy: 0.9615\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1640 - binary_accuracy: 0.9615\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1627 - binary_accuracy: 0.9615\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1618 - binary_accuracy: 0.9615\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1610 - binary_accuracy: 0.9615\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.1602 - binary_accuracy: 0.9615\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1594 - binary_accuracy: 0.9615\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1586 - binary_accuracy: 0.9615\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.1578 - binary_accuracy: 0.9615\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1568 - binary_accuracy: 0.9615\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1557 - binary_accuracy: 0.9615\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1546 - binary_accuracy: 0.9615\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1533 - binary_accuracy: 0.9615\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1520 - binary_accuracy: 0.9615\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1505 - binary_accuracy: 0.9615\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1489 - binary_accuracy: 0.9615\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1472 - binary_accuracy: 0.9615\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1454 - binary_accuracy: 0.9615\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1436 - binary_accuracy: 0.9615\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1416 - binary_accuracy: 0.9615\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.1397 - binary_accuracy: 0.9615\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.1377 - binary_accuracy: 0.9615\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1356 - binary_accuracy: 0.9615\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1336 - binary_accuracy: 0.9616\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1316 - binary_accuracy: 0.9616\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1296 - binary_accuracy: 0.9617\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1274 - binary_accuracy: 0.9617\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1252 - binary_accuracy: 0.9618\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1230 - binary_accuracy: 0.9619\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1209 - binary_accuracy: 0.9620\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1188 - binary_accuracy: 0.9622\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1167 - binary_accuracy: 0.9625\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.1148 - binary_accuracy: 0.9627\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1127 - binary_accuracy: 0.9629\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1109 - binary_accuracy: 0.9632\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1090 - binary_accuracy: 0.9636\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1072 - binary_accuracy: 0.9639\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1053 - binary_accuracy: 0.9645\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1036 - binary_accuracy: 0.9650\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1018 - binary_accuracy: 0.9655\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.1000 - binary_accuracy: 0.9659\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0983 - binary_accuracy: 0.9663\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0966 - binary_accuracy: 0.9670\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0949 - binary_accuracy: 0.9675\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0932 - binary_accuracy: 0.9680\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0916 - binary_accuracy: 0.9683\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0900 - binary_accuracy: 0.9688\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0885 - binary_accuracy: 0.9695\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0869 - binary_accuracy: 0.9698\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0855 - binary_accuracy: 0.9704\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0840 - binary_accuracy: 0.9709\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0826 - binary_accuracy: 0.9715\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0813 - binary_accuracy: 0.9718\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0799 - binary_accuracy: 0.9723\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0786 - binary_accuracy: 0.9725\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0774 - binary_accuracy: 0.9731\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0762 - binary_accuracy: 0.9735\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0750 - binary_accuracy: 0.9741\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.0738 - binary_accuracy: 0.9745\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.0727 - binary_accuracy: 0.9751\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0717 - binary_accuracy: 0.9753\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0706 - binary_accuracy: 0.9759\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0695 - binary_accuracy: 0.9763\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0684 - binary_accuracy: 0.9767\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0675 - binary_accuracy: 0.9770\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0665 - binary_accuracy: 0.9773\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0655 - binary_accuracy: 0.9777\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0645 - binary_accuracy: 0.9781\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 0s 108us/step - loss: 0.0636 - binary_accuracy: 0.9785\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0627 - binary_accuracy: 0.9790\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0618 - binary_accuracy: 0.9794\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0609 - binary_accuracy: 0.9797\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0601 - binary_accuracy: 0.9800\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0592 - binary_accuracy: 0.9800\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0584 - binary_accuracy: 0.9805\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0576 - binary_accuracy: 0.9807\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0568 - binary_accuracy: 0.9809\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.0560 - binary_accuracy: 0.9815\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0553 - binary_accuracy: 0.9816\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0546 - binary_accuracy: 0.9818\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0539 - binary_accuracy: 0.9820\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0532 - binary_accuracy: 0.9823\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0525 - binary_accuracy: 0.9826\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0518 - binary_accuracy: 0.9828\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0512 - binary_accuracy: 0.9831\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0505 - binary_accuracy: 0.9832\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0500 - binary_accuracy: 0.9837\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0494 - binary_accuracy: 0.9837\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0488 - binary_accuracy: 0.9840\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0483 - binary_accuracy: 0.9841\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0478 - binary_accuracy: 0.9844\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0472 - binary_accuracy: 0.9846\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0466 - binary_accuracy: 0.9847\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.0461 - binary_accuracy: 0.9849\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0456 - binary_accuracy: 0.9850\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0451 - binary_accuracy: 0.9855\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0446 - binary_accuracy: 0.9854\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0442 - binary_accuracy: 0.9858\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0437 - binary_accuracy: 0.9860\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0431 - binary_accuracy: 0.9861\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0427 - binary_accuracy: 0.9862\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0423 - binary_accuracy: 0.9864\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0418 - binary_accuracy: 0.9868\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0413 - binary_accuracy: 0.9869\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0409 - binary_accuracy: 0.9869\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0405 - binary_accuracy: 0.9874\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0401 - binary_accuracy: 0.9875\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 0.0396 - binary_accuracy: 0.9876\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 0s 105us/step - loss: 0.0393 - binary_accuracy: 0.9878\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.0388 - binary_accuracy: 0.9877\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.0384 - binary_accuracy: 0.9879\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0381 - binary_accuracy: 0.9883\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0378 - binary_accuracy: 0.9883\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0373 - binary_accuracy: 0.9885\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0370 - binary_accuracy: 0.9883\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0366 - binary_accuracy: 0.9888\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 0s 98us/step - loss: 0.0363 - binary_accuracy: 0.9887\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0359 - binary_accuracy: 0.9888\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0356 - binary_accuracy: 0.9889\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0352 - binary_accuracy: 0.9892\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0349 - binary_accuracy: 0.9891\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0347 - binary_accuracy: 0.9892\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0343 - binary_accuracy: 0.9896\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0340 - binary_accuracy: 0.9894\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0337 - binary_accuracy: 0.9897\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0334 - binary_accuracy: 0.9897\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0330 - binary_accuracy: 0.9898\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0327 - binary_accuracy: 0.9899\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0325 - binary_accuracy: 0.9899\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0321 - binary_accuracy: 0.9901\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 0s 107us/step - loss: 0.0319 - binary_accuracy: 0.9903\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0316 - binary_accuracy: 0.9904\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 0s 105us/step - loss: 0.0314 - binary_accuracy: 0.9905\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0310 - binary_accuracy: 0.9906\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0307 - binary_accuracy: 0.9908\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0305 - binary_accuracy: 0.9909\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0302 - binary_accuracy: 0.9910\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0300 - binary_accuracy: 0.9911\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0297 - binary_accuracy: 0.9911\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0293 - binary_accuracy: 0.9912\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0292 - binary_accuracy: 0.9914\n",
      "Epoch 146/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0288 - binary_accuracy: 0.9914\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0287 - binary_accuracy: 0.9915\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0283 - binary_accuracy: 0.9917\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0281 - binary_accuracy: 0.9915\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0278 - binary_accuracy: 0.9918\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0276 - binary_accuracy: 0.9920\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0274 - binary_accuracy: 0.9921\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0271 - binary_accuracy: 0.9921\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0269 - binary_accuracy: 0.9921\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0268 - binary_accuracy: 0.9921\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0264 - binary_accuracy: 0.9921\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0262 - binary_accuracy: 0.9923\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0259 - binary_accuracy: 0.9924\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.0257 - binary_accuracy: 0.9927\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0255 - binary_accuracy: 0.9925\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0253 - binary_accuracy: 0.9927\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0250 - binary_accuracy: 0.9929\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0249 - binary_accuracy: 0.9929\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0246 - binary_accuracy: 0.9929\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0244 - binary_accuracy: 0.9929\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0242 - binary_accuracy: 0.9931\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0240 - binary_accuracy: 0.9930\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0238 - binary_accuracy: 0.9933\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0236 - binary_accuracy: 0.9933\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0234 - binary_accuracy: 0.9934\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0231 - binary_accuracy: 0.9934\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0230 - binary_accuracy: 0.9935\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0228 - binary_accuracy: 0.9933\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0226 - binary_accuracy: 0.9935\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0224 - binary_accuracy: 0.9937\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0223 - binary_accuracy: 0.9935\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0220 - binary_accuracy: 0.9939\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0218 - binary_accuracy: 0.9937\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0218 - binary_accuracy: 0.9939\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0215 - binary_accuracy: 0.9940\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0213 - binary_accuracy: 0.9939\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0212 - binary_accuracy: 0.9941\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0210 - binary_accuracy: 0.9942\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0209 - binary_accuracy: 0.9942\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0207 - binary_accuracy: 0.9943\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0206 - binary_accuracy: 0.9943\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.0204 - binary_accuracy: 0.9942\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0202 - binary_accuracy: 0.9945\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0200 - binary_accuracy: 0.9945\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0199 - binary_accuracy: 0.9946\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.0197 - binary_accuracy: 0.9945\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 0.0196 - binary_accuracy: 0.9947\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 0s 114us/step - loss: 0.0194 - binary_accuracy: 0.9948\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 0s 108us/step - loss: 0.0193 - binary_accuracy: 0.9948\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 0.0192 - binary_accuracy: 0.9948\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 0s 107us/step - loss: 0.0190 - binary_accuracy: 0.9948\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.0188 - binary_accuracy: 0.9950\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0188 - binary_accuracy: 0.9948\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0186 - binary_accuracy: 0.9950\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0185 - binary_accuracy: 0.9951\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0183 - binary_accuracy: 0.9951\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 0.0182 - binary_accuracy: 0.9950\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0181 - binary_accuracy: 0.9951\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0179 - binary_accuracy: 0.9952\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.0178 - binary_accuracy: 0.9953\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0177 - binary_accuracy: 0.9953\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0176 - binary_accuracy: 0.9953\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0174 - binary_accuracy: 0.9955\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0173 - binary_accuracy: 0.9953\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0173 - binary_accuracy: 0.9955\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0170 - binary_accuracy: 0.9955\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0170 - binary_accuracy: 0.9954\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0169 - binary_accuracy: 0.9956\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0167 - binary_accuracy: 0.9955\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0166 - binary_accuracy: 0.9957\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0164 - binary_accuracy: 0.9957\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0163 - binary_accuracy: 0.9958\n",
      "Epoch 218/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0163 - binary_accuracy: 0.9957\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0161 - binary_accuracy: 0.9958\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0160 - binary_accuracy: 0.9960\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0159 - binary_accuracy: 0.9957\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.0158 - binary_accuracy: 0.9959\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0157 - binary_accuracy: 0.9958\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0156 - binary_accuracy: 0.9960\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.0154 - binary_accuracy: 0.9959\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0153 - binary_accuracy: 0.9962\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0153 - binary_accuracy: 0.9961\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0151 - binary_accuracy: 0.9961\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0150 - binary_accuracy: 0.9962\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0150 - binary_accuracy: 0.9962\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0149 - binary_accuracy: 0.9963\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0147 - binary_accuracy: 0.9964\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.0147 - binary_accuracy: 0.9963\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.0145 - binary_accuracy: 0.9963\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.0144 - binary_accuracy: 0.9963\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0143 - binary_accuracy: 0.9964\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0143 - binary_accuracy: 0.9963\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0142 - binary_accuracy: 0.9965\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 0.0140 - binary_accuracy: 0.9964\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0140 - binary_accuracy: 0.9965\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0138 - binary_accuracy: 0.9966\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0138 - binary_accuracy: 0.9965\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0136 - binary_accuracy: 0.9967\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0136 - binary_accuracy: 0.9965\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0135 - binary_accuracy: 0.9967\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0134 - binary_accuracy: 0.9967\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0133 - binary_accuracy: 0.9967\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0132 - binary_accuracy: 0.9967\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0131 - binary_accuracy: 0.9968\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0130 - binary_accuracy: 0.9970\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0130 - binary_accuracy: 0.9968\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0128 - binary_accuracy: 0.9971\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0127 - binary_accuracy: 0.9970\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0127 - binary_accuracy: 0.9969\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0126 - binary_accuracy: 0.9970\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0124 - binary_accuracy: 0.9971\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0124 - binary_accuracy: 0.9970\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0124 - binary_accuracy: 0.9971\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0123 - binary_accuracy: 0.9971\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0122 - binary_accuracy: 0.9970\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.0120 - binary_accuracy: 0.9971\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0120 - binary_accuracy: 0.9973\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0118 - binary_accuracy: 0.9972\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0118 - binary_accuracy: 0.9973\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0117 - binary_accuracy: 0.9972\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0117 - binary_accuracy: 0.9973\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0116 - binary_accuracy: 0.9974\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0115 - binary_accuracy: 0.9974\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0114 - binary_accuracy: 0.9972\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0114 - binary_accuracy: 0.9975\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0113 - binary_accuracy: 0.9974\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0112 - binary_accuracy: 0.9974\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0112 - binary_accuracy: 0.9973\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0110 - binary_accuracy: 0.9976\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0110 - binary_accuracy: 0.9975\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0109 - binary_accuracy: 0.9976\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0108 - binary_accuracy: 0.9976\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0108 - binary_accuracy: 0.9977\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0106 - binary_accuracy: 0.9976\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0105 - binary_accuracy: 0.9976\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0106 - binary_accuracy: 0.9976\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0105 - binary_accuracy: 0.9978\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0105 - binary_accuracy: 0.9977\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0103 - binary_accuracy: 0.9979\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0102 - binary_accuracy: 0.9978\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0102 - binary_accuracy: 0.9979\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0101 - binary_accuracy: 0.9979\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.0101 - binary_accuracy: 0.9979\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0099 - binary_accuracy: 0.9979\n",
      "Epoch 290/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0099 - binary_accuracy: 0.9978\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0098 - binary_accuracy: 0.9979\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0098 - binary_accuracy: 0.9980\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.0097 - binary_accuracy: 0.9981\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0095 - binary_accuracy: 0.9981\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0096 - binary_accuracy: 0.9980\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.0095 - binary_accuracy: 0.9981\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0094 - binary_accuracy: 0.9982\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0093 - binary_accuracy: 0.9982\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0093 - binary_accuracy: 0.9982\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0092 - binary_accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a585d7b70>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, y_test_small = data_genelization(sample_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11505960857868194, 0.9791249980926514]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let strat with the simpliest model, say our alphabet has there letter ABC and the \"caeser\" function is to shift one place, ie. shift ABC to BCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size = 2,loops = 1000, size = 3, key = 1, x_as_vector = False, y_as_vector = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start at one middle layer\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=x_train.shape[1], activation='relu', name = \"input\"))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid', name = \"layer1\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1000/1000 [==============================] - 0s 383us/step - loss: 0.6871 - binary_accuracy: 0.5760\n",
      "Epoch 2/150\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.6657 - binary_accuracy: 0.5975\n",
      "Epoch 3/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6471 - binary_accuracy: 0.6115\n",
      "Epoch 4/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6296 - binary_accuracy: 0.6360\n",
      "Epoch 5/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6124 - binary_accuracy: 0.6602\n",
      "Epoch 6/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.5947 - binary_accuracy: 0.6923\n",
      "Epoch 7/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.5761 - binary_accuracy: 0.7293\n",
      "Epoch 8/150\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.5561 - binary_accuracy: 0.7473\n",
      "Epoch 9/150\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.5363 - binary_accuracy: 0.7772\n",
      "Epoch 10/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.5165 - binary_accuracy: 0.7977\n",
      "Epoch 11/150\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.4964 - binary_accuracy: 0.8012\n",
      "Epoch 12/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.4736 - binary_accuracy: 0.8370\n",
      "Epoch 13/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.4509 - binary_accuracy: 0.8370\n",
      "Epoch 14/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.4293 - binary_accuracy: 0.8413\n",
      "Epoch 15/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.4085 - binary_accuracy: 0.8535\n",
      "Epoch 16/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.3882 - binary_accuracy: 0.8582\n",
      "Epoch 17/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.3683 - binary_accuracy: 0.8727\n",
      "Epoch 18/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.3490 - binary_accuracy: 0.8727\n",
      "Epoch 19/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.3305 - binary_accuracy: 0.8862\n",
      "Epoch 20/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.3125 - binary_accuracy: 0.8920\n",
      "Epoch 21/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.2949 - binary_accuracy: 0.9078\n",
      "Epoch 22/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2779 - binary_accuracy: 0.9205\n",
      "Epoch 23/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.2618 - binary_accuracy: 0.9307\n",
      "Epoch 24/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.2463 - binary_accuracy: 0.9495\n",
      "Epoch 25/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.2317 - binary_accuracy: 0.9538\n",
      "Epoch 26/150\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.2176 - binary_accuracy: 0.9667\n",
      "Epoch 27/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.2041 - binary_accuracy: 0.9792\n",
      "Epoch 28/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1911 - binary_accuracy: 0.9832\n",
      "Epoch 29/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1787 - binary_accuracy: 0.9832\n",
      "Epoch 30/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1669 - binary_accuracy: 0.9832\n",
      "Epoch 31/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1555 - binary_accuracy: 0.9832\n",
      "Epoch 32/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1450 - binary_accuracy: 0.9832\n",
      "Epoch 33/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1348 - binary_accuracy: 0.9832\n",
      "Epoch 34/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1252 - binary_accuracy: 0.9832\n",
      "Epoch 35/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1163 - binary_accuracy: 0.9832\n",
      "Epoch 36/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1079 - binary_accuracy: 0.9832\n",
      "Epoch 37/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1000 - binary_accuracy: 0.9978\n",
      "Epoch 38/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0926 - binary_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0857 - binary_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0793 - binary_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0735 - binary_accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0680 - binary_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0631 - binary_accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0586 - binary_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0544 - binary_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0505 - binary_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0470 - binary_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0438 - binary_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0409 - binary_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0382 - binary_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0357 - binary_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0334 - binary_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0314 - binary_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0295 - binary_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0277 - binary_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0261 - binary_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0247 - binary_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0233 - binary_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0220 - binary_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0209 - binary_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0198 - binary_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0188 - binary_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0178 - binary_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0170 - binary_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0161 - binary_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0154 - binary_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0147 - binary_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0140 - binary_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0134 - binary_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0128 - binary_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0122 - binary_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0117 - binary_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0112 - binary_accuracy: 1.0000\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0108 - binary_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0103 - binary_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0099 - binary_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0095 - binary_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0091 - binary_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0088 - binary_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0085 - binary_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0081 - binary_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0076 - binary_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0073 - binary_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0065 - binary_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0063 - binary_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0061 - binary_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0059 - binary_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0057 - binary_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0055 - binary_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0053 - binary_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0052 - binary_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0050 - binary_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0048 - binary_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0047 - binary_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0044 - binary_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0043 - binary_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0041 - binary_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0040 - binary_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0039 - binary_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0038 - binary_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0037 - binary_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0036 - binary_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0035 - binary_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0034 - binary_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0033 - binary_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0032 - binary_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0031 - binary_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0030 - binary_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0029 - binary_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0028 - binary_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0028 - binary_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0027 - binary_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0026 - binary_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0026 - binary_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0025 - binary_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0024 - binary_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0024 - binary_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0023 - binary_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0022 - binary_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0022 - binary_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0021 - binary_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0021 - binary_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0012 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2c3c9208>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what did the model learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 6)                 36        \n",
      "=================================================================\n",
      "Total params: 71\n",
      "Trainable params: 71\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our simple model structure:\n",
    "<img src=\"./images/simple.png\" width=\"400\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that we have 71 parameters. In the first layer, we have 30 weights and 5 biases. In the second layer, we have 30 weights and 6 biases which show as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.82606924,  0.8205743 , -2.2852252 ,  1.6901608 ,  1.1319901 ],\n",
       "        [ 1.3760408 ,  2.5458488 , -2.1797671 , -1.5172253 ,  1.0308439 ],\n",
       "        [-0.16585648, -0.2794935 ,  2.2665577 , -0.80191505,  1.6642292 ],\n",
       "        [-0.5681321 ,  1.5671    ,  2.4999106 ,  0.70694906, -2.2617538 ],\n",
       "        [ 2.1957273 , -2.2039256 ,  0.5776802 ,  1.5100118 , -0.7955079 ],\n",
       "        [-0.5618616 ,  0.95752865,  0.6824657 ,  0.3680279 ,  2.0694983 ]],\n",
       "       dtype=float32),\n",
       " array([1.3878925, 1.6281852, 1.6025935, 1.1489217, 1.1298584],\n",
       "       dtype=float32),\n",
       " array([[ 1.5484006 , -0.5972057 , -1.7155966 ,  2.036288  , -1.78507   ,\n",
       "         -1.5388893 ],\n",
       "        [ 1.1309438 , -1.8847716 , -0.26149613, -2.1800714 ,  0.05703444,\n",
       "          1.2034626 ],\n",
       "        [-1.292776  ,  2.1703794 , -1.2448043 , -0.38088757, -0.77099156,\n",
       "          0.731896  ],\n",
       "        [-2.5167356 , -1.4012274 ,  2.6635358 ,  0.7620649 , -1.3250663 ,\n",
       "         -0.17841093],\n",
       "        [-0.52961814,  0.6876993 , -0.24701497, -0.41188228,  2.614583  ,\n",
       "         -2.6184678 ]], dtype=float32),\n",
       " array([-0.28764233,  0.07647046, -0.3012865 , -0.0309343 , -0.8558167 ,\n",
       "         0.90004164], dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "biases = model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "# Set one layer as output we can get every layers' information given the input\n",
    "\n",
    "dense1_layer_model = Model(inputs=model.input,\n",
    "                                     outputs=model.get_layer('input').output)\n",
    "\n",
    "dense1_output = dense1_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.       , 3.4062881, 0.       , 3.2071104, 4.331347 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1299.,  468.,  116.,  349.,  214.,  541.,  118.,  229.,  114.,\n",
       "         328.,   99.,  448.,  236.,  224.,    0.,  101.,  116.]),\n",
       " array([0.       , 0.3746507, 0.7493014, 1.123952 , 1.4986027, 1.8732533,\n",
       "        2.247904 , 2.6225548, 2.9972055, 3.371856 , 3.7465067, 4.1211576,\n",
       "        4.495808 , 4.8704586, 5.2451096, 5.61976  , 5.994411 , 6.3690615],\n",
       "       dtype=float32),\n",
       " <a list of 17 Patch objects>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.hstack([dense1_output[i] for i in range(1000)])\n",
    "plt.hist(a, bins='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2_layer_model = Model(inputs=model.input, outputs=model.get_layer('layer1').output)\n",
    "\n",
    "dense2_output = dense2_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4000.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0., 2000.]),\n",
       " array([1.9353628e-04, 7.1577862e-02, 1.4296219e-01, 2.1434651e-01,\n",
       "        2.8573084e-01, 3.5711515e-01, 4.2849949e-01, 4.9988380e-01,\n",
       "        5.7126814e-01, 6.4265245e-01, 7.1403676e-01, 7.8542107e-01,\n",
       "        8.5680544e-01, 9.2818975e-01, 9.9957407e-01], dtype=float32),\n",
       " <a list of 14 Patch objects>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dense2_output[1]\n",
    "a = np.hstack([dense2_output[i] for i in range(1000)])\n",
    "plt.hist(a, bins='auto') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, after calculating by two layers weights, the training data reduce the 1 value in the origin place and increase the value corresponding to the label place with value 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myfun import simpledata\n",
    "from myfun import simpledata_hidden\n",
    "# simpledata_hidden hides the combination AB\n",
    "x_train, y_train = simpledata_hidden()\n",
    "x_test, y_test = simpledata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start at one middle layer\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=x_train.shape[1], activation='relu', name = \"input\"))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid', name = \"layer1\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "801/801 [==============================] - 0s 259us/step - loss: 0.6962 - binary_accuracy: 0.5622\n",
      "Epoch 2/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.6801 - binary_accuracy: 0.5622\n",
      "Epoch 3/150\n",
      "801/801 [==============================] - 0s 39us/step - loss: 0.6648 - binary_accuracy: 0.5907\n",
      "Epoch 4/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.6499 - binary_accuracy: 0.6128\n",
      "Epoch 5/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.6345 - binary_accuracy: 0.6278\n",
      "Epoch 6/150\n",
      "801/801 [==============================] - 0s 42us/step - loss: 0.6190 - binary_accuracy: 0.6819\n",
      "Epoch 7/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.6035 - binary_accuracy: 0.7112\n",
      "Epoch 8/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.5863 - binary_accuracy: 0.7025\n",
      "Epoch 9/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.5658 - binary_accuracy: 0.7247\n",
      "Epoch 10/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.5432 - binary_accuracy: 0.7291\n",
      "Epoch 11/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.5217 - binary_accuracy: 0.7387\n",
      "Epoch 12/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.5009 - binary_accuracy: 0.7341\n",
      "Epoch 13/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.4810 - binary_accuracy: 0.7499\n",
      "Epoch 14/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.4621 - binary_accuracy: 0.7528\n",
      "Epoch 15/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.4443 - binary_accuracy: 0.7788\n",
      "Epoch 16/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.4275 - binary_accuracy: 0.8217\n",
      "Epoch 17/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.4115 - binary_accuracy: 0.8373\n",
      "Epoch 18/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.3958 - binary_accuracy: 0.8658\n",
      "Epoch 19/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.3808 - binary_accuracy: 0.8841\n",
      "Epoch 20/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.3668 - binary_accuracy: 0.8960\n",
      "Epoch 21/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.3536 - binary_accuracy: 0.8960\n",
      "Epoch 22/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.3409 - binary_accuracy: 0.8960\n",
      "Epoch 23/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.3287 - binary_accuracy: 0.8960\n",
      "Epoch 24/150\n",
      "801/801 [==============================] - 0s 39us/step - loss: 0.3169 - binary_accuracy: 0.8972\n",
      "Epoch 25/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.3051 - binary_accuracy: 0.9168\n",
      "Epoch 26/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.2936 - binary_accuracy: 0.9168\n",
      "Epoch 27/150\n",
      "801/801 [==============================] - 0s 51us/step - loss: 0.2823 - binary_accuracy: 0.9168\n",
      "Epoch 28/150\n",
      "801/801 [==============================] - 0s 46us/step - loss: 0.2709 - binary_accuracy: 0.9376\n",
      "Epoch 29/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.2598 - binary_accuracy: 0.9376\n",
      "Epoch 30/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.2489 - binary_accuracy: 0.9376\n",
      "Epoch 31/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.2383 - binary_accuracy: 0.9376\n",
      "Epoch 32/150\n",
      "801/801 [==============================] - 0s 39us/step - loss: 0.2277 - binary_accuracy: 0.9376\n",
      "Epoch 33/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.2171 - binary_accuracy: 0.9382\n",
      "Epoch 34/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.2070 - binary_accuracy: 0.9792\n",
      "Epoch 35/150\n",
      "801/801 [==============================] - 0s 38us/step - loss: 0.1971 - binary_accuracy: 0.9792\n",
      "Epoch 36/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.1874 - binary_accuracy: 0.9792\n",
      "Epoch 37/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.1783 - binary_accuracy: 0.9792\n",
      "Epoch 38/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.1692 - binary_accuracy: 0.9792\n",
      "Epoch 39/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.1606 - binary_accuracy: 0.9792\n",
      "Epoch 40/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.1522 - binary_accuracy: 0.9792\n",
      "Epoch 41/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.1442 - binary_accuracy: 0.9792\n",
      "Epoch 42/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.1364 - binary_accuracy: 0.9792\n",
      "Epoch 43/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.1291 - binary_accuracy: 0.9792\n",
      "Epoch 44/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.1223 - binary_accuracy: 0.9792\n",
      "Epoch 45/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.1157 - binary_accuracy: 0.9848\n",
      "Epoch 46/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.1095 - binary_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.1036 - binary_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0981 - binary_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.0928 - binary_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.0878 - binary_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "801/801 [==============================] - 0s 57us/step - loss: 0.0831 - binary_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0787 - binary_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0745 - binary_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0706 - binary_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "801/801 [==============================] - 0s 36us/step - loss: 0.0668 - binary_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0633 - binary_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0600 - binary_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0568 - binary_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0539 - binary_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0512 - binary_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0486 - binary_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0462 - binary_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0440 - binary_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0418 - binary_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0398 - binary_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0379 - binary_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0362 - binary_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0345 - binary_accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0330 - binary_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0316 - binary_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0302 - binary_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0289 - binary_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0277 - binary_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "801/801 [==============================] - 0s 33us/step - loss: 0.0265 - binary_accuracy: 1.0000\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 33us/step - loss: 0.0254 - binary_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "801/801 [==============================] - 0s 37us/step - loss: 0.0244 - binary_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "801/801 [==============================] - 0s 34us/step - loss: 0.0234 - binary_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.0225 - binary_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0216 - binary_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0208 - binary_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0200 - binary_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0193 - binary_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "801/801 [==============================] - 0s 28us/step - loss: 0.0186 - binary_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0179 - binary_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0172 - binary_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0166 - binary_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0160 - binary_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0155 - binary_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0150 - binary_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0145 - binary_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0140 - binary_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0135 - binary_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "801/801 [==============================] - 0s 23us/step - loss: 0.0131 - binary_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0127 - binary_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "801/801 [==============================] - 0s 23us/step - loss: 0.0123 - binary_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0119 - binary_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0115 - binary_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0112 - binary_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0108 - binary_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0105 - binary_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0102 - binary_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0099 - binary_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0096 - binary_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0093 - binary_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0090 - binary_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0088 - binary_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0085 - binary_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0083 - binary_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0081 - binary_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0076 - binary_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0074 - binary_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0072 - binary_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0070 - binary_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0067 - binary_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0065 - binary_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0063 - binary_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0062 - binary_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0060 - binary_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0059 - binary_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0057 - binary_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0056 - binary_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0054 - binary_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0053 - binary_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0052 - binary_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0050 - binary_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0049 - binary_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "801/801 [==============================] - 0s 24us/step - loss: 0.0048 - binary_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0047 - binary_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0046 - binary_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "801/801 [==============================] - 0s 29us/step - loss: 0.0044 - binary_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0043 - binary_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0042 - binary_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "801/801 [==============================] - 0s 32us/step - loss: 0.0041 - binary_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "801/801 [==============================] - 0s 35us/step - loss: 0.0040 - binary_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0039 - binary_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "801/801 [==============================] - 0s 26us/step - loss: 0.0038 - binary_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "801/801 [==============================] - 0s 27us/step - loss: 0.0037 - binary_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0036 - binary_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "801/801 [==============================] - 0s 25us/step - loss: 0.0035 - binary_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "801/801 [==============================] - 0s 28us/step - loss: 0.0035 - binary_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "801/801 [==============================] - 0s 29us/step - loss: 0.0034 - binary_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "801/801 [==============================] - 0s 31us/step - loss: 0.0033 - binary_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.0032 - binary_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.0032 - binary_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "801/801 [==============================] - 0s 30us/step - loss: 0.0031 - binary_accuracy: 1.0000\n",
      "Epoch 149/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 32us/step - loss: 0.0030 - binary_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "801/801 [==============================] - 0s 29us/step - loss: 0.0030 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb28a93b70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 0s 12us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06111194011440023, 0.981502013121805]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that it cannot learn it well, so it maybe need to combine with some rule by using logic programming method to guide it. Say given AB, BA have similar structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad activation function and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we choose a bad activation function what would happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 3.6653 - categorical_accuracy: 0.2120\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 3.5776 - categorical_accuracy: 0.2120\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 3.5016 - categorical_accuracy: 0.3370\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 3.4364 - categorical_accuracy: 0.3500\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 3.3696 - categorical_accuracy: 0.2830\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 3.2995 - categorical_accuracy: 0.2120\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 3.2234 - categorical_accuracy: 0.2120\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 3.1440 - categorical_accuracy: 0.2120\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 3.0622 - categorical_accuracy: 0.2540\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 2.9762 - categorical_accuracy: 0.3230\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 2.8866 - categorical_accuracy: 0.3230\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 2.7943 - categorical_accuracy: 0.3390\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 2.6932 - categorical_accuracy: 0.4610\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 2.5884 - categorical_accuracy: 0.4610\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 2.4892 - categorical_accuracy: 0.4610\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 2.3944 - categorical_accuracy: 0.4610\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.3104 - categorical_accuracy: 0.4610\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 2.2364 - categorical_accuracy: 0.4610\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.1700 - categorical_accuracy: 0.4610\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 2.1109 - categorical_accuracy: 0.3910\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.0582 - categorical_accuracy: 0.3570\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 2.0106 - categorical_accuracy: 0.3570\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.9678 - categorical_accuracy: 0.3570\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.9279 - categorical_accuracy: 0.3570\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.8916 - categorical_accuracy: 0.3570\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.8586 - categorical_accuracy: 0.3570\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.8269 - categorical_accuracy: 0.3570\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 1.7972 - categorical_accuracy: 0.3570\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.7689 - categorical_accuracy: 0.4030\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 1.7420 - categorical_accuracy: 0.3570\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.7162 - categorical_accuracy: 0.3570\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.6917 - categorical_accuracy: 0.3970\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 1.6686 - categorical_accuracy: 0.4490\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.6462 - categorical_accuracy: 0.5120\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.6246 - categorical_accuracy: 0.4660\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.6042 - categorical_accuracy: 0.5370\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.5850 - categorical_accuracy: 0.5810\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.5672 - categorical_accuracy: 0.5190\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 1.5504 - categorical_accuracy: 0.6740\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 1.5352 - categorical_accuracy: 0.6260\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 1.5210 - categorical_accuracy: 0.6470\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.5083 - categorical_accuracy: 0.6740\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.4967 - categorical_accuracy: 0.6740\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.4864 - categorical_accuracy: 0.6740\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.4771 - categorical_accuracy: 0.6740\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.4687 - categorical_accuracy: 0.6740\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.4613 - categorical_accuracy: 0.6740\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.4546 - categorical_accuracy: 0.6280\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4488 - categorical_accuracy: 0.6270\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4436 - categorical_accuracy: 0.6670\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4390 - categorical_accuracy: 0.6210\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4349 - categorical_accuracy: 0.5850\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.4312 - categorical_accuracy: 0.6380\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4279 - categorical_accuracy: 0.5960\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4250 - categorical_accuracy: 0.6050\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4224 - categorical_accuracy: 0.6390\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4200 - categorical_accuracy: 0.5780\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4178 - categorical_accuracy: 0.5630\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 1.4158 - categorical_accuracy: 0.6530\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.4140 - categorical_accuracy: 0.5830\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.4124 - categorical_accuracy: 0.5820\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4109 - categorical_accuracy: 0.5630\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.4095 - categorical_accuracy: 0.5030\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 1.4083 - categorical_accuracy: 0.6100\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4071 - categorical_accuracy: 0.5940\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.4060 - categorical_accuracy: 0.5550\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 1.4051 - categorical_accuracy: 0.5630\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 1.4041 - categorical_accuracy: 0.6750\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 1.4033 - categorical_accuracy: 0.5740\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 1.4025 - categorical_accuracy: 0.6430\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 46us/step - loss: 1.4017 - categorical_accuracy: 0.7110\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 1.4011 - categorical_accuracy: 0.5740\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 1.4004 - categorical_accuracy: 0.6570\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 1.3998 - categorical_accuracy: 0.5610\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 1.3992 - categorical_accuracy: 0.6420\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 1.3987 - categorical_accuracy: 0.6180\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.3982 - categorical_accuracy: 0.5980\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.3977 - categorical_accuracy: 0.7040\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 1.3973 - categorical_accuracy: 0.5670\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 1.3968 - categorical_accuracy: 0.6790\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.3964 - categorical_accuracy: 0.6310\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 1.3960 - categorical_accuracy: 0.5760\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.3957 - categorical_accuracy: 0.5800\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 1.3953 - categorical_accuracy: 0.6260\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.3950 - categorical_accuracy: 0.6130\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 1.3947 - categorical_accuracy: 0.5450\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 1.3944 - categorical_accuracy: 0.5640\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1.3941 - categorical_accuracy: 0.6420\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 1.3939 - categorical_accuracy: 0.6060\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 1.3936 - categorical_accuracy: 0.5910\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1.3934 - categorical_accuracy: 0.6380\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 1.3931 - categorical_accuracy: 0.5980\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.3929 - categorical_accuracy: 0.5640\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 1.3927 - categorical_accuracy: 0.5990\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 1.3925 - categorical_accuracy: 0.5540\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.3923 - categorical_accuracy: 0.6200\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 1.3921 - categorical_accuracy: 0.5490\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 1.3920 - categorical_accuracy: 0.5880\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 1.3918 - categorical_accuracy: 0.5510\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 1.3916 - categorical_accuracy: 0.5970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a585eec88>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the accuracy cannot converge to 1 because the softmax and categorical cross entropy treat the output as a distribution, however, it is not a classfication problem. This time our output has two value should be 1, so it is not suitable to use softmax and categorical crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6919137e-04, 4.9912450e-01, 1.3113728e-04, 4.9975443e-01,\n",
       "       2.6179088e-04, 3.5900806e-04], dtype=float32)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000536238076"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.predict(x_train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO  loops, error probs loops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import misslabeled_data_genelization\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index1, index2, size=26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return ([I2L[index1], I2L[index2]])\n",
    "\n",
    "\n",
    "def predict_results_only_2(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index1 = np.argmax(predictions[:, 0:26], axis=1)\n",
    "    index2 = np.argmax(predictions[:, 26:52], axis=1)\n",
    "    label1 = np.argmax(y_train[:, 0:26], axis=1)\n",
    "    label2 = np.argmax(y_train[:, 26:52], axis=1)\n",
    "\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index1, index2))\n",
    "    label_list = list(map(num2str, label1, label2))\n",
    "\n",
    "    return (prediction_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(list1, list2, ifprint = False):\n",
    "    if \"\".join(list1) != \"\".join(list2):\n",
    "        if ifprint == True:\n",
    "            print(\"\".join(list1), \"\".join(list2))\n",
    "        return (\"\".join(list1), \"\".join(list2))\n",
    "    else:\n",
    "        return (True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function misslabeled_data_genelization in module myfun:\n",
      "\n",
      "misslabeled_data_genelization(sample_size=2, loops=1000, size=26, key=3, prob=0.1, x_as_vector=False, y_as_vector=False)\n",
      "    data_genelization(sample_size = 2,loops = 1000, size = 26, key = 3, x_as_vector = False, y_as_vector = False):\n",
      "    return x_train, label with equual size, labels with 1 dimension\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(misslabeled_data_genelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = misslabeled_data_genelization(loops=10000, prob=0)\n",
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10000/10000 [==============================] - 1s 58us/step - loss: 0.2733 - acc: 0.9253\n",
      "Epoch 2/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1459 - acc: 0.9615\n",
      "Epoch 3/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1144 - acc: 0.9622\n",
      "Epoch 4/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0816 - acc: 0.9690\n",
      "Epoch 5/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0575 - acc: 0.9792\n",
      "Epoch 6/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0397 - acc: 0.9866\n",
      "Epoch 7/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0267 - acc: 0.9922\n",
      "Epoch 8/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0180 - acc: 0.9955\n",
      "Epoch 9/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0121 - acc: 0.9974\n",
      "Epoch 10/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0081 - acc: 0.9987\n",
      "Epoch 11/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0054 - acc: 0.9994\n",
      "Epoch 12/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0036 - acc: 0.9997\n",
      "Epoch 13/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0025 - acc: 0.9999\n",
      "Epoch 14/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 15/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 16/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 8.6940e-04 - acc: 1.0000\n",
      "Epoch 17/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 6.4030e-04 - acc: 1.0000\n",
      "Epoch 18/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 4.7999e-04 - acc: 1.0000\n",
      "Epoch 19/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 3.6524e-04 - acc: 1.0000\n",
      "Epoch 20/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 2.8181e-04 - acc: 1.0000\n",
      "Epoch 21/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 2.1865e-04 - acc: 1.0000\n",
      "Epoch 22/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.7182e-04 - acc: 1.0000\n",
      "Epoch 23/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.3591e-04 - acc: 1.0000\n",
      "Epoch 24/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0813e-04 - acc: 1.0000\n",
      "Epoch 25/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 8.6493e-05 - acc: 1.0000\n",
      "Epoch 26/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 6.9610e-05 - acc: 1.0000\n",
      "Epoch 27/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 5.6196e-05 - acc: 1.0000\n",
      "Epoch 28/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 4.5588e-05 - acc: 1.0000\n",
      "Epoch 29/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.7033e-05 - acc: 1.0000\n",
      "Epoch 30/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.0210e-05 - acc: 1.0000\n",
      "Epoch 31/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.4694e-05 - acc: 1.0000\n",
      "Epoch 32/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 2.0271e-05 - acc: 1.0000\n",
      "Epoch 33/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.6651e-05 - acc: 1.0000\n",
      "Epoch 34/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.3710e-05 - acc: 1.0000\n",
      "Epoch 35/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.1309e-05 - acc: 1.0000\n",
      "Epoch 36/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 9.3405e-06 - acc: 1.0000\n",
      "Epoch 37/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 7.7300e-06 - acc: 1.0000\n",
      "Epoch 38/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 6.4087e-06 - acc: 1.0000\n",
      "Epoch 39/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 5.3226e-06 - acc: 1.0000\n",
      "Epoch 40/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 4.4261e-06 - acc: 1.0000\n",
      "Epoch 41/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 3.6833e-06 - acc: 1.0000\n",
      "Epoch 42/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 3.0772e-06 - acc: 1.0000\n",
      "Epoch 43/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.5746e-06 - acc: 1.0000\n",
      "Epoch 44/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.1571e-06 - acc: 1.0000\n",
      "Epoch 45/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.8133e-06 - acc: 1.0000\n",
      "Epoch 46/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.5278e-06 - acc: 1.0000\n",
      "Epoch 47/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.2922e-06 - acc: 1.0000\n",
      "Epoch 48/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0960e-06 - acc: 1.0000\n",
      "Epoch 49/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 9.3311e-07 - acc: 1.0000\n",
      "Epoch 50/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 7.9692e-07 - acc: 1.0000\n",
      "Epoch 51/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 6.8385e-07 - acc: 1.0000\n",
      "Epoch 52/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 5.8999e-07 - acc: 1.0000\n",
      "Epoch 53/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 5.1103e-07 - acc: 1.0000\n",
      "Epoch 54/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 4.4580e-07 - acc: 1.0000\n",
      "Epoch 55/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.9107e-07 - acc: 1.0000\n",
      "Epoch 56/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.4543e-07 - acc: 1.0000\n",
      "Epoch 57/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 3.0730e-07 - acc: 1.0000\n",
      "Epoch 58/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.7532e-07 - acc: 1.0000\n",
      "Epoch 59/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.4854e-07 - acc: 1.0000\n",
      "Epoch 60/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.2619e-07 - acc: 1.0000\n",
      "Epoch 61/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 2.0733e-07 - acc: 1.0000\n",
      "Epoch 62/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.9153e-07 - acc: 1.0000\n",
      "Epoch 63/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.7835e-07 - acc: 1.0000\n",
      "Epoch 64/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.6708e-07 - acc: 1.0000\n",
      "Epoch 65/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.5768e-07 - acc: 1.0000\n",
      "Epoch 66/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.4971e-07 - acc: 1.0000\n",
      "Epoch 67/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.4296e-07 - acc: 1.0000\n",
      "Epoch 68/200\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 1.3726e-07 - acc: 1.0000\n",
      "Epoch 69/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.3242e-07 - acc: 1.0000\n",
      "Epoch 70/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.2837e-07 - acc: 1.0000\n",
      "Epoch 71/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.2486e-07 - acc: 1.0000\n",
      "Epoch 72/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.2192e-07 - acc: 1.0000\n",
      "Epoch 73/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.1938e-07 - acc: 1.0000\n",
      "Epoch 74/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.1717e-07 - acc: 1.0000\n",
      "Epoch 75/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.1528e-07 - acc: 1.0000\n",
      "Epoch 76/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.1367e-07 - acc: 1.0000\n",
      "Epoch 77/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.1229e-07 - acc: 1.0000\n",
      "Epoch 78/200\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 1.1110e-07 - acc: 1.0000\n",
      "Epoch 79/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.1002e-07 - acc: 1.0000\n",
      "Epoch 80/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0915e-07 - acc: 1.0000\n",
      "Epoch 81/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0832e-07 - acc: 1.0000\n",
      "Epoch 82/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0761e-07 - acc: 1.0000\n",
      "Epoch 83/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0700e-07 - acc: 1.0000\n",
      "Epoch 84/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0646e-07 - acc: 1.0000\n",
      "Epoch 85/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0597e-07 - acc: 1.0000\n",
      "Epoch 86/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0552e-07 - acc: 1.0000\n",
      "Epoch 87/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.0514e-07 - acc: 1.0000\n",
      "Epoch 88/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.0483e-07 - acc: 1.0000\n",
      "Epoch 89/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0452e-07 - acc: 1.0000\n",
      "Epoch 90/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0427e-07 - acc: 1.0000\n",
      "Epoch 91/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0401e-07 - acc: 1.0000\n",
      "Epoch 92/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0378e-07 - acc: 1.0000\n",
      "Epoch 93/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0358e-07 - acc: 1.0000\n",
      "Epoch 94/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0341e-07 - acc: 1.0000\n",
      "Epoch 95/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0325e-07 - acc: 1.0000\n",
      "Epoch 96/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0310e-07 - acc: 1.0000\n",
      "Epoch 97/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0296e-07 - acc: 1.0000\n",
      "Epoch 98/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0284e-07 - acc: 1.0000\n",
      "Epoch 99/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0272e-07 - acc: 1.0000\n",
      "Epoch 100/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0261e-07 - acc: 1.0000\n",
      "Epoch 101/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0252e-07 - acc: 1.0000\n",
      "Epoch 102/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0242e-07 - acc: 1.0000\n",
      "Epoch 103/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0233e-07 - acc: 1.0000\n",
      "Epoch 104/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0225e-07 - acc: 1.0000\n",
      "Epoch 105/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0217e-07 - acc: 1.0000\n",
      "Epoch 106/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0212e-07 - acc: 1.0000\n",
      "Epoch 107/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0204e-07 - acc: 1.0000\n",
      "Epoch 108/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0198e-07 - acc: 1.0000\n",
      "Epoch 109/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0193e-07 - acc: 1.0000\n",
      "Epoch 110/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0188e-07 - acc: 1.0000\n",
      "Epoch 111/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0182e-07 - acc: 1.0000\n",
      "Epoch 112/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0179e-07 - acc: 1.0000\n",
      "Epoch 113/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0175e-07 - acc: 1.0000\n",
      "Epoch 114/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.0171e-07 - acc: 1.0000\n",
      "Epoch 115/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0166e-07 - acc: 1.0000\n",
      "Epoch 116/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0164e-07 - acc: 1.0000\n",
      "Epoch 117/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0160e-07 - acc: 1.0000\n",
      "Epoch 118/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0157e-07 - acc: 1.0000\n",
      "Epoch 119/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0154e-07 - acc: 1.0000\n",
      "Epoch 120/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0150e-07 - acc: 1.0000\n",
      "Epoch 121/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0150e-07 - acc: 1.0000\n",
      "Epoch 122/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0147e-07 - acc: 1.0000\n",
      "Epoch 123/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0145e-07 - acc: 1.0000\n",
      "Epoch 124/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0141e-07 - acc: 1.0000\n",
      "Epoch 125/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0140e-07 - acc: 1.0000\n",
      "Epoch 126/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0137e-07 - acc: 1.0000\n",
      "Epoch 127/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0136e-07 - acc: 1.0000\n",
      "Epoch 128/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0134e-07 - acc: 1.0000\n",
      "Epoch 129/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0132e-07 - acc: 1.0000\n",
      "Epoch 130/200\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 1.0130e-07 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0128e-07 - acc: 1.0000\n",
      "Epoch 132/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0126e-07 - acc: 1.0000\n",
      "Epoch 133/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0125e-07 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0124e-07 - acc: 1.0000\n",
      "Epoch 135/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0121e-07 - acc: 1.0000\n",
      "Epoch 136/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0120e-07 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0119e-07 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0117e-07 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0117e-07 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0116e-07 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0113e-07 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0112e-07 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0113e-07 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0112e-07 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0110e-07 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0110e-07 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0108e-07 - acc: 1.0000\n",
      "Epoch 148/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0108e-07 - acc: 1.0000\n",
      "Epoch 149/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.0108e-07 - acc: 1.0000\n",
      "Epoch 150/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0108e-07 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0106e-07 - acc: 1.0000\n",
      "Epoch 152/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0105e-07 - acc: 1.0000\n",
      "Epoch 153/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0104e-07 - acc: 1.0000\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0104e-07 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0103e-07 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0103e-07 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 1.0102e-07 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0102e-07 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0101e-07 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 1.0100e-07 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0100e-07 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0099e-07 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0098e-07 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0098e-07 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0098e-07 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0097e-07 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0096e-07 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0097e-07 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0095e-07 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0095e-07 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0095e-07 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0094e-07 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0094e-07 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0094e-07 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0094e-07 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0093e-07 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0093e-07 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0092e-07 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0092e-07 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 1.0092e-07 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0091e-07 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0089e-07 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0090e-07 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0089e-07 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0089e-07 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0089e-07 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0088e-07 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0088e-07 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0088e-07 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 1.0088e-07 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 1.0087e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb33e8a898>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 99us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0087433304306614e-07, 1.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = data_genelization()\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction_list, label_list = predict_results_only_2(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.count(True)/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 0.2882 - acc: 0.9191\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1466 - acc: 0.9615\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1199 - acc: 0.9620\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0943 - acc: 0.9665\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0768 - acc: 0.9749\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0671 - acc: 0.9809\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0617 - acc: 0.9842\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0583 - acc: 0.9859\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0559 - acc: 0.9873\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0540 - acc: 0.9882\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0524 - acc: 0.9889\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0510 - acc: 0.9896\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0499 - acc: 0.9901\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0489 - acc: 0.9906\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0481 - acc: 0.9910\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0473 - acc: 0.9914\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0467 - acc: 0.9917\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0462 - acc: 0.9918\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0456 - acc: 0.9919\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0452 - acc: 0.9921\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0448 - acc: 0.9922\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0445 - acc: 0.9923\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0442 - acc: 0.9924\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0439 - acc: 0.9924\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0436 - acc: 0.9925\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0434 - acc: 0.9925\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0431 - acc: 0.9926\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0429 - acc: 0.9926\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0427 - acc: 0.9926\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0425 - acc: 0.9926\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0424 - acc: 0.9926\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0422 - acc: 0.9926\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0420 - acc: 0.9926\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0419 - acc: 0.9927\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0417 - acc: 0.9926\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0416 - acc: 0.9927\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0414 - acc: 0.9927\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0413 - acc: 0.9927\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0412 - acc: 0.9927\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0411 - acc: 0.9927\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0410 - acc: 0.9927\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0409 - acc: 0.9927\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0407 - acc: 0.9927\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0406 - acc: 0.9927\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0406 - acc: 0.9927\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0405 - acc: 0.9927\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0404 - acc: 0.9927\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0403 - acc: 0.9927\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0402 - acc: 0.9927\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0401 - acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb34edfac8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = misslabeled_data_genelization(loops=10000, prob=0.1)\n",
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.010234667018055916, 0.9998576957702636]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = data_genelization()\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction_list, label_list = predict_results_only_2(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.count(True)/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 65us/step - loss: 0.2886 - acc: 0.9219\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1595 - acc: 0.9615\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1543 - acc: 0.9615\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1480 - acc: 0.9615\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1427 - acc: 0.9615\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1390 - acc: 0.9616\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1362 - acc: 0.9616\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1342 - acc: 0.9617\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1325 - acc: 0.9618\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1311 - acc: 0.9619\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1301 - acc: 0.9621\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1293 - acc: 0.9622\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1287 - acc: 0.9623\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1282 - acc: 0.9623\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1278 - acc: 0.9624\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1273 - acc: 0.9624\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1270 - acc: 0.9625\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1266 - acc: 0.9626\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1263 - acc: 0.9627\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1260 - acc: 0.9627\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1257 - acc: 0.9629\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1255 - acc: 0.9628\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1253 - acc: 0.9627\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1251 - acc: 0.9629\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1249 - acc: 0.9629\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1247 - acc: 0.9629\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1246 - acc: 0.9630\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1244 - acc: 0.9629\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1242 - acc: 0.9631\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1240 - acc: 0.9632\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1240 - acc: 0.9631\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1238 - acc: 0.9631\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1236 - acc: 0.9633\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1235 - acc: 0.9632\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1234 - acc: 0.9631\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1233 - acc: 0.9632\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1231 - acc: 0.9632\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1230 - acc: 0.9634\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1230 - acc: 0.9634\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1228 - acc: 0.9634\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1227 - acc: 0.9635\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1227 - acc: 0.9635\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1226 - acc: 0.9633\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1225 - acc: 0.9634\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1225 - acc: 0.9635\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1224 - acc: 0.9635\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1223 - acc: 0.9634\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1223 - acc: 0.9635\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1222 - acc: 0.9634\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1222 - acc: 0.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb350bccc0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = misslabeled_data_genelization(loops=10000,prob=0.5)\n",
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05628207671642303, 0.9727115383148194]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = data_genelization()\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction_list, label_list = predict_results_only_2(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.count(True)/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 1s 69us/step - loss: 0.2870 - acc: 0.9283\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1636 - acc: 0.9615\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1634 - acc: 0.9615\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1633 - acc: 0.9615\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1632 - acc: 0.9615\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1631 - acc: 0.9615\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1631 - acc: 0.9615\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1630 - acc: 0.9615\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1629 - acc: 0.9615\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1628 - acc: 0.9615\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1628 - acc: 0.9615\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1627 - acc: 0.9615\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1627 - acc: 0.9615\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1626 - acc: 0.9615\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1625 - acc: 0.9615\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1625 - acc: 0.9615\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1624 - acc: 0.9615\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1624 - acc: 0.9615\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1623 - acc: 0.9615\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1623 - acc: 0.9615\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.1623 - acc: 0.9615\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1622 - acc: 0.9615\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1622 - acc: 0.9615\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1621 - acc: 0.9615\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1621 - acc: 0.9615\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1621 - acc: 0.9615\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1620 - acc: 0.9615\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1620 - acc: 0.9615\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1619 - acc: 0.9615\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1619 - acc: 0.9615\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1619 - acc: 0.9615\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1619 - acc: 0.9615\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1618 - acc: 0.9615\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1618 - acc: 0.9615\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1618 - acc: 0.9615\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1617 - acc: 0.9615\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1617 - acc: 0.9615\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1617 - acc: 0.9615\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1617 - acc: 0.9615\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1616 - acc: 0.9615\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1616 - acc: 0.9615\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1616 - acc: 0.9615\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1616 - acc: 0.9615\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.1616 - acc: 0.9615\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1616 - acc: 0.9615\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1615 - acc: 0.9615\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1615 - acc: 0.9615\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1615 - acc: 0.9615\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1615 - acc: 0.9615\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1614 - acc: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb356bd9e8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = misslabeled_data_genelization(loops=10000,prob=1)\n",
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 153us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16452448892593383, 0.9615384340286255]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, y_train_small = data_genelization()\n",
    "model.evaluate(x_train, y_train)\n",
    "# accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04283839, 0.03006983, 0.03108829, 0.03086495, 0.03821969,\n",
       "       0.04318464, 0.04275879, 0.02881029, 0.02591237, 0.05666709,\n",
       "       0.04924551, 0.04192016, 0.04666957, 0.04626572, 0.04118401,\n",
       "       0.03622824, 0.02944967, 0.03765562, 0.03575623, 0.03924397,\n",
       "       0.03410533, 0.03530636, 0.04261568, 0.03204012, 0.04352927,\n",
       "       0.03008407, 0.05662912, 0.04116714, 0.04893467, 0.05282199,\n",
       "       0.03043225, 0.04488924, 0.05681634, 0.04138765, 0.05441827,\n",
       "       0.02774709, 0.03407055, 0.04218432, 0.03569707, 0.03512883,\n",
       "       0.04342568, 0.05268621, 0.04676977, 0.02773789, 0.02489308,\n",
       "       0.0423353 , 0.04129213, 0.03324315, 0.03560084, 0.02898619,\n",
       "       0.03714329, 0.036331  ], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction_list, label_list = predict_results_only_2(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.count(True)/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes hours to get the curves, the python file is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubostibility of deep learning with large size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "with open('./data/noise_size_500.pickle', 'rb') as f:\n",
    "    info500 = pickle.load(f)\n",
    "with open('./data/noise_size_1000.pickle', 'rb') as f:\n",
    "    info1000 = pickle.load(f)\n",
    "with open('./data/noise_size_10000.pickle', 'rb') as f:\n",
    "    info10000 = pickle.load(f)\n",
    "with open('./data/noise_size_20000.pickle', 'rb') as f:\n",
    "    info20000 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Write some analyse about the rubostiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.legend((l2, l3, l4, l5), ('500', '1000', '10000', '20000'))\n",
    "l2, = plt.plot(np.arange(0, 1, .01), info500, label='data size 500')\n",
    "l3, = plt.plot(np.arange(0, 1, .01), info1000, label='data size 1000')\n",
    "l4, = plt.plot(np.arange(0, 1, .01), info10000, label='data size 10000')\n",
    "l5, = plt.plot(np.arange(0, 1, .01), info20000, label='data size 20000')\n",
    "plt.xlabel('Error rate in encryption')\n",
    "plt.ylabel('Accuracy of model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL algorithms are quite robust to random errors in the training set especially when the data size is big enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For systematic errors, we can imagine that it cannot generate a good result as the model will predict in the wrong way, which made the system losting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Write some analyse about the system error maybe add some codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
