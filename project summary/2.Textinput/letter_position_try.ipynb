{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from myfun import caeserde\n",
    "from myfun import data_genelization\n",
    "from myfun import data_test\n",
    "key = 3\n",
    "size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function data_genelization in module myfun:\n",
      "\n",
      "data_genelization(sample_size=2, loops=1000, size=26, key=3, x_as_vector=False, y_as_vector=False)\n",
      "    data_genelization(sample_size = 2,loops = 1000, size = 26, key = 3, x_as_vector = False, y_as_vector = False):\n",
      "    return x_train, label with equual size, labels with 1 dimension\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_genelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "x_train, y_train, y_train_small = data_genelization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 0s 424us/step - loss: 0.6710 - acc: 0.7043\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.5927 - acc: 0.8943\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.4116 - acc: 0.9590\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.2240 - acc: 0.9615\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1729 - acc: 0.9615\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1662 - acc: 0.9615\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1629 - acc: 0.9615\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1606 - acc: 0.9615\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1587 - acc: 0.9615\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1570 - acc: 0.9615\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1554 - acc: 0.9615\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1538 - acc: 0.9615\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1520 - acc: 0.9615\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1502 - acc: 0.9615\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1482 - acc: 0.9615\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1461 - acc: 0.9615\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1437 - acc: 0.9615\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1412 - acc: 0.9615\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1385 - acc: 0.9615\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1355 - acc: 0.9615\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1323 - acc: 0.9615\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1289 - acc: 0.9615\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1254 - acc: 0.9615\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1217 - acc: 0.9615\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1179 - acc: 0.9615\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1140 - acc: 0.9616\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1100 - acc: 0.9618\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1061 - acc: 0.9623\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.1022 - acc: 0.9630\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.0983 - acc: 0.9639\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0947 - acc: 0.9646\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0910 - acc: 0.9656\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0875 - acc: 0.9667\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0841 - acc: 0.9684\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0808 - acc: 0.9693\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0777 - acc: 0.9707\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0747 - acc: 0.9719\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0717 - acc: 0.9728\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0689 - acc: 0.9740\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0662 - acc: 0.9753\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0636 - acc: 0.9764\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0612 - acc: 0.9776\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0588 - acc: 0.9790\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0564 - acc: 0.9803\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0541 - acc: 0.9812\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0521 - acc: 0.9825\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0500 - acc: 0.9835\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0479 - acc: 0.9848\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0460 - acc: 0.9855\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0442 - acc: 0.9862\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0423 - acc: 0.9873\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0407 - acc: 0.9877\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0390 - acc: 0.9883\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0373 - acc: 0.9888\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0357 - acc: 0.9892\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0342 - acc: 0.9896\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0327 - acc: 0.9900\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0300 - acc: 0.9911\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0287 - acc: 0.9915\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0275 - acc: 0.9922\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0263 - acc: 0.9925\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0251 - acc: 0.9931\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0241 - acc: 0.9932\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0231 - acc: 0.9935\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0221 - acc: 0.9941\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0211 - acc: 0.9943\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0203 - acc: 0.9948\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0195 - acc: 0.9951\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0186 - acc: 0.9954\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0179 - acc: 0.9956\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0172 - acc: 0.9958\n",
      "Epoch 73/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0164 - acc: 0.9961\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0158 - acc: 0.9963\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0151 - acc: 0.9966\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0146 - acc: 0.9965\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0140 - acc: 0.9967\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0134 - acc: 0.9968\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0129 - acc: 0.9971\n",
      "Epoch 80/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0124 - acc: 0.9970\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0119 - acc: 0.9976\n",
      "Epoch 82/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0115 - acc: 0.9974\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0111 - acc: 0.9977\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0107 - acc: 0.9979\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0103 - acc: 0.9979\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0096 - acc: 0.9981\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0092 - acc: 0.9983\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0089 - acc: 0.9983\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0086 - acc: 0.9983\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0083 - acc: 0.9985\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0080 - acc: 0.9986\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0077 - acc: 0.9984\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0074 - acc: 0.9987\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0072 - acc: 0.9987\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0069 - acc: 0.9987\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0067 - acc: 0.9988\n",
      "Epoch 98/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0065 - acc: 0.9989\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0062 - acc: 0.9989\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0060 - acc: 0.9989\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0058 - acc: 0.9990\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0056 - acc: 0.9991\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0054 - acc: 0.9991\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0053 - acc: 0.9992\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0051 - acc: 0.9993\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0049 - acc: 0.9993\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0047 - acc: 0.9994\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0046 - acc: 0.9994\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0044 - acc: 0.9994\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0043 - acc: 0.9995\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0042 - acc: 0.9996\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0040 - acc: 0.9996\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0039 - acc: 0.9996\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0037 - acc: 0.9996\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0036 - acc: 0.9996\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0035 - acc: 0.9997\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0034 - acc: 0.9997\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0033 - acc: 0.9997\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0032 - acc: 0.9997\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0031 - acc: 0.9997\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0018 - acc: 0.9999\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 145/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 146/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0011 - acc: 0.9999\n",
      "Epoch 153/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 9.8325e-04 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 9.6062e-04 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 9.3047e-04 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 9.0728e-04 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 8.7761e-04 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 8.5295e-04 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 8.3128e-04 - acc: 1.0000\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 27us/step - loss: 8.0689e-04 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 7.8267e-04 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 7.6363e-04 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 7.4519e-04 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 7.2382e-04 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 7.0438e-04 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 6.8432e-04 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 6.6783e-04 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 6.4961e-04 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 6.3136e-04 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 6.1924e-04 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 5.9772e-04 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 5.8245e-04 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 5.6611e-04 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 5.5166e-04 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 5.3848e-04 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 5.2359e-04 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 5.1027e-04 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 4.9682e-04 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 4.8608e-04 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 4.7332e-04 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 4.6048e-04 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 4.4862e-04 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 4.3797e-04 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 4.2702e-04 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 4.1702e-04 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 4.0552e-04 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 3.9730e-04 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 3.8667e-04 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 3.7793e-04 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 3.6744e-04 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 3.5899e-04 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 3.5105e-04 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 3.4207e-04 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 3.3328e-04 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 3.2582e-04 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 3.1875e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb30b7c860>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(index1, index2, size = 26):\n",
    "    I2L = dict(zip(range(size), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
    "    return ([I2L[index1], I2L[index2]])\n",
    "\n",
    "\n",
    "def predict_results_only_2(model, x_train, y_train):\n",
    "    predictions = model.predict(x_train)\n",
    "    # index1, index2, label1, label2 represent two predictions and two labels respectively\n",
    "    index1 = np.argmax(predictions[:, 0:26], axis=1)\n",
    "    index2 = np.argmax(predictions[:, 26:52], axis=1)\n",
    "    label1 = np.argmax(y_train[:, 0:26], axis=1)\n",
    "    label2 = np.argmax(y_train[:, 26:52], axis=1)\n",
    "\n",
    "    # Change number to string and do an output\n",
    "    prediction_list = list(map(num2str, index1, index2))\n",
    "    label_list = list(map(num2str, label1, label2))\n",
    "\n",
    "    return (prediction_list, label_list)\n",
    "\n",
    "\n",
    "# 理论上只要把矩阵转成字符就好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff(list1, list2):\n",
    "    if \"\".join(list1) != \"\".join(list2):\n",
    "        print(\"\".join(list1), \"\".join(list2))\n",
    "        return(\"\".join(list1), \"\".join(list2))\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 73us/step\n",
      "\n",
      "acc: 99.68%\n",
      "UZ UZ\n",
      "UL UL\n",
      "VU VU\n",
      "KV KV\n",
      "GW GW\n",
      "NF NF\n",
      "HL HL\n",
      "GE GE\n",
      "HA HA\n",
      "XB XB\n",
      "MK MK\n",
      "AY AY\n",
      "NE NE\n",
      "IN IN\n",
      "SJ SJ\n",
      "PC PC\n",
      "AN AN\n",
      "TE TE\n",
      "PK PK\n",
      "UE UE\n",
      "QI QI\n",
      "AI AI\n",
      "NB NB\n",
      "OM IR\n",
      "CL CL\n",
      "JV JV\n",
      "BY BY\n",
      "RP RP\n",
      "YL YL\n",
      "ZF ZF\n",
      "IK IK\n",
      "ML ML\n",
      "NV NV\n",
      "UC UC\n",
      "NW NW\n",
      "HY HY\n",
      "TM TM\n",
      "UR UR\n",
      "ZV ZV\n",
      "YC YC\n",
      "SY SY\n",
      "QI QI\n",
      "BK BK\n",
      "OG OG\n",
      "DN DN\n",
      "XD JE\n",
      "RF RF\n",
      "PD PD\n",
      "QQ QQ\n",
      "NM NM\n",
      "XE XE\n",
      "KF KF\n",
      "MY MY\n",
      "QQ QQ\n",
      "CF CF\n",
      "YC YC\n",
      "KA KS\n",
      "MZ MZ\n",
      "ES ES\n",
      "ZZ ZZ\n",
      "KA KA\n",
      "AN AN\n",
      "CX CX\n",
      "FA FA\n",
      "DB DB\n",
      "QM QM\n",
      "VN VN\n",
      "YS YS\n",
      "MT MT\n",
      "SE SE\n",
      "TS TS\n",
      "CF CF\n",
      "DH DH\n",
      "CO CO\n",
      "PF PF\n",
      "YD YD\n",
      "ZB ZB\n",
      "OC XA\n",
      "HM HM\n",
      "FC FC\n",
      "XX XX\n",
      "NP NP\n",
      "MC MC\n",
      "OE OE\n",
      "AT AT\n",
      "IT IT\n",
      "LJ LJ\n",
      "PT PT\n",
      "LG LG\n",
      "MK MK\n",
      "WA WA\n",
      "DW DW\n",
      "BU BU\n",
      "OZ OZ\n",
      "IP IP\n",
      "OD OD\n",
      "XQ XQ\n",
      "JU JU\n",
      "PS PS\n",
      "OI OI\n",
      "JX JX\n",
      "TA TA\n",
      "KC KC\n",
      "WX WX\n",
      "DO DO\n",
      "XG XG\n",
      "HB HB\n",
      "ZI ZI\n",
      "EY EY\n",
      "JF JF\n",
      "VX VX\n",
      "RU RU\n",
      "YM YM\n",
      "FH FH\n",
      "DJ DJ\n",
      "LS LS\n",
      "RL RL\n",
      "HZ HZ\n",
      "QY QY\n",
      "WB WB\n",
      "OI OI\n",
      "EI EI\n",
      "RZ RZ\n",
      "EJ EJ\n",
      "SK SK\n",
      "HI HI\n",
      "EP EP\n",
      "YV YV\n",
      "CT CT\n",
      "LG LK\n",
      "DS DS\n",
      "TE TE\n",
      "XS XS\n",
      "MN MN\n",
      "HN HN\n",
      "GU GS\n",
      "SG SG\n",
      "VH VH\n",
      "ED ED\n",
      "XL XL\n",
      "NU LU\n",
      "CO CO\n",
      "YM YM\n",
      "JP JP\n",
      "BZ BZ\n",
      "YE YE\n",
      "FW FW\n",
      "AO AO\n",
      "UT UT\n",
      "BQ BQ\n",
      "UX UX\n",
      "ZO ZO\n",
      "NV NV\n",
      "BJ BJ\n",
      "IS IS\n",
      "UX UX\n",
      "EN EN\n",
      "YL YL\n",
      "LG LK\n",
      "QL QL\n",
      "DV DV\n",
      "RC RC\n",
      "BA BA\n",
      "WV WV\n",
      "QH QH\n",
      "HA HA\n",
      "FZ FZ\n",
      "CA CA\n",
      "FT FT\n",
      "BK BK\n",
      "ZZ ZZ\n",
      "DI DI\n",
      "ID ID\n",
      "GU GS\n",
      "KG KG\n",
      "GV GV\n",
      "XS XS\n",
      "IV IV\n",
      "ZX ZX\n",
      "KT KT\n",
      "GV GV\n",
      "AH AH\n",
      "VP VK\n",
      "MT MT\n",
      "PQ PQ\n",
      "XD XD\n",
      "VL VL\n",
      "GL GL\n",
      "SB SB\n",
      "FY FY\n",
      "SO SO\n",
      "VJ VJ\n",
      "TZ TZ\n",
      "OE OE\n",
      "ZB ZB\n",
      "AT AT\n",
      "XW XW\n",
      "VR VR\n",
      "DH DH\n",
      "AD AD\n",
      "QN QN\n",
      "MO MO\n",
      "CO CO\n",
      "LX LX\n",
      "RU RU\n",
      "JH JH\n",
      "LN LN\n",
      "EM EM\n",
      "ZK ZK\n",
      "FO FO\n",
      "ML ML\n",
      "VR VR\n",
      "NW NW\n",
      "RK RK\n",
      "KF KF\n",
      "CL CL\n",
      "JP JP\n",
      "GX GX\n",
      "VW VW\n",
      "QY QY\n",
      "GW GW\n",
      "UM UM\n",
      "ST ST\n",
      "PE PE\n",
      "GZ GZ\n",
      "PQ PQ\n",
      "ZS ZS\n",
      "IG IG\n",
      "NQ NQ\n",
      "ZQ ZM\n",
      "FK FK\n",
      "AM AM\n",
      "FE FE\n",
      "AU AU\n",
      "DJ DJ\n",
      "GG GG\n",
      "VV VV\n",
      "NL NL\n",
      "DR DR\n",
      "QK QK\n",
      "WG HT\n",
      "SG SG\n",
      "DR DR\n",
      "MP MP\n",
      "XR XR\n",
      "WQ WQ\n",
      "QY QY\n",
      "HB HB\n",
      "BH BH\n",
      "RN RN\n",
      "ZD ZD\n",
      "NE NE\n",
      "UB UB\n",
      "VD VD\n",
      "GI GI\n",
      "SQ SQ\n",
      "VU VU\n",
      "TH TH\n",
      "MF MF\n",
      "DT DT\n",
      "EE EE\n",
      "DJ DJ\n",
      "HW HW\n",
      "BG BG\n",
      "QG QG\n",
      "DC DC\n",
      "YC YC\n",
      "HO WO\n",
      "CQ CQ\n",
      "FB FB\n",
      "FX FX\n",
      "TQ TQ\n",
      "HV HV\n",
      "LS LS\n",
      "MX MX\n",
      "WP WP\n",
      "ZZ ZZ\n",
      "LS LS\n",
      "VA VA\n",
      "MK MK\n",
      "ZF ZF\n",
      "PL PL\n",
      "OX OX\n",
      "IW IW\n",
      "YC YC\n",
      "EN EN\n",
      "FX FX\n",
      "ZL ZL\n",
      "WX JN\n",
      "AJ AJ\n",
      "HY HY\n",
      "UR UR\n",
      "CK CK\n",
      "US US\n",
      "TV TV\n",
      "TZ TZ\n",
      "DD DD\n",
      "PM PM\n",
      "DW DW\n",
      "PR PR\n",
      "LG LK\n",
      "TI TI\n",
      "FA FA\n",
      "OC OC\n",
      "IG IG\n",
      "RZ RZ\n",
      "VN VN\n",
      "SE SE\n",
      "CR CR\n",
      "NM NM\n",
      "SF SF\n",
      "QG QG\n",
      "KR KR\n",
      "ZN ZN\n",
      "FR FR\n",
      "SN SN\n",
      "SP SP\n",
      "SZ SZ\n",
      "UW UW\n",
      "OR OR\n",
      "DC DC\n",
      "PF PF\n",
      "IC IC\n",
      "OT OT\n",
      "LD LD\n",
      "ZD ZD\n",
      "AG AG\n",
      "GX GX\n",
      "YS YS\n",
      "HG HG\n",
      "NY NY\n",
      "HA HA\n",
      "VM VM\n",
      "VE VE\n",
      "RT RT\n",
      "UT UT\n",
      "DX DX\n",
      "EJ EJ\n",
      "YU YU\n",
      "FI FI\n",
      "OS OS\n",
      "WV WV\n",
      "QZ QZ\n",
      "NY NY\n",
      "BY BY\n",
      "HQ HQ\n",
      "FS FS\n",
      "BA BA\n",
      "PP YP\n",
      "DJ DJ\n",
      "WR WR\n",
      "CT CT\n",
      "ZA ZA\n",
      "QE QE\n",
      "HP HP\n",
      "HS HS\n",
      "MM MM\n",
      "YU YU\n",
      "BG BG\n",
      "YG YG\n",
      "GC GC\n",
      "OJ OJ\n",
      "DC DC\n",
      "HK HK\n",
      "LG LG\n",
      "QP QP\n",
      "AC AC\n",
      "CN CN\n",
      "UC UC\n",
      "PM PM\n",
      "NJ NJ\n",
      "CF CF\n",
      "QP QP\n",
      "TO TO\n",
      "SX SX\n",
      "UI UI\n",
      "EM EM\n",
      "EC EC\n",
      "JI JI\n",
      "ZD ZD\n",
      "YG YG\n",
      "MW MW\n",
      "DM DM\n",
      "GI GI\n",
      "NS NS\n",
      "HB HB\n",
      "EX EX\n",
      "NQ NQ\n",
      "LY LY\n",
      "NC NC\n",
      "LH LH\n",
      "VN VN\n",
      "ZP DP\n",
      "HR HR\n",
      "OL OL\n",
      "RG RG\n",
      "GM GM\n",
      "HL HL\n",
      "IF IF\n",
      "IE IE\n",
      "ZN ZN\n",
      "TA TA\n",
      "HB HB\n",
      "ZA ZA\n",
      "FK FK\n",
      "ER ER\n",
      "GV GV\n",
      "QH QH\n",
      "TT TT\n",
      "RB RB\n",
      "MB MB\n",
      "EQ EQ\n",
      "DU DU\n",
      "JO JO\n",
      "AJ AJ\n",
      "HD HD\n",
      "ZY ZY\n",
      "VI VI\n",
      "ZK ZK\n",
      "ML ML\n",
      "HK HK\n",
      "KT KT\n",
      "EY EY\n",
      "CK CK\n",
      "FJ FJ\n",
      "OI OI\n",
      "GR GR\n",
      "CJ CJ\n",
      "PD PD\n",
      "AI AI\n",
      "YM YM\n",
      "WG WG\n",
      "SS SS\n",
      "KH KH\n",
      "AC AC\n",
      "ER ER\n",
      "MZ MZ\n",
      "GN GN\n",
      "IY IY\n",
      "TE TE\n",
      "LL LL\n",
      "XQ XQ\n",
      "GU GU\n",
      "YW YW\n",
      "IN IN\n",
      "RH RH\n",
      "DD DD\n",
      "YB YB\n",
      "EL EL\n",
      "KN KN\n",
      "FU FU\n",
      "CY CY\n",
      "EW EW\n",
      "XL XL\n",
      "LW LW\n",
      "IB IB\n",
      "JV JV\n",
      "KR KR\n",
      "BY BY\n",
      "TC TC\n",
      "MJ MJ\n",
      "FE FE\n",
      "VT VT\n",
      "IB IB\n",
      "SQ SQ\n",
      "UR UR\n",
      "CN CN\n",
      "LJ LJ\n",
      "GD GD\n",
      "LF LF\n",
      "VA VA\n",
      "YA YA\n",
      "PO PO\n",
      "AT AT\n",
      "GD GD\n",
      "BQ BQ\n",
      "QQ QQ\n",
      "SN SN\n",
      "GG GG\n",
      "DR DR\n",
      "XH XH\n",
      "GJ GJ\n",
      "VV VV\n",
      "AB AB\n",
      "OP OP\n",
      "FQ FQ\n",
      "XB XB\n",
      "IQ IQ\n",
      "MF MF\n",
      "KO KO\n",
      "EV EV\n",
      "HV HV\n",
      "OJ OJ\n",
      "WM WM\n",
      "QZ QZ\n",
      "NS NS\n",
      "GC GC\n",
      "HR HR\n",
      "XX XX\n",
      "DW DW\n",
      "LG LG\n",
      "RE RE\n",
      "EJ EJ\n",
      "KQ KQ\n",
      "UT UT\n",
      "DI DI\n",
      "OV OV\n",
      "VP VK\n",
      "EI EI\n",
      "CR CR\n",
      "OC OC\n",
      "HP HP\n",
      "IE IE\n",
      "LN LN\n",
      "II II\n",
      "IF IF\n",
      "YA YA\n",
      "DI DI\n",
      "GN GN\n",
      "HC HC\n",
      "DE DE\n",
      "WL WL\n",
      "OX OX\n",
      "ZZ ZZ\n",
      "YQ YQ\n",
      "VA VA\n",
      "PJ PJ\n",
      "FC FC\n",
      "PT PT\n",
      "ZB ZB\n",
      "LE LE\n",
      "CD CD\n",
      "ZI ZI\n",
      "TC TC\n",
      "JG JG\n",
      "IG IG\n",
      "JM JM\n",
      "JG JG\n",
      "BU BU\n",
      "XS XS\n",
      "KV KV\n",
      "TR TR\n",
      "GJ GJ\n",
      "IU IU\n",
      "RF RF\n",
      "UB UB\n",
      "WT WT\n",
      "BS BS\n",
      "XI XI\n",
      "UC UC\n",
      "NF NF\n",
      "GI GI\n",
      "ZF ZF\n",
      "GZ GZ\n",
      "MI MI\n",
      "QS QS\n",
      "DL DL\n",
      "AC AC\n",
      "XE XE\n",
      "GF GF\n",
      "JQ JQ\n",
      "EH EH\n",
      "TU TU\n",
      "SX SX\n",
      "BB BB\n",
      "AX AX\n",
      "CI CI\n",
      "WB WB\n",
      "HE HE\n",
      "WG HT\n",
      "XM XM\n",
      "DD DD\n",
      "NU NU\n",
      "WZ WZ\n",
      "HL HL\n",
      "HX HX\n",
      "ZR ZR\n",
      "UK UK\n",
      "HJ HJ\n",
      "UV UV\n",
      "PV PV\n",
      "PJ PJ\n",
      "CT CT\n",
      "YM YM\n",
      "DZ DZ\n",
      "IU IU\n",
      "FY FY\n",
      "EM EM\n",
      "RR RR\n",
      "KZ KZ\n",
      "AP AP\n",
      "EI EI\n",
      "EQ EQ\n",
      "IK IK\n",
      "WE WE\n",
      "FO FO\n",
      "II II\n",
      "QU QU\n",
      "ZY ZY\n",
      "KJ KJ\n",
      "JC JC\n",
      "ME ME\n",
      "BJ BJ\n",
      "GE GE\n",
      "ZU ZU\n",
      "IO IO\n",
      "GB GB\n",
      "XI XI\n",
      "PT PT\n",
      "EM EM\n",
      "NT NT\n",
      "QT QT\n",
      "BZ BZ\n",
      "FM FM\n",
      "MC KW\n",
      "IE IE\n",
      "JH JH\n",
      "QC QC\n",
      "DS DS\n",
      "GN GN\n",
      "MB MB\n",
      "BY BY\n",
      "YE YE\n",
      "OS OS\n",
      "RC RC\n",
      "KR KR\n",
      "QC QC\n",
      "XY XY\n",
      "ET ET\n",
      "TP TP\n",
      "YM YM\n",
      "KV KV\n",
      "LS LS\n",
      "EG EG\n",
      "YH YH\n",
      "DN DN\n",
      "SO SO\n",
      "KM KM\n",
      "RV RV\n",
      "HY HY\n",
      "XR XR\n",
      "SO SO\n",
      "NU NU\n",
      "LW LW\n",
      "IQ IQ\n",
      "ZQ ZQ\n",
      "HA HA\n",
      "PO PO\n",
      "SU SU\n",
      "FG FG\n",
      "EH EH\n",
      "EW EW\n",
      "AG AG\n",
      "GW GW\n",
      "YK YK\n",
      "LL LL\n",
      "GB GB\n",
      "ZL ZL\n",
      "QS QS\n",
      "HI HI\n",
      "WM WM\n",
      "SQ SQ\n",
      "DI DI\n",
      "OY OY\n",
      "UN UN\n",
      "AS AS\n",
      "MQ MQ\n",
      "YW YW\n",
      "NR NR\n",
      "UZ UZ\n",
      "OA OA\n",
      "BG BG\n",
      "ML ML\n",
      "KD KD\n",
      "SG SG\n",
      "HB HB\n",
      "LN LN\n",
      "NZ NZ\n",
      "JQ JQ\n",
      "MX MX\n",
      "AH AH\n",
      "OS OS\n",
      "XH XH\n",
      "SJ SJ\n",
      "LE LE\n",
      "TR TR\n",
      "NV NV\n",
      "UA UA\n",
      "IX IX\n",
      "ZB ZB\n",
      "FX FX\n",
      "EO EO\n",
      "JK JK\n",
      "YI YI\n",
      "QP QP\n",
      "YL YL\n",
      "GK GK\n",
      "LP LP\n",
      "VI VI\n",
      "OC OC\n",
      "DR DR\n",
      "XZ XZ\n",
      "YO YO\n",
      "JX JX\n",
      "LL LL\n",
      "MD MD\n",
      "DV DV\n",
      "DR DR\n",
      "KU KU\n",
      "TL TL\n",
      "YV YV\n",
      "NG NA\n",
      "AP AP\n",
      "HY HY\n",
      "XC XC\n",
      "SL SL\n",
      "OB OB\n",
      "CN CN\n",
      "CI CI\n",
      "FK FK\n",
      "IG IG\n",
      "NS NS\n",
      "ZF ZF\n",
      "PD PD\n",
      "QP QP\n",
      "MH MH\n",
      "QX QX\n",
      "RC RC\n",
      "LC LC\n",
      "XY XY\n",
      "FS FS\n",
      "LR LR\n",
      "WN WN\n",
      "HL HL\n",
      "JK JK\n",
      "MQ MQ\n",
      "MR MR\n",
      "RB RB\n",
      "UT UT\n",
      "IO IO\n",
      "MI MI\n",
      "SH SH\n",
      "IO IO\n",
      "II II\n",
      "EB EB\n",
      "IK IK\n",
      "SG SG\n",
      "AF AF\n",
      "LS LS\n",
      "NQ NQ\n",
      "DH DH\n",
      "TO TO\n",
      "MP MP\n",
      "KD KD\n",
      "OR OR\n",
      "RU RU\n",
      "AV AV\n",
      "OL OL\n",
      "OM OM\n",
      "QB QB\n",
      "QM QM\n",
      "JU JU\n",
      "RF RF\n",
      "TL TL\n",
      "YL YL\n",
      "EE EE\n",
      "DG DG\n",
      "VX VX\n",
      "VW VW\n",
      "AO AO\n",
      "YJ YJ\n",
      "EF EF\n",
      "ZA ZA\n",
      "NI NI\n",
      "EQ EQ\n",
      "SF SF\n",
      "XW XW\n",
      "DE DE\n",
      "WI WI\n",
      "WW WW\n",
      "VJ VJ\n",
      "JW JW\n",
      "XE XE\n",
      "QJ QJ\n",
      "EV EV\n",
      "WF WF\n",
      "AH AH\n",
      "CX CX\n",
      "NS NX\n",
      "UV UU\n",
      "XJ XJ\n",
      "YV YV\n",
      "IZ IZ\n",
      "NF NF\n",
      "EA EA\n",
      "MA MA\n",
      "XT XT\n",
      "ST ST\n",
      "ZX ZX\n",
      "PP YP\n",
      "BB BB\n",
      "RL RL\n",
      "IQ IQ\n",
      "LX LX\n",
      "LE LE\n",
      "MH MH\n",
      "QZ QZ\n",
      "UO UO\n",
      "FV FV\n",
      "CJ CJ\n",
      "IE IE\n",
      "DS DS\n",
      "XD XD\n",
      "FM FM\n",
      "VF VF\n",
      "GC GC\n",
      "NM NM\n",
      "XL XL\n",
      "NS NS\n",
      "TG TG\n",
      "NN NN\n",
      "JA JA\n",
      "JG JG\n",
      "RN RN\n",
      "BD BD\n",
      "MR MR\n",
      "DF DF\n",
      "PX PX\n",
      "EU EU\n",
      "DL DL\n",
      "PP YP\n",
      "QN QN\n",
      "NO NO\n",
      "TC TC\n",
      "UK UK\n",
      "HN HN\n",
      "XR XR\n",
      "QS QS\n",
      "RY RY\n",
      "IO IO\n",
      "IX IX\n",
      "HR HR\n",
      "ZZ ZZ\n",
      "QM QM\n",
      "NU NU\n",
      "RX RX\n",
      "WX WX\n",
      "VS VS\n",
      "EX EX\n",
      "ZC ZC\n",
      "UX UX\n",
      "ML ML\n",
      "NR NR\n",
      "EP EP\n",
      "UC UC\n",
      "RI RI\n",
      "KX KX\n",
      "EX EX\n",
      "FV FV\n",
      "DT DT\n",
      "QK QK\n",
      "QZ QZ\n",
      "VG VG\n",
      "CH CH\n",
      "PN PN\n",
      "IY IY\n",
      "ED ED\n",
      "UV UV\n",
      "CJ CJ\n",
      "BC BC\n",
      "BU BU\n",
      "PW PW\n",
      "FB FB\n",
      "WL WL\n",
      "KO KO\n",
      "GN GN\n",
      "YS YS\n",
      "MO MO\n",
      "BB BB\n",
      "JC JC\n",
      "DO DO\n",
      "PZ PZ\n",
      "WV WV\n",
      "LB LB\n",
      "GK GK\n",
      "ZT ZT\n",
      "AY AY\n",
      "GG GG\n",
      "AF AF\n",
      "PS PS\n",
      "OC OC\n",
      "VT VT\n",
      "UY UY\n",
      "EG EG\n",
      "GL GL\n",
      "ZQ ZQ\n",
      "KC KC\n",
      "GZ GZ\n",
      "HL HL\n",
      "OC XA\n",
      "KZ KZ\n",
      "UI UI\n",
      "YN YN\n",
      "RF RF\n",
      "IX IX\n",
      "PP PP\n",
      "XP XP\n",
      "XU XU\n",
      "TZ TZ\n",
      "OD OD\n",
      "ZC ZC\n",
      "FG FG\n",
      "FZ FZ\n",
      "KK KK\n",
      "JK JK\n",
      "ZL ZL\n",
      "HM HM\n",
      "HM HM\n",
      "ZH ZH\n",
      "DX DX\n",
      "KV KV\n",
      "GZ GZ\n",
      "FE FE\n",
      "AB AB\n",
      "QU QU\n",
      "WF WF\n",
      "MX MX\n",
      "OC OC\n",
      "PP YP\n",
      "MC MC\n",
      "GW GW\n",
      "WX JN\n",
      "OQ OQ\n",
      "GZ GZ\n",
      "QC QC\n",
      "LP LP\n",
      "EU EU\n",
      "AZ AZ\n",
      "BP BP\n",
      "XO XO\n",
      "IM IM\n",
      "JP JP\n",
      "RF RF\n",
      "KU KU\n",
      "YM YM\n",
      "LZ LZ\n",
      "UZ UZ\n",
      "NI NI\n",
      "BO BO\n",
      "OH OH\n",
      "EC EC\n",
      "LQ LQ\n",
      "FR FR\n",
      "OP OP\n",
      "PT PT\n",
      "VT VT\n",
      "HL HL\n",
      "VN VN\n",
      "IB IB\n",
      "IU IU\n",
      "YX YX\n",
      "JB JB\n",
      "HO WO\n",
      "AE AE\n",
      "JJ JJ\n",
      "DD DD\n",
      "JA JA\n",
      "YF YF\n",
      "VD VD\n",
      "TF TF\n",
      "NJ NJ\n",
      "TY TY\n",
      "CV CV\n",
      "HQ HQ\n",
      "DX DX\n",
      "XC XC\n",
      "LD LD\n",
      "GL GL\n",
      "HJ HJ\n",
      "LZ LZ\n",
      "AU AU\n",
      "XY XY\n",
      "VW VW\n",
      "DE DE\n",
      "GG GG\n",
      "DE DE\n",
      "LL LL\n",
      "LZ LZ\n",
      "IB IB\n",
      "PJ PJ\n",
      "ZR ZR\n",
      "NU LU\n",
      "NK NK\n",
      "QY QY\n",
      "CZ CZ\n",
      "DG DG\n",
      "LJ LJ\n",
      "SE SE\n",
      "OQ OQ\n",
      "HR HR\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test, y_test_small = data_genelization()\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "prediction_list, label_list = predict_results_only_2(model, x_test, y_test)\n",
    "\n",
    "for i in range(len(prediction_list)):\n",
    "    print(\"\".join(prediction_list[i]), \"\".join(label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OM IR\n",
      "XD JE\n",
      "KA KS\n",
      "OC XA\n",
      "LG LK\n",
      "GU GS\n",
      "NU LU\n",
      "LG LK\n",
      "GU GS\n",
      "VP VK\n",
      "ZQ ZM\n",
      "WG HT\n",
      "HO WO\n",
      "WX JN\n",
      "LG LK\n",
      "PP YP\n",
      "ZP DP\n",
      "VP VK\n",
      "WG HT\n",
      "MC KW\n",
      "NG NA\n",
      "NS NX\n",
      "UV UU\n",
      "PP YP\n",
      "PP YP\n",
      "OC XA\n",
      "PP YP\n",
      "WX JN\n",
      "HO WO\n",
      "NU LU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = list(map(find_diff, prediction_list, label_list))\n",
    "diff[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [\"NC\"]\n",
    "for i in range(1000):\n",
    "    temp.append(\"NC\")\n",
    "x_test, y_test, y_test_small = data_test(temp)\n",
    "prediction_list, label_list = predict_results_only_2(model, x_test, y_test)\n",
    "diff = list(map(find_diff, prediction_list, label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy didn't go to 1 but remained at 50% level.(when 26)\n",
    "Try more training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 0s 355us/step - loss: 0.6605 - acc: 0.7376\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.5386 - acc: 0.9307\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.3100 - acc: 0.9613\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1824 - acc: 0.9615\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1669 - acc: 0.9615\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1643 - acc: 0.9615\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1627 - acc: 0.9615\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1614 - acc: 0.9615\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1604 - acc: 0.9615\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1594 - acc: 0.9615\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1584 - acc: 0.9615\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1573 - acc: 0.9615\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1562 - acc: 0.9615\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.1550 - acc: 0.9615\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.1537 - acc: 0.9615\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.1522 - acc: 0.9615\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.1507 - acc: 0.9615\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1489 - acc: 0.9615\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1469 - acc: 0.9615\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1448 - acc: 0.9615\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.1426 - acc: 0.9615\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1402 - acc: 0.9615\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.1378 - acc: 0.9616\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.1352 - acc: 0.9616\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1325 - acc: 0.9616\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1298 - acc: 0.9617\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.1270 - acc: 0.9617\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1243 - acc: 0.9617\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.1215 - acc: 0.9618\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.1187 - acc: 0.9620\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.1160 - acc: 0.9622\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1133 - acc: 0.9625\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1107 - acc: 0.9629\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1081 - acc: 0.9632\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.1056 - acc: 0.9636\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.1031 - acc: 0.9641\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.1008 - acc: 0.9646\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0984 - acc: 0.9654\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0961 - acc: 0.9660\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0939 - acc: 0.9665\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0917 - acc: 0.9673\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0895 - acc: 0.9678\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0874 - acc: 0.9687\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0853 - acc: 0.9693\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0833 - acc: 0.9703\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0813 - acc: 0.9710\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0792 - acc: 0.9719\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0773 - acc: 0.9726\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0754 - acc: 0.9735\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0735 - acc: 0.9740\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0717 - acc: 0.9749\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0700 - acc: 0.9757\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0684 - acc: 0.9763\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0667 - acc: 0.9772\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0653 - acc: 0.9775\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0637 - acc: 0.9782\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0622 - acc: 0.9789\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0609 - acc: 0.9795\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0595 - acc: 0.9800\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0581 - acc: 0.9804\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0569 - acc: 0.9808\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0556 - acc: 0.9814\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0545 - acc: 0.9819\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0533 - acc: 0.9824\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0522 - acc: 0.9828\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0511 - acc: 0.9832\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0500 - acc: 0.9839\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0490 - acc: 0.9843\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0480 - acc: 0.9848\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0470 - acc: 0.9850\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0461 - acc: 0.9854\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0452 - acc: 0.9859\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0443 - acc: 0.9861\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0433 - acc: 0.9865\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0425 - acc: 0.9867\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0416 - acc: 0.9873\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0407 - acc: 0.9874\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0399 - acc: 0.9878\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0392 - acc: 0.9880\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0384 - acc: 0.9883\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0375 - acc: 0.9887\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0368 - acc: 0.9886\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0360 - acc: 0.9889\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0353 - acc: 0.9893\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0346 - acc: 0.9897\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0339 - acc: 0.9899\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0332 - acc: 0.9902\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0326 - acc: 0.9902\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0319 - acc: 0.9904\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0312 - acc: 0.9908\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0307 - acc: 0.9911\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0301 - acc: 0.9912\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0295 - acc: 0.9913\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0289 - acc: 0.9915\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0283 - acc: 0.9918\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0279 - acc: 0.9920\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0273 - acc: 0.9920\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0268 - acc: 0.9923\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0263 - acc: 0.9926\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0258 - acc: 0.9928\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0253 - acc: 0.9927\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0249 - acc: 0.9932\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0245 - acc: 0.9932\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0240 - acc: 0.9934\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0235 - acc: 0.9937\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0231 - acc: 0.9936\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0227 - acc: 0.9940\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0223 - acc: 0.9940\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0220 - acc: 0.9941\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0216 - acc: 0.9942\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0212 - acc: 0.9947\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0208 - acc: 0.9944\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0205 - acc: 0.9948\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0202 - acc: 0.9946\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0198 - acc: 0.9949\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0195 - acc: 0.9947\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0191 - acc: 0.9950\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0188 - acc: 0.9951\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0185 - acc: 0.9951\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0182 - acc: 0.9953\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0178 - acc: 0.9953\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0176 - acc: 0.9954\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0172 - acc: 0.9956\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0169 - acc: 0.9956\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0167 - acc: 0.9957\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0164 - acc: 0.9959\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0162 - acc: 0.9959\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0159 - acc: 0.9960\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0156 - acc: 0.9961\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0153 - acc: 0.9962\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0151 - acc: 0.9964\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0148 - acc: 0.9964\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0146 - acc: 0.9965\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0143 - acc: 0.9965\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0142 - acc: 0.9966\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0139 - acc: 0.9968\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0136 - acc: 0.9968\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0133 - acc: 0.9969\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0132 - acc: 0.9970\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0130 - acc: 0.9970\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0127 - acc: 0.9972\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0125 - acc: 0.9972\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0123 - acc: 0.9973\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0121 - acc: 0.9972\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0119 - acc: 0.9974\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0117 - acc: 0.9975\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0115 - acc: 0.9975\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0113 - acc: 0.9977\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0111 - acc: 0.9977\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0109 - acc: 0.9977\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0108 - acc: 0.9978\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0106 - acc: 0.9977\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0104 - acc: 0.9980\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0103 - acc: 0.9980\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0100 - acc: 0.9979\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0099 - acc: 0.9982\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0097 - acc: 0.9981\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0096 - acc: 0.9982\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0094 - acc: 0.9982\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0093 - acc: 0.9983\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0091 - acc: 0.9983\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0089 - acc: 0.9984\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0088 - acc: 0.9985\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0087 - acc: 0.9986\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0085 - acc: 0.9984\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0084 - acc: 0.9986\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0082 - acc: 0.9987\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0081 - acc: 0.9985\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.0079 - acc: 0.9987\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0078 - acc: 0.9987\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0077 - acc: 0.9988\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0075 - acc: 0.9987\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0074 - acc: 0.9988\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0073 - acc: 0.9988\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0071 - acc: 0.9989\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0070 - acc: 0.9988\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0069 - acc: 0.9989\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0067 - acc: 0.9989\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0065 - acc: 0.9990\n",
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0064 - acc: 0.9989\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0063 - acc: 0.9990\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0062 - acc: 0.9991\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0061 - acc: 0.9990\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0060 - acc: 0.9991\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0059 - acc: 0.9991\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0057 - acc: 0.9992\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0056 - acc: 0.9992\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0056 - acc: 0.9993\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0055 - acc: 0.9992\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0054 - acc: 0.9992\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0052 - acc: 0.9993\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0052 - acc: 0.9993\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0051 - acc: 0.9994\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0049 - acc: 0.9994\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0048 - acc: 0.9993\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0047 - acc: 0.9994\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0046 - acc: 0.9994\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0045 - acc: 0.9995\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0045 - acc: 0.9994\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0044 - acc: 0.9995\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0043 - acc: 0.9995\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0042 - acc: 0.9995\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0040 - acc: 0.9995\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0039 - acc: 0.9997\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.0038 - acc: 0.9996\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0038 - acc: 0.9997\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0037 - acc: 0.9997\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0036 - acc: 0.9997\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0036 - acc: 0.9997\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0035 - acc: 0.9998\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0034 - acc: 0.9997\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0034 - acc: 0.9998\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0032 - acc: 0.9998\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0031 - acc: 0.9998\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0029 - acc: 0.9999\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0028 - acc: 0.9999\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0028 - acc: 0.9999\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0027 - acc: 0.9999\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0027 - acc: 0.9999\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0027 - acc: 0.9999\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0026 - acc: 0.9999\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0025 - acc: 0.9999\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0025 - acc: 0.9999\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0025 - acc: 0.9999\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0024 - acc: 0.9999\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0024 - acc: 0.9999\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0023 - acc: 0.9999\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0022 - acc: 0.9999\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0020 - acc: 0.9999\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 9.9120e-04 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 9.7065e-04 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 9.5704e-04 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 9.3697e-04 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 9.2654e-04 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 9.0956e-04 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 8.9138e-04 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 8.7983e-04 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 8.6693e-04 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 8.3944e-04 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 8.3200e-04 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 8.1688e-04 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 8.0135e-04 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 7.8961e-04 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 7.7063e-04 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 7.6180e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb30a63828>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, y_train_small = data_genelization(sample_size = 2,loops = 10000, size = 3, key = 1, x_as_vector = False, y_as_vector = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    " # assume that we have got our data x_train y_train\n",
    "# now we are going to train it in our model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 66us/step - loss: 0.6555 - acc: 0.6667\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.5025 - acc: 0.6926\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.4092 - acc: 0.7230\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.3497 - acc: 0.7206\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.3000 - acc: 0.7076\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2709 - acc: 0.7192\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2564 - acc: 0.7295\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2485 - acc: 0.7270\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2439 - acc: 0.7140\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2409 - acc: 0.7055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb35b74ac8>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.5685940e+00, -7.5578344e-01,  2.9726129e+00,  2.8926406e-02],\n",
       "        [-6.4602363e-01, -1.3272898e+00, -1.6753883e+00,  8.8879782e-01],\n",
       "        [ 2.8905544e-01,  2.7274203e+00, -4.1011357e-01,  1.4950769e+00],\n",
       "        [-1.3924526e+00,  4.8229340e-01,  1.2612160e+00, -2.0509748e+00],\n",
       "        [-7.5499356e-01, -2.2950272e-01,  1.1744325e+00,  1.8901294e+00],\n",
       "        [ 2.3575439e+00,  8.6360145e-04, -5.5712640e-01, -1.1779923e+00]],\n",
       "       dtype=float32),\n",
       " array([1.5374192, 1.1142339, 1.0893863, 1.1623676], dtype=float32),\n",
       " array([[-0.13530163, -0.6692685 ,  0.12882563, -1.424377  ,  1.9253594 ,\n",
       "         -2.1576288 ],\n",
       "        [-1.4458797 ,  2.652958  , -1.4707116 , -1.4061795 , -0.41814592,\n",
       "          1.441015  ],\n",
       "        [-1.1648395 , -1.4701993 ,  1.5168785 ,  0.04260638, -1.8375388 ,\n",
       "          1.301559  ],\n",
       "        [ 0.4505602 , -0.20008475, -0.8927824 ,  2.7003853 , -1.1340812 ,\n",
       "         -2.3374708 ]], dtype=float32),\n",
       " array([ 1.884285 , -1.6483525, -1.9364004, -1.4228922, -0.187781 ,\n",
       "         0.6112278], dtype=float32)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5374192, 1.1142339, 1.0893863, 1.1623676], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.13530163, -0.6692685 ,  0.12882563, -1.424377  ,  1.9253594 ,\n",
       "         -2.1576288 ],\n",
       "        [-1.4458797 ,  2.652958  , -1.4707116 , -1.4061795 , -0.41814592,\n",
       "          1.441015  ],\n",
       "        [-1.1648395 , -1.4701993 ,  1.5168785 ,  0.04260638, -1.8375388 ,\n",
       "          1.301559  ],\n",
       "        [ 0.4505602 , -0.20008475, -0.8927824 ,  2.7003853 , -1.1340812 ,\n",
       "         -2.3374708 ]], dtype=float32),\n",
       " array([ 1.884285 , -1.6483525, -1.9364004, -1.4228922, -0.187781 ,\n",
       "         0.6112278], dtype=float32)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "biases = model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5685940e+00, -7.5578344e-01,  2.9726129e+00,  2.8926406e-02],\n",
       "       [-6.4602363e-01, -1.3272898e+00, -1.6753883e+00,  8.8879782e-01],\n",
       "       [ 2.8905544e-01,  2.7274203e+00, -4.1011357e-01,  1.4950769e+00],\n",
       "       [-1.3924526e+00,  4.8229340e-01,  1.2612160e+00, -2.0509748e+00],\n",
       "       [-7.5499356e-01, -2.2950272e-01,  1.1744325e+00,  1.8901294e+00],\n",
       "       [ 2.3575439e+00,  8.6360145e-04, -5.5712640e-01, -1.1779923e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3233396, 1.1500345, 1.5411345, 1.7671634], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.52297187, -1.7569    ,  0.43578267, -2.4818363 ,  1.0081764 ,\n",
       "          0.9765191 ],\n",
       "        [-0.50075877,  3.203936  , -3.1619108 , -0.61574787,  1.1032968 ,\n",
       "         -1.5845432 ],\n",
       "        [ 2.610292  , -1.8877181 , -1.6999984 ,  1.4167665 , -1.3344872 ,\n",
       "         -0.4839891 ],\n",
       "        [-2.1381495 , -0.88884467,  2.319683  ,  1.6311033 , -0.59197724,\n",
       "         -1.642379  ]], dtype=float32),\n",
       " array([-2.2643292 ,  0.6654069 ,  0.14345963, -1.4512864 , -3.1625571 ,\n",
       "         2.3429961 ], dtype=float32)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6)                 30        \n",
      "=================================================================\n",
      "Total params: 58\n",
      "Trainable params: 58\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "#取某一层的输出为输出新建为model，采用函数模型\n",
    "dense1_layer_model = Model(inputs=model.input,\n",
    "                                     outputs=model.get_layer('dense_22').output)\n",
    "\n",
    "#以这个model的预测值作为输出\n",
    "dense1_output = dense1_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0714811, 3.6121516, 1.8537053, 4.547574 ], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2_layer_model = Model(inputs=model.input,\n",
    "                                     outputs=model.get_layer('dense_23').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2_output = dense2_layer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6759535e-02, 9.7293854e-01, 2.3421645e-04, 9.8701334e-01,\n",
       "       2.7492642e-04, 8.9016557e-03], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense2_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Obviously, for this model, softmax function cannot get a good result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 0.6292 - acc: 0.6694\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.4786 - acc: 0.7031\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.3667 - acc: 0.7187\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.3080 - acc: 0.7211\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2794 - acc: 0.7162\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2631 - acc: 0.6989\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2531 - acc: 0.7017\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2466 - acc: 0.6973\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2422 - acc: 0.7071\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2392 - acc: 0.7162\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.2371 - acc: 0.7238\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.2356 - acc: 0.7297\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2345 - acc: 0.7327\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2338 - acc: 0.7366\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2332 - acc: 0.7377\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2327 - acc: 0.7437\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2324 - acc: 0.7451\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2321 - acc: 0.7439\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.2319 - acc: 0.7490\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2318 - acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb36730710>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "# change loss from possion to binary it works well :P\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.2311 - acc: 0.8297\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8327\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8025\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.2311 - acc: 0.7930\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.2311 - acc: 0.8062\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8316\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8302\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8235\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8320\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8149\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2311 - acc: 0.8176\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8076\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8322\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8056\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8033\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8254\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8316\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2311 - acc: 0.8222\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.2311 - acc: 0.8311\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.2311 - acc: 0.8323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb361ab518>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "loops =10000\n",
    "size =26\n",
    "sample_size =2\n",
    "temp = ''.join(random.choices(string.ascii_uppercase[0:size], k = loops*sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 s, sys: 8.99 s, total: 33.4 s\n",
      "Wall time: 7.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from myfun import misslabeled_data_genelization\n",
    "misslabeled_data_genelization(loops=10000,prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 20]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-115-3a148efc50c6>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-115-3a148efc50c6>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    model.add(Conv2D(64, kernel_size=3, activation=’relu’, input_shape=(28,28,1)))\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation=’relu’, input_shape=(2,56,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation=’relu’))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=’softmax’))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
